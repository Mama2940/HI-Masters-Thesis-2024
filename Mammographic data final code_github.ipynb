{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1f42e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mammographic mass dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3cb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages and Libraries\n",
    "# 1. Data Analysis and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 3: ML Model Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca87152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset \n",
    "mammographic_data = pd.read_csv('mammographic mass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396d55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bafde45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total instances 830\n",
      "Total number of features are  6\n",
      "Data Types: BI-RADS     int64\n",
      "Age         int64\n",
      "Shape       int64\n",
      "Margin      int64\n",
      "Density     int64\n",
      "Severity    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Features, instances and data types\n",
    "print(\"Total instances\",mammographic_data.shape[0])\n",
    "print(\"Total number of features are \", mammographic_data.shape[1])\n",
    "print(\"Data Types:\", mammographic_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0134ec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    427\n",
      "1    403\n",
      "Name: Severity, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking Class labels and distribution\n",
    "class_counts = mammographic_data['Severity'].value_counts()\n",
    "print(class_counts)\n",
    "class_counts.plot(kind='bar', color=['green','pink'], edgecolor=\"black\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.title(\"Benign (0) and Malignant(1) Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d9add3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BI-RADS     0\n",
      "Age         0\n",
      "Shape       0\n",
      "Margin      0\n",
      "Density     0\n",
      "Severity    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking missing values\n",
    "missing_data= mammographic_data.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ab5dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking correlation between faetures:\n",
    "correlation_matrix = mammographic_data.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of All Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c072c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_threshold = 0.8\n",
    "correlated_features = {}\n",
    "for feature1 in correlation_matrix.columns:\n",
    "    for feature2 in correlation_matrix.columns:\n",
    "        if feature1 != feature2:\n",
    "            correlation_value = correlation_matrix.loc[feature1, feature2]\n",
    "            if abs(correlation_value) > correlation_threshold:\n",
    "                if feature1 not in correlated_features:\n",
    "                    correlated_features[feature1] = [feature2]\n",
    "                else:\n",
    "                    correlated_features[feature1].append(feature2)\n",
    "for feature, correlated_list in correlated_features.items():\n",
    "    print(f\"{feature} is correlated with: {', '.join(correlated_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40af9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# 1.NO Class label mapping required\n",
    "# 2. No missing values\n",
    "# 3. Feature selection- No correlated features                                  \n",
    "# 4. No data imbalance handling required as dataset is balanced\n",
    "# 5. Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f9f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean= mammographic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb39aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasplit 80:20\n",
    "X =clean.drop(['Severity'], axis=1)\n",
    "y =  clean['Severity']\n",
    "random_state=123\n",
    "feature_names = X.columns                      \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add45b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data\n",
    "sc = MinMaxScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c5d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml Models Hyperparameter optimization, training ,testing, performance and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e553ac03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters: {'splitter': 'best', 'min_samples_split': 40, 'min_samples_leaf': 4, 'max_depth': 5, 'criterion': 'gini'}\n",
      "Best f1 score for DT during training:  0.8248580687257409\n"
     ]
    }
   ],
   "source": [
    "# 1.DECISION TREE\n",
    "\n",
    "# hyperpaarmeter optimization using randomized search\n",
    "dt_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 2, 5, 10, 20], \n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 30, 40],\n",
    "     'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "search_dt = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=random_state),\n",
    "    param_distributions=dt_params,  \n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# DT training\n",
    "\n",
    "search_dt.fit(X_train_scaled, y_train)\n",
    "best_params = search_dt.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best f1 score for DT during training: \", search_dt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88aae795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for dt:\n",
      "Accuracy: 0.8192771084337349\n",
      "Precision: 0.7931034482758621\n",
      "Recall: 0.8518518518518519\n",
      "F1 Score: 0.8214285714285715\n",
      "F2 Score: 0.8394160583941606\n",
      "AUC: 0.8971677559912854\n"
     ]
    }
   ],
   "source": [
    "# DT Testing\n",
    "best_dt_model = search_dt.best_estimator_\n",
    "y_pred_dt = best_dt_model.predict(X_test_scaled)\n",
    "\n",
    "# DT performance evaluation\n",
    "print(\"\\nEvaluation Metrics for dt:\")\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred_dt)\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test, y_pred_dt)\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test, y_pred_dt)\n",
    "print(\"F1 Score:\", f1)\n",
    "f_beta = fbeta_score(y_test, y_pred_dt, beta=2)\n",
    "print(\"F2 Score:\", f_beta)\n",
    "auc = roc_auc_score(y_test,best_dt_model.predict_proba(X_test_scaled)[:, 1])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8694fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dictionary: {'BI-RADS': 4, 'Age': 47, 'Shape': 2, 'Margin': 4, 'Density': 2}\n"
     ]
    }
   ],
   "source": [
    "# Test set instance 1 would be used for local interpretability\n",
    "instance = X_test.iloc[0]\n",
    "feature_dict = instance.to_dict()\n",
    "print(\"Feature Dictionary:\", feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64d96456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as standardized data was used for model training and testing, we need to define scaled data instance for explaianbility as well\n",
    "instance_to_explain = X_test_scaled[0, :].reshape(1, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cae06c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Model prediction and feature relevance based on decision path - Interpretability\n",
    "prediction = best_dt_model.predict(instance_to_explain)[0]\n",
    "print(f\"Model Prediction: {prediction}\")\n",
    "\n",
    "feature_relevance = OrderedDict({feature: 0 for feature in X_test.columns.tolist()})\n",
    "decision_path = best_dt_model.decision_path(instance_to_explain).toarray()\n",
    "nodes_in_path = np.where(decision_path[0] == 1)[0]\n",
    "for node in nodes_in_path:\n",
    "    feature_index = best_dt_model.tree_.feature[node]\n",
    "    if feature_index != -1 and feature_index < len(X_test.columns):\n",
    "        feature_name = X_test.columns[feature_index]\n",
    "        feature_relevance[feature_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "333cfb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualising feature relevance by DT in descending order\n",
    "sorted_feature_relevance = dict(sorted(feature_relevance.items(), key=lambda item: item[1], reverse=True))\n",
    "feature_names = list(sorted_feature_relevance.keys())\n",
    "feature_values = list(sorted_feature_relevance.values())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, feature_values, color='lightblue')\n",
    "plt.xlabel(\"Feature appearence Count\", fontsize=18)\n",
    "plt.title(\"Ranked Feature Relevance by DT\", fontsize=20)\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a10f6ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Parameters for Random Forest: {'n_estimators': 25, 'min_samples_split': 30, 'min_samples_leaf': 2, 'max_depth': None, 'criterion': 'entropy'}\n",
      "Best f1 score for Rf during training:  0.8464912280701753\n"
     ]
    }
   ],
   "source": [
    "# 2.RANDOM FOREST\n",
    "\n",
    "# Hyperparameters optimization\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 15, 20, 25, 30, 50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20, 30, 40],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(\n",
    "     RandomForestClassifier(random_state=random_state),\n",
    "     param_distributions=param_dist,\n",
    "     cv=5,\n",
    "     verbose=1,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# RF Training\n",
    "search_rf.fit(X_train_scaled, y_train)\n",
    "best_params_rf = search_rf.best_params_\n",
    "print(\"Best Parameters for Random Forest:\", best_params_rf)\n",
    "print(\"Best f1 score for Rf during training: \", search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d83c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for Random Forest:\n",
      "Accuracy: 0.8313253012048193\n",
      "Precision: 0.8117647058823529\n",
      "Recall: 0.8518518518518519\n",
      "F1 Score: 0.8313253012048193\n",
      "F2 Score: 0.8435207823960879\n",
      "AUC: 0.8900508351488743\n"
     ]
    }
   ],
   "source": [
    "# RF testing\n",
    "best_rf_model =search_rf.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# RF Performance Evaluation\n",
    "print(\"\\nEvaluation Metrics for Random Forest:\")\n",
    "accuracy= accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred_rf)\n",
    "print(\"Precision:\", precision)\n",
    "recall= recall_score(y_test, y_pred_rf)\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test, y_pred_rf)\n",
    "print(\"F1 Score:\", f1)\n",
    "f_beta = fbeta_score(y_test, y_pred_rf, beta=2)\n",
    "print(\"F2 Score:\", f_beta)\n",
    "auc= roc_auc_score(y_test, best_rf_model.predict_proba(X_test_scaled)[:, 1])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd614c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "#Model prediction and local feature importance- Interpretability\n",
    "prediction = best_rf_model.predict(instance_to_explain)[0]\n",
    "print(f\"Model Prediction: {prediction}\")\n",
    "rf_feature_importances = best_rf_model.feature_importances_\n",
    "sorted_indices = np.argsort(rf_feature_importances)[::-1]\n",
    "sorted_features = [feature_names[idx] for idx in sorted_indices]\n",
    "sorted_importances = [rf_feature_importances[idx] for idx in sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8123851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising feature relevance by RF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_importances, color='yellow')\n",
    "plt.gca().tick_params( labelsize=18)\n",
    "plt.xlabel('Feature Importance', fontsize=18 )\n",
    "plt.title('Ranked feature relevance for RF', fontsize=20)\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4764ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "epoch 0  | loss: 0.57311 | val_0_auc: 0.84154 |  0:00:01s\n",
      "epoch 1  | loss: 0.43672 | val_0_auc: 0.82266 |  0:00:02s\n",
      "epoch 2  | loss: 0.40019 | val_0_auc: 0.84401 |  0:00:03s\n",
      "epoch 3  | loss: 0.41964 | val_0_auc: 0.87553 |  0:00:04s\n",
      "epoch 4  | loss: 0.40263 | val_0_auc: 0.86115 |  0:00:06s\n",
      "epoch 5  | loss: 0.39989 | val_0_auc: 0.85795 |  0:00:07s\n",
      "epoch 6  | loss: 0.38713 | val_0_auc: 0.86565 |  0:00:08s\n",
      "epoch 7  | loss: 0.3823  | val_0_auc: 0.86783 |  0:00:09s\n",
      "epoch 8  | loss: 0.37344 | val_0_auc: 0.86797 |  0:00:10s\n",
      "epoch 9  | loss: 0.37272 | val_0_auc: 0.86362 |  0:00:12s\n",
      "epoch 10 | loss: 0.39863 | val_0_auc: 0.85592 |  0:00:14s\n",
      "epoch 11 | loss: 0.36131 | val_0_auc: 0.8533  |  0:00:16s\n",
      "epoch 12 | loss: 0.40392 | val_0_auc: 0.86986 |  0:00:18s\n",
      "epoch 13 | loss: 0.36257 | val_0_auc: 0.87219 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.87553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56514 | val_0_auc: 0.8093  |  0:00:01s\n",
      "epoch 1  | loss: 0.44014 | val_0_auc: 0.85723 |  0:00:03s\n",
      "epoch 2  | loss: 0.41745 | val_0_auc: 0.73725 |  0:00:05s\n",
      "epoch 3  | loss: 0.4044  | val_0_auc: 0.85534 |  0:00:07s\n",
      "epoch 4  | loss: 0.38897 | val_0_auc: 0.84401 |  0:00:09s\n",
      "epoch 5  | loss: 0.39833 | val_0_auc: 0.85243 |  0:00:11s\n",
      "epoch 6  | loss: 0.3844  | val_0_auc: 0.86478 |  0:00:13s\n",
      "epoch 7  | loss: 0.40107 | val_0_auc: 0.84096 |  0:00:15s\n",
      "epoch 8  | loss: 0.38068 | val_0_auc: 0.84023 |  0:00:16s\n",
      "epoch 9  | loss: 0.37899 | val_0_auc: 0.85258 |  0:00:18s\n",
      "epoch 10 | loss: 0.39851 | val_0_auc: 0.84401 |  0:00:20s\n",
      "epoch 11 | loss: 0.38663 | val_0_auc: 0.81206 |  0:00:22s\n",
      "epoch 12 | loss: 0.39516 | val_0_auc: 0.85113 |  0:00:23s\n",
      "epoch 13 | loss: 0.38582 | val_0_auc: 0.86812 |  0:00:25s\n",
      "epoch 14 | loss: 0.39491 | val_0_auc: 0.87306 |  0:00:27s\n",
      "epoch 15 | loss: 0.39695 | val_0_auc: 0.85229 |  0:00:29s\n",
      "epoch 16 | loss: 0.38811 | val_0_auc: 0.87451 |  0:00:31s\n",
      "epoch 17 | loss: 0.37207 | val_0_auc: 0.86681 |  0:00:34s\n",
      "epoch 18 | loss: 0.36408 | val_0_auc: 0.86725 |  0:00:37s\n",
      "epoch 19 | loss: 0.37342 | val_0_auc: 0.86797 |  0:00:39s\n",
      "epoch 20 | loss: 0.38311 | val_0_auc: 0.85069 |  0:00:42s\n",
      "epoch 21 | loss: 0.40234 | val_0_auc: 0.85723 |  0:00:44s\n",
      "epoch 22 | loss: 0.37105 | val_0_auc: 0.85606 |  0:00:46s\n",
      "epoch 23 | loss: 0.38464 | val_0_auc: 0.85977 |  0:00:48s\n",
      "epoch 24 | loss: 0.39176 | val_0_auc: 0.87858 |  0:00:50s\n",
      "epoch 25 | loss: 0.36841 | val_0_auc: 0.88642 |  0:00:52s\n",
      "epoch 26 | loss: 0.39078 | val_0_auc: 0.86957 |  0:00:54s\n",
      "epoch 27 | loss: 0.37892 | val_0_auc: 0.86478 |  0:00:56s\n",
      "epoch 28 | loss: 0.37343 | val_0_auc: 0.88627 |  0:00:58s\n",
      "epoch 29 | loss: 0.37405 | val_0_auc: 0.87858 |  0:01:00s\n",
      "epoch 30 | loss: 0.39127 | val_0_auc: 0.87683 |  0:01:01s\n",
      "epoch 31 | loss: 0.37552 | val_0_auc: 0.88076 |  0:01:03s\n",
      "epoch 32 | loss: 0.39469 | val_0_auc: 0.87988 |  0:01:04s\n",
      "epoch 33 | loss: 0.38611 | val_0_auc: 0.86855 |  0:01:06s\n",
      "epoch 34 | loss: 0.38037 | val_0_auc: 0.87712 |  0:01:08s\n",
      "epoch 35 | loss: 0.39429 | val_0_auc: 0.88119 |  0:01:09s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.88642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62152 | val_0_auc: 0.7557  |  0:00:01s\n",
      "epoch 1  | loss: 0.43827 | val_0_auc: 0.65599 |  0:00:03s\n",
      "epoch 2  | loss: 0.4182  | val_0_auc: 0.81133 |  0:00:05s\n",
      "epoch 3  | loss: 0.42518 | val_0_auc: 0.82934 |  0:00:06s\n",
      "epoch 4  | loss: 0.39946 | val_0_auc: 0.85084 |  0:00:08s\n",
      "epoch 5  | loss: 0.40365 | val_0_auc: 0.81786 |  0:00:10s\n",
      "epoch 6  | loss: 0.42206 | val_0_auc: 0.79346 |  0:00:11s\n",
      "epoch 7  | loss: 0.41264 | val_0_auc: 0.81394 |  0:00:13s\n",
      "epoch 8  | loss: 0.39974 | val_0_auc: 0.8215  |  0:00:15s\n",
      "epoch 9  | loss: 0.39407 | val_0_auc: 0.84444 |  0:00:16s\n",
      "epoch 10 | loss: 0.37626 | val_0_auc: 0.85054 |  0:00:18s\n",
      "epoch 11 | loss: 0.38355 | val_0_auc: 0.81394 |  0:00:20s\n",
      "epoch 12 | loss: 0.38789 | val_0_auc: 0.86449 |  0:00:22s\n",
      "epoch 13 | loss: 0.40155 | val_0_auc: 0.80566 |  0:00:23s\n",
      "epoch 14 | loss: 0.39664 | val_0_auc: 0.84343 |  0:00:24s\n",
      "epoch 15 | loss: 0.37712 | val_0_auc: 0.81612 |  0:00:25s\n",
      "epoch 16 | loss: 0.41019 | val_0_auc: 0.83355 |  0:00:27s\n",
      "epoch 17 | loss: 0.40597 | val_0_auc: 0.83406 |  0:00:28s\n",
      "epoch 18 | loss: 0.40469 | val_0_auc: 0.85113 |  0:00:29s\n",
      "epoch 19 | loss: 0.38154 | val_0_auc: 0.8549  |  0:00:30s\n",
      "epoch 20 | loss: 0.3722  | val_0_auc: 0.81402 |  0:00:32s\n",
      "epoch 21 | loss: 0.40529 | val_0_auc: 0.86296 |  0:00:33s\n",
      "epoch 22 | loss: 0.38997 | val_0_auc: 0.87669 |  0:00:34s\n",
      "epoch 23 | loss: 0.3881  | val_0_auc: 0.85984 |  0:00:35s\n",
      "epoch 24 | loss: 0.3929  | val_0_auc: 0.87044 |  0:00:37s\n",
      "epoch 25 | loss: 0.40304 | val_0_auc: 0.87298 |  0:00:38s\n",
      "epoch 26 | loss: 0.38294 | val_0_auc: 0.8809  |  0:00:39s\n",
      "epoch 27 | loss: 0.40174 | val_0_auc: 0.89049 |  0:00:41s\n",
      "epoch 28 | loss: 0.38009 | val_0_auc: 0.88555 |  0:00:42s\n",
      "epoch 29 | loss: 0.37508 | val_0_auc: 0.88308 |  0:00:43s\n",
      "epoch 30 | loss: 0.39523 | val_0_auc: 0.89412 |  0:00:45s\n",
      "epoch 31 | loss: 0.39577 | val_0_auc: 0.88758 |  0:00:46s\n",
      "epoch 32 | loss: 0.42142 | val_0_auc: 0.87974 |  0:00:47s\n",
      "epoch 33 | loss: 0.40824 | val_0_auc: 0.89586 |  0:00:49s\n",
      "epoch 34 | loss: 0.38681 | val_0_auc: 0.89165 |  0:00:50s\n",
      "epoch 35 | loss: 0.39819 | val_0_auc: 0.87872 |  0:00:51s\n",
      "epoch 36 | loss: 0.38127 | val_0_auc: 0.87422 |  0:00:53s\n",
      "epoch 37 | loss: 0.3768  | val_0_auc: 0.88526 |  0:00:54s\n",
      "epoch 38 | loss: 0.37488 | val_0_auc: 0.8716  |  0:00:55s\n",
      "epoch 39 | loss: 0.37393 | val_0_auc: 0.87204 |  0:00:57s\n",
      "epoch 40 | loss: 0.38278 | val_0_auc: 0.87102 |  0:00:58s\n",
      "epoch 41 | loss: 0.41126 | val_0_auc: 0.87422 |  0:00:59s\n",
      "epoch 42 | loss: 0.38098 | val_0_auc: 0.87596 |  0:01:01s\n",
      "epoch 43 | loss: 0.37879 | val_0_auc: 0.89368 |  0:01:02s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.89586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53574 | val_0_auc: 0.85229 |  0:00:01s\n",
      "epoch 1  | loss: 0.45564 | val_0_auc: 0.77081 |  0:00:02s\n",
      "epoch 2  | loss: 0.40529 | val_0_auc: 0.80871 |  0:00:04s\n",
      "epoch 3  | loss: 0.42729 | val_0_auc: 0.84415 |  0:00:05s\n",
      "epoch 4  | loss: 0.39361 | val_0_auc: 0.86057 |  0:00:06s\n",
      "epoch 5  | loss: 0.40832 | val_0_auc: 0.83428 |  0:00:08s\n",
      "epoch 6  | loss: 0.39086 | val_0_auc: 0.82861 |  0:00:09s\n",
      "epoch 7  | loss: 0.42341 | val_0_auc: 0.82963 |  0:00:10s\n",
      "epoch 8  | loss: 0.40444 | val_0_auc: 0.81786 |  0:00:12s\n",
      "epoch 9  | loss: 0.41463 | val_0_auc: 0.84532 |  0:00:13s\n",
      "epoch 10 | loss: 0.37649 | val_0_auc: 0.85664 |  0:00:14s\n",
      "epoch 11 | loss: 0.38057 | val_0_auc: 0.84662 |  0:00:16s\n",
      "epoch 12 | loss: 0.39452 | val_0_auc: 0.86391 |  0:00:17s\n",
      "epoch 13 | loss: 0.37363 | val_0_auc: 0.86812 |  0:00:18s\n",
      "epoch 14 | loss: 0.38703 | val_0_auc: 0.8671  |  0:00:20s\n",
      "epoch 15 | loss: 0.38608 | val_0_auc: 0.87407 |  0:00:21s\n",
      "epoch 16 | loss: 0.37682 | val_0_auc: 0.87015 |  0:00:22s\n",
      "epoch 17 | loss: 0.39886 | val_0_auc: 0.87611 |  0:00:23s\n",
      "epoch 18 | loss: 0.38631 | val_0_auc: 0.88032 |  0:00:25s\n",
      "epoch 19 | loss: 0.36724 | val_0_auc: 0.8703  |  0:00:26s\n",
      "epoch 20 | loss: 0.37162 | val_0_auc: 0.87756 |  0:00:27s\n",
      "epoch 21 | loss: 0.3702  | val_0_auc: 0.85621 |  0:00:28s\n",
      "epoch 22 | loss: 0.39301 | val_0_auc: 0.86187 |  0:00:30s\n",
      "epoch 23 | loss: 0.3775  | val_0_auc: 0.861   |  0:00:31s\n",
      "epoch 24 | loss: 0.37074 | val_0_auc: 0.8687  |  0:00:32s\n",
      "epoch 25 | loss: 0.38297 | val_0_auc: 0.88889 |  0:00:34s\n",
      "epoch 26 | loss: 0.37876 | val_0_auc: 0.87146 |  0:00:35s\n",
      "epoch 27 | loss: 0.39168 | val_0_auc: 0.87393 |  0:00:36s\n",
      "epoch 28 | loss: 0.36016 | val_0_auc: 0.88555 |  0:00:37s\n",
      "epoch 29 | loss: 0.358   | val_0_auc: 0.89063 |  0:00:39s\n",
      "epoch 30 | loss: 0.36208 | val_0_auc: 0.89659 |  0:00:40s\n",
      "epoch 31 | loss: 0.37174 | val_0_auc: 0.88976 |  0:00:41s\n",
      "epoch 32 | loss: 0.38269 | val_0_auc: 0.88105 |  0:00:42s\n",
      "epoch 33 | loss: 0.36158 | val_0_auc: 0.88511 |  0:00:44s\n",
      "epoch 34 | loss: 0.37309 | val_0_auc: 0.87378 |  0:00:45s\n",
      "epoch 35 | loss: 0.36923 | val_0_auc: 0.88003 |  0:00:46s\n",
      "epoch 36 | loss: 0.37374 | val_0_auc: 0.89237 |  0:00:48s\n",
      "epoch 37 | loss: 0.37039 | val_0_auc: 0.89383 |  0:00:49s\n",
      "epoch 38 | loss: 0.36271 | val_0_auc: 0.89804 |  0:00:50s\n",
      "epoch 39 | loss: 0.3678  | val_0_auc: 0.90065 |  0:00:52s\n",
      "epoch 40 | loss: 0.36614 | val_0_auc: 0.89455 |  0:00:53s\n",
      "epoch 41 | loss: 0.38599 | val_0_auc: 0.89426 |  0:00:54s\n",
      "epoch 42 | loss: 0.37135 | val_0_auc: 0.89412 |  0:00:56s\n",
      "epoch 43 | loss: 0.37036 | val_0_auc: 0.8931  |  0:00:57s\n",
      "epoch 44 | loss: 0.37132 | val_0_auc: 0.87669 |  0:00:58s\n",
      "epoch 45 | loss: 0.36493 | val_0_auc: 0.88192 |  0:00:59s\n",
      "epoch 46 | loss: 0.37603 | val_0_auc: 0.88337 |  0:01:01s\n",
      "epoch 47 | loss: 0.37228 | val_0_auc: 0.88642 |  0:01:02s\n",
      "epoch 48 | loss: 0.36924 | val_0_auc: 0.88889 |  0:01:03s\n",
      "epoch 49 | loss: 0.37025 | val_0_auc: 0.8971  |  0:01:04s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.90065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5985  | val_0_auc: 0.84996 |  0:00:01s\n",
      "epoch 1  | loss: 0.46487 | val_0_auc: 0.85505 |  0:00:02s\n",
      "epoch 2  | loss: 0.42059 | val_0_auc: 0.86521 |  0:00:03s\n",
      "epoch 3  | loss: 0.47464 | val_0_auc: 0.84532 |  0:00:05s\n",
      "epoch 4  | loss: 0.43902 | val_0_auc: 0.81641 |  0:00:06s\n",
      "epoch 5  | loss: 0.40852 | val_0_auc: 0.82702 |  0:00:07s\n",
      "epoch 6  | loss: 0.40404 | val_0_auc: 0.84212 |  0:00:09s\n",
      "epoch 7  | loss: 0.42437 | val_0_auc: 0.85214 |  0:00:10s\n",
      "epoch 8  | loss: 0.42352 | val_0_auc: 0.85287 |  0:00:11s\n",
      "epoch 9  | loss: 0.4019  | val_0_auc: 0.84691 |  0:00:13s\n",
      "epoch 10 | loss: 0.41689 | val_0_auc: 0.87872 |  0:00:14s\n",
      "epoch 11 | loss: 0.4091  | val_0_auc: 0.85113 |  0:00:15s\n",
      "epoch 12 | loss: 0.38501 | val_0_auc: 0.87306 |  0:00:17s\n",
      "epoch 13 | loss: 0.41146 | val_0_auc: 0.88366 |  0:00:18s\n",
      "epoch 14 | loss: 0.41155 | val_0_auc: 0.87146 |  0:00:19s\n",
      "epoch 15 | loss: 0.41169 | val_0_auc: 0.88264 |  0:00:20s\n",
      "epoch 16 | loss: 0.42408 | val_0_auc: 0.86405 |  0:00:21s\n",
      "epoch 17 | loss: 0.40648 | val_0_auc: 0.8732  |  0:00:23s\n",
      "epoch 18 | loss: 0.42197 | val_0_auc: 0.87887 |  0:00:24s\n",
      "epoch 19 | loss: 0.42527 | val_0_auc: 0.87233 |  0:00:25s\n",
      "epoch 20 | loss: 0.42126 | val_0_auc: 0.87262 |  0:00:27s\n",
      "epoch 21 | loss: 0.38542 | val_0_auc: 0.88729 |  0:00:28s\n",
      "epoch 22 | loss: 0.41652 | val_0_auc: 0.86739 |  0:00:29s\n",
      "epoch 23 | loss: 0.396   | val_0_auc: 0.88715 |  0:00:30s\n",
      "epoch 24 | loss: 0.39188 | val_0_auc: 0.89484 |  0:00:32s\n",
      "epoch 25 | loss: 0.40899 | val_0_auc: 0.88932 |  0:00:33s\n",
      "epoch 26 | loss: 0.40729 | val_0_auc: 0.89746 |  0:00:34s\n",
      "epoch 27 | loss: 0.40118 | val_0_auc: 0.89426 |  0:00:35s\n",
      "epoch 28 | loss: 0.38804 | val_0_auc: 0.89739 |  0:00:37s\n",
      "epoch 29 | loss: 0.39314 | val_0_auc: 0.87872 |  0:00:38s\n",
      "epoch 30 | loss: 0.43196 | val_0_auc: 0.90639 |  0:00:39s\n",
      "epoch 31 | loss: 0.4179  | val_0_auc: 0.88983 |  0:00:40s\n",
      "epoch 32 | loss: 0.4141  | val_0_auc: 0.87988 |  0:00:42s\n",
      "epoch 33 | loss: 0.39781 | val_0_auc: 0.89528 |  0:00:43s\n",
      "epoch 34 | loss: 0.39335 | val_0_auc: 0.89702 |  0:00:44s\n",
      "epoch 35 | loss: 0.40303 | val_0_auc: 0.89419 |  0:00:46s\n",
      "epoch 36 | loss: 0.39585 | val_0_auc: 0.89187 |  0:00:47s\n",
      "epoch 37 | loss: 0.37462 | val_0_auc: 0.90254 |  0:00:48s\n",
      "epoch 38 | loss: 0.41926 | val_0_auc: 0.88903 |  0:00:50s\n",
      "epoch 39 | loss: 0.39515 | val_0_auc: 0.88279 |  0:00:51s\n",
      "epoch 40 | loss: 0.40441 | val_0_auc: 0.878   |  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.90639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61885 | val_0_auc: 0.71423 |  0:00:00s\n",
      "epoch 1  | loss: 0.45942 | val_0_auc: 0.78983 |  0:00:01s\n",
      "epoch 2  | loss: 0.4334  | val_0_auc: 0.87625 |  0:00:02s\n",
      "epoch 3  | loss: 0.40882 | val_0_auc: 0.79753 |  0:00:03s\n",
      "epoch 4  | loss: 0.39567 | val_0_auc: 0.80741 |  0:00:04s\n",
      "epoch 5  | loss: 0.39898 | val_0_auc: 0.83762 |  0:00:05s\n",
      "epoch 6  | loss: 0.42146 | val_0_auc: 0.81249 |  0:00:06s\n",
      "epoch 7  | loss: 0.40185 | val_0_auc: 0.81336 |  0:00:07s\n",
      "epoch 8  | loss: 0.36626 | val_0_auc: 0.83965 |  0:00:08s\n",
      "epoch 9  | loss: 0.37229 | val_0_auc: 0.82237 |  0:00:09s\n",
      "epoch 10 | loss: 0.39771 | val_0_auc: 0.79949 |  0:00:10s\n",
      "epoch 11 | loss: 0.38935 | val_0_auc: 0.82977 |  0:00:11s\n",
      "epoch 12 | loss: 0.38548 | val_0_auc: 0.83689 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.87625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60178 | val_0_auc: 0.79942 |  0:00:00s\n",
      "epoch 1  | loss: 0.44592 | val_0_auc: 0.79695 |  0:00:01s\n",
      "epoch 2  | loss: 0.4535  | val_0_auc: 0.79753 |  0:00:02s\n",
      "epoch 3  | loss: 0.44324 | val_0_auc: 0.70545 |  0:00:03s\n",
      "epoch 4  | loss: 0.42136 | val_0_auc: 0.81917 |  0:00:04s\n",
      "epoch 5  | loss: 0.40848 | val_0_auc: 0.7512  |  0:00:05s\n",
      "epoch 6  | loss: 0.43753 | val_0_auc: 0.76943 |  0:00:06s\n",
      "epoch 7  | loss: 0.40444 | val_0_auc: 0.81757 |  0:00:07s\n",
      "epoch 8  | loss: 0.42432 | val_0_auc: 0.86347 |  0:00:08s\n",
      "epoch 9  | loss: 0.41029 | val_0_auc: 0.86086 |  0:00:09s\n",
      "epoch 10 | loss: 0.40717 | val_0_auc: 0.87349 |  0:00:09s\n",
      "epoch 11 | loss: 0.40837 | val_0_auc: 0.86797 |  0:00:10s\n",
      "epoch 12 | loss: 0.38194 | val_0_auc: 0.87829 |  0:00:11s\n",
      "epoch 13 | loss: 0.38845 | val_0_auc: 0.87393 |  0:00:12s\n",
      "epoch 14 | loss: 0.41278 | val_0_auc: 0.86739 |  0:00:13s\n",
      "epoch 15 | loss: 0.39102 | val_0_auc: 0.8716  |  0:00:14s\n",
      "epoch 16 | loss: 0.40288 | val_0_auc: 0.85069 |  0:00:15s\n",
      "epoch 17 | loss: 0.428   | val_0_auc: 0.86456 |  0:00:16s\n",
      "epoch 18 | loss: 0.38255 | val_0_auc: 0.86333 |  0:00:17s\n",
      "epoch 19 | loss: 0.4063  | val_0_auc: 0.88533 |  0:00:18s\n",
      "epoch 20 | loss: 0.39772 | val_0_auc: 0.87567 |  0:00:19s\n",
      "epoch 21 | loss: 0.41103 | val_0_auc: 0.85861 |  0:00:20s\n",
      "epoch 22 | loss: 0.40323 | val_0_auc: 0.85316 |  0:00:21s\n",
      "epoch 23 | loss: 0.39953 | val_0_auc: 0.8748  |  0:00:22s\n",
      "epoch 24 | loss: 0.402   | val_0_auc: 0.88264 |  0:00:23s\n",
      "epoch 25 | loss: 0.40341 | val_0_auc: 0.87393 |  0:00:24s\n",
      "epoch 26 | loss: 0.41553 | val_0_auc: 0.88264 |  0:00:25s\n",
      "epoch 27 | loss: 0.40078 | val_0_auc: 0.86928 |  0:00:25s\n",
      "epoch 28 | loss: 0.373   | val_0_auc: 0.87611 |  0:00:26s\n",
      "epoch 29 | loss: 0.41664 | val_0_auc: 0.87879 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.88533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62691 | val_0_auc: 0.81816 |  0:00:00s\n",
      "epoch 1  | loss: 0.46758 | val_0_auc: 0.81082 |  0:00:01s\n",
      "epoch 2  | loss: 0.4356  | val_0_auc: 0.83101 |  0:00:02s\n",
      "epoch 3  | loss: 0.46176 | val_0_auc: 0.82012 |  0:00:03s\n",
      "epoch 4  | loss: 0.40471 | val_0_auc: 0.81816 |  0:00:04s\n",
      "epoch 5  | loss: 0.42475 | val_0_auc: 0.7984  |  0:00:04s\n",
      "epoch 6  | loss: 0.43698 | val_0_auc: 0.82564 |  0:00:05s\n",
      "epoch 7  | loss: 0.42621 | val_0_auc: 0.82505 |  0:00:06s\n",
      "epoch 8  | loss: 0.4237  | val_0_auc: 0.81961 |  0:00:07s\n",
      "epoch 9  | loss: 0.40544 | val_0_auc: 0.80203 |  0:00:08s\n",
      "epoch 10 | loss: 0.40095 | val_0_auc: 0.80886 |  0:00:09s\n",
      "epoch 11 | loss: 0.39028 | val_0_auc: 0.79317 |  0:00:09s\n",
      "epoch 12 | loss: 0.3784  | val_0_auc: 0.80661 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.83101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60893 | val_0_auc: 0.76028 |  0:00:00s\n",
      "epoch 1  | loss: 0.49727 | val_0_auc: 0.79383 |  0:00:01s\n",
      "epoch 2  | loss: 0.42193 | val_0_auc: 0.79935 |  0:00:02s\n",
      "epoch 3  | loss: 0.40866 | val_0_auc: 0.83021 |  0:00:03s\n",
      "epoch 4  | loss: 0.40831 | val_0_auc: 0.85418 |  0:00:04s\n",
      "epoch 5  | loss: 0.41774 | val_0_auc: 0.8427  |  0:00:05s\n",
      "epoch 6  | loss: 0.41146 | val_0_auc: 0.8406  |  0:00:05s\n",
      "epoch 7  | loss: 0.41691 | val_0_auc: 0.81743 |  0:00:06s\n",
      "epoch 8  | loss: 0.40134 | val_0_auc: 0.83696 |  0:00:07s\n",
      "epoch 9  | loss: 0.37516 | val_0_auc: 0.85381 |  0:00:08s\n",
      "epoch 10 | loss: 0.40845 | val_0_auc: 0.8658  |  0:00:09s\n",
      "epoch 11 | loss: 0.38981 | val_0_auc: 0.85149 |  0:00:10s\n",
      "epoch 12 | loss: 0.36869 | val_0_auc: 0.84372 |  0:00:10s\n",
      "epoch 13 | loss: 0.40247 | val_0_auc: 0.8772  |  0:00:11s\n",
      "epoch 14 | loss: 0.37265 | val_0_auc: 0.87952 |  0:00:12s\n",
      "epoch 15 | loss: 0.37951 | val_0_auc: 0.89027 |  0:00:13s\n",
      "epoch 16 | loss: 0.38214 | val_0_auc: 0.89063 |  0:00:14s\n",
      "epoch 17 | loss: 0.39509 | val_0_auc: 0.87081 |  0:00:15s\n",
      "epoch 18 | loss: 0.3705  | val_0_auc: 0.88402 |  0:00:16s\n",
      "epoch 19 | loss: 0.37586 | val_0_auc: 0.89499 |  0:00:17s\n",
      "epoch 20 | loss: 0.39736 | val_0_auc: 0.89978 |  0:00:17s\n",
      "epoch 21 | loss: 0.37861 | val_0_auc: 0.88293 |  0:00:18s\n",
      "epoch 22 | loss: 0.36976 | val_0_auc: 0.87633 |  0:00:19s\n",
      "epoch 23 | loss: 0.38966 | val_0_auc: 0.87582 |  0:00:20s\n",
      "epoch 24 | loss: 0.37546 | val_0_auc: 0.88155 |  0:00:21s\n",
      "epoch 25 | loss: 0.36849 | val_0_auc: 0.88598 |  0:00:22s\n",
      "epoch 26 | loss: 0.3737  | val_0_auc: 0.89455 |  0:00:22s\n",
      "epoch 27 | loss: 0.36739 | val_0_auc: 0.89593 |  0:00:23s\n",
      "epoch 28 | loss: 0.35621 | val_0_auc: 0.89194 |  0:00:24s\n",
      "epoch 29 | loss: 0.36819 | val_0_auc: 0.88802 |  0:00:25s\n",
      "epoch 30 | loss: 0.37152 | val_0_auc: 0.87901 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.89978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64078 | val_0_auc: 0.74067 |  0:00:00s\n",
      "epoch 1  | loss: 0.46829 | val_0_auc: 0.84771 |  0:00:01s\n",
      "epoch 2  | loss: 0.4455  | val_0_auc: 0.84016 |  0:00:02s\n",
      "epoch 3  | loss: 0.46222 | val_0_auc: 0.878   |  0:00:03s\n",
      "epoch 4  | loss: 0.42002 | val_0_auc: 0.88642 |  0:00:04s\n",
      "epoch 5  | loss: 0.43783 | val_0_auc: 0.87553 |  0:00:05s\n",
      "epoch 6  | loss: 0.45272 | val_0_auc: 0.86275 |  0:00:05s\n",
      "epoch 7  | loss: 0.43741 | val_0_auc: 0.8716  |  0:00:06s\n",
      "epoch 8  | loss: 0.43385 | val_0_auc: 0.87393 |  0:00:07s\n",
      "epoch 9  | loss: 0.41722 | val_0_auc: 0.88932 |  0:00:08s\n",
      "epoch 10 | loss: 0.41141 | val_0_auc: 0.88017 |  0:00:09s\n",
      "epoch 11 | loss: 0.45089 | val_0_auc: 0.87843 |  0:00:10s\n",
      "epoch 12 | loss: 0.41258 | val_0_auc: 0.87829 |  0:00:10s\n",
      "epoch 13 | loss: 0.41443 | val_0_auc: 0.81845 |  0:00:11s\n",
      "epoch 14 | loss: 0.41005 | val_0_auc: 0.86463 |  0:00:12s\n",
      "epoch 15 | loss: 0.39451 | val_0_auc: 0.86478 |  0:00:13s\n",
      "epoch 16 | loss: 0.39041 | val_0_auc: 0.887   |  0:00:14s\n",
      "epoch 17 | loss: 0.37124 | val_0_auc: 0.9008  |  0:00:15s\n",
      "epoch 18 | loss: 0.40729 | val_0_auc: 0.86093 |  0:00:15s\n",
      "epoch 19 | loss: 0.42624 | val_0_auc: 0.83275 |  0:00:16s\n",
      "epoch 20 | loss: 0.41451 | val_0_auc: 0.887   |  0:00:17s\n",
      "epoch 21 | loss: 0.3933  | val_0_auc: 0.89789 |  0:00:18s\n",
      "epoch 22 | loss: 0.39015 | val_0_auc: 0.88206 |  0:00:19s\n",
      "epoch 23 | loss: 0.40342 | val_0_auc: 0.84096 |  0:00:20s\n",
      "epoch 24 | loss: 0.40019 | val_0_auc: 0.89601 |  0:00:20s\n",
      "epoch 25 | loss: 0.39767 | val_0_auc: 0.89586 |  0:00:21s\n",
      "epoch 26 | loss: 0.40158 | val_0_auc: 0.87836 |  0:00:22s\n",
      "epoch 27 | loss: 0.37815 | val_0_auc: 0.8833  |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60026 | val_0_auc: 0.68221 |  0:00:00s\n",
      "epoch 1  | loss: 0.39978 | val_0_auc: 0.8276  |  0:00:01s\n",
      "epoch 2  | loss: 0.41507 | val_0_auc: 0.81496 |  0:00:02s\n",
      "epoch 3  | loss: 0.41187 | val_0_auc: 0.83065 |  0:00:03s\n",
      "epoch 4  | loss: 0.39369 | val_0_auc: 0.83108 |  0:00:03s\n",
      "epoch 5  | loss: 0.39276 | val_0_auc: 0.83842 |  0:00:04s\n",
      "epoch 6  | loss: 0.40895 | val_0_auc: 0.83936 |  0:00:05s\n",
      "epoch 7  | loss: 0.3815  | val_0_auc: 0.85635 |  0:00:06s\n",
      "epoch 8  | loss: 0.37484 | val_0_auc: 0.82992 |  0:00:06s\n",
      "epoch 9  | loss: 0.37322 | val_0_auc: 0.84749 |  0:00:07s\n",
      "epoch 10 | loss: 0.37609 | val_0_auc: 0.84139 |  0:00:08s\n",
      "epoch 11 | loss: 0.4072  | val_0_auc: 0.82077 |  0:00:09s\n",
      "epoch 12 | loss: 0.37982 | val_0_auc: 0.86086 |  0:00:10s\n",
      "epoch 13 | loss: 0.39139 | val_0_auc: 0.86122 |  0:00:10s\n",
      "epoch 14 | loss: 0.36069 | val_0_auc: 0.86282 |  0:00:11s\n",
      "epoch 15 | loss: 0.3679  | val_0_auc: 0.86449 |  0:00:12s\n",
      "epoch 16 | loss: 0.37307 | val_0_auc: 0.86028 |  0:00:13s\n",
      "epoch 17 | loss: 0.36849 | val_0_auc: 0.85926 |  0:00:13s\n",
      "epoch 18 | loss: 0.38117 | val_0_auc: 0.85374 |  0:00:14s\n",
      "epoch 19 | loss: 0.37778 | val_0_auc: 0.86304 |  0:00:15s\n",
      "epoch 20 | loss: 0.3777  | val_0_auc: 0.86057 |  0:00:16s\n",
      "epoch 21 | loss: 0.3512  | val_0_auc: 0.87698 |  0:00:17s\n",
      "epoch 22 | loss: 0.37191 | val_0_auc: 0.86957 |  0:00:17s\n",
      "epoch 23 | loss: 0.37151 | val_0_auc: 0.86173 |  0:00:18s\n",
      "epoch 24 | loss: 0.36273 | val_0_auc: 0.86492 |  0:00:19s\n",
      "epoch 25 | loss: 0.37509 | val_0_auc: 0.8716  |  0:00:20s\n",
      "epoch 26 | loss: 0.35863 | val_0_auc: 0.86725 |  0:00:21s\n",
      "epoch 27 | loss: 0.35962 | val_0_auc: 0.8581  |  0:00:22s\n",
      "epoch 28 | loss: 0.36091 | val_0_auc: 0.88853 |  0:00:23s\n",
      "epoch 29 | loss: 0.35586 | val_0_auc: 0.88569 |  0:00:24s\n",
      "epoch 30 | loss: 0.36828 | val_0_auc: 0.87284 |  0:00:25s\n",
      "epoch 31 | loss: 0.38363 | val_0_auc: 0.8862  |  0:00:25s\n",
      "epoch 32 | loss: 0.36876 | val_0_auc: 0.87734 |  0:00:26s\n",
      "epoch 33 | loss: 0.36575 | val_0_auc: 0.8809  |  0:00:27s\n",
      "epoch 34 | loss: 0.35927 | val_0_auc: 0.887   |  0:00:28s\n",
      "epoch 35 | loss: 0.36304 | val_0_auc: 0.88482 |  0:00:29s\n",
      "epoch 36 | loss: 0.35254 | val_0_auc: 0.88061 |  0:00:30s\n",
      "epoch 37 | loss: 0.35545 | val_0_auc: 0.87836 |  0:00:31s\n",
      "epoch 38 | loss: 0.3659  | val_0_auc: 0.87734 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.88853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57354 | val_0_auc: 0.81554 |  0:00:00s\n",
      "epoch 1  | loss: 0.458   | val_0_auc: 0.81757 |  0:00:01s\n",
      "epoch 2  | loss: 0.46181 | val_0_auc: 0.84735 |  0:00:02s\n",
      "epoch 3  | loss: 0.41874 | val_0_auc: 0.83747 |  0:00:03s\n",
      "epoch 4  | loss: 0.42138 | val_0_auc: 0.85214 |  0:00:04s\n",
      "epoch 5  | loss: 0.42179 | val_0_auc: 0.84473 |  0:00:05s\n",
      "epoch 6  | loss: 0.418   | val_0_auc: 0.84749 |  0:00:05s\n",
      "epoch 7  | loss: 0.39055 | val_0_auc: 0.84982 |  0:00:06s\n",
      "epoch 8  | loss: 0.39625 | val_0_auc: 0.85025 |  0:00:07s\n",
      "epoch 9  | loss: 0.38198 | val_0_auc: 0.8504  |  0:00:08s\n",
      "epoch 10 | loss: 0.40227 | val_0_auc: 0.84503 |  0:00:09s\n",
      "epoch 11 | loss: 0.40928 | val_0_auc: 0.84735 |  0:00:10s\n",
      "epoch 12 | loss: 0.38362 | val_0_auc: 0.8512  |  0:00:10s\n",
      "epoch 13 | loss: 0.37804 | val_0_auc: 0.85955 |  0:00:11s\n",
      "epoch 14 | loss: 0.36729 | val_0_auc: 0.86565 |  0:00:12s\n",
      "epoch 15 | loss: 0.37914 | val_0_auc: 0.87683 |  0:00:13s\n",
      "epoch 16 | loss: 0.39103 | val_0_auc: 0.87596 |  0:00:14s\n",
      "epoch 17 | loss: 0.39436 | val_0_auc: 0.86376 |  0:00:15s\n",
      "epoch 18 | loss: 0.37302 | val_0_auc: 0.8703  |  0:00:16s\n",
      "epoch 19 | loss: 0.38291 | val_0_auc: 0.87364 |  0:00:16s\n",
      "epoch 20 | loss: 0.37517 | val_0_auc: 0.87175 |  0:00:17s\n",
      "epoch 21 | loss: 0.36516 | val_0_auc: 0.87669 |  0:00:18s\n",
      "epoch 22 | loss: 0.37793 | val_0_auc: 0.87567 |  0:00:19s\n",
      "epoch 23 | loss: 0.37845 | val_0_auc: 0.87814 |  0:00:20s\n",
      "epoch 24 | loss: 0.39138 | val_0_auc: 0.8671  |  0:00:21s\n",
      "epoch 25 | loss: 0.40188 | val_0_auc: 0.88366 |  0:00:22s\n",
      "epoch 26 | loss: 0.36979 | val_0_auc: 0.86463 |  0:00:23s\n",
      "epoch 27 | loss: 0.36473 | val_0_auc: 0.87204 |  0:00:24s\n",
      "epoch 28 | loss: 0.37837 | val_0_auc: 0.85911 |  0:00:25s\n",
      "epoch 29 | loss: 0.37303 | val_0_auc: 0.87451 |  0:00:25s\n",
      "epoch 30 | loss: 0.35841 | val_0_auc: 0.86848 |  0:00:26s\n",
      "epoch 31 | loss: 0.39167 | val_0_auc: 0.85316 |  0:00:27s\n",
      "epoch 32 | loss: 0.38176 | val_0_auc: 0.87821 |  0:00:28s\n",
      "epoch 33 | loss: 0.36043 | val_0_auc: 0.87712 |  0:00:29s\n",
      "epoch 34 | loss: 0.35744 | val_0_auc: 0.8772  |  0:00:30s\n",
      "epoch 35 | loss: 0.38245 | val_0_auc: 0.86943 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.88366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55755 | val_0_auc: 0.835   |  0:00:00s\n",
      "epoch 1  | loss: 0.46118 | val_0_auc: 0.67756 |  0:00:01s\n",
      "epoch 2  | loss: 0.44706 | val_0_auc: 0.79637 |  0:00:02s\n",
      "epoch 3  | loss: 0.41585 | val_0_auc: 0.84009 |  0:00:03s\n",
      "epoch 4  | loss: 0.41805 | val_0_auc: 0.77153 |  0:00:04s\n",
      "epoch 5  | loss: 0.41339 | val_0_auc: 0.77908 |  0:00:05s\n",
      "epoch 6  | loss: 0.4181  | val_0_auc: 0.83675 |  0:00:06s\n",
      "epoch 7  | loss: 0.40017 | val_0_auc: 0.83791 |  0:00:07s\n",
      "epoch 8  | loss: 0.41588 | val_0_auc: 0.85701 |  0:00:07s\n",
      "epoch 9  | loss: 0.40823 | val_0_auc: 0.84924 |  0:00:08s\n",
      "epoch 10 | loss: 0.39775 | val_0_auc: 0.83863 |  0:00:09s\n",
      "epoch 11 | loss: 0.42088 | val_0_auc: 0.83776 |  0:00:10s\n",
      "epoch 12 | loss: 0.40425 | val_0_auc: 0.82019 |  0:00:10s\n",
      "epoch 13 | loss: 0.38714 | val_0_auc: 0.8411  |  0:00:11s\n",
      "epoch 14 | loss: 0.39355 | val_0_auc: 0.84503 |  0:00:12s\n",
      "epoch 15 | loss: 0.40691 | val_0_auc: 0.83094 |  0:00:13s\n",
      "epoch 16 | loss: 0.39223 | val_0_auc: 0.85214 |  0:00:14s\n",
      "epoch 17 | loss: 0.41099 | val_0_auc: 0.852   |  0:00:14s\n",
      "epoch 18 | loss: 0.415   | val_0_auc: 0.88308 |  0:00:15s\n",
      "epoch 19 | loss: 0.40521 | val_0_auc: 0.87625 |  0:00:16s\n",
      "epoch 20 | loss: 0.39939 | val_0_auc: 0.88526 |  0:00:17s\n",
      "epoch 21 | loss: 0.3846  | val_0_auc: 0.88221 |  0:00:17s\n",
      "epoch 22 | loss: 0.40661 | val_0_auc: 0.88642 |  0:00:18s\n",
      "epoch 23 | loss: 0.40255 | val_0_auc: 0.87553 |  0:00:19s\n",
      "epoch 24 | loss: 0.39891 | val_0_auc: 0.85737 |  0:00:20s\n",
      "epoch 25 | loss: 0.38042 | val_0_auc: 0.88932 |  0:00:21s\n",
      "epoch 26 | loss: 0.38548 | val_0_auc: 0.89789 |  0:00:22s\n",
      "epoch 27 | loss: 0.37075 | val_0_auc: 0.89484 |  0:00:22s\n",
      "epoch 28 | loss: 0.38828 | val_0_auc: 0.90138 |  0:00:23s\n",
      "epoch 29 | loss: 0.4022  | val_0_auc: 0.8931  |  0:00:24s\n",
      "epoch 30 | loss: 0.39809 | val_0_auc: 0.86725 |  0:00:25s\n",
      "epoch 31 | loss: 0.38836 | val_0_auc: 0.87255 |  0:00:25s\n",
      "epoch 32 | loss: 0.37377 | val_0_auc: 0.87277 |  0:00:26s\n",
      "epoch 33 | loss: 0.38246 | val_0_auc: 0.8772  |  0:00:27s\n",
      "epoch 34 | loss: 0.39057 | val_0_auc: 0.87095 |  0:00:28s\n",
      "epoch 35 | loss: 0.38965 | val_0_auc: 0.87778 |  0:00:29s\n",
      "epoch 36 | loss: 0.38813 | val_0_auc: 0.87509 |  0:00:29s\n",
      "epoch 37 | loss: 0.37727 | val_0_auc: 0.87778 |  0:00:30s\n",
      "epoch 38 | loss: 0.37737 | val_0_auc: 0.87037 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.90138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.51513 | val_0_auc: 0.77008 |  0:00:00s\n",
      "epoch 1  | loss: 0.45442 | val_0_auc: 0.72186 |  0:00:01s\n",
      "epoch 2  | loss: 0.40768 | val_0_auc: 0.82208 |  0:00:02s\n",
      "epoch 3  | loss: 0.40745 | val_0_auc: 0.82614 |  0:00:03s\n",
      "epoch 4  | loss: 0.40744 | val_0_auc: 0.8411  |  0:00:04s\n",
      "epoch 5  | loss: 0.39616 | val_0_auc: 0.8427  |  0:00:05s\n",
      "epoch 6  | loss: 0.42518 | val_0_auc: 0.86638 |  0:00:06s\n",
      "epoch 7  | loss: 0.39792 | val_0_auc: 0.81481 |  0:00:07s\n",
      "epoch 8  | loss: 0.3847  | val_0_auc: 0.81699 |  0:00:08s\n",
      "epoch 9  | loss: 0.39718 | val_0_auc: 0.8427  |  0:00:09s\n",
      "epoch 10 | loss: 0.4062  | val_0_auc: 0.87335 |  0:00:10s\n",
      "epoch 11 | loss: 0.38206 | val_0_auc: 0.87436 |  0:00:11s\n",
      "epoch 12 | loss: 0.38749 | val_0_auc: 0.87233 |  0:00:12s\n",
      "epoch 13 | loss: 0.3761  | val_0_auc: 0.89194 |  0:00:13s\n",
      "epoch 14 | loss: 0.38265 | val_0_auc: 0.88853 |  0:00:14s\n",
      "epoch 15 | loss: 0.41484 | val_0_auc: 0.89041 |  0:00:15s\n",
      "epoch 16 | loss: 0.38238 | val_0_auc: 0.88831 |  0:00:16s\n",
      "epoch 17 | loss: 0.38484 | val_0_auc: 0.87553 |  0:00:17s\n",
      "epoch 18 | loss: 0.39271 | val_0_auc: 0.87364 |  0:00:18s\n",
      "epoch 19 | loss: 0.38715 | val_0_auc: 0.89339 |  0:00:19s\n",
      "epoch 20 | loss: 0.38391 | val_0_auc: 0.88686 |  0:00:20s\n",
      "epoch 21 | loss: 0.39032 | val_0_auc: 0.88569 |  0:00:21s\n",
      "epoch 22 | loss: 0.38988 | val_0_auc: 0.90603 |  0:00:22s\n",
      "epoch 23 | loss: 0.40085 | val_0_auc: 0.82803 |  0:00:23s\n",
      "epoch 24 | loss: 0.41264 | val_0_auc: 0.83776 |  0:00:24s\n",
      "epoch 25 | loss: 0.39423 | val_0_auc: 0.88272 |  0:00:25s\n",
      "epoch 26 | loss: 0.40221 | val_0_auc: 0.9024  |  0:00:26s\n",
      "epoch 27 | loss: 0.40567 | val_0_auc: 0.89833 |  0:00:27s\n",
      "epoch 28 | loss: 0.39222 | val_0_auc: 0.90036 |  0:00:28s\n",
      "epoch 29 | loss: 0.39163 | val_0_auc: 0.88453 |  0:00:29s\n",
      "epoch 30 | loss: 0.38721 | val_0_auc: 0.89078 |  0:00:30s\n",
      "epoch 31 | loss: 0.38443 | val_0_auc: 0.86492 |  0:00:31s\n",
      "epoch 32 | loss: 0.36862 | val_0_auc: 0.87349 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.90603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5835  | val_0_auc: 0.81845 |  0:00:01s\n",
      "epoch 1  | loss: 0.47461 | val_0_auc: 0.80595 |  0:00:02s\n",
      "epoch 2  | loss: 0.45469 | val_0_auc: 0.87146 |  0:00:03s\n",
      "epoch 3  | loss: 0.45632 | val_0_auc: 0.86783 |  0:00:04s\n",
      "epoch 4  | loss: 0.43423 | val_0_auc: 0.82585 |  0:00:05s\n",
      "epoch 5  | loss: 0.46338 | val_0_auc: 0.82803 |  0:00:06s\n",
      "epoch 6  | loss: 0.44306 | val_0_auc: 0.85054 |  0:00:07s\n",
      "epoch 7  | loss: 0.42656 | val_0_auc: 0.8602  |  0:00:08s\n",
      "epoch 8  | loss: 0.42239 | val_0_auc: 0.82571 |  0:00:09s\n",
      "epoch 9  | loss: 0.40858 | val_0_auc: 0.85418 |  0:00:10s\n",
      "epoch 10 | loss: 0.44737 | val_0_auc: 0.82643 |  0:00:11s\n",
      "epoch 11 | loss: 0.42189 | val_0_auc: 0.84227 |  0:00:12s\n",
      "epoch 12 | loss: 0.41085 | val_0_auc: 0.84183 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.87146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.68998 | val_0_auc: 0.82963 |  0:00:01s\n",
      "epoch 1  | loss: 0.57415 | val_0_auc: 0.86405 |  0:00:04s\n",
      "epoch 2  | loss: 0.46889 | val_0_auc: 0.81002 |  0:00:05s\n",
      "epoch 3  | loss: 0.4188  | val_0_auc: 0.64125 |  0:00:07s\n",
      "epoch 4  | loss: 0.42399 | val_0_auc: 0.84473 |  0:00:09s\n",
      "epoch 5  | loss: 0.40232 | val_0_auc: 0.87422 |  0:00:11s\n",
      "epoch 6  | loss: 0.41118 | val_0_auc: 0.8549  |  0:00:13s\n",
      "epoch 7  | loss: 0.433   | val_0_auc: 0.80276 |  0:00:14s\n",
      "epoch 8  | loss: 0.37379 | val_0_auc: 0.81845 |  0:00:16s\n",
      "epoch 9  | loss: 0.40779 | val_0_auc: 0.82774 |  0:00:18s\n",
      "epoch 10 | loss: 0.39394 | val_0_auc: 0.81017 |  0:00:19s\n",
      "epoch 11 | loss: 0.38625 | val_0_auc: 0.82876 |  0:00:21s\n",
      "epoch 12 | loss: 0.39106 | val_0_auc: 0.84749 |  0:00:22s\n",
      "epoch 13 | loss: 0.38568 | val_0_auc: 0.85185 |  0:00:24s\n",
      "epoch 14 | loss: 0.38826 | val_0_auc: 0.83253 |  0:00:25s\n",
      "epoch 15 | loss: 0.36334 | val_0_auc: 0.86449 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.87422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70975 | val_0_auc: 0.81888 |  0:00:01s\n",
      "epoch 1  | loss: 0.46329 | val_0_auc: 0.84198 |  0:00:03s\n",
      "epoch 2  | loss: 0.52033 | val_0_auc: 0.83253 |  0:00:04s\n",
      "epoch 3  | loss: 0.41996 | val_0_auc: 0.79056 |  0:00:06s\n",
      "epoch 4  | loss: 0.41975 | val_0_auc: 0.86754 |  0:00:08s\n",
      "epoch 5  | loss: 0.42117 | val_0_auc: 0.85142 |  0:00:10s\n",
      "epoch 6  | loss: 0.40967 | val_0_auc: 0.75904 |  0:00:12s\n",
      "epoch 7  | loss: 0.46029 | val_0_auc: 0.83907 |  0:00:14s\n",
      "epoch 8  | loss: 0.38593 | val_0_auc: 0.86594 |  0:00:16s\n",
      "epoch 9  | loss: 0.40102 | val_0_auc: 0.85708 |  0:00:17s\n",
      "epoch 10 | loss: 0.42082 | val_0_auc: 0.86086 |  0:00:19s\n",
      "epoch 11 | loss: 0.41281 | val_0_auc: 0.86594 |  0:00:21s\n",
      "epoch 12 | loss: 0.42027 | val_0_auc: 0.87829 |  0:00:23s\n",
      "epoch 13 | loss: 0.37799 | val_0_auc: 0.878   |  0:00:25s\n",
      "epoch 14 | loss: 0.39093 | val_0_auc: 0.86362 |  0:00:27s\n",
      "epoch 15 | loss: 0.36701 | val_0_auc: 0.87771 |  0:00:29s\n",
      "epoch 16 | loss: 0.40054 | val_0_auc: 0.87248 |  0:00:31s\n",
      "epoch 17 | loss: 0.4197  | val_0_auc: 0.87124 |  0:00:33s\n",
      "epoch 18 | loss: 0.43546 | val_0_auc: 0.85882 |  0:00:35s\n",
      "epoch 19 | loss: 0.38966 | val_0_auc: 0.86216 |  0:00:37s\n",
      "epoch 20 | loss: 0.39028 | val_0_auc: 0.86906 |  0:00:39s\n",
      "epoch 21 | loss: 0.41135 | val_0_auc: 0.86812 |  0:00:41s\n",
      "epoch 22 | loss: 0.4201  | val_0_auc: 0.87502 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.87829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.79787 | val_0_auc: 0.80247 |  0:00:02s\n",
      "epoch 1  | loss: 0.4834  | val_0_auc: 0.84633 |  0:00:04s\n",
      "epoch 2  | loss: 0.48029 | val_0_auc: 0.86362 |  0:00:06s\n",
      "epoch 3  | loss: 0.4231  | val_0_auc: 0.83558 |  0:00:08s\n",
      "epoch 4  | loss: 0.46945 | val_0_auc: 0.85171 |  0:00:10s\n",
      "epoch 5  | loss: 0.42414 | val_0_auc: 0.8533  |  0:00:11s\n",
      "epoch 6  | loss: 0.4486  | val_0_auc: 0.86071 |  0:00:13s\n",
      "epoch 7  | loss: 0.43398 | val_0_auc: 0.85359 |  0:00:15s\n",
      "epoch 8  | loss: 0.37935 | val_0_auc: 0.87843 |  0:00:17s\n",
      "epoch 9  | loss: 0.43089 | val_0_auc: 0.8215  |  0:00:19s\n",
      "epoch 10 | loss: 0.43611 | val_0_auc: 0.826   |  0:00:21s\n",
      "epoch 11 | loss: 0.43381 | val_0_auc: 0.85781 |  0:00:23s\n",
      "epoch 12 | loss: 0.39938 | val_0_auc: 0.82324 |  0:00:25s\n",
      "epoch 13 | loss: 0.40958 | val_0_auc: 0.83471 |  0:00:27s\n",
      "epoch 14 | loss: 0.41417 | val_0_auc: 0.83268 |  0:00:28s\n",
      "epoch 15 | loss: 0.39122 | val_0_auc: 0.85664 |  0:00:30s\n",
      "epoch 16 | loss: 0.37313 | val_0_auc: 0.85418 |  0:00:32s\n",
      "epoch 17 | loss: 0.39575 | val_0_auc: 0.84597 |  0:00:34s\n",
      "epoch 18 | loss: 0.41863 | val_0_auc: 0.84728 |  0:00:36s\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.87843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72359 | val_0_auc: 0.71344 |  0:00:01s\n",
      "epoch 1  | loss: 0.46209 | val_0_auc: 0.75599 |  0:00:03s\n",
      "epoch 2  | loss: 0.43633 | val_0_auc: 0.78591 |  0:00:05s\n",
      "epoch 3  | loss: 0.45535 | val_0_auc: 0.85374 |  0:00:07s\n",
      "epoch 4  | loss: 0.43775 | val_0_auc: 0.81002 |  0:00:09s\n",
      "epoch 5  | loss: 0.42605 | val_0_auc: 0.83253 |  0:00:11s\n",
      "epoch 6  | loss: 0.39809 | val_0_auc: 0.8671  |  0:00:13s\n",
      "epoch 7  | loss: 0.43043 | val_0_auc: 0.85824 |  0:00:15s\n",
      "epoch 8  | loss: 0.39373 | val_0_auc: 0.83137 |  0:00:16s\n",
      "epoch 9  | loss: 0.38815 | val_0_auc: 0.85287 |  0:00:18s\n",
      "epoch 10 | loss: 0.39487 | val_0_auc: 0.87197 |  0:00:20s\n",
      "epoch 11 | loss: 0.41368 | val_0_auc: 0.87836 |  0:00:22s\n",
      "epoch 12 | loss: 0.41647 | val_0_auc: 0.88141 |  0:00:24s\n",
      "epoch 13 | loss: 0.37155 | val_0_auc: 0.88838 |  0:00:26s\n",
      "epoch 14 | loss: 0.40354 | val_0_auc: 0.88824 |  0:00:28s\n",
      "epoch 15 | loss: 0.35347 | val_0_auc: 0.8716  |  0:00:30s\n",
      "epoch 16 | loss: 0.3742  | val_0_auc: 0.87233 |  0:00:32s\n",
      "epoch 17 | loss: 0.39127 | val_0_auc: 0.86885 |  0:00:34s\n",
      "epoch 18 | loss: 0.3753  | val_0_auc: 0.86158 |  0:00:35s\n",
      "epoch 19 | loss: 0.37974 | val_0_auc: 0.87785 |  0:00:37s\n",
      "epoch 20 | loss: 0.37359 | val_0_auc: 0.86311 |  0:00:39s\n",
      "epoch 21 | loss: 0.39324 | val_0_auc: 0.8854  |  0:00:41s\n",
      "epoch 22 | loss: 0.39852 | val_0_auc: 0.89339 |  0:00:43s\n",
      "epoch 23 | loss: 0.38866 | val_0_auc: 0.88163 |  0:00:45s\n",
      "epoch 24 | loss: 0.40103 | val_0_auc: 0.89383 |  0:00:47s\n",
      "epoch 25 | loss: 0.38093 | val_0_auc: 0.88395 |  0:00:48s\n",
      "epoch 26 | loss: 0.36772 | val_0_auc: 0.8841  |  0:00:50s\n",
      "epoch 27 | loss: 0.38003 | val_0_auc: 0.89078 |  0:00:52s\n",
      "epoch 28 | loss: 0.37483 | val_0_auc: 0.8732  |  0:00:54s\n",
      "epoch 29 | loss: 0.39182 | val_0_auc: 0.89426 |  0:00:56s\n",
      "epoch 30 | loss: 0.36343 | val_0_auc: 0.90007 |  0:00:58s\n",
      "epoch 31 | loss: 0.37323 | val_0_auc: 0.89935 |  0:01:00s\n",
      "epoch 32 | loss: 0.3728  | val_0_auc: 0.89455 |  0:01:02s\n",
      "epoch 33 | loss: 0.38599 | val_0_auc: 0.89484 |  0:01:04s\n",
      "epoch 34 | loss: 0.36344 | val_0_auc: 0.89034 |  0:01:06s\n",
      "epoch 35 | loss: 0.38245 | val_0_auc: 0.88773 |  0:01:08s\n",
      "epoch 36 | loss: 0.38876 | val_0_auc: 0.88816 |  0:01:09s\n",
      "epoch 37 | loss: 0.37979 | val_0_auc: 0.88337 |  0:01:11s\n",
      "epoch 38 | loss: 0.37209 | val_0_auc: 0.89746 |  0:01:13s\n",
      "epoch 39 | loss: 0.37651 | val_0_auc: 0.89673 |  0:01:15s\n",
      "epoch 40 | loss: 0.3794  | val_0_auc: 0.90211 |  0:01:17s\n",
      "epoch 41 | loss: 0.36122 | val_0_auc: 0.90123 |  0:01:19s\n",
      "epoch 42 | loss: 0.39327 | val_0_auc: 0.89121 |  0:01:21s\n",
      "epoch 43 | loss: 0.36665 | val_0_auc: 0.88439 |  0:01:23s\n",
      "epoch 44 | loss: 0.35419 | val_0_auc: 0.88773 |  0:01:25s\n",
      "epoch 45 | loss: 0.3752  | val_0_auc: 0.89136 |  0:01:26s\n",
      "epoch 46 | loss: 0.37198 | val_0_auc: 0.88511 |  0:01:28s\n",
      "epoch 47 | loss: 0.37598 | val_0_auc: 0.87843 |  0:01:30s\n",
      "epoch 48 | loss: 0.37131 | val_0_auc: 0.88729 |  0:01:32s\n",
      "epoch 49 | loss: 0.37014 | val_0_auc: 0.88932 |  0:01:34s\n",
      "epoch 50 | loss: 0.37518 | val_0_auc: 0.88017 |  0:01:36s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.90211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.69546 | val_0_auc: 0.54161 |  0:00:01s\n",
      "epoch 1  | loss: 0.58692 | val_0_auc: 0.84575 |  0:00:03s\n",
      "epoch 2  | loss: 0.50745 | val_0_auc: 0.83224 |  0:00:05s\n",
      "epoch 3  | loss: 0.48628 | val_0_auc: 0.83123 |  0:00:07s\n",
      "epoch 4  | loss: 0.5094  | val_0_auc: 0.84677 |  0:00:09s\n",
      "epoch 5  | loss: 0.45961 | val_0_auc: 0.85113 |  0:00:11s\n",
      "epoch 6  | loss: 0.43278 | val_0_auc: 0.85563 |  0:00:13s\n",
      "epoch 7  | loss: 0.45164 | val_0_auc: 0.83573 |  0:00:15s\n",
      "epoch 8  | loss: 0.42564 | val_0_auc: 0.84604 |  0:00:16s\n",
      "epoch 9  | loss: 0.43657 | val_0_auc: 0.86914 |  0:00:18s\n",
      "epoch 10 | loss: 0.43153 | val_0_auc: 0.84285 |  0:00:20s\n",
      "epoch 11 | loss: 0.40832 | val_0_auc: 0.8671  |  0:00:22s\n",
      "epoch 12 | loss: 0.41469 | val_0_auc: 0.86754 |  0:00:24s\n",
      "epoch 13 | loss: 0.39802 | val_0_auc: 0.87538 |  0:00:26s\n",
      "epoch 14 | loss: 0.41607 | val_0_auc: 0.87771 |  0:00:28s\n",
      "epoch 15 | loss: 0.40668 | val_0_auc: 0.84924 |  0:00:30s\n",
      "epoch 16 | loss: 0.4081  | val_0_auc: 0.835   |  0:00:32s\n",
      "epoch 17 | loss: 0.42607 | val_0_auc: 0.85069 |  0:00:34s\n",
      "epoch 18 | loss: 0.42947 | val_0_auc: 0.8825  |  0:00:36s\n",
      "epoch 19 | loss: 0.44333 | val_0_auc: 0.87959 |  0:00:38s\n",
      "epoch 20 | loss: 0.42236 | val_0_auc: 0.89412 |  0:00:40s\n",
      "epoch 21 | loss: 0.39774 | val_0_auc: 0.85969 |  0:00:42s\n",
      "epoch 22 | loss: 0.41294 | val_0_auc: 0.87567 |  0:00:44s\n",
      "epoch 23 | loss: 0.42086 | val_0_auc: 0.87451 |  0:00:46s\n",
      "epoch 24 | loss: 0.41357 | val_0_auc: 0.88119 |  0:00:48s\n",
      "epoch 25 | loss: 0.42116 | val_0_auc: 0.88686 |  0:00:50s\n",
      "epoch 26 | loss: 0.40418 | val_0_auc: 0.86057 |  0:00:52s\n",
      "epoch 27 | loss: 0.41338 | val_0_auc: 0.87415 |  0:00:54s\n",
      "epoch 28 | loss: 0.41133 | val_0_auc: 0.88381 |  0:00:56s\n",
      "epoch 29 | loss: 0.4072  | val_0_auc: 0.87959 |  0:00:58s\n",
      "epoch 30 | loss: 0.4075  | val_0_auc: 0.86783 |  0:01:00s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.89412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55536 | val_0_auc: 0.58555 |  0:00:01s\n",
      "epoch 1  | loss: 0.42516 | val_0_auc: 0.80813 |  0:00:02s\n",
      "epoch 2  | loss: 0.39309 | val_0_auc: 0.78453 |  0:00:03s\n",
      "epoch 3  | loss: 0.37538 | val_0_auc: 0.73958 |  0:00:04s\n",
      "epoch 4  | loss: 0.39564 | val_0_auc: 0.7801  |  0:00:05s\n",
      "epoch 5  | loss: 0.38758 | val_0_auc: 0.76848 |  0:00:06s\n",
      "epoch 6  | loss: 0.39452 | val_0_auc: 0.76674 |  0:00:07s\n",
      "epoch 7  | loss: 0.39    | val_0_auc: 0.77647 |  0:00:08s\n",
      "epoch 8  | loss: 0.3681  | val_0_auc: 0.82048 |  0:00:09s\n",
      "epoch 9  | loss: 0.36212 | val_0_auc: 0.83224 |  0:00:10s\n",
      "epoch 10 | loss: 0.37747 | val_0_auc: 0.8459  |  0:00:12s\n",
      "epoch 11 | loss: 0.36263 | val_0_auc: 0.83094 |  0:00:13s\n",
      "epoch 12 | loss: 0.37199 | val_0_auc: 0.81322 |  0:00:14s\n",
      "epoch 13 | loss: 0.38228 | val_0_auc: 0.84125 |  0:00:15s\n",
      "epoch 14 | loss: 0.38351 | val_0_auc: 0.8321  |  0:00:16s\n",
      "epoch 15 | loss: 0.37959 | val_0_auc: 0.8297  |  0:00:17s\n",
      "epoch 16 | loss: 0.36482 | val_0_auc: 0.81939 |  0:00:18s\n",
      "epoch 17 | loss: 0.36767 | val_0_auc: 0.82012 |  0:00:19s\n",
      "epoch 18 | loss: 0.35695 | val_0_auc: 0.8167  |  0:00:20s\n",
      "epoch 19 | loss: 0.36644 | val_0_auc: 0.84662 |  0:00:21s\n",
      "epoch 20 | loss: 0.37917 | val_0_auc: 0.84495 |  0:00:22s\n",
      "epoch 21 | loss: 0.38469 | val_0_auc: 0.84074 |  0:00:23s\n",
      "epoch 22 | loss: 0.36613 | val_0_auc: 0.8573  |  0:00:24s\n",
      "epoch 23 | loss: 0.37508 | val_0_auc: 0.85933 |  0:00:25s\n",
      "epoch 24 | loss: 0.37274 | val_0_auc: 0.87378 |  0:00:26s\n",
      "epoch 25 | loss: 0.38669 | val_0_auc: 0.87858 |  0:00:28s\n",
      "epoch 26 | loss: 0.35434 | val_0_auc: 0.88911 |  0:00:29s\n",
      "epoch 27 | loss: 0.34667 | val_0_auc: 0.88548 |  0:00:30s\n",
      "epoch 28 | loss: 0.36442 | val_0_auc: 0.88744 |  0:00:31s\n",
      "epoch 29 | loss: 0.36195 | val_0_auc: 0.89383 |  0:00:32s\n",
      "epoch 30 | loss: 0.38105 | val_0_auc: 0.89005 |  0:00:33s\n",
      "epoch 31 | loss: 0.36677 | val_0_auc: 0.8854  |  0:00:34s\n",
      "epoch 32 | loss: 0.36871 | val_0_auc: 0.89448 |  0:00:35s\n",
      "epoch 33 | loss: 0.3626  | val_0_auc: 0.89252 |  0:00:36s\n",
      "epoch 34 | loss: 0.37799 | val_0_auc: 0.89259 |  0:00:37s\n",
      "epoch 35 | loss: 0.36287 | val_0_auc: 0.89455 |  0:00:38s\n",
      "epoch 36 | loss: 0.36341 | val_0_auc: 0.89637 |  0:00:39s\n",
      "epoch 37 | loss: 0.36346 | val_0_auc: 0.89136 |  0:00:40s\n",
      "epoch 38 | loss: 0.38538 | val_0_auc: 0.88112 |  0:00:41s\n",
      "epoch 39 | loss: 0.35861 | val_0_auc: 0.87451 |  0:00:42s\n",
      "epoch 40 | loss: 0.36351 | val_0_auc: 0.87081 |  0:00:43s\n",
      "epoch 41 | loss: 0.36545 | val_0_auc: 0.87444 |  0:00:44s\n",
      "epoch 42 | loss: 0.36514 | val_0_auc: 0.87545 |  0:00:46s\n",
      "epoch 43 | loss: 0.36916 | val_0_auc: 0.88882 |  0:00:47s\n",
      "epoch 44 | loss: 0.35359 | val_0_auc: 0.88402 |  0:00:48s\n",
      "epoch 45 | loss: 0.3553  | val_0_auc: 0.88533 |  0:00:49s\n",
      "epoch 46 | loss: 0.34944 | val_0_auc: 0.88998 |  0:00:50s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.89637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55031 | val_0_auc: 0.76238 |  0:00:01s\n",
      "epoch 1  | loss: 0.44087 | val_0_auc: 0.68446 |  0:00:02s\n",
      "epoch 2  | loss: 0.41565 | val_0_auc: 0.77182 |  0:00:03s\n",
      "epoch 3  | loss: 0.41863 | val_0_auc: 0.71794 |  0:00:04s\n",
      "epoch 4  | loss: 0.40626 | val_0_auc: 0.67858 |  0:00:05s\n",
      "epoch 5  | loss: 0.39901 | val_0_auc: 0.79012 |  0:00:06s\n",
      "epoch 6  | loss: 0.41648 | val_0_auc: 0.79579 |  0:00:07s\n",
      "epoch 7  | loss: 0.40346 | val_0_auc: 0.79593 |  0:00:08s\n",
      "epoch 8  | loss: 0.41333 | val_0_auc: 0.84604 |  0:00:09s\n",
      "epoch 9  | loss: 0.39351 | val_0_auc: 0.83994 |  0:00:10s\n",
      "epoch 10 | loss: 0.39375 | val_0_auc: 0.84662 |  0:00:11s\n",
      "epoch 11 | loss: 0.401   | val_0_auc: 0.85229 |  0:00:12s\n",
      "epoch 12 | loss: 0.37263 | val_0_auc: 0.84183 |  0:00:13s\n",
      "epoch 13 | loss: 0.39061 | val_0_auc: 0.83987 |  0:00:14s\n",
      "epoch 14 | loss: 0.3916  | val_0_auc: 0.82651 |  0:00:15s\n",
      "epoch 15 | loss: 0.38673 | val_0_auc: 0.78562 |  0:00:16s\n",
      "epoch 16 | loss: 0.39009 | val_0_auc: 0.84466 |  0:00:17s\n",
      "epoch 17 | loss: 0.38201 | val_0_auc: 0.83914 |  0:00:18s\n",
      "epoch 18 | loss: 0.37053 | val_0_auc: 0.85679 |  0:00:19s\n",
      "epoch 19 | loss: 0.37003 | val_0_auc: 0.85468 |  0:00:20s\n",
      "epoch 20 | loss: 0.39875 | val_0_auc: 0.84285 |  0:00:21s\n",
      "epoch 21 | loss: 0.37131 | val_0_auc: 0.84619 |  0:00:22s\n",
      "epoch 22 | loss: 0.38794 | val_0_auc: 0.85476 |  0:00:23s\n",
      "epoch 23 | loss: 0.38996 | val_0_auc: 0.86442 |  0:00:24s\n",
      "epoch 24 | loss: 0.37874 | val_0_auc: 0.8419  |  0:00:25s\n",
      "epoch 25 | loss: 0.38567 | val_0_auc: 0.85577 |  0:00:26s\n",
      "epoch 26 | loss: 0.36942 | val_0_auc: 0.86478 |  0:00:27s\n",
      "epoch 27 | loss: 0.37034 | val_0_auc: 0.87625 |  0:00:29s\n",
      "epoch 28 | loss: 0.37667 | val_0_auc: 0.87611 |  0:00:30s\n",
      "epoch 29 | loss: 0.39588 | val_0_auc: 0.8894  |  0:00:31s\n",
      "epoch 30 | loss: 0.37646 | val_0_auc: 0.88998 |  0:00:32s\n",
      "epoch 31 | loss: 0.38098 | val_0_auc: 0.89179 |  0:00:33s\n",
      "epoch 32 | loss: 0.38048 | val_0_auc: 0.89492 |  0:00:34s\n",
      "epoch 33 | loss: 0.37661 | val_0_auc: 0.89506 |  0:00:35s\n",
      "epoch 34 | loss: 0.38983 | val_0_auc: 0.90123 |  0:00:36s\n",
      "epoch 35 | loss: 0.38127 | val_0_auc: 0.90153 |  0:00:37s\n",
      "epoch 36 | loss: 0.36994 | val_0_auc: 0.88686 |  0:00:38s\n",
      "epoch 37 | loss: 0.39658 | val_0_auc: 0.86754 |  0:00:39s\n",
      "epoch 38 | loss: 0.42543 | val_0_auc: 0.87603 |  0:00:40s\n",
      "epoch 39 | loss: 0.37919 | val_0_auc: 0.87044 |  0:00:41s\n",
      "epoch 40 | loss: 0.3855  | val_0_auc: 0.861   |  0:00:42s\n",
      "epoch 41 | loss: 0.39767 | val_0_auc: 0.86376 |  0:00:43s\n",
      "epoch 42 | loss: 0.39327 | val_0_auc: 0.84365 |  0:00:44s\n",
      "epoch 43 | loss: 0.38508 | val_0_auc: 0.85999 |  0:00:45s\n",
      "epoch 44 | loss: 0.37741 | val_0_auc: 0.86282 |  0:00:46s\n",
      "epoch 45 | loss: 0.3805  | val_0_auc: 0.86398 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.90153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54055 | val_0_auc: 0.69288 |  0:00:00s\n",
      "epoch 1  | loss: 0.48153 | val_0_auc: 0.81481 |  0:00:01s\n",
      "epoch 2  | loss: 0.46248 | val_0_auc: 0.75556 |  0:00:02s\n",
      "epoch 3  | loss: 0.47067 | val_0_auc: 0.83137 |  0:00:03s\n",
      "epoch 4  | loss: 0.40568 | val_0_auc: 0.82135 |  0:00:04s\n",
      "epoch 5  | loss: 0.42423 | val_0_auc: 0.83747 |  0:00:05s\n",
      "epoch 6  | loss: 0.41112 | val_0_auc: 0.82295 |  0:00:06s\n",
      "epoch 7  | loss: 0.4431  | val_0_auc: 0.81322 |  0:00:07s\n",
      "epoch 8  | loss: 0.40365 | val_0_auc: 0.8398  |  0:00:08s\n",
      "epoch 9  | loss: 0.39894 | val_0_auc: 0.85229 |  0:00:09s\n",
      "epoch 10 | loss: 0.413   | val_0_auc: 0.84953 |  0:00:10s\n",
      "epoch 11 | loss: 0.40987 | val_0_auc: 0.83631 |  0:00:11s\n",
      "epoch 12 | loss: 0.39132 | val_0_auc: 0.83166 |  0:00:12s\n",
      "epoch 13 | loss: 0.39895 | val_0_auc: 0.84749 |  0:00:13s\n",
      "epoch 14 | loss: 0.43534 | val_0_auc: 0.83631 |  0:00:14s\n",
      "epoch 15 | loss: 0.3893  | val_0_auc: 0.83341 |  0:00:15s\n",
      "epoch 16 | loss: 0.38868 | val_0_auc: 0.85897 |  0:00:16s\n",
      "epoch 17 | loss: 0.39589 | val_0_auc: 0.82977 |  0:00:18s\n",
      "epoch 18 | loss: 0.38387 | val_0_auc: 0.86304 |  0:00:19s\n",
      "epoch 19 | loss: 0.36319 | val_0_auc: 0.8671  |  0:00:20s\n",
      "epoch 20 | loss: 0.37718 | val_0_auc: 0.86826 |  0:00:21s\n",
      "epoch 21 | loss: 0.38437 | val_0_auc: 0.88134 |  0:00:22s\n",
      "epoch 22 | loss: 0.37754 | val_0_auc: 0.87335 |  0:00:23s\n",
      "epoch 23 | loss: 0.39642 | val_0_auc: 0.86725 |  0:00:24s\n",
      "epoch 24 | loss: 0.38996 | val_0_auc: 0.88163 |  0:00:25s\n",
      "epoch 25 | loss: 0.36069 | val_0_auc: 0.88076 |  0:00:26s\n",
      "epoch 26 | loss: 0.38532 | val_0_auc: 0.86275 |  0:00:27s\n",
      "epoch 27 | loss: 0.37306 | val_0_auc: 0.86129 |  0:00:28s\n",
      "epoch 28 | loss: 0.37006 | val_0_auc: 0.87436 |  0:00:29s\n",
      "epoch 29 | loss: 0.3774  | val_0_auc: 0.88148 |  0:00:30s\n",
      "epoch 30 | loss: 0.3794  | val_0_auc: 0.87988 |  0:00:31s\n",
      "epoch 31 | loss: 0.37201 | val_0_auc: 0.88744 |  0:00:32s\n",
      "epoch 32 | loss: 0.36263 | val_0_auc: 0.87567 |  0:00:33s\n",
      "epoch 33 | loss: 0.36336 | val_0_auc: 0.87495 |  0:00:34s\n",
      "epoch 34 | loss: 0.3859  | val_0_auc: 0.88613 |  0:00:35s\n",
      "epoch 35 | loss: 0.37368 | val_0_auc: 0.88511 |  0:00:36s\n",
      "epoch 36 | loss: 0.39638 | val_0_auc: 0.84183 |  0:00:37s\n",
      "epoch 37 | loss: 0.38862 | val_0_auc: 0.86928 |  0:00:38s\n",
      "epoch 38 | loss: 0.37924 | val_0_auc: 0.8793  |  0:00:39s\n",
      "epoch 39 | loss: 0.3654  | val_0_auc: 0.88003 |  0:00:40s\n",
      "epoch 40 | loss: 0.37568 | val_0_auc: 0.87422 |  0:00:41s\n",
      "epoch 41 | loss: 0.38203 | val_0_auc: 0.8732  |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.88744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59068 | val_0_auc: 0.79346 |  0:00:00s\n",
      "epoch 1  | loss: 0.48994 | val_0_auc: 0.62876 |  0:00:02s\n",
      "epoch 2  | loss: 0.46187 | val_0_auc: 0.79361 |  0:00:03s\n",
      "epoch 3  | loss: 0.45016 | val_0_auc: 0.81743 |  0:00:04s\n",
      "epoch 4  | loss: 0.40931 | val_0_auc: 0.84786 |  0:00:05s\n",
      "epoch 5  | loss: 0.40025 | val_0_auc: 0.8549  |  0:00:06s\n",
      "epoch 6  | loss: 0.38365 | val_0_auc: 0.84648 |  0:00:07s\n",
      "epoch 7  | loss: 0.39407 | val_0_auc: 0.85766 |  0:00:08s\n",
      "epoch 8  | loss: 0.3629  | val_0_auc: 0.86797 |  0:00:09s\n",
      "epoch 9  | loss: 0.38926 | val_0_auc: 0.86797 |  0:00:10s\n",
      "epoch 10 | loss: 0.39231 | val_0_auc: 0.83297 |  0:00:11s\n",
      "epoch 11 | loss: 0.39328 | val_0_auc: 0.8642  |  0:00:12s\n",
      "epoch 12 | loss: 0.38389 | val_0_auc: 0.87509 |  0:00:14s\n",
      "epoch 13 | loss: 0.38502 | val_0_auc: 0.8703  |  0:00:15s\n",
      "epoch 14 | loss: 0.37664 | val_0_auc: 0.87262 |  0:00:16s\n",
      "epoch 15 | loss: 0.37874 | val_0_auc: 0.87901 |  0:00:17s\n",
      "epoch 16 | loss: 0.37675 | val_0_auc: 0.8642  |  0:00:18s\n",
      "epoch 17 | loss: 0.38015 | val_0_auc: 0.88947 |  0:00:19s\n",
      "epoch 18 | loss: 0.3908  | val_0_auc: 0.87945 |  0:00:20s\n",
      "epoch 19 | loss: 0.38645 | val_0_auc: 0.85084 |  0:00:21s\n",
      "epoch 20 | loss: 0.38417 | val_0_auc: 0.81104 |  0:00:22s\n",
      "epoch 21 | loss: 0.37039 | val_0_auc: 0.87974 |  0:00:24s\n",
      "epoch 22 | loss: 0.3681  | val_0_auc: 0.88221 |  0:00:25s\n",
      "epoch 23 | loss: 0.41306 | val_0_auc: 0.90327 |  0:00:26s\n",
      "epoch 24 | loss: 0.3835  | val_0_auc: 0.9008  |  0:00:27s\n",
      "epoch 25 | loss: 0.36536 | val_0_auc: 0.88489 |  0:00:28s\n",
      "epoch 26 | loss: 0.37209 | val_0_auc: 0.87785 |  0:00:29s\n",
      "epoch 27 | loss: 0.37008 | val_0_auc: 0.87756 |  0:00:30s\n",
      "epoch 28 | loss: 0.36227 | val_0_auc: 0.87683 |  0:00:31s\n",
      "epoch 29 | loss: 0.36384 | val_0_auc: 0.887   |  0:00:32s\n",
      "epoch 30 | loss: 0.39574 | val_0_auc: 0.89731 |  0:00:34s\n",
      "epoch 31 | loss: 0.37514 | val_0_auc: 0.8894  |  0:00:35s\n",
      "epoch 32 | loss: 0.35997 | val_0_auc: 0.89637 |  0:00:36s\n",
      "epoch 33 | loss: 0.38954 | val_0_auc: 0.89637 |  0:00:37s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.90327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57311 | val_0_auc: 0.74408 |  0:00:01s\n",
      "epoch 1  | loss: 0.45109 | val_0_auc: 0.80305 |  0:00:02s\n",
      "epoch 2  | loss: 0.4236  | val_0_auc: 0.84401 |  0:00:03s\n",
      "epoch 3  | loss: 0.45272 | val_0_auc: 0.8565  |  0:00:04s\n",
      "epoch 4  | loss: 0.44965 | val_0_auc: 0.80537 |  0:00:05s\n",
      "epoch 5  | loss: 0.43695 | val_0_auc: 0.81728 |  0:00:06s\n",
      "epoch 6  | loss: 0.42379 | val_0_auc: 0.85461 |  0:00:07s\n",
      "epoch 7  | loss: 0.4299  | val_0_auc: 0.8533  |  0:00:08s\n",
      "epoch 8  | loss: 0.4026  | val_0_auc: 0.86296 |  0:00:10s\n",
      "epoch 9  | loss: 0.4056  | val_0_auc: 0.85948 |  0:00:11s\n",
      "epoch 10 | loss: 0.39314 | val_0_auc: 0.83914 |  0:00:12s\n",
      "epoch 11 | loss: 0.39558 | val_0_auc: 0.77168 |  0:00:13s\n",
      "epoch 12 | loss: 0.41804 | val_0_auc: 0.86115 |  0:00:14s\n",
      "epoch 13 | loss: 0.40546 | val_0_auc: 0.86928 |  0:00:15s\n",
      "epoch 14 | loss: 0.42247 | val_0_auc: 0.88119 |  0:00:16s\n",
      "epoch 15 | loss: 0.40346 | val_0_auc: 0.85599 |  0:00:17s\n",
      "epoch 16 | loss: 0.39592 | val_0_auc: 0.86863 |  0:00:18s\n",
      "epoch 17 | loss: 0.38485 | val_0_auc: 0.84677 |  0:00:19s\n",
      "epoch 18 | loss: 0.39537 | val_0_auc: 0.87466 |  0:00:20s\n",
      "epoch 19 | loss: 0.39991 | val_0_auc: 0.88003 |  0:00:21s\n",
      "epoch 20 | loss: 0.39501 | val_0_auc: 0.88787 |  0:00:22s\n",
      "epoch 21 | loss: 0.38202 | val_0_auc: 0.88373 |  0:00:23s\n",
      "epoch 22 | loss: 0.37965 | val_0_auc: 0.87967 |  0:00:24s\n",
      "epoch 23 | loss: 0.43404 | val_0_auc: 0.88134 |  0:00:26s\n",
      "epoch 24 | loss: 0.41507 | val_0_auc: 0.85599 |  0:00:27s\n",
      "epoch 25 | loss: 0.38516 | val_0_auc: 0.89332 |  0:00:28s\n",
      "epoch 26 | loss: 0.37975 | val_0_auc: 0.88976 |  0:00:29s\n",
      "epoch 27 | loss: 0.39121 | val_0_auc: 0.88802 |  0:00:30s\n",
      "epoch 28 | loss: 0.3889  | val_0_auc: 0.88758 |  0:00:31s\n",
      "epoch 29 | loss: 0.38357 | val_0_auc: 0.8968  |  0:00:32s\n",
      "epoch 30 | loss: 0.38819 | val_0_auc: 0.87175 |  0:00:33s\n",
      "epoch 31 | loss: 0.38093 | val_0_auc: 0.88969 |  0:00:34s\n",
      "epoch 32 | loss: 0.38847 | val_0_auc: 0.87778 |  0:00:35s\n",
      "epoch 33 | loss: 0.39881 | val_0_auc: 0.88606 |  0:00:36s\n",
      "epoch 34 | loss: 0.38873 | val_0_auc: 0.8894  |  0:00:37s\n",
      "epoch 35 | loss: 0.39587 | val_0_auc: 0.8923  |  0:00:38s\n",
      "epoch 36 | loss: 0.38029 | val_0_auc: 0.89114 |  0:00:39s\n",
      "epoch 37 | loss: 0.38748 | val_0_auc: 0.85817 |  0:00:40s\n",
      "epoch 38 | loss: 0.38888 | val_0_auc: 0.86623 |  0:00:41s\n",
      "epoch 39 | loss: 0.39646 | val_0_auc: 0.87277 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61271 | val_0_auc: 0.77001 |  0:00:01s\n",
      "epoch 1  | loss: 0.50645 | val_0_auc: 0.83515 |  0:00:02s\n",
      "epoch 2  | loss: 0.4232  | val_0_auc: 0.79419 |  0:00:04s\n",
      "epoch 3  | loss: 0.42873 | val_0_auc: 0.74713 |  0:00:05s\n",
      "epoch 4  | loss: 0.41226 | val_0_auc: 0.80261 |  0:00:07s\n",
      "epoch 5  | loss: 0.40554 | val_0_auc: 0.80218 |  0:00:08s\n",
      "epoch 6  | loss: 0.4026  | val_0_auc: 0.80254 |  0:00:10s\n",
      "epoch 7  | loss: 0.40036 | val_0_auc: 0.81794 |  0:00:11s\n",
      "epoch 8  | loss: 0.39106 | val_0_auc: 0.84423 |  0:00:13s\n",
      "epoch 9  | loss: 0.36557 | val_0_auc: 0.78141 |  0:00:14s\n",
      "epoch 10 | loss: 0.371   | val_0_auc: 0.80566 |  0:00:16s\n",
      "epoch 11 | loss: 0.36459 | val_0_auc: 0.81525 |  0:00:17s\n",
      "epoch 12 | loss: 0.41083 | val_0_auc: 0.82121 |  0:00:19s\n",
      "epoch 13 | loss: 0.37685 | val_0_auc: 0.82847 |  0:00:20s\n",
      "epoch 14 | loss: 0.37598 | val_0_auc: 0.85664 |  0:00:21s\n",
      "epoch 15 | loss: 0.37524 | val_0_auc: 0.86514 |  0:00:23s\n",
      "epoch 16 | loss: 0.37842 | val_0_auc: 0.83638 |  0:00:24s\n",
      "epoch 17 | loss: 0.41052 | val_0_auc: 0.84524 |  0:00:26s\n",
      "epoch 18 | loss: 0.402   | val_0_auc: 0.84503 |  0:00:27s\n",
      "epoch 19 | loss: 0.40642 | val_0_auc: 0.8459  |  0:00:28s\n",
      "epoch 20 | loss: 0.37302 | val_0_auc: 0.83907 |  0:00:30s\n",
      "epoch 21 | loss: 0.39678 | val_0_auc: 0.83319 |  0:00:31s\n",
      "epoch 22 | loss: 0.4151  | val_0_auc: 0.84887 |  0:00:32s\n",
      "epoch 23 | loss: 0.3895  | val_0_auc: 0.83958 |  0:00:34s\n",
      "epoch 24 | loss: 0.38928 | val_0_auc: 0.8565  |  0:00:35s\n",
      "epoch 25 | loss: 0.38557 | val_0_auc: 0.87044 |  0:00:36s\n",
      "epoch 26 | loss: 0.38269 | val_0_auc: 0.86914 |  0:00:38s\n",
      "epoch 27 | loss: 0.39206 | val_0_auc: 0.87829 |  0:00:39s\n",
      "epoch 28 | loss: 0.37242 | val_0_auc: 0.87727 |  0:00:41s\n",
      "epoch 29 | loss: 0.37999 | val_0_auc: 0.87088 |  0:00:42s\n",
      "epoch 30 | loss: 0.37454 | val_0_auc: 0.85861 |  0:00:43s\n",
      "epoch 31 | loss: 0.37113 | val_0_auc: 0.85991 |  0:00:44s\n",
      "epoch 32 | loss: 0.36612 | val_0_auc: 0.86471 |  0:00:46s\n",
      "epoch 33 | loss: 0.35761 | val_0_auc: 0.86253 |  0:00:47s\n",
      "epoch 34 | loss: 0.37206 | val_0_auc: 0.86304 |  0:00:48s\n",
      "epoch 35 | loss: 0.39294 | val_0_auc: 0.8756  |  0:00:50s\n",
      "epoch 36 | loss: 0.36253 | val_0_auc: 0.8756  |  0:00:51s\n",
      "epoch 37 | loss: 0.37825 | val_0_auc: 0.87255 |  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.87829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58806 | val_0_auc: 0.72484 |  0:00:01s\n",
      "epoch 1  | loss: 0.42154 | val_0_auc: 0.85781 |  0:00:02s\n",
      "epoch 2  | loss: 0.42098 | val_0_auc: 0.86049 |  0:00:03s\n",
      "epoch 3  | loss: 0.45115 | val_0_auc: 0.86253 |  0:00:04s\n",
      "epoch 4  | loss: 0.38484 | val_0_auc: 0.84038 |  0:00:05s\n",
      "epoch 5  | loss: 0.38925 | val_0_auc: 0.86507 |  0:00:07s\n",
      "epoch 6  | loss: 0.41915 | val_0_auc: 0.86914 |  0:00:08s\n",
      "epoch 7  | loss: 0.39347 | val_0_auc: 0.87712 |  0:00:10s\n",
      "epoch 8  | loss: 0.39824 | val_0_auc: 0.8626  |  0:00:11s\n",
      "epoch 9  | loss: 0.38037 | val_0_auc: 0.86943 |  0:00:13s\n",
      "epoch 10 | loss: 0.40317 | val_0_auc: 0.82977 |  0:00:14s\n",
      "epoch 11 | loss: 0.39563 | val_0_auc: 0.86028 |  0:00:15s\n",
      "epoch 12 | loss: 0.41317 | val_0_auc: 0.86696 |  0:00:17s\n",
      "epoch 13 | loss: 0.40583 | val_0_auc: 0.83951 |  0:00:18s\n",
      "epoch 14 | loss: 0.39318 | val_0_auc: 0.83399 |  0:00:19s\n",
      "epoch 15 | loss: 0.38767 | val_0_auc: 0.87524 |  0:00:21s\n",
      "epoch 16 | loss: 0.38361 | val_0_auc: 0.86921 |  0:00:22s\n",
      "epoch 17 | loss: 0.39279 | val_0_auc: 0.86623 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.87712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.68199 | val_0_auc: 0.79695 |  0:00:01s\n",
      "epoch 1  | loss: 0.4823  | val_0_auc: 0.78555 |  0:00:02s\n",
      "epoch 2  | loss: 0.46925 | val_0_auc: 0.83021 |  0:00:04s\n",
      "epoch 3  | loss: 0.4318  | val_0_auc: 0.78983 |  0:00:05s\n",
      "epoch 4  | loss: 0.44475 | val_0_auc: 0.81147 |  0:00:06s\n",
      "epoch 5  | loss: 0.39811 | val_0_auc: 0.81961 |  0:00:08s\n",
      "epoch 6  | loss: 0.42693 | val_0_auc: 0.81198 |  0:00:09s\n",
      "epoch 7  | loss: 0.39706 | val_0_auc: 0.8093  |  0:00:10s\n",
      "epoch 8  | loss: 0.39704 | val_0_auc: 0.84815 |  0:00:12s\n",
      "epoch 9  | loss: 0.38417 | val_0_auc: 0.82171 |  0:00:13s\n",
      "epoch 10 | loss: 0.38333 | val_0_auc: 0.83755 |  0:00:14s\n",
      "epoch 11 | loss: 0.38817 | val_0_auc: 0.83551 |  0:00:16s\n",
      "epoch 12 | loss: 0.37889 | val_0_auc: 0.83544 |  0:00:17s\n",
      "epoch 13 | loss: 0.40754 | val_0_auc: 0.84306 |  0:00:18s\n",
      "epoch 14 | loss: 0.38722 | val_0_auc: 0.85381 |  0:00:19s\n",
      "epoch 15 | loss: 0.36788 | val_0_auc: 0.84045 |  0:00:21s\n",
      "epoch 16 | loss: 0.37809 | val_0_auc: 0.84677 |  0:00:22s\n",
      "epoch 17 | loss: 0.37676 | val_0_auc: 0.84641 |  0:00:23s\n",
      "epoch 18 | loss: 0.37704 | val_0_auc: 0.83965 |  0:00:24s\n",
      "epoch 19 | loss: 0.40892 | val_0_auc: 0.85839 |  0:00:25s\n",
      "epoch 20 | loss: 0.38967 | val_0_auc: 0.86042 |  0:00:27s\n",
      "epoch 21 | loss: 0.39806 | val_0_auc: 0.87291 |  0:00:28s\n",
      "epoch 22 | loss: 0.40442 | val_0_auc: 0.865   |  0:00:29s\n",
      "epoch 23 | loss: 0.38366 | val_0_auc: 0.87386 |  0:00:30s\n",
      "epoch 24 | loss: 0.36613 | val_0_auc: 0.85991 |  0:00:31s\n",
      "epoch 25 | loss: 0.3878  | val_0_auc: 0.87858 |  0:00:33s\n",
      "epoch 26 | loss: 0.38723 | val_0_auc: 0.89964 |  0:00:34s\n",
      "epoch 27 | loss: 0.39409 | val_0_auc: 0.87407 |  0:00:35s\n",
      "epoch 28 | loss: 0.39978 | val_0_auc: 0.86093 |  0:00:36s\n",
      "epoch 29 | loss: 0.3925  | val_0_auc: 0.87211 |  0:00:37s\n",
      "epoch 30 | loss: 0.3744  | val_0_auc: 0.8772  |  0:00:38s\n",
      "epoch 31 | loss: 0.41886 | val_0_auc: 0.86921 |  0:00:39s\n",
      "epoch 32 | loss: 0.38291 | val_0_auc: 0.86892 |  0:00:40s\n",
      "epoch 33 | loss: 0.38604 | val_0_auc: 0.87807 |  0:00:42s\n",
      "epoch 34 | loss: 0.38316 | val_0_auc: 0.8894  |  0:00:43s\n",
      "epoch 35 | loss: 0.38142 | val_0_auc: 0.88475 |  0:00:44s\n",
      "epoch 36 | loss: 0.38211 | val_0_auc: 0.88344 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5748  | val_0_auc: 0.8305  |  0:00:01s\n",
      "epoch 1  | loss: 0.44565 | val_0_auc: 0.83086 |  0:00:02s\n",
      "epoch 2  | loss: 0.45091 | val_0_auc: 0.81278 |  0:00:04s\n",
      "epoch 3  | loss: 0.44121 | val_0_auc: 0.81786 |  0:00:05s\n",
      "epoch 4  | loss: 0.44854 | val_0_auc: 0.80356 |  0:00:06s\n",
      "epoch 5  | loss: 0.42842 | val_0_auc: 0.80806 |  0:00:08s\n",
      "epoch 6  | loss: 0.40471 | val_0_auc: 0.80741 |  0:00:10s\n",
      "epoch 7  | loss: 0.39452 | val_0_auc: 0.80951 |  0:00:12s\n",
      "epoch 8  | loss: 0.39403 | val_0_auc: 0.80167 |  0:00:14s\n",
      "epoch 9  | loss: 0.39681 | val_0_auc: 0.81518 |  0:00:16s\n",
      "epoch 10 | loss: 0.403   | val_0_auc: 0.80908 |  0:00:18s\n",
      "epoch 11 | loss: 0.40303 | val_0_auc: 0.84517 |  0:00:20s\n",
      "epoch 12 | loss: 0.39139 | val_0_auc: 0.8146  |  0:00:23s\n",
      "epoch 13 | loss: 0.40326 | val_0_auc: 0.83043 |  0:00:25s\n",
      "epoch 14 | loss: 0.39513 | val_0_auc: 0.80668 |  0:00:27s\n",
      "epoch 15 | loss: 0.38244 | val_0_auc: 0.8496  |  0:00:29s\n",
      "epoch 16 | loss: 0.40362 | val_0_auc: 0.85301 |  0:00:31s\n",
      "epoch 17 | loss: 0.39732 | val_0_auc: 0.83261 |  0:00:33s\n",
      "epoch 18 | loss: 0.37669 | val_0_auc: 0.8358  |  0:00:36s\n",
      "epoch 19 | loss: 0.38826 | val_0_auc: 0.85788 |  0:00:38s\n",
      "epoch 20 | loss: 0.39329 | val_0_auc: 0.83566 |  0:00:40s\n",
      "epoch 21 | loss: 0.38795 | val_0_auc: 0.83972 |  0:00:41s\n",
      "epoch 22 | loss: 0.37627 | val_0_auc: 0.84597 |  0:00:42s\n",
      "epoch 23 | loss: 0.3773  | val_0_auc: 0.85991 |  0:00:44s\n",
      "epoch 24 | loss: 0.3816  | val_0_auc: 0.85454 |  0:00:45s\n",
      "epoch 25 | loss: 0.38272 | val_0_auc: 0.84401 |  0:00:46s\n",
      "epoch 26 | loss: 0.3746  | val_0_auc: 0.85236 |  0:00:48s\n",
      "epoch 27 | loss: 0.37877 | val_0_auc: 0.84931 |  0:00:49s\n",
      "epoch 28 | loss: 0.38673 | val_0_auc: 0.87458 |  0:00:51s\n",
      "epoch 29 | loss: 0.38554 | val_0_auc: 0.87335 |  0:00:53s\n",
      "epoch 30 | loss: 0.36246 | val_0_auc: 0.87894 |  0:00:54s\n",
      "epoch 31 | loss: 0.40099 | val_0_auc: 0.87153 |  0:00:56s\n",
      "epoch 32 | loss: 0.36819 | val_0_auc: 0.86848 |  0:00:58s\n",
      "epoch 33 | loss: 0.37984 | val_0_auc: 0.8687  |  0:00:59s\n",
      "epoch 34 | loss: 0.36212 | val_0_auc: 0.87088 |  0:01:01s\n",
      "epoch 35 | loss: 0.36554 | val_0_auc: 0.87248 |  0:01:03s\n",
      "epoch 36 | loss: 0.36964 | val_0_auc: 0.86776 |  0:01:04s\n",
      "epoch 37 | loss: 0.37823 | val_0_auc: 0.8488  |  0:01:06s\n",
      "epoch 38 | loss: 0.38191 | val_0_auc: 0.87495 |  0:01:08s\n",
      "epoch 39 | loss: 0.37168 | val_0_auc: 0.86238 |  0:01:10s\n",
      "epoch 40 | loss: 0.37062 | val_0_auc: 0.84713 |  0:01:12s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.87894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6566  | val_0_auc: 0.81147 |  0:00:01s\n",
      "epoch 1  | loss: 0.48444 | val_0_auc: 0.73094 |  0:00:03s\n",
      "epoch 2  | loss: 0.45089 | val_0_auc: 0.76463 |  0:00:05s\n",
      "epoch 3  | loss: 0.43033 | val_0_auc: 0.79477 |  0:00:07s\n",
      "epoch 4  | loss: 0.44435 | val_0_auc: 0.76122 |  0:00:08s\n",
      "epoch 5  | loss: 0.4496  | val_0_auc: 0.80479 |  0:00:09s\n",
      "epoch 6  | loss: 0.40513 | val_0_auc: 0.84263 |  0:00:11s\n",
      "epoch 7  | loss: 0.42879 | val_0_auc: 0.83072 |  0:00:12s\n",
      "epoch 8  | loss: 0.42874 | val_0_auc: 0.82963 |  0:00:14s\n",
      "epoch 9  | loss: 0.40046 | val_0_auc: 0.83834 |  0:00:15s\n",
      "epoch 10 | loss: 0.39757 | val_0_auc: 0.85541 |  0:00:16s\n",
      "epoch 11 | loss: 0.41353 | val_0_auc: 0.85832 |  0:00:18s\n",
      "epoch 12 | loss: 0.40553 | val_0_auc: 0.86434 |  0:00:19s\n",
      "epoch 13 | loss: 0.40154 | val_0_auc: 0.87698 |  0:00:20s\n",
      "epoch 14 | loss: 0.3997  | val_0_auc: 0.87967 |  0:00:22s\n",
      "epoch 15 | loss: 0.39864 | val_0_auc: 0.88526 |  0:00:23s\n",
      "epoch 16 | loss: 0.41854 | val_0_auc: 0.8626  |  0:00:24s\n",
      "epoch 17 | loss: 0.41295 | val_0_auc: 0.85643 |  0:00:26s\n",
      "epoch 18 | loss: 0.43081 | val_0_auc: 0.85621 |  0:00:27s\n",
      "epoch 19 | loss: 0.39588 | val_0_auc: 0.85621 |  0:00:29s\n",
      "epoch 20 | loss: 0.39062 | val_0_auc: 0.87553 |  0:00:30s\n",
      "epoch 21 | loss: 0.40586 | val_0_auc: 0.86267 |  0:00:32s\n",
      "epoch 22 | loss: 0.39329 | val_0_auc: 0.87988 |  0:00:34s\n",
      "epoch 23 | loss: 0.39308 | val_0_auc: 0.86652 |  0:00:36s\n",
      "epoch 24 | loss: 0.40239 | val_0_auc: 0.86863 |  0:00:38s\n",
      "epoch 25 | loss: 0.39177 | val_0_auc: 0.86318 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.88526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.13323 | val_0_auc: 0.82382 |  0:00:03s\n",
      "epoch 1  | loss: 0.54647 | val_0_auc: 0.79492 |  0:00:06s\n",
      "epoch 2  | loss: 0.57214 | val_0_auc: 0.78882 |  0:00:09s\n",
      "epoch 3  | loss: 0.50802 | val_0_auc: 0.81845 |  0:00:12s\n",
      "epoch 4  | loss: 0.43787 | val_0_auc: 0.82556 |  0:00:16s\n",
      "epoch 5  | loss: 0.40026 | val_0_auc: 0.80305 |  0:00:19s\n",
      "epoch 6  | loss: 0.41949 | val_0_auc: 0.81816 |  0:00:23s\n",
      "epoch 7  | loss: 0.4137  | val_0_auc: 0.83108 |  0:00:26s\n",
      "epoch 8  | loss: 0.45375 | val_0_auc: 0.84619 |  0:00:30s\n",
      "epoch 9  | loss: 0.39768 | val_0_auc: 0.82876 |  0:00:33s\n",
      "epoch 10 | loss: 0.39111 | val_0_auc: 0.84822 |  0:00:36s\n",
      "epoch 11 | loss: 0.41574 | val_0_auc: 0.85447 |  0:00:39s\n",
      "epoch 12 | loss: 0.42952 | val_0_auc: 0.84575 |  0:00:42s\n",
      "epoch 13 | loss: 0.39237 | val_0_auc: 0.84444 |  0:00:45s\n",
      "epoch 14 | loss: 0.40747 | val_0_auc: 0.84633 |  0:00:48s\n",
      "epoch 15 | loss: 0.39506 | val_0_auc: 0.84633 |  0:00:50s\n",
      "epoch 16 | loss: 0.37058 | val_0_auc: 0.8382  |  0:00:53s\n",
      "epoch 17 | loss: 0.38076 | val_0_auc: 0.84532 |  0:00:56s\n",
      "epoch 18 | loss: 0.37464 | val_0_auc: 0.79477 |  0:00:58s\n",
      "epoch 19 | loss: 0.38413 | val_0_auc: 0.86013 |  0:01:01s\n",
      "epoch 20 | loss: 0.40436 | val_0_auc: 0.87131 |  0:01:03s\n",
      "epoch 21 | loss: 0.39008 | val_0_auc: 0.85505 |  0:01:06s\n",
      "epoch 22 | loss: 0.38015 | val_0_auc: 0.86674 |  0:01:09s\n",
      "epoch 23 | loss: 0.39359 | val_0_auc: 0.8764  |  0:01:12s\n",
      "epoch 24 | loss: 0.40574 | val_0_auc: 0.87553 |  0:01:16s\n",
      "epoch 25 | loss: 0.36126 | val_0_auc: 0.87829 |  0:01:19s\n",
      "epoch 26 | loss: 0.38391 | val_0_auc: 0.88838 |  0:01:22s\n",
      "epoch 27 | loss: 0.37398 | val_0_auc: 0.87647 |  0:01:26s\n",
      "epoch 28 | loss: 0.37304 | val_0_auc: 0.89818 |  0:01:29s\n",
      "epoch 29 | loss: 0.36417 | val_0_auc: 0.88577 |  0:01:32s\n",
      "epoch 30 | loss: 0.38182 | val_0_auc: 0.89405 |  0:01:35s\n",
      "epoch 31 | loss: 0.38149 | val_0_auc: 0.88054 |  0:01:38s\n",
      "epoch 32 | loss: 0.39004 | val_0_auc: 0.88598 |  0:01:41s\n",
      "epoch 33 | loss: 0.38013 | val_0_auc: 0.8931  |  0:01:44s\n",
      "epoch 34 | loss: 0.39281 | val_0_auc: 0.8907  |  0:01:47s\n",
      "epoch 35 | loss: 0.38293 | val_0_auc: 0.89085 |  0:01:50s\n",
      "epoch 36 | loss: 0.37305 | val_0_auc: 0.8947  |  0:01:53s\n",
      "epoch 37 | loss: 0.36682 | val_0_auc: 0.8894  |  0:01:55s\n",
      "epoch 38 | loss: 0.37547 | val_0_auc: 0.87792 |  0:01:57s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.89818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.2337  | val_0_auc: 0.71816 |  0:00:02s\n",
      "epoch 1  | loss: 0.74958 | val_0_auc: 0.52999 |  0:00:04s\n",
      "epoch 2  | loss: 0.53487 | val_0_auc: 0.65025 |  0:00:06s\n",
      "epoch 3  | loss: 0.47901 | val_0_auc: 0.80305 |  0:00:09s\n",
      "epoch 4  | loss: 0.46359 | val_0_auc: 0.84633 |  0:00:12s\n",
      "epoch 5  | loss: 0.43392 | val_0_auc: 0.81249 |  0:00:15s\n",
      "epoch 6  | loss: 0.4273  | val_0_auc: 0.76616 |  0:00:18s\n",
      "epoch 7  | loss: 0.4262  | val_0_auc: 0.83907 |  0:00:21s\n",
      "epoch 8  | loss: 0.44806 | val_0_auc: 0.84473 |  0:00:23s\n",
      "epoch 9  | loss: 0.4239  | val_0_auc: 0.80392 |  0:00:26s\n",
      "epoch 10 | loss: 0.43039 | val_0_auc: 0.86347 |  0:00:28s\n",
      "epoch 11 | loss: 0.40674 | val_0_auc: 0.85563 |  0:00:31s\n",
      "epoch 12 | loss: 0.42584 | val_0_auc: 0.85113 |  0:00:34s\n",
      "epoch 13 | loss: 0.45014 | val_0_auc: 0.83704 |  0:00:36s\n",
      "epoch 14 | loss: 0.37993 | val_0_auc: 0.80407 |  0:00:39s\n",
      "epoch 15 | loss: 0.39299 | val_0_auc: 0.81235 |  0:00:42s\n",
      "epoch 16 | loss: 0.43071 | val_0_auc: 0.83529 |  0:00:45s\n",
      "epoch 17 | loss: 0.39975 | val_0_auc: 0.85403 |  0:00:47s\n",
      "epoch 18 | loss: 0.4055  | val_0_auc: 0.85352 |  0:00:50s\n",
      "epoch 19 | loss: 0.42274 | val_0_auc: 0.8658  |  0:00:52s\n",
      "epoch 20 | loss: 0.40118 | val_0_auc: 0.88097 |  0:00:55s\n",
      "epoch 21 | loss: 0.40109 | val_0_auc: 0.86812 |  0:00:58s\n",
      "epoch 22 | loss: 0.39969 | val_0_auc: 0.87393 |  0:01:01s\n",
      "epoch 23 | loss: 0.41126 | val_0_auc: 0.88214 |  0:01:05s\n",
      "epoch 24 | loss: 0.41005 | val_0_auc: 0.8825  |  0:01:08s\n",
      "epoch 25 | loss: 0.37805 | val_0_auc: 0.8931  |  0:01:10s\n",
      "epoch 26 | loss: 0.40451 | val_0_auc: 0.88177 |  0:01:12s\n",
      "epoch 27 | loss: 0.38332 | val_0_auc: 0.88315 |  0:01:13s\n",
      "epoch 28 | loss: 0.36051 | val_0_auc: 0.88511 |  0:01:15s\n",
      "epoch 29 | loss: 0.37226 | val_0_auc: 0.88787 |  0:01:16s\n",
      "epoch 30 | loss: 0.36609 | val_0_auc: 0.89572 |  0:01:17s\n",
      "epoch 31 | loss: 0.3863  | val_0_auc: 0.88962 |  0:01:19s\n",
      "epoch 32 | loss: 0.39756 | val_0_auc: 0.89361 |  0:01:20s\n",
      "epoch 33 | loss: 0.39981 | val_0_auc: 0.89942 |  0:01:22s\n",
      "epoch 34 | loss: 0.39438 | val_0_auc: 0.88279 |  0:01:23s\n",
      "epoch 35 | loss: 0.39736 | val_0_auc: 0.88635 |  0:01:25s\n",
      "epoch 36 | loss: 0.38493 | val_0_auc: 0.8984  |  0:01:26s\n",
      "epoch 37 | loss: 0.37097 | val_0_auc: 0.89492 |  0:01:28s\n",
      "epoch 38 | loss: 0.38137 | val_0_auc: 0.88693 |  0:01:29s\n",
      "epoch 39 | loss: 0.38456 | val_0_auc: 0.88475 |  0:01:30s\n",
      "epoch 40 | loss: 0.35724 | val_0_auc: 0.88548 |  0:01:32s\n",
      "epoch 41 | loss: 0.38243 | val_0_auc: 0.88918 |  0:01:33s\n",
      "epoch 42 | loss: 0.37308 | val_0_auc: 0.90378 |  0:01:35s\n",
      "epoch 43 | loss: 0.37404 | val_0_auc: 0.90356 |  0:01:36s\n",
      "epoch 44 | loss: 0.38308 | val_0_auc: 0.9029  |  0:01:38s\n",
      "epoch 45 | loss: 0.37812 | val_0_auc: 0.8902  |  0:01:39s\n",
      "epoch 46 | loss: 0.37949 | val_0_auc: 0.88511 |  0:01:41s\n",
      "epoch 47 | loss: 0.38304 | val_0_auc: 0.88991 |  0:01:42s\n",
      "epoch 48 | loss: 0.36683 | val_0_auc: 0.87741 |  0:01:44s\n",
      "epoch 49 | loss: 0.38681 | val_0_auc: 0.8886  |  0:01:45s\n",
      "epoch 50 | loss: 0.37257 | val_0_auc: 0.89397 |  0:01:47s\n",
      "epoch 51 | loss: 0.36946 | val_0_auc: 0.90254 |  0:01:48s\n",
      "epoch 52 | loss: 0.3866  | val_0_auc: 0.89826 |  0:01:50s\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.90378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.06735 | val_0_auc: 0.81496 |  0:00:01s\n",
      "epoch 1  | loss: 0.63591 | val_0_auc: 0.75439 |  0:00:03s\n",
      "epoch 2  | loss: 0.49894 | val_0_auc: 0.76834 |  0:00:04s\n",
      "epoch 3  | loss: 0.45295 | val_0_auc: 0.78925 |  0:00:06s\n",
      "epoch 4  | loss: 0.43428 | val_0_auc: 0.77981 |  0:00:07s\n",
      "epoch 5  | loss: 0.45906 | val_0_auc: 0.81394 |  0:00:08s\n",
      "epoch 6  | loss: 0.44333 | val_0_auc: 0.77182 |  0:00:10s\n",
      "epoch 7  | loss: 0.42357 | val_0_auc: 0.80189 |  0:00:12s\n",
      "epoch 8  | loss: 0.44968 | val_0_auc: 0.82121 |  0:00:13s\n",
      "epoch 9  | loss: 0.39678 | val_0_auc: 0.81118 |  0:00:15s\n",
      "epoch 10 | loss: 0.43366 | val_0_auc: 0.81874 |  0:00:16s\n",
      "epoch 11 | loss: 0.39476 | val_0_auc: 0.81481 |  0:00:18s\n",
      "epoch 12 | loss: 0.43183 | val_0_auc: 0.85113 |  0:00:20s\n",
      "epoch 13 | loss: 0.42018 | val_0_auc: 0.83529 |  0:00:22s\n",
      "epoch 14 | loss: 0.41664 | val_0_auc: 0.84938 |  0:00:24s\n",
      "epoch 15 | loss: 0.39184 | val_0_auc: 0.8626  |  0:00:26s\n",
      "epoch 16 | loss: 0.43888 | val_0_auc: 0.84328 |  0:00:27s\n",
      "epoch 17 | loss: 0.394   | val_0_auc: 0.84241 |  0:00:29s\n",
      "epoch 18 | loss: 0.38909 | val_0_auc: 0.84227 |  0:00:31s\n",
      "epoch 19 | loss: 0.39689 | val_0_auc: 0.84561 |  0:00:32s\n",
      "epoch 20 | loss: 0.42077 | val_0_auc: 0.85025 |  0:00:34s\n",
      "epoch 21 | loss: 0.41371 | val_0_auc: 0.86565 |  0:00:36s\n",
      "epoch 22 | loss: 0.4087  | val_0_auc: 0.86013 |  0:00:37s\n",
      "epoch 23 | loss: 0.39973 | val_0_auc: 0.87168 |  0:00:39s\n",
      "epoch 24 | loss: 0.40957 | val_0_auc: 0.87611 |  0:00:40s\n",
      "epoch 25 | loss: 0.37651 | val_0_auc: 0.88054 |  0:00:42s\n",
      "epoch 26 | loss: 0.40798 | val_0_auc: 0.88381 |  0:00:44s\n",
      "epoch 27 | loss: 0.38382 | val_0_auc: 0.87894 |  0:00:45s\n",
      "epoch 28 | loss: 0.38473 | val_0_auc: 0.87269 |  0:00:47s\n",
      "epoch 29 | loss: 0.40449 | val_0_auc: 0.85817 |  0:00:49s\n",
      "epoch 30 | loss: 0.37381 | val_0_auc: 0.87908 |  0:00:50s\n",
      "epoch 31 | loss: 0.39143 | val_0_auc: 0.86267 |  0:00:52s\n",
      "epoch 32 | loss: 0.41917 | val_0_auc: 0.86848 |  0:00:54s\n",
      "epoch 33 | loss: 0.38052 | val_0_auc: 0.88068 |  0:00:55s\n",
      "epoch 34 | loss: 0.39307 | val_0_auc: 0.88083 |  0:00:57s\n",
      "epoch 35 | loss: 0.37976 | val_0_auc: 0.86972 |  0:00:58s\n",
      "epoch 36 | loss: 0.39501 | val_0_auc: 0.87211 |  0:01:00s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.88381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.13162 | val_0_auc: 0.80073 |  0:00:01s\n",
      "epoch 1  | loss: 0.67754 | val_0_auc: 0.7772  |  0:00:03s\n",
      "epoch 2  | loss: 0.51091 | val_0_auc: 0.83268 |  0:00:04s\n",
      "epoch 3  | loss: 0.51699 | val_0_auc: 0.85316 |  0:00:06s\n",
      "epoch 4  | loss: 0.474   | val_0_auc: 0.85229 |  0:00:08s\n",
      "epoch 5  | loss: 0.48747 | val_0_auc: 0.82672 |  0:00:09s\n",
      "epoch 6  | loss: 0.41546 | val_0_auc: 0.81481 |  0:00:11s\n",
      "epoch 7  | loss: 0.4371  | val_0_auc: 0.84691 |  0:00:13s\n",
      "epoch 8  | loss: 0.47157 | val_0_auc: 0.84749 |  0:00:14s\n",
      "epoch 9  | loss: 0.44646 | val_0_auc: 0.76412 |  0:00:16s\n",
      "epoch 10 | loss: 0.50167 | val_0_auc: 0.83486 |  0:00:17s\n",
      "epoch 11 | loss: 0.41775 | val_0_auc: 0.81089 |  0:00:18s\n",
      "epoch 12 | loss: 0.42304 | val_0_auc: 0.85926 |  0:00:20s\n",
      "epoch 13 | loss: 0.43101 | val_0_auc: 0.87466 |  0:00:22s\n",
      "epoch 14 | loss: 0.42052 | val_0_auc: 0.85054 |  0:00:23s\n",
      "epoch 15 | loss: 0.38268 | val_0_auc: 0.84895 |  0:00:25s\n",
      "epoch 16 | loss: 0.42193 | val_0_auc: 0.85127 |  0:00:27s\n",
      "epoch 17 | loss: 0.3864  | val_0_auc: 0.85781 |  0:00:28s\n",
      "epoch 18 | loss: 0.39438 | val_0_auc: 0.85054 |  0:00:30s\n",
      "epoch 19 | loss: 0.38669 | val_0_auc: 0.8472  |  0:00:31s\n",
      "epoch 20 | loss: 0.38621 | val_0_auc: 0.83021 |  0:00:33s\n",
      "epoch 21 | loss: 0.39038 | val_0_auc: 0.84139 |  0:00:34s\n",
      "epoch 22 | loss: 0.35098 | val_0_auc: 0.85708 |  0:00:36s\n",
      "epoch 23 | loss: 0.39419 | val_0_auc: 0.86216 |  0:00:37s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.87466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.17224 | val_0_auc: 0.7862  |  0:00:01s\n",
      "epoch 1  | loss: 0.59687 | val_0_auc: 0.7907  |  0:00:02s\n",
      "epoch 2  | loss: 0.61007 | val_0_auc: 0.82338 |  0:00:04s\n",
      "epoch 3  | loss: 0.53212 | val_0_auc: 0.78068 |  0:00:05s\n",
      "epoch 4  | loss: 0.51592 | val_0_auc: 0.78664 |  0:00:07s\n",
      "epoch 5  | loss: 0.45717 | val_0_auc: 0.84285 |  0:00:08s\n",
      "epoch 6  | loss: 0.44495 | val_0_auc: 0.84328 |  0:00:10s\n",
      "epoch 7  | loss: 0.45005 | val_0_auc: 0.85955 |  0:00:11s\n",
      "epoch 8  | loss: 0.50335 | val_0_auc: 0.83399 |  0:00:13s\n",
      "epoch 9  | loss: 0.44692 | val_0_auc: 0.83152 |  0:00:15s\n",
      "epoch 10 | loss: 0.47828 | val_0_auc: 0.80697 |  0:00:16s\n",
      "epoch 11 | loss: 0.44739 | val_0_auc: 0.80537 |  0:00:18s\n",
      "epoch 12 | loss: 0.41698 | val_0_auc: 0.83842 |  0:00:19s\n",
      "epoch 13 | loss: 0.43734 | val_0_auc: 0.83558 |  0:00:21s\n",
      "epoch 14 | loss: 0.43501 | val_0_auc: 0.84858 |  0:00:23s\n",
      "epoch 15 | loss: 0.42183 | val_0_auc: 0.8435  |  0:00:24s\n",
      "epoch 16 | loss: 0.43682 | val_0_auc: 0.81126 |  0:00:26s\n",
      "epoch 17 | loss: 0.43416 | val_0_auc: 0.8215  |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.85955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76124 | val_0_auc: 0.36035 |  0:00:01s\n",
      "epoch 1  | loss: 0.79958 | val_0_auc: 0.78504 |  0:00:03s\n",
      "epoch 2  | loss: 0.499   | val_0_auc: 0.8411  |  0:00:05s\n",
      "epoch 3  | loss: 0.42769 | val_0_auc: 0.79201 |  0:00:06s\n",
      "epoch 4  | loss: 0.43037 | val_0_auc: 0.84256 |  0:00:08s\n",
      "epoch 5  | loss: 0.42012 | val_0_auc: 0.83602 |  0:00:10s\n",
      "epoch 6  | loss: 0.40096 | val_0_auc: 0.82977 |  0:00:11s\n",
      "epoch 7  | loss: 0.41363 | val_0_auc: 0.79506 |  0:00:13s\n",
      "epoch 8  | loss: 0.42467 | val_0_auc: 0.79985 |  0:00:15s\n",
      "epoch 9  | loss: 0.3862  | val_0_auc: 0.86158 |  0:00:16s\n",
      "epoch 10 | loss: 0.38545 | val_0_auc: 0.86667 |  0:00:18s\n",
      "epoch 11 | loss: 0.40051 | val_0_auc: 0.84444 |  0:00:20s\n",
      "epoch 12 | loss: 0.40107 | val_0_auc: 0.84866 |  0:00:21s\n",
      "epoch 13 | loss: 0.40075 | val_0_auc: 0.86013 |  0:00:23s\n",
      "epoch 14 | loss: 0.39164 | val_0_auc: 0.8289  |  0:00:25s\n",
      "epoch 15 | loss: 0.40714 | val_0_auc: 0.86754 |  0:00:26s\n",
      "epoch 16 | loss: 0.38953 | val_0_auc: 0.87422 |  0:00:28s\n",
      "epoch 17 | loss: 0.42762 | val_0_auc: 0.86928 |  0:00:30s\n",
      "epoch 18 | loss: 0.39332 | val_0_auc: 0.87654 |  0:00:31s\n",
      "epoch 19 | loss: 0.36532 | val_0_auc: 0.88816 |  0:00:33s\n",
      "epoch 20 | loss: 0.37821 | val_0_auc: 0.89978 |  0:00:34s\n",
      "epoch 21 | loss: 0.39211 | val_0_auc: 0.90719 |  0:00:36s\n",
      "epoch 22 | loss: 0.37839 | val_0_auc: 0.89317 |  0:00:38s\n",
      "epoch 23 | loss: 0.39371 | val_0_auc: 0.88918 |  0:00:39s\n",
      "epoch 24 | loss: 0.35559 | val_0_auc: 0.88918 |  0:00:41s\n",
      "epoch 25 | loss: 0.36862 | val_0_auc: 0.86943 |  0:00:42s\n",
      "epoch 26 | loss: 0.3739  | val_0_auc: 0.8642  |  0:00:44s\n",
      "epoch 27 | loss: 0.36802 | val_0_auc: 0.8756  |  0:00:46s\n",
      "epoch 28 | loss: 0.38165 | val_0_auc: 0.87052 |  0:00:47s\n",
      "epoch 29 | loss: 0.36341 | val_0_auc: 0.87509 |  0:00:49s\n",
      "epoch 30 | loss: 0.38639 | val_0_auc: 0.85548 |  0:00:50s\n",
      "epoch 31 | loss: 0.37883 | val_0_auc: 0.85606 |  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.90719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82141 | val_0_auc: 0.75062 |  0:00:01s\n",
      "epoch 1  | loss: 0.56527 | val_0_auc: 0.82898 |  0:00:03s\n",
      "epoch 2  | loss: 0.51315 | val_0_auc: 0.85672 |  0:00:05s\n",
      "epoch 3  | loss: 0.42913 | val_0_auc: 0.79898 |  0:00:06s\n",
      "epoch 4  | loss: 0.45258 | val_0_auc: 0.81837 |  0:00:08s\n",
      "epoch 5  | loss: 0.4526  | val_0_auc: 0.82266 |  0:00:10s\n",
      "epoch 6  | loss: 0.40381 | val_0_auc: 0.81961 |  0:00:11s\n",
      "epoch 7  | loss: 0.40768 | val_0_auc: 0.85352 |  0:00:13s\n",
      "epoch 8  | loss: 0.40182 | val_0_auc: 0.8207  |  0:00:15s\n",
      "epoch 9  | loss: 0.41927 | val_0_auc: 0.85069 |  0:00:16s\n",
      "epoch 10 | loss: 0.39887 | val_0_auc: 0.8284  |  0:00:18s\n",
      "epoch 11 | loss: 0.39931 | val_0_auc: 0.82491 |  0:00:19s\n",
      "epoch 12 | loss: 0.42894 | val_0_auc: 0.82607 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.85672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82061 | val_0_auc: 0.58315 |  0:00:01s\n",
      "epoch 1  | loss: 0.54758 | val_0_auc: 0.7963  |  0:00:03s\n",
      "epoch 2  | loss: 0.54267 | val_0_auc: 0.80407 |  0:00:04s\n",
      "epoch 3  | loss: 0.47332 | val_0_auc: 0.85062 |  0:00:06s\n",
      "epoch 4  | loss: 0.42513 | val_0_auc: 0.79513 |  0:00:08s\n",
      "epoch 5  | loss: 0.42884 | val_0_auc: 0.83065 |  0:00:09s\n",
      "epoch 6  | loss: 0.41981 | val_0_auc: 0.87538 |  0:00:11s\n",
      "epoch 7  | loss: 0.42141 | val_0_auc: 0.85708 |  0:00:13s\n",
      "epoch 8  | loss: 0.39006 | val_0_auc: 0.84691 |  0:00:15s\n",
      "epoch 9  | loss: 0.39413 | val_0_auc: 0.84343 |  0:00:17s\n",
      "epoch 10 | loss: 0.411   | val_0_auc: 0.85723 |  0:00:18s\n",
      "epoch 11 | loss: 0.41429 | val_0_auc: 0.85795 |  0:00:20s\n",
      "epoch 12 | loss: 0.40183 | val_0_auc: 0.86609 |  0:00:22s\n",
      "epoch 13 | loss: 0.41245 | val_0_auc: 0.87633 |  0:00:24s\n",
      "epoch 14 | loss: 0.40452 | val_0_auc: 0.87124 |  0:00:26s\n",
      "epoch 15 | loss: 0.40471 | val_0_auc: 0.88134 |  0:00:27s\n",
      "epoch 16 | loss: 0.3975  | val_0_auc: 0.86057 |  0:00:29s\n",
      "epoch 17 | loss: 0.41502 | val_0_auc: 0.84473 |  0:00:31s\n",
      "epoch 18 | loss: 0.40951 | val_0_auc: 0.87407 |  0:00:33s\n",
      "epoch 19 | loss: 0.40024 | val_0_auc: 0.88105 |  0:00:35s\n",
      "epoch 20 | loss: 0.40919 | val_0_auc: 0.88221 |  0:00:37s\n",
      "epoch 21 | loss: 0.38713 | val_0_auc: 0.89325 |  0:00:38s\n",
      "epoch 22 | loss: 0.39456 | val_0_auc: 0.89557 |  0:00:40s\n",
      "epoch 23 | loss: 0.38689 | val_0_auc: 0.89325 |  0:00:42s\n",
      "epoch 24 | loss: 0.3922  | val_0_auc: 0.88105 |  0:00:44s\n",
      "epoch 25 | loss: 0.4046  | val_0_auc: 0.88678 |  0:00:45s\n",
      "epoch 26 | loss: 0.39313 | val_0_auc: 0.89143 |  0:00:47s\n",
      "epoch 27 | loss: 0.40049 | val_0_auc: 0.87284 |  0:00:49s\n",
      "epoch 28 | loss: 0.42683 | val_0_auc: 0.86986 |  0:00:51s\n",
      "epoch 29 | loss: 0.40346 | val_0_auc: 0.87574 |  0:00:52s\n",
      "epoch 30 | loss: 0.42518 | val_0_auc: 0.88475 |  0:00:54s\n",
      "epoch 31 | loss: 0.4219  | val_0_auc: 0.89419 |  0:00:56s\n",
      "epoch 32 | loss: 0.40809 | val_0_auc: 0.8947  |  0:00:57s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.89557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.708   | val_0_auc: 0.74757 |  0:00:01s\n",
      "epoch 1  | loss: 0.60551 | val_0_auc: 0.82527 |  0:00:03s\n",
      "epoch 2  | loss: 0.47314 | val_0_auc: 0.84808 |  0:00:05s\n",
      "epoch 3  | loss: 0.49021 | val_0_auc: 0.84619 |  0:00:06s\n",
      "epoch 4  | loss: 0.42247 | val_0_auc: 0.84822 |  0:00:08s\n",
      "epoch 5  | loss: 0.39962 | val_0_auc: 0.85679 |  0:00:10s\n",
      "epoch 6  | loss: 0.39601 | val_0_auc: 0.83588 |  0:00:12s\n",
      "epoch 7  | loss: 0.41571 | val_0_auc: 0.88526 |  0:00:13s\n",
      "epoch 8  | loss: 0.41219 | val_0_auc: 0.8825  |  0:00:15s\n",
      "epoch 9  | loss: 0.3902  | val_0_auc: 0.85694 |  0:00:17s\n",
      "epoch 10 | loss: 0.43149 | val_0_auc: 0.87524 |  0:00:18s\n",
      "epoch 11 | loss: 0.39414 | val_0_auc: 0.88046 |  0:00:20s\n",
      "epoch 12 | loss: 0.39302 | val_0_auc: 0.86536 |  0:00:22s\n",
      "epoch 13 | loss: 0.40281 | val_0_auc: 0.86957 |  0:00:24s\n",
      "epoch 14 | loss: 0.39359 | val_0_auc: 0.87073 |  0:00:25s\n",
      "epoch 15 | loss: 0.39307 | val_0_auc: 0.86478 |  0:00:27s\n",
      "epoch 16 | loss: 0.38289 | val_0_auc: 0.85977 |  0:00:29s\n",
      "epoch 17 | loss: 0.38763 | val_0_auc: 0.84481 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.88526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.7942  | val_0_auc: 0.79535 |  0:00:01s\n",
      "epoch 1  | loss: 0.66344 | val_0_auc: 0.81423 |  0:00:03s\n",
      "epoch 2  | loss: 0.54688 | val_0_auc: 0.3854  |  0:00:05s\n",
      "epoch 3  | loss: 0.4921  | val_0_auc: 0.78381 |  0:00:07s\n",
      "epoch 4  | loss: 0.45813 | val_0_auc: 0.81307 |  0:00:08s\n",
      "epoch 5  | loss: 0.43374 | val_0_auc: 0.80842 |  0:00:10s\n",
      "epoch 6  | loss: 0.50525 | val_0_auc: 0.79012 |  0:00:12s\n",
      "epoch 7  | loss: 0.43736 | val_0_auc: 0.85534 |  0:00:13s\n",
      "epoch 8  | loss: 0.42379 | val_0_auc: 0.86841 |  0:00:15s\n",
      "epoch 9  | loss: 0.41233 | val_0_auc: 0.86863 |  0:00:17s\n",
      "epoch 10 | loss: 0.42583 | val_0_auc: 0.87088 |  0:00:18s\n",
      "epoch 11 | loss: 0.42808 | val_0_auc: 0.85185 |  0:00:20s\n",
      "epoch 12 | loss: 0.45729 | val_0_auc: 0.84561 |  0:00:22s\n",
      "epoch 13 | loss: 0.45507 | val_0_auc: 0.87422 |  0:00:23s\n",
      "epoch 14 | loss: 0.43384 | val_0_auc: 0.86521 |  0:00:25s\n",
      "epoch 15 | loss: 0.42641 | val_0_auc: 0.82498 |  0:00:27s\n",
      "epoch 16 | loss: 0.442   | val_0_auc: 0.8589  |  0:00:28s\n",
      "epoch 17 | loss: 0.43963 | val_0_auc: 0.85454 |  0:00:30s\n",
      "epoch 18 | loss: 0.41548 | val_0_auc: 0.85214 |  0:00:32s\n",
      "epoch 19 | loss: 0.4176  | val_0_auc: 0.87037 |  0:00:33s\n",
      "epoch 20 | loss: 0.3915  | val_0_auc: 0.87059 |  0:00:35s\n",
      "epoch 21 | loss: 0.40049 | val_0_auc: 0.8756  |  0:00:37s\n",
      "epoch 22 | loss: 0.40766 | val_0_auc: 0.87175 |  0:00:38s\n",
      "epoch 23 | loss: 0.39405 | val_0_auc: 0.87291 |  0:00:40s\n",
      "epoch 24 | loss: 0.38728 | val_0_auc: 0.87771 |  0:00:42s\n",
      "epoch 25 | loss: 0.39512 | val_0_auc: 0.8658  |  0:00:43s\n",
      "epoch 26 | loss: 0.42991 | val_0_auc: 0.87451 |  0:00:45s\n",
      "epoch 27 | loss: 0.45899 | val_0_auc: 0.84938 |  0:00:47s\n",
      "epoch 28 | loss: 0.3886  | val_0_auc: 0.86761 |  0:00:49s\n",
      "epoch 29 | loss: 0.40582 | val_0_auc: 0.86093 |  0:00:50s\n",
      "epoch 30 | loss: 0.39891 | val_0_auc: 0.88548 |  0:00:52s\n",
      "epoch 31 | loss: 0.40856 | val_0_auc: 0.88635 |  0:00:54s\n",
      "epoch 32 | loss: 0.39762 | val_0_auc: 0.89622 |  0:00:55s\n",
      "epoch 33 | loss: 0.40157 | val_0_auc: 0.89557 |  0:00:57s\n",
      "epoch 34 | loss: 0.41386 | val_0_auc: 0.88932 |  0:00:59s\n",
      "epoch 35 | loss: 0.39232 | val_0_auc: 0.89434 |  0:01:01s\n",
      "epoch 36 | loss: 0.39957 | val_0_auc: 0.89455 |  0:01:02s\n",
      "epoch 37 | loss: 0.38045 | val_0_auc: 0.88366 |  0:01:04s\n",
      "epoch 38 | loss: 0.37067 | val_0_auc: 0.88991 |  0:01:06s\n",
      "epoch 39 | loss: 0.39199 | val_0_auc: 0.90232 |  0:01:08s\n",
      "epoch 40 | loss: 0.37875 | val_0_auc: 0.90501 |  0:01:09s\n",
      "epoch 41 | loss: 0.38233 | val_0_auc: 0.90385 |  0:01:11s\n",
      "epoch 42 | loss: 0.37951 | val_0_auc: 0.90015 |  0:01:13s\n",
      "epoch 43 | loss: 0.38598 | val_0_auc: 0.90007 |  0:01:15s\n",
      "epoch 44 | loss: 0.39342 | val_0_auc: 0.90414 |  0:01:17s\n",
      "epoch 45 | loss: 0.37929 | val_0_auc: 0.89281 |  0:01:18s\n",
      "epoch 46 | loss: 0.37106 | val_0_auc: 0.88453 |  0:01:20s\n",
      "epoch 47 | loss: 0.4129  | val_0_auc: 0.90675 |  0:01:22s\n",
      "epoch 48 | loss: 0.37624 | val_0_auc: 0.89855 |  0:01:23s\n",
      "epoch 49 | loss: 0.39687 | val_0_auc: 0.90748 |  0:01:25s\n",
      "epoch 50 | loss: 0.38405 | val_0_auc: 0.90015 |  0:01:27s\n",
      "epoch 51 | loss: 0.37358 | val_0_auc: 0.88954 |  0:01:29s\n",
      "epoch 52 | loss: 0.38679 | val_0_auc: 0.8971  |  0:01:30s\n",
      "epoch 53 | loss: 0.38001 | val_0_auc: 0.89441 |  0:01:32s\n",
      "epoch 54 | loss: 0.39788 | val_0_auc: 0.89891 |  0:01:34s\n",
      "epoch 55 | loss: 0.38803 | val_0_auc: 0.89731 |  0:01:36s\n",
      "epoch 56 | loss: 0.38683 | val_0_auc: 0.89412 |  0:01:37s\n",
      "epoch 57 | loss: 0.37461 | val_0_auc: 0.89208 |  0:01:39s\n",
      "epoch 58 | loss: 0.37585 | val_0_auc: 0.89782 |  0:01:41s\n",
      "epoch 59 | loss: 0.38773 | val_0_auc: 0.89455 |  0:01:42s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_auc = 0.90748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.68179 | val_0_auc: 0.66841 |  0:00:01s\n",
      "epoch 1  | loss: 0.46709 | val_0_auc: 0.80487 |  0:00:02s\n",
      "epoch 2  | loss: 0.52479 | val_0_auc: 0.80755 |  0:00:03s\n",
      "epoch 3  | loss: 0.41576 | val_0_auc: 0.79375 |  0:00:04s\n",
      "epoch 4  | loss: 0.40557 | val_0_auc: 0.80102 |  0:00:05s\n",
      "epoch 5  | loss: 0.4394  | val_0_auc: 0.78838 |  0:00:06s\n",
      "epoch 6  | loss: 0.42006 | val_0_auc: 0.82331 |  0:00:08s\n",
      "epoch 7  | loss: 0.42159 | val_0_auc: 0.82731 |  0:00:09s\n",
      "epoch 8  | loss: 0.36998 | val_0_auc: 0.85127 |  0:00:10s\n",
      "epoch 9  | loss: 0.44488 | val_0_auc: 0.81307 |  0:00:11s\n",
      "epoch 10 | loss: 0.39128 | val_0_auc: 0.83733 |  0:00:12s\n",
      "epoch 11 | loss: 0.36935 | val_0_auc: 0.83631 |  0:00:13s\n",
      "epoch 12 | loss: 0.39308 | val_0_auc: 0.83065 |  0:00:14s\n",
      "epoch 13 | loss: 0.36733 | val_0_auc: 0.84285 |  0:00:16s\n",
      "epoch 14 | loss: 0.37748 | val_0_auc: 0.8504  |  0:00:17s\n",
      "epoch 15 | loss: 0.3932  | val_0_auc: 0.83282 |  0:00:18s\n",
      "epoch 16 | loss: 0.39188 | val_0_auc: 0.84706 |  0:00:19s\n",
      "epoch 17 | loss: 0.37717 | val_0_auc: 0.86216 |  0:00:20s\n",
      "epoch 18 | loss: 0.38398 | val_0_auc: 0.87436 |  0:00:21s\n",
      "epoch 19 | loss: 0.38461 | val_0_auc: 0.8533  |  0:00:22s\n",
      "epoch 20 | loss: 0.3793  | val_0_auc: 0.84386 |  0:00:23s\n",
      "epoch 21 | loss: 0.3749  | val_0_auc: 0.8589  |  0:00:25s\n",
      "epoch 22 | loss: 0.38241 | val_0_auc: 0.86674 |  0:00:26s\n",
      "epoch 23 | loss: 0.37163 | val_0_auc: 0.8711  |  0:00:27s\n",
      "epoch 24 | loss: 0.37116 | val_0_auc: 0.89441 |  0:00:28s\n",
      "epoch 25 | loss: 0.37402 | val_0_auc: 0.88308 |  0:00:29s\n",
      "epoch 26 | loss: 0.36297 | val_0_auc: 0.87596 |  0:00:30s\n",
      "epoch 27 | loss: 0.3657  | val_0_auc: 0.85207 |  0:00:31s\n",
      "epoch 28 | loss: 0.40339 | val_0_auc: 0.84001 |  0:00:32s\n",
      "epoch 29 | loss: 0.39008 | val_0_auc: 0.87756 |  0:00:34s\n",
      "epoch 30 | loss: 0.40064 | val_0_auc: 0.88649 |  0:00:35s\n",
      "epoch 31 | loss: 0.3713  | val_0_auc: 0.88119 |  0:00:36s\n",
      "epoch 32 | loss: 0.37417 | val_0_auc: 0.88591 |  0:00:37s\n",
      "epoch 33 | loss: 0.37721 | val_0_auc: 0.8772  |  0:00:38s\n",
      "epoch 34 | loss: 0.40811 | val_0_auc: 0.85527 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.89441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71892 | val_0_auc: 0.83326 |  0:00:01s\n",
      "epoch 1  | loss: 0.59549 | val_0_auc: 0.86972 |  0:00:02s\n",
      "epoch 2  | loss: 0.50471 | val_0_auc: 0.88366 |  0:00:03s\n",
      "epoch 3  | loss: 0.48495 | val_0_auc: 0.87248 |  0:00:04s\n",
      "epoch 4  | loss: 0.4009  | val_0_auc: 0.87901 |  0:00:06s\n",
      "epoch 5  | loss: 0.44933 | val_0_auc: 0.87015 |  0:00:07s\n",
      "epoch 6  | loss: 0.42584 | val_0_auc: 0.87785 |  0:00:08s\n",
      "epoch 7  | loss: 0.41519 | val_0_auc: 0.89078 |  0:00:09s\n",
      "epoch 8  | loss: 0.40711 | val_0_auc: 0.88642 |  0:00:11s\n",
      "epoch 9  | loss: 0.42489 | val_0_auc: 0.87393 |  0:00:12s\n",
      "epoch 10 | loss: 0.38965 | val_0_auc: 0.88729 |  0:00:13s\n",
      "epoch 11 | loss: 0.39475 | val_0_auc: 0.88322 |  0:00:14s\n",
      "epoch 12 | loss: 0.41889 | val_0_auc: 0.88017 |  0:00:16s\n",
      "epoch 13 | loss: 0.40075 | val_0_auc: 0.8841  |  0:00:17s\n",
      "epoch 14 | loss: 0.39478 | val_0_auc: 0.86565 |  0:00:18s\n",
      "epoch 15 | loss: 0.39302 | val_0_auc: 0.88293 |  0:00:20s\n",
      "epoch 16 | loss: 0.40107 | val_0_auc: 0.88831 |  0:00:21s\n",
      "epoch 17 | loss: 0.41752 | val_0_auc: 0.89484 |  0:00:22s\n",
      "epoch 18 | loss: 0.41871 | val_0_auc: 0.88424 |  0:00:23s\n",
      "epoch 19 | loss: 0.37906 | val_0_auc: 0.8976  |  0:00:24s\n",
      "epoch 20 | loss: 0.38356 | val_0_auc: 0.88221 |  0:00:25s\n",
      "epoch 21 | loss: 0.39555 | val_0_auc: 0.89208 |  0:00:27s\n",
      "epoch 22 | loss: 0.38282 | val_0_auc: 0.89572 |  0:00:28s\n",
      "epoch 23 | loss: 0.38756 | val_0_auc: 0.89659 |  0:00:29s\n",
      "epoch 24 | loss: 0.38077 | val_0_auc: 0.90022 |  0:00:30s\n",
      "epoch 25 | loss: 0.39332 | val_0_auc: 0.89368 |  0:00:31s\n",
      "epoch 26 | loss: 0.38832 | val_0_auc: 0.90821 |  0:00:32s\n",
      "epoch 27 | loss: 0.37546 | val_0_auc: 0.90675 |  0:00:33s\n",
      "epoch 28 | loss: 0.39357 | val_0_auc: 0.88359 |  0:00:35s\n",
      "epoch 29 | loss: 0.3757  | val_0_auc: 0.88911 |  0:00:36s\n",
      "epoch 30 | loss: 0.37176 | val_0_auc: 0.88838 |  0:00:37s\n",
      "epoch 31 | loss: 0.37367 | val_0_auc: 0.88613 |  0:00:38s\n",
      "epoch 32 | loss: 0.38661 | val_0_auc: 0.89789 |  0:00:39s\n",
      "epoch 33 | loss: 0.38309 | val_0_auc: 0.88932 |  0:00:40s\n",
      "epoch 34 | loss: 0.37853 | val_0_auc: 0.88526 |  0:00:41s\n",
      "epoch 35 | loss: 0.35719 | val_0_auc: 0.88199 |  0:00:43s\n",
      "epoch 36 | loss: 0.41043 | val_0_auc: 0.89593 |  0:00:44s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.90821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.68295 | val_0_auc: 0.86877 |  0:00:01s\n",
      "epoch 1  | loss: 0.53186 | val_0_auc: 0.85635 |  0:00:02s\n",
      "epoch 2  | loss: 0.5095  | val_0_auc: 0.85258 |  0:00:03s\n",
      "epoch 3  | loss: 0.46008 | val_0_auc: 0.86158 |  0:00:04s\n",
      "epoch 4  | loss: 0.40846 | val_0_auc: 0.79245 |  0:00:05s\n",
      "epoch 5  | loss: 0.41341 | val_0_auc: 0.81525 |  0:00:07s\n",
      "epoch 6  | loss: 0.4019  | val_0_auc: 0.83486 |  0:00:08s\n",
      "epoch 7  | loss: 0.44366 | val_0_auc: 0.81975 |  0:00:09s\n",
      "epoch 8  | loss: 0.43275 | val_0_auc: 0.84241 |  0:00:10s\n",
      "epoch 9  | loss: 0.43471 | val_0_auc: 0.85389 |  0:00:11s\n",
      "epoch 10 | loss: 0.45972 | val_0_auc: 0.8276  |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.86877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62159 | val_0_auc: 0.82992 |  0:00:01s\n",
      "epoch 1  | loss: 0.56011 | val_0_auc: 0.73885 |  0:00:02s\n",
      "epoch 2  | loss: 0.49668 | val_0_auc: 0.81133 |  0:00:03s\n",
      "epoch 3  | loss: 0.44797 | val_0_auc: 0.86957 |  0:00:04s\n",
      "epoch 4  | loss: 0.45116 | val_0_auc: 0.84096 |  0:00:05s\n",
      "epoch 5  | loss: 0.42849 | val_0_auc: 0.8411  |  0:00:06s\n",
      "epoch 6  | loss: 0.41997 | val_0_auc: 0.85185 |  0:00:08s\n",
      "epoch 7  | loss: 0.40818 | val_0_auc: 0.86311 |  0:00:09s\n",
      "epoch 8  | loss: 0.39472 | val_0_auc: 0.84728 |  0:00:10s\n",
      "epoch 9  | loss: 0.40816 | val_0_auc: 0.8337  |  0:00:11s\n",
      "epoch 10 | loss: 0.39705 | val_0_auc: 0.85512 |  0:00:12s\n",
      "epoch 11 | loss: 0.40823 | val_0_auc: 0.86594 |  0:00:13s\n",
      "epoch 12 | loss: 0.37118 | val_0_auc: 0.83268 |  0:00:14s\n",
      "epoch 13 | loss: 0.40079 | val_0_auc: 0.83951 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.86957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59478 | val_0_auc: 0.76209 |  0:00:01s\n",
      "epoch 1  | loss: 0.56753 | val_0_auc: 0.81932 |  0:00:02s\n",
      "epoch 2  | loss: 0.47011 | val_0_auc: 0.7862  |  0:00:03s\n",
      "epoch 3  | loss: 0.45312 | val_0_auc: 0.85534 |  0:00:04s\n",
      "epoch 4  | loss: 0.42481 | val_0_auc: 0.82295 |  0:00:05s\n",
      "epoch 5  | loss: 0.45386 | val_0_auc: 0.84139 |  0:00:07s\n",
      "epoch 6  | loss: 0.44433 | val_0_auc: 0.82164 |  0:00:08s\n",
      "epoch 7  | loss: 0.43528 | val_0_auc: 0.80901 |  0:00:09s\n",
      "epoch 8  | loss: 0.41747 | val_0_auc: 0.74365 |  0:00:10s\n",
      "epoch 9  | loss: 0.42825 | val_0_auc: 0.79884 |  0:00:12s\n",
      "epoch 10 | loss: 0.42291 | val_0_auc: 0.80697 |  0:00:13s\n",
      "epoch 11 | loss: 0.44085 | val_0_auc: 0.80595 |  0:00:14s\n",
      "epoch 12 | loss: 0.40739 | val_0_auc: 0.82542 |  0:00:15s\n",
      "epoch 13 | loss: 0.40676 | val_0_auc: 0.85214 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.85534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52136 | val_0_auc: 0.82092 |  0:00:01s\n",
      "epoch 1  | loss: 0.42998 | val_0_auc: 0.81206 |  0:00:02s\n",
      "epoch 2  | loss: 0.38508 | val_0_auc: 0.78373 |  0:00:03s\n",
      "epoch 3  | loss: 0.39599 | val_0_auc: 0.80901 |  0:00:04s\n",
      "epoch 4  | loss: 0.38367 | val_0_auc: 0.83863 |  0:00:06s\n",
      "epoch 5  | loss: 0.40242 | val_0_auc: 0.84357 |  0:00:07s\n",
      "epoch 6  | loss: 0.38167 | val_0_auc: 0.85301 |  0:00:08s\n",
      "epoch 7  | loss: 0.40123 | val_0_auc: 0.84212 |  0:00:09s\n",
      "epoch 8  | loss: 0.38611 | val_0_auc: 0.86899 |  0:00:11s\n",
      "epoch 9  | loss: 0.38343 | val_0_auc: 0.88308 |  0:00:12s\n",
      "epoch 10 | loss: 0.38603 | val_0_auc: 0.85258 |  0:00:13s\n",
      "epoch 11 | loss: 0.39552 | val_0_auc: 0.85868 |  0:00:14s\n",
      "epoch 12 | loss: 0.38297 | val_0_auc: 0.86638 |  0:00:15s\n",
      "epoch 13 | loss: 0.41367 | val_0_auc: 0.85534 |  0:00:16s\n",
      "epoch 14 | loss: 0.37136 | val_0_auc: 0.86696 |  0:00:18s\n",
      "epoch 15 | loss: 0.38444 | val_0_auc: 0.87669 |  0:00:19s\n",
      "epoch 16 | loss: 0.36524 | val_0_auc: 0.89063 |  0:00:20s\n",
      "epoch 17 | loss: 0.36128 | val_0_auc: 0.88969 |  0:00:21s\n",
      "epoch 18 | loss: 0.38398 | val_0_auc: 0.86267 |  0:00:23s\n",
      "epoch 19 | loss: 0.36017 | val_0_auc: 0.85294 |  0:00:24s\n",
      "epoch 20 | loss: 0.35042 | val_0_auc: 0.86819 |  0:00:25s\n",
      "epoch 21 | loss: 0.3673  | val_0_auc: 0.88642 |  0:00:26s\n",
      "epoch 22 | loss: 0.37588 | val_0_auc: 0.88671 |  0:00:27s\n",
      "epoch 23 | loss: 0.37102 | val_0_auc: 0.87814 |  0:00:28s\n",
      "epoch 24 | loss: 0.38682 | val_0_auc: 0.88482 |  0:00:29s\n",
      "epoch 25 | loss: 0.38075 | val_0_auc: 0.87756 |  0:00:31s\n",
      "epoch 26 | loss: 0.37507 | val_0_auc: 0.88017 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.89063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57251 | val_0_auc: 0.86594 |  0:00:01s\n",
      "epoch 1  | loss: 0.43263 | val_0_auc: 0.82963 |  0:00:02s\n",
      "epoch 2  | loss: 0.39808 | val_0_auc: 0.82266 |  0:00:03s\n",
      "epoch 3  | loss: 0.42506 | val_0_auc: 0.85359 |  0:00:04s\n",
      "epoch 4  | loss: 0.41228 | val_0_auc: 0.83268 |  0:00:05s\n",
      "epoch 5  | loss: 0.40684 | val_0_auc: 0.8459  |  0:00:07s\n",
      "epoch 6  | loss: 0.40357 | val_0_auc: 0.85577 |  0:00:08s\n",
      "epoch 7  | loss: 0.4316  | val_0_auc: 0.86783 |  0:00:09s\n",
      "epoch 8  | loss: 0.38273 | val_0_auc: 0.86158 |  0:00:10s\n",
      "epoch 9  | loss: 0.39726 | val_0_auc: 0.87131 |  0:00:11s\n",
      "epoch 10 | loss: 0.39393 | val_0_auc: 0.87233 |  0:00:13s\n",
      "epoch 11 | loss: 0.39619 | val_0_auc: 0.87349 |  0:00:14s\n",
      "epoch 12 | loss: 0.40193 | val_0_auc: 0.87102 |  0:00:15s\n",
      "epoch 13 | loss: 0.4058  | val_0_auc: 0.87734 |  0:00:16s\n",
      "epoch 14 | loss: 0.38779 | val_0_auc: 0.8719  |  0:00:17s\n",
      "epoch 15 | loss: 0.39907 | val_0_auc: 0.86768 |  0:00:18s\n",
      "epoch 16 | loss: 0.39515 | val_0_auc: 0.89165 |  0:00:20s\n",
      "epoch 17 | loss: 0.38677 | val_0_auc: 0.88032 |  0:00:21s\n",
      "epoch 18 | loss: 0.37139 | val_0_auc: 0.8841  |  0:00:22s\n",
      "epoch 19 | loss: 0.39221 | val_0_auc: 0.89237 |  0:00:23s\n",
      "epoch 20 | loss: 0.40118 | val_0_auc: 0.87974 |  0:00:24s\n",
      "epoch 21 | loss: 0.4074  | val_0_auc: 0.88439 |  0:00:25s\n",
      "epoch 22 | loss: 0.40334 | val_0_auc: 0.88613 |  0:00:27s\n",
      "epoch 23 | loss: 0.37879 | val_0_auc: 0.89208 |  0:00:28s\n",
      "epoch 24 | loss: 0.39188 | val_0_auc: 0.88932 |  0:00:29s\n",
      "epoch 25 | loss: 0.41041 | val_0_auc: 0.86928 |  0:00:30s\n",
      "epoch 26 | loss: 0.36622 | val_0_auc: 0.86841 |  0:00:31s\n",
      "epoch 27 | loss: 0.37661 | val_0_auc: 0.89368 |  0:00:32s\n",
      "epoch 28 | loss: 0.37898 | val_0_auc: 0.88656 |  0:00:34s\n",
      "epoch 29 | loss: 0.36473 | val_0_auc: 0.88903 |  0:00:35s\n",
      "epoch 30 | loss: 0.37085 | val_0_auc: 0.89499 |  0:00:36s\n",
      "epoch 31 | loss: 0.38623 | val_0_auc: 0.89724 |  0:00:37s\n",
      "epoch 32 | loss: 0.38485 | val_0_auc: 0.88511 |  0:00:38s\n",
      "epoch 33 | loss: 0.36855 | val_0_auc: 0.89237 |  0:00:39s\n",
      "epoch 34 | loss: 0.38578 | val_0_auc: 0.9008  |  0:00:40s\n",
      "epoch 35 | loss: 0.36234 | val_0_auc: 0.89049 |  0:00:42s\n",
      "epoch 36 | loss: 0.39845 | val_0_auc: 0.8963  |  0:00:43s\n",
      "epoch 37 | loss: 0.37955 | val_0_auc: 0.89441 |  0:00:44s\n",
      "epoch 38 | loss: 0.37827 | val_0_auc: 0.89542 |  0:00:45s\n",
      "epoch 39 | loss: 0.39338 | val_0_auc: 0.88584 |  0:00:46s\n",
      "epoch 40 | loss: 0.37678 | val_0_auc: 0.88395 |  0:00:47s\n",
      "epoch 41 | loss: 0.3765  | val_0_auc: 0.89252 |  0:00:48s\n",
      "epoch 42 | loss: 0.37634 | val_0_auc: 0.89484 |  0:00:50s\n",
      "epoch 43 | loss: 0.37544 | val_0_auc: 0.89797 |  0:00:51s\n",
      "epoch 44 | loss: 0.39363 | val_0_auc: 0.89412 |  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54704 | val_0_auc: 0.78954 |  0:00:01s\n",
      "epoch 1  | loss: 0.49958 | val_0_auc: 0.7663  |  0:00:02s\n",
      "epoch 2  | loss: 0.43203 | val_0_auc: 0.79884 |  0:00:03s\n",
      "epoch 3  | loss: 0.44144 | val_0_auc: 0.83253 |  0:00:04s\n",
      "epoch 4  | loss: 0.39919 | val_0_auc: 0.83268 |  0:00:05s\n",
      "epoch 5  | loss: 0.43272 | val_0_auc: 0.83558 |  0:00:06s\n",
      "epoch 6  | loss: 0.41599 | val_0_auc: 0.84256 |  0:00:07s\n",
      "epoch 7  | loss: 0.43025 | val_0_auc: 0.84793 |  0:00:08s\n",
      "epoch 8  | loss: 0.39079 | val_0_auc: 0.8655  |  0:00:10s\n",
      "epoch 9  | loss: 0.40883 | val_0_auc: 0.88264 |  0:00:11s\n",
      "epoch 10 | loss: 0.3987  | val_0_auc: 0.88264 |  0:00:12s\n",
      "epoch 11 | loss: 0.4004  | val_0_auc: 0.88903 |  0:00:13s\n",
      "epoch 12 | loss: 0.40294 | val_0_auc: 0.86696 |  0:00:14s\n",
      "epoch 13 | loss: 0.41921 | val_0_auc: 0.87785 |  0:00:15s\n",
      "epoch 14 | loss: 0.408   | val_0_auc: 0.88787 |  0:00:16s\n",
      "epoch 15 | loss: 0.40583 | val_0_auc: 0.87785 |  0:00:17s\n",
      "epoch 16 | loss: 0.39922 | val_0_auc: 0.88874 |  0:00:18s\n",
      "epoch 17 | loss: 0.39486 | val_0_auc: 0.88017 |  0:00:19s\n",
      "epoch 18 | loss: 0.40412 | val_0_auc: 0.8825  |  0:00:21s\n",
      "epoch 19 | loss: 0.39915 | val_0_auc: 0.87436 |  0:00:22s\n",
      "epoch 20 | loss: 0.38673 | val_0_auc: 0.8732  |  0:00:23s\n",
      "epoch 21 | loss: 0.41379 | val_0_auc: 0.88584 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.88903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55298 | val_0_auc: 0.81743 |  0:00:01s\n",
      "epoch 1  | loss: 0.46094 | val_0_auc: 0.81975 |  0:00:02s\n",
      "epoch 2  | loss: 0.39529 | val_0_auc: 0.83922 |  0:00:03s\n",
      "epoch 3  | loss: 0.43854 | val_0_auc: 0.84633 |  0:00:04s\n",
      "epoch 4  | loss: 0.3976  | val_0_auc: 0.83791 |  0:00:05s\n",
      "epoch 5  | loss: 0.4132  | val_0_auc: 0.87378 |  0:00:06s\n",
      "epoch 6  | loss: 0.42034 | val_0_auc: 0.86173 |  0:00:08s\n",
      "epoch 7  | loss: 0.40083 | val_0_auc: 0.8719  |  0:00:09s\n",
      "epoch 8  | loss: 0.38841 | val_0_auc: 0.86434 |  0:00:10s\n",
      "epoch 9  | loss: 0.40115 | val_0_auc: 0.85374 |  0:00:11s\n",
      "epoch 10 | loss: 0.38308 | val_0_auc: 0.85519 |  0:00:12s\n",
      "epoch 11 | loss: 0.41279 | val_0_auc: 0.8215  |  0:00:14s\n",
      "epoch 12 | loss: 0.40812 | val_0_auc: 0.85272 |  0:00:15s\n",
      "epoch 13 | loss: 0.40724 | val_0_auc: 0.86376 |  0:00:16s\n",
      "epoch 14 | loss: 0.41379 | val_0_auc: 0.85999 |  0:00:18s\n",
      "epoch 15 | loss: 0.36501 | val_0_auc: 0.82585 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.87378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56356 | val_0_auc: 0.8337  |  0:00:01s\n",
      "epoch 1  | loss: 0.46341 | val_0_auc: 0.84125 |  0:00:02s\n",
      "epoch 2  | loss: 0.46215 | val_0_auc: 0.84691 |  0:00:03s\n",
      "epoch 3  | loss: 0.47399 | val_0_auc: 0.85025 |  0:00:04s\n",
      "epoch 4  | loss: 0.42185 | val_0_auc: 0.84764 |  0:00:06s\n",
      "epoch 5  | loss: 0.44946 | val_0_auc: 0.85127 |  0:00:07s\n",
      "epoch 6  | loss: 0.42932 | val_0_auc: 0.83951 |  0:00:08s\n",
      "epoch 7  | loss: 0.45385 | val_0_auc: 0.87146 |  0:00:09s\n",
      "epoch 8  | loss: 0.43923 | val_0_auc: 0.84386 |  0:00:10s\n",
      "epoch 9  | loss: 0.43025 | val_0_auc: 0.80871 |  0:00:11s\n",
      "epoch 10 | loss: 0.39955 | val_0_auc: 0.83834 |  0:00:13s\n",
      "epoch 11 | loss: 0.4108  | val_0_auc: 0.79288 |  0:00:14s\n",
      "epoch 12 | loss: 0.43287 | val_0_auc: 0.86943 |  0:00:15s\n",
      "epoch 13 | loss: 0.42092 | val_0_auc: 0.88192 |  0:00:16s\n",
      "epoch 14 | loss: 0.41248 | val_0_auc: 0.86449 |  0:00:17s\n",
      "epoch 15 | loss: 0.40841 | val_0_auc: 0.8793  |  0:00:18s\n",
      "epoch 16 | loss: 0.41961 | val_0_auc: 0.87277 |  0:00:19s\n",
      "epoch 17 | loss: 0.39601 | val_0_auc: 0.85214 |  0:00:20s\n",
      "epoch 18 | loss: 0.42279 | val_0_auc: 0.88192 |  0:00:21s\n",
      "epoch 19 | loss: 0.41367 | val_0_auc: 0.87654 |  0:00:22s\n",
      "epoch 20 | loss: 0.39263 | val_0_auc: 0.88773 |  0:00:23s\n",
      "epoch 21 | loss: 0.40074 | val_0_auc: 0.89136 |  0:00:25s\n",
      "epoch 22 | loss: 0.41515 | val_0_auc: 0.89804 |  0:00:26s\n",
      "epoch 23 | loss: 0.39847 | val_0_auc: 0.87829 |  0:00:27s\n",
      "epoch 24 | loss: 0.40538 | val_0_auc: 0.89063 |  0:00:28s\n",
      "epoch 25 | loss: 0.42656 | val_0_auc: 0.90646 |  0:00:29s\n",
      "epoch 26 | loss: 0.40115 | val_0_auc: 0.89644 |  0:00:30s\n",
      "epoch 27 | loss: 0.414   | val_0_auc: 0.89397 |  0:00:31s\n",
      "epoch 28 | loss: 0.40161 | val_0_auc: 0.88976 |  0:00:32s\n",
      "epoch 29 | loss: 0.41119 | val_0_auc: 0.88627 |  0:00:33s\n",
      "epoch 30 | loss: 0.42809 | val_0_auc: 0.89368 |  0:00:34s\n",
      "epoch 31 | loss: 0.39406 | val_0_auc: 0.88903 |  0:00:35s\n",
      "epoch 32 | loss: 0.39959 | val_0_auc: 0.89252 |  0:00:37s\n",
      "epoch 33 | loss: 0.42218 | val_0_auc: 0.88642 |  0:00:38s\n",
      "epoch 34 | loss: 0.41576 | val_0_auc: 0.88715 |  0:00:39s\n",
      "epoch 35 | loss: 0.39931 | val_0_auc: 0.89601 |  0:00:40s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.90646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5506  | val_0_auc: 0.77618 |  0:00:00s\n",
      "epoch 1  | loss: 0.41956 | val_0_auc: 0.78606 |  0:00:01s\n",
      "epoch 2  | loss: 0.40956 | val_0_auc: 0.8443  |  0:00:02s\n",
      "epoch 3  | loss: 0.3938  | val_0_auc: 0.80886 |  0:00:02s\n",
      "epoch 4  | loss: 0.40375 | val_0_auc: 0.8366  |  0:00:03s\n",
      "epoch 5  | loss: 0.4018  | val_0_auc: 0.85142 |  0:00:04s\n",
      "epoch 6  | loss: 0.39744 | val_0_auc: 0.85461 |  0:00:04s\n",
      "epoch 7  | loss: 0.37123 | val_0_auc: 0.84343 |  0:00:05s\n",
      "epoch 8  | loss: 0.38105 | val_0_auc: 0.82818 |  0:00:06s\n",
      "epoch 9  | loss: 0.39532 | val_0_auc: 0.82179 |  0:00:07s\n",
      "epoch 10 | loss: 0.38903 | val_0_auc: 0.81278 |  0:00:07s\n",
      "epoch 11 | loss: 0.38576 | val_0_auc: 0.82469 |  0:00:08s\n",
      "epoch 12 | loss: 0.38442 | val_0_auc: 0.83834 |  0:00:09s\n",
      "epoch 13 | loss: 0.38457 | val_0_auc: 0.85113 |  0:00:09s\n",
      "epoch 14 | loss: 0.37428 | val_0_auc: 0.84931 |  0:00:10s\n",
      "epoch 15 | loss: 0.38204 | val_0_auc: 0.80857 |  0:00:11s\n",
      "epoch 16 | loss: 0.3605  | val_0_auc: 0.84089 |  0:00:11s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.85461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53143 | val_0_auc: 0.73384 |  0:00:00s\n",
      "epoch 1  | loss: 0.42624 | val_0_auc: 0.85664 |  0:00:01s\n",
      "epoch 2  | loss: 0.42043 | val_0_auc: 0.86565 |  0:00:02s\n",
      "epoch 3  | loss: 0.38644 | val_0_auc: 0.8658  |  0:00:02s\n",
      "epoch 4  | loss: 0.41098 | val_0_auc: 0.75962 |  0:00:03s\n",
      "epoch 5  | loss: 0.41241 | val_0_auc: 0.85403 |  0:00:04s\n",
      "epoch 6  | loss: 0.38486 | val_0_auc: 0.80668 |  0:00:05s\n",
      "epoch 7  | loss: 0.40116 | val_0_auc: 0.86042 |  0:00:05s\n",
      "epoch 8  | loss: 0.39463 | val_0_auc: 0.86013 |  0:00:06s\n",
      "epoch 9  | loss: 0.41932 | val_0_auc: 0.85287 |  0:00:07s\n",
      "epoch 10 | loss: 0.40208 | val_0_auc: 0.86231 |  0:00:07s\n",
      "epoch 11 | loss: 0.39506 | val_0_auc: 0.87945 |  0:00:08s\n",
      "epoch 12 | loss: 0.38976 | val_0_auc: 0.87393 |  0:00:09s\n",
      "epoch 13 | loss: 0.41617 | val_0_auc: 0.87052 |  0:00:10s\n",
      "epoch 14 | loss: 0.3869  | val_0_auc: 0.83624 |  0:00:11s\n",
      "epoch 15 | loss: 0.40333 | val_0_auc: 0.82157 |  0:00:11s\n",
      "epoch 16 | loss: 0.39197 | val_0_auc: 0.8284  |  0:00:12s\n",
      "epoch 17 | loss: 0.3773  | val_0_auc: 0.8398  |  0:00:13s\n",
      "epoch 18 | loss: 0.3866  | val_0_auc: 0.85207 |  0:00:14s\n",
      "epoch 19 | loss: 0.40034 | val_0_auc: 0.83951 |  0:00:15s\n",
      "epoch 20 | loss: 0.37429 | val_0_auc: 0.85781 |  0:00:15s\n",
      "epoch 21 | loss: 0.3678  | val_0_auc: 0.85686 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.87945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57708 | val_0_auc: 0.83704 |  0:00:00s\n",
      "epoch 1  | loss: 0.45171 | val_0_auc: 0.848   |  0:00:01s\n",
      "epoch 2  | loss: 0.41859 | val_0_auc: 0.81823 |  0:00:02s\n",
      "epoch 3  | loss: 0.42941 | val_0_auc: 0.83508 |  0:00:03s\n",
      "epoch 4  | loss: 0.41278 | val_0_auc: 0.8549  |  0:00:04s\n",
      "epoch 5  | loss: 0.39918 | val_0_auc: 0.85156 |  0:00:05s\n",
      "epoch 6  | loss: 0.40412 | val_0_auc: 0.82077 |  0:00:05s\n",
      "epoch 7  | loss: 0.4163  | val_0_auc: 0.85359 |  0:00:06s\n",
      "epoch 8  | loss: 0.41815 | val_0_auc: 0.85229 |  0:00:07s\n",
      "epoch 9  | loss: 0.39207 | val_0_auc: 0.86173 |  0:00:08s\n",
      "epoch 10 | loss: 0.38085 | val_0_auc: 0.8642  |  0:00:09s\n",
      "epoch 11 | loss: 0.37729 | val_0_auc: 0.83021 |  0:00:09s\n",
      "epoch 12 | loss: 0.3869  | val_0_auc: 0.87393 |  0:00:10s\n",
      "epoch 13 | loss: 0.39051 | val_0_auc: 0.887   |  0:00:11s\n",
      "epoch 14 | loss: 0.41494 | val_0_auc: 0.8732  |  0:00:12s\n",
      "epoch 15 | loss: 0.42748 | val_0_auc: 0.84488 |  0:00:13s\n",
      "epoch 16 | loss: 0.39967 | val_0_auc: 0.83253 |  0:00:13s\n",
      "epoch 17 | loss: 0.38846 | val_0_auc: 0.86086 |  0:00:14s\n",
      "epoch 18 | loss: 0.39333 | val_0_auc: 0.85824 |  0:00:15s\n",
      "epoch 19 | loss: 0.38552 | val_0_auc: 0.87654 |  0:00:16s\n",
      "epoch 20 | loss: 0.37789 | val_0_auc: 0.8841  |  0:00:17s\n",
      "epoch 21 | loss: 0.39131 | val_0_auc: 0.87407 |  0:00:17s\n",
      "epoch 22 | loss: 0.39027 | val_0_auc: 0.85432 |  0:00:18s\n",
      "epoch 23 | loss: 0.3951  | val_0_auc: 0.88395 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53936 | val_0_auc: 0.82375 |  0:00:00s\n",
      "epoch 1  | loss: 0.47923 | val_0_auc: 0.84147 |  0:00:01s\n",
      "epoch 2  | loss: 0.41449 | val_0_auc: 0.82709 |  0:00:02s\n",
      "epoch 3  | loss: 0.40362 | val_0_auc: 0.81678 |  0:00:03s\n",
      "epoch 4  | loss: 0.43084 | val_0_auc: 0.83108 |  0:00:04s\n",
      "epoch 5  | loss: 0.39591 | val_0_auc: 0.82469 |  0:00:04s\n",
      "epoch 6  | loss: 0.39535 | val_0_auc: 0.79237 |  0:00:05s\n",
      "epoch 7  | loss: 0.42016 | val_0_auc: 0.81656 |  0:00:06s\n",
      "epoch 8  | loss: 0.40397 | val_0_auc: 0.80516 |  0:00:07s\n",
      "epoch 9  | loss: 0.3842  | val_0_auc: 0.8366  |  0:00:08s\n",
      "epoch 10 | loss: 0.38011 | val_0_auc: 0.86507 |  0:00:08s\n",
      "epoch 11 | loss: 0.38055 | val_0_auc: 0.86028 |  0:00:09s\n",
      "epoch 12 | loss: 0.36741 | val_0_auc: 0.85287 |  0:00:10s\n",
      "epoch 13 | loss: 0.36812 | val_0_auc: 0.86935 |  0:00:11s\n",
      "epoch 14 | loss: 0.38827 | val_0_auc: 0.87487 |  0:00:11s\n",
      "epoch 15 | loss: 0.38851 | val_0_auc: 0.85977 |  0:00:12s\n",
      "epoch 16 | loss: 0.37731 | val_0_auc: 0.85715 |  0:00:13s\n",
      "epoch 17 | loss: 0.36094 | val_0_auc: 0.85359 |  0:00:14s\n",
      "epoch 18 | loss: 0.37756 | val_0_auc: 0.85142 |  0:00:15s\n",
      "epoch 19 | loss: 0.37307 | val_0_auc: 0.8634  |  0:00:15s\n",
      "epoch 20 | loss: 0.38035 | val_0_auc: 0.87988 |  0:00:16s\n",
      "epoch 21 | loss: 0.37835 | val_0_auc: 0.87901 |  0:00:17s\n",
      "epoch 22 | loss: 0.3737  | val_0_auc: 0.87371 |  0:00:17s\n",
      "epoch 23 | loss: 0.40033 | val_0_auc: 0.88264 |  0:00:18s\n",
      "epoch 24 | loss: 0.3834  | val_0_auc: 0.8756  |  0:00:19s\n",
      "epoch 25 | loss: 0.38618 | val_0_auc: 0.87487 |  0:00:20s\n",
      "epoch 26 | loss: 0.37024 | val_0_auc: 0.88126 |  0:00:20s\n",
      "epoch 27 | loss: 0.37695 | val_0_auc: 0.88126 |  0:00:21s\n",
      "epoch 28 | loss: 0.3728  | val_0_auc: 0.86674 |  0:00:22s\n",
      "epoch 29 | loss: 0.36579 | val_0_auc: 0.8724  |  0:00:23s\n",
      "epoch 30 | loss: 0.36983 | val_0_auc: 0.87633 |  0:00:23s\n",
      "epoch 31 | loss: 0.3767  | val_0_auc: 0.87052 |  0:00:24s\n",
      "epoch 32 | loss: 0.37559 | val_0_auc: 0.87676 |  0:00:25s\n",
      "epoch 33 | loss: 0.37079 | val_0_auc: 0.87429 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.88264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61193 | val_0_auc: 0.84924 |  0:00:00s\n",
      "epoch 1  | loss: 0.44023 | val_0_auc: 0.8947  |  0:00:01s\n",
      "epoch 2  | loss: 0.40011 | val_0_auc: 0.85969 |  0:00:02s\n",
      "epoch 3  | loss: 0.40688 | val_0_auc: 0.86609 |  0:00:03s\n",
      "epoch 4  | loss: 0.4238  | val_0_auc: 0.83718 |  0:00:03s\n",
      "epoch 5  | loss: 0.43463 | val_0_auc: 0.81692 |  0:00:04s\n",
      "epoch 6  | loss: 0.45025 | val_0_auc: 0.83195 |  0:00:05s\n",
      "epoch 7  | loss: 0.41091 | val_0_auc: 0.84561 |  0:00:06s\n",
      "epoch 8  | loss: 0.44104 | val_0_auc: 0.83537 |  0:00:06s\n",
      "epoch 9  | loss: 0.40938 | val_0_auc: 0.8191  |  0:00:07s\n",
      "epoch 10 | loss: 0.40862 | val_0_auc: 0.81954 |  0:00:08s\n",
      "epoch 11 | loss: 0.43081 | val_0_auc: 0.84975 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57066 | val_0_auc: 0.86224 |  0:00:00s\n",
      "epoch 1  | loss: 0.43625 | val_0_auc: 0.84967 |  0:00:01s\n",
      "epoch 2  | loss: 0.40352 | val_0_auc: 0.82266 |  0:00:02s\n",
      "epoch 3  | loss: 0.39808 | val_0_auc: 0.82426 |  0:00:03s\n",
      "epoch 4  | loss: 0.39061 | val_0_auc: 0.79971 |  0:00:04s\n",
      "epoch 5  | loss: 0.3893  | val_0_auc: 0.83544 |  0:00:05s\n",
      "epoch 6  | loss: 0.37108 | val_0_auc: 0.84227 |  0:00:06s\n",
      "epoch 7  | loss: 0.38524 | val_0_auc: 0.83355 |  0:00:06s\n",
      "epoch 8  | loss: 0.36548 | val_0_auc: 0.84277 |  0:00:07s\n",
      "epoch 9  | loss: 0.37776 | val_0_auc: 0.82317 |  0:00:08s\n",
      "epoch 10 | loss: 0.36748 | val_0_auc: 0.84633 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.86224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57009 | val_0_auc: 0.85142 |  0:00:00s\n",
      "epoch 1  | loss: 0.46262 | val_0_auc: 0.75861 |  0:00:01s\n",
      "epoch 2  | loss: 0.46368 | val_0_auc: 0.79855 |  0:00:02s\n",
      "epoch 3  | loss: 0.45868 | val_0_auc: 0.85897 |  0:00:03s\n",
      "epoch 4  | loss: 0.43094 | val_0_auc: 0.83413 |  0:00:04s\n",
      "epoch 5  | loss: 0.43604 | val_0_auc: 0.86129 |  0:00:05s\n",
      "epoch 6  | loss: 0.42759 | val_0_auc: 0.86042 |  0:00:06s\n",
      "epoch 7  | loss: 0.41259 | val_0_auc: 0.84517 |  0:00:07s\n",
      "epoch 8  | loss: 0.42083 | val_0_auc: 0.82121 |  0:00:07s\n",
      "epoch 9  | loss: 0.39273 | val_0_auc: 0.86035 |  0:00:08s\n",
      "epoch 10 | loss: 0.39366 | val_0_auc: 0.8467  |  0:00:09s\n",
      "epoch 11 | loss: 0.39162 | val_0_auc: 0.85447 |  0:00:10s\n",
      "epoch 12 | loss: 0.37005 | val_0_auc: 0.85592 |  0:00:11s\n",
      "epoch 13 | loss: 0.37441 | val_0_auc: 0.84386 |  0:00:12s\n",
      "epoch 14 | loss: 0.40517 | val_0_auc: 0.84401 |  0:00:13s\n",
      "epoch 15 | loss: 0.40052 | val_0_auc: 0.86078 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.86129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55238 | val_0_auc: 0.69731 |  0:00:00s\n",
      "epoch 1  | loss: 0.50995 | val_0_auc: 0.8191  |  0:00:01s\n",
      "epoch 2  | loss: 0.49671 | val_0_auc: 0.83813 |  0:00:02s\n",
      "epoch 3  | loss: 0.4535  | val_0_auc: 0.82796 |  0:00:03s\n",
      "epoch 4  | loss: 0.44272 | val_0_auc: 0.84248 |  0:00:04s\n",
      "epoch 5  | loss: 0.42132 | val_0_auc: 0.82338 |  0:00:05s\n",
      "epoch 6  | loss: 0.44193 | val_0_auc: 0.82193 |  0:00:06s\n",
      "epoch 7  | loss: 0.42605 | val_0_auc: 0.83057 |  0:00:07s\n",
      "epoch 8  | loss: 0.40622 | val_0_auc: 0.82331 |  0:00:07s\n",
      "epoch 9  | loss: 0.40915 | val_0_auc: 0.83413 |  0:00:08s\n",
      "epoch 10 | loss: 0.43242 | val_0_auc: 0.85933 |  0:00:09s\n",
      "epoch 11 | loss: 0.39794 | val_0_auc: 0.86964 |  0:00:10s\n",
      "epoch 12 | loss: 0.39092 | val_0_auc: 0.87066 |  0:00:11s\n",
      "epoch 13 | loss: 0.40161 | val_0_auc: 0.85178 |  0:00:12s\n",
      "epoch 14 | loss: 0.41957 | val_0_auc: 0.87124 |  0:00:13s\n",
      "epoch 15 | loss: 0.39049 | val_0_auc: 0.87328 |  0:00:13s\n",
      "epoch 16 | loss: 0.41175 | val_0_auc: 0.8435  |  0:00:14s\n",
      "epoch 17 | loss: 0.39338 | val_0_auc: 0.85969 |  0:00:15s\n",
      "epoch 18 | loss: 0.39649 | val_0_auc: 0.87792 |  0:00:16s\n",
      "epoch 19 | loss: 0.37961 | val_0_auc: 0.87211 |  0:00:17s\n",
      "epoch 20 | loss: 0.3768  | val_0_auc: 0.86914 |  0:00:17s\n",
      "epoch 21 | loss: 0.36961 | val_0_auc: 0.8772  |  0:00:18s\n",
      "epoch 22 | loss: 0.37891 | val_0_auc: 0.87487 |  0:00:19s\n",
      "epoch 23 | loss: 0.40454 | val_0_auc: 0.88184 |  0:00:20s\n",
      "epoch 24 | loss: 0.40939 | val_0_auc: 0.87248 |  0:00:21s\n",
      "epoch 25 | loss: 0.39884 | val_0_auc: 0.87945 |  0:00:22s\n",
      "epoch 26 | loss: 0.39986 | val_0_auc: 0.87211 |  0:00:22s\n",
      "epoch 27 | loss: 0.38206 | val_0_auc: 0.88482 |  0:00:23s\n",
      "epoch 28 | loss: 0.38434 | val_0_auc: 0.88584 |  0:00:24s\n",
      "epoch 29 | loss: 0.39664 | val_0_auc: 0.8809  |  0:00:25s\n",
      "epoch 30 | loss: 0.37633 | val_0_auc: 0.88221 |  0:00:26s\n",
      "epoch 31 | loss: 0.37751 | val_0_auc: 0.88243 |  0:00:26s\n",
      "epoch 32 | loss: 0.38198 | val_0_auc: 0.86282 |  0:00:27s\n",
      "epoch 33 | loss: 0.38854 | val_0_auc: 0.86296 |  0:00:28s\n",
      "epoch 34 | loss: 0.39172 | val_0_auc: 0.86231 |  0:00:29s\n",
      "epoch 35 | loss: 0.38324 | val_0_auc: 0.86049 |  0:00:30s\n",
      "epoch 36 | loss: 0.3869  | val_0_auc: 0.8663  |  0:00:31s\n",
      "epoch 37 | loss: 0.38661 | val_0_auc: 0.85294 |  0:00:31s\n",
      "epoch 38 | loss: 0.37378 | val_0_auc: 0.86572 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.88584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59046 | val_0_auc: 0.68838 |  0:00:00s\n",
      "epoch 1  | loss: 0.46104 | val_0_auc: 0.81256 |  0:00:01s\n",
      "epoch 2  | loss: 0.42368 | val_0_auc: 0.79949 |  0:00:02s\n",
      "epoch 3  | loss: 0.43133 | val_0_auc: 0.81278 |  0:00:03s\n",
      "epoch 4  | loss: 0.42741 | val_0_auc: 0.81852 |  0:00:03s\n",
      "epoch 5  | loss: 0.42286 | val_0_auc: 0.78453 |  0:00:04s\n",
      "epoch 6  | loss: 0.40002 | val_0_auc: 0.81394 |  0:00:05s\n",
      "epoch 7  | loss: 0.42993 | val_0_auc: 0.80218 |  0:00:06s\n",
      "epoch 8  | loss: 0.37702 | val_0_auc: 0.81365 |  0:00:07s\n",
      "epoch 9  | loss: 0.41325 | val_0_auc: 0.78555 |  0:00:07s\n",
      "epoch 10 | loss: 0.42309 | val_0_auc: 0.80465 |  0:00:08s\n",
      "epoch 11 | loss: 0.41186 | val_0_auc: 0.82077 |  0:00:09s\n",
      "epoch 12 | loss: 0.38927 | val_0_auc: 0.82716 |  0:00:10s\n",
      "epoch 13 | loss: 0.3787  | val_0_auc: 0.81147 |  0:00:11s\n",
      "epoch 14 | loss: 0.39578 | val_0_auc: 0.82614 |  0:00:11s\n",
      "epoch 15 | loss: 0.38718 | val_0_auc: 0.83711 |  0:00:12s\n",
      "epoch 16 | loss: 0.38213 | val_0_auc: 0.83834 |  0:00:13s\n",
      "epoch 17 | loss: 0.39391 | val_0_auc: 0.83333 |  0:00:14s\n",
      "epoch 18 | loss: 0.39582 | val_0_auc: 0.85345 |  0:00:14s\n",
      "epoch 19 | loss: 0.3706  | val_0_auc: 0.84641 |  0:00:15s\n",
      "epoch 20 | loss: 0.38506 | val_0_auc: 0.83043 |  0:00:16s\n",
      "epoch 21 | loss: 0.37487 | val_0_auc: 0.84967 |  0:00:17s\n",
      "epoch 22 | loss: 0.36789 | val_0_auc: 0.85955 |  0:00:18s\n",
      "epoch 23 | loss: 0.39801 | val_0_auc: 0.84524 |  0:00:18s\n",
      "epoch 24 | loss: 0.37571 | val_0_auc: 0.83885 |  0:00:19s\n",
      "epoch 25 | loss: 0.37905 | val_0_auc: 0.86173 |  0:00:20s\n",
      "epoch 26 | loss: 0.38198 | val_0_auc: 0.85977 |  0:00:21s\n",
      "epoch 27 | loss: 0.38522 | val_0_auc: 0.8634  |  0:00:22s\n",
      "epoch 28 | loss: 0.37217 | val_0_auc: 0.84771 |  0:00:23s\n",
      "epoch 29 | loss: 0.37277 | val_0_auc: 0.8642  |  0:00:24s\n",
      "epoch 30 | loss: 0.40127 | val_0_auc: 0.84648 |  0:00:24s\n",
      "epoch 31 | loss: 0.3772  | val_0_auc: 0.85505 |  0:00:25s\n",
      "epoch 32 | loss: 0.36108 | val_0_auc: 0.85214 |  0:00:26s\n",
      "epoch 33 | loss: 0.39445 | val_0_auc: 0.84902 |  0:00:27s\n",
      "epoch 34 | loss: 0.40059 | val_0_auc: 0.85011 |  0:00:28s\n",
      "epoch 35 | loss: 0.3763  | val_0_auc: 0.8589  |  0:00:29s\n",
      "epoch 36 | loss: 0.37168 | val_0_auc: 0.86391 |  0:00:29s\n",
      "epoch 37 | loss: 0.39318 | val_0_auc: 0.87705 |  0:00:30s\n",
      "epoch 38 | loss: 0.36895 | val_0_auc: 0.88344 |  0:00:31s\n",
      "epoch 39 | loss: 0.3649  | val_0_auc: 0.8557  |  0:00:32s\n",
      "epoch 40 | loss: 0.37815 | val_0_auc: 0.84706 |  0:00:33s\n",
      "epoch 41 | loss: 0.39269 | val_0_auc: 0.85744 |  0:00:34s\n",
      "epoch 42 | loss: 0.3864  | val_0_auc: 0.84553 |  0:00:35s\n",
      "epoch 43 | loss: 0.36111 | val_0_auc: 0.865   |  0:00:36s\n",
      "epoch 44 | loss: 0.36919 | val_0_auc: 0.87284 |  0:00:37s\n",
      "epoch 45 | loss: 0.3808  | val_0_auc: 0.86819 |  0:00:38s\n",
      "epoch 46 | loss: 0.40225 | val_0_auc: 0.85788 |  0:00:38s\n",
      "epoch 47 | loss: 0.35789 | val_0_auc: 0.84394 |  0:00:39s\n",
      "epoch 48 | loss: 0.38625 | val_0_auc: 0.84757 |  0:00:40s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.88344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5887  | val_0_auc: 0.82135 |  0:00:00s\n",
      "epoch 1  | loss: 0.47033 | val_0_auc: 0.77676 |  0:00:01s\n",
      "epoch 2  | loss: 0.43948 | val_0_auc: 0.78286 |  0:00:02s\n",
      "epoch 3  | loss: 0.45578 | val_0_auc: 0.80712 |  0:00:03s\n",
      "epoch 4  | loss: 0.46658 | val_0_auc: 0.83522 |  0:00:04s\n",
      "epoch 5  | loss: 0.42581 | val_0_auc: 0.8321  |  0:00:05s\n",
      "epoch 6  | loss: 0.4354  | val_0_auc: 0.84837 |  0:00:06s\n",
      "epoch 7  | loss: 0.44276 | val_0_auc: 0.84524 |  0:00:07s\n",
      "epoch 8  | loss: 0.42868 | val_0_auc: 0.86405 |  0:00:08s\n",
      "epoch 9  | loss: 0.39837 | val_0_auc: 0.86325 |  0:00:08s\n",
      "epoch 10 | loss: 0.42621 | val_0_auc: 0.85207 |  0:00:09s\n",
      "epoch 11 | loss: 0.40309 | val_0_auc: 0.86173 |  0:00:10s\n",
      "epoch 12 | loss: 0.42405 | val_0_auc: 0.87698 |  0:00:11s\n",
      "epoch 13 | loss: 0.416   | val_0_auc: 0.85955 |  0:00:12s\n",
      "epoch 14 | loss: 0.42885 | val_0_auc: 0.86696 |  0:00:12s\n",
      "epoch 15 | loss: 0.41203 | val_0_auc: 0.87233 |  0:00:13s\n",
      "epoch 16 | loss: 0.40547 | val_0_auc: 0.88729 |  0:00:14s\n",
      "epoch 17 | loss: 0.38345 | val_0_auc: 0.86819 |  0:00:15s\n",
      "epoch 18 | loss: 0.39643 | val_0_auc: 0.87988 |  0:00:16s\n",
      "epoch 19 | loss: 0.40399 | val_0_auc: 0.87422 |  0:00:17s\n",
      "epoch 20 | loss: 0.40175 | val_0_auc: 0.87306 |  0:00:17s\n",
      "epoch 21 | loss: 0.3932  | val_0_auc: 0.87727 |  0:00:18s\n",
      "epoch 22 | loss: 0.38434 | val_0_auc: 0.86086 |  0:00:19s\n",
      "epoch 23 | loss: 0.44583 | val_0_auc: 0.85897 |  0:00:20s\n",
      "epoch 24 | loss: 0.41674 | val_0_auc: 0.8634  |  0:00:21s\n",
      "epoch 25 | loss: 0.39593 | val_0_auc: 0.88497 |  0:00:22s\n",
      "epoch 26 | loss: 0.40073 | val_0_auc: 0.86245 |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.88729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64452 | val_0_auc: 0.78126 |  0:00:01s\n",
      "epoch 1  | loss: 0.48041 | val_0_auc: 0.82033 |  0:00:03s\n",
      "epoch 2  | loss: 0.47897 | val_0_auc: 0.76412 |  0:00:04s\n",
      "epoch 3  | loss: 0.4277  | val_0_auc: 0.79172 |  0:00:06s\n",
      "epoch 4  | loss: 0.41335 | val_0_auc: 0.7833  |  0:00:08s\n",
      "epoch 5  | loss: 0.41914 | val_0_auc: 0.80813 |  0:00:09s\n",
      "epoch 6  | loss: 0.40847 | val_0_auc: 0.84706 |  0:00:11s\n",
      "epoch 7  | loss: 0.46231 | val_0_auc: 0.78765 |  0:00:13s\n",
      "epoch 8  | loss: 0.38314 | val_0_auc: 0.84982 |  0:00:14s\n",
      "epoch 9  | loss: 0.39949 | val_0_auc: 0.82789 |  0:00:16s\n",
      "epoch 10 | loss: 0.40895 | val_0_auc: 0.8398  |  0:00:18s\n",
      "epoch 11 | loss: 0.38627 | val_0_auc: 0.80102 |  0:00:20s\n",
      "epoch 12 | loss: 0.38368 | val_0_auc: 0.84459 |  0:00:22s\n",
      "epoch 13 | loss: 0.40438 | val_0_auc: 0.82062 |  0:00:24s\n",
      "epoch 14 | loss: 0.39394 | val_0_auc: 0.83413 |  0:00:25s\n",
      "epoch 15 | loss: 0.36674 | val_0_auc: 0.84488 |  0:00:27s\n",
      "epoch 16 | loss: 0.40975 | val_0_auc: 0.85272 |  0:00:28s\n",
      "epoch 17 | loss: 0.37358 | val_0_auc: 0.86667 |  0:00:30s\n",
      "epoch 18 | loss: 0.38338 | val_0_auc: 0.85221 |  0:00:31s\n",
      "epoch 19 | loss: 0.39892 | val_0_auc: 0.88344 |  0:00:33s\n",
      "epoch 20 | loss: 0.37805 | val_0_auc: 0.90247 |  0:00:34s\n",
      "epoch 21 | loss: 0.38298 | val_0_auc: 0.88417 |  0:00:36s\n",
      "epoch 22 | loss: 0.39382 | val_0_auc: 0.88519 |  0:00:38s\n",
      "epoch 23 | loss: 0.37017 | val_0_auc: 0.88511 |  0:00:39s\n",
      "epoch 24 | loss: 0.39046 | val_0_auc: 0.89354 |  0:00:41s\n",
      "epoch 25 | loss: 0.37846 | val_0_auc: 0.8793  |  0:00:42s\n",
      "epoch 26 | loss: 0.39742 | val_0_auc: 0.90138 |  0:00:44s\n",
      "epoch 27 | loss: 0.39179 | val_0_auc: 0.90632 |  0:00:45s\n",
      "epoch 28 | loss: 0.36683 | val_0_auc: 0.87611 |  0:00:47s\n",
      "epoch 29 | loss: 0.35774 | val_0_auc: 0.8687  |  0:00:48s\n",
      "epoch 30 | loss: 0.37134 | val_0_auc: 0.89993 |  0:00:50s\n",
      "epoch 31 | loss: 0.40075 | val_0_auc: 0.90123 |  0:00:51s\n",
      "epoch 32 | loss: 0.38153 | val_0_auc: 0.89644 |  0:00:53s\n",
      "epoch 33 | loss: 0.38538 | val_0_auc: 0.89956 |  0:00:54s\n",
      "epoch 34 | loss: 0.36127 | val_0_auc: 0.89317 |  0:00:56s\n",
      "epoch 35 | loss: 0.34914 | val_0_auc: 0.89121 |  0:00:57s\n",
      "epoch 36 | loss: 0.36253 | val_0_auc: 0.89158 |  0:00:59s\n",
      "epoch 37 | loss: 0.37606 | val_0_auc: 0.89601 |  0:01:00s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.90632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71351 | val_0_auc: 0.64866 |  0:00:01s\n",
      "epoch 1  | loss: 0.47351 | val_0_auc: 0.67814 |  0:00:03s\n",
      "epoch 2  | loss: 0.50691 | val_0_auc: 0.81344 |  0:00:04s\n",
      "epoch 3  | loss: 0.4067  | val_0_auc: 0.8687  |  0:00:06s\n",
      "epoch 4  | loss: 0.41268 | val_0_auc: 0.83275 |  0:00:08s\n",
      "epoch 5  | loss: 0.41591 | val_0_auc: 0.86638 |  0:00:09s\n",
      "epoch 6  | loss: 0.39159 | val_0_auc: 0.87422 |  0:00:11s\n",
      "epoch 7  | loss: 0.45498 | val_0_auc: 0.86565 |  0:00:13s\n",
      "epoch 8  | loss: 0.39276 | val_0_auc: 0.86057 |  0:00:14s\n",
      "epoch 9  | loss: 0.41161 | val_0_auc: 0.87131 |  0:00:16s\n",
      "epoch 10 | loss: 0.42527 | val_0_auc: 0.88504 |  0:00:17s\n",
      "epoch 11 | loss: 0.4163  | val_0_auc: 0.86275 |  0:00:19s\n",
      "epoch 12 | loss: 0.39769 | val_0_auc: 0.84771 |  0:00:20s\n",
      "epoch 13 | loss: 0.37287 | val_0_auc: 0.86434 |  0:00:22s\n",
      "epoch 14 | loss: 0.39479 | val_0_auc: 0.85664 |  0:00:23s\n",
      "epoch 15 | loss: 0.371   | val_0_auc: 0.85069 |  0:00:25s\n",
      "epoch 16 | loss: 0.39694 | val_0_auc: 0.87146 |  0:00:26s\n",
      "epoch 17 | loss: 0.41227 | val_0_auc: 0.87698 |  0:00:28s\n",
      "epoch 18 | loss: 0.3895  | val_0_auc: 0.85781 |  0:00:29s\n",
      "epoch 19 | loss: 0.3813  | val_0_auc: 0.88962 |  0:00:31s\n",
      "epoch 20 | loss: 0.37352 | val_0_auc: 0.85795 |  0:00:32s\n",
      "epoch 21 | loss: 0.38731 | val_0_auc: 0.85098 |  0:00:34s\n",
      "epoch 22 | loss: 0.39151 | val_0_auc: 0.86405 |  0:00:35s\n",
      "epoch 23 | loss: 0.39482 | val_0_auc: 0.86899 |  0:00:37s\n",
      "epoch 24 | loss: 0.41777 | val_0_auc: 0.87175 |  0:00:38s\n",
      "epoch 25 | loss: 0.39592 | val_0_auc: 0.89891 |  0:00:40s\n",
      "epoch 26 | loss: 0.37718 | val_0_auc: 0.84953 |  0:00:41s\n",
      "epoch 27 | loss: 0.42435 | val_0_auc: 0.88017 |  0:00:43s\n",
      "epoch 28 | loss: 0.38881 | val_0_auc: 0.85439 |  0:00:44s\n",
      "epoch 29 | loss: 0.38236 | val_0_auc: 0.88809 |  0:00:45s\n",
      "epoch 30 | loss: 0.39374 | val_0_auc: 0.88656 |  0:00:47s\n",
      "epoch 31 | loss: 0.38227 | val_0_auc: 0.87582 |  0:00:48s\n",
      "epoch 32 | loss: 0.38818 | val_0_auc: 0.89237 |  0:00:50s\n",
      "epoch 33 | loss: 0.37585 | val_0_auc: 0.89049 |  0:00:52s\n",
      "epoch 34 | loss: 0.37688 | val_0_auc: 0.87495 |  0:00:53s\n",
      "epoch 35 | loss: 0.3658  | val_0_auc: 0.88003 |  0:00:55s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.89891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76986 | val_0_auc: 0.87364 |  0:00:01s\n",
      "epoch 1  | loss: 0.49684 | val_0_auc: 0.7695  |  0:00:03s\n",
      "epoch 2  | loss: 0.50229 | val_0_auc: 0.84532 |  0:00:04s\n",
      "epoch 3  | loss: 0.41259 | val_0_auc: 0.75527 |  0:00:06s\n",
      "epoch 4  | loss: 0.45346 | val_0_auc: 0.82992 |  0:00:08s\n",
      "epoch 5  | loss: 0.42796 | val_0_auc: 0.85752 |  0:00:09s\n",
      "epoch 6  | loss: 0.41753 | val_0_auc: 0.82498 |  0:00:11s\n",
      "epoch 7  | loss: 0.45705 | val_0_auc: 0.79375 |  0:00:13s\n",
      "epoch 8  | loss: 0.3789  | val_0_auc: 0.86826 |  0:00:15s\n",
      "epoch 9  | loss: 0.40549 | val_0_auc: 0.84779 |  0:00:17s\n",
      "epoch 10 | loss: 0.39499 | val_0_auc: 0.8337  |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.87364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71463 | val_0_auc: 0.60523 |  0:00:01s\n",
      "epoch 1  | loss: 0.46673 | val_0_auc: 0.8199  |  0:00:03s\n",
      "epoch 2  | loss: 0.46752 | val_0_auc: 0.81975 |  0:00:05s\n",
      "epoch 3  | loss: 0.41717 | val_0_auc: 0.78272 |  0:00:06s\n",
      "epoch 4  | loss: 0.44266 | val_0_auc: 0.83805 |  0:00:08s\n",
      "epoch 5  | loss: 0.41389 | val_0_auc: 0.70153 |  0:00:10s\n",
      "epoch 6  | loss: 0.41334 | val_0_auc: 0.75512 |  0:00:11s\n",
      "epoch 7  | loss: 0.40964 | val_0_auc: 0.85853 |  0:00:12s\n",
      "epoch 8  | loss: 0.38907 | val_0_auc: 0.85069 |  0:00:14s\n",
      "epoch 9  | loss: 0.37618 | val_0_auc: 0.8504  |  0:00:15s\n",
      "epoch 10 | loss: 0.41435 | val_0_auc: 0.83253 |  0:00:17s\n",
      "epoch 11 | loss: 0.45285 | val_0_auc: 0.83551 |  0:00:18s\n",
      "epoch 12 | loss: 0.41258 | val_0_auc: 0.82963 |  0:00:20s\n",
      "epoch 13 | loss: 0.3756  | val_0_auc: 0.85047 |  0:00:21s\n",
      "epoch 14 | loss: 0.42419 | val_0_auc: 0.8687  |  0:00:23s\n",
      "epoch 15 | loss: 0.38125 | val_0_auc: 0.85657 |  0:00:24s\n",
      "epoch 16 | loss: 0.39403 | val_0_auc: 0.85933 |  0:00:26s\n",
      "epoch 17 | loss: 0.39753 | val_0_auc: 0.86623 |  0:00:27s\n",
      "epoch 18 | loss: 0.40623 | val_0_auc: 0.85664 |  0:00:29s\n",
      "epoch 19 | loss: 0.407   | val_0_auc: 0.87676 |  0:00:30s\n",
      "epoch 20 | loss: 0.38588 | val_0_auc: 0.88722 |  0:00:32s\n",
      "epoch 21 | loss: 0.39414 | val_0_auc: 0.88983 |  0:00:33s\n",
      "epoch 22 | loss: 0.39241 | val_0_auc: 0.8634  |  0:00:35s\n",
      "epoch 23 | loss: 0.40218 | val_0_auc: 0.87611 |  0:00:36s\n",
      "epoch 24 | loss: 0.39988 | val_0_auc: 0.88613 |  0:00:38s\n",
      "epoch 25 | loss: 0.39659 | val_0_auc: 0.8825  |  0:00:39s\n",
      "epoch 26 | loss: 0.37244 | val_0_auc: 0.88192 |  0:00:41s\n",
      "epoch 27 | loss: 0.38014 | val_0_auc: 0.88736 |  0:00:43s\n",
      "epoch 28 | loss: 0.38334 | val_0_auc: 0.87487 |  0:00:44s\n",
      "epoch 29 | loss: 0.40564 | val_0_auc: 0.8785  |  0:00:46s\n",
      "epoch 30 | loss: 0.36064 | val_0_auc: 0.88751 |  0:00:47s\n",
      "epoch 31 | loss: 0.37951 | val_0_auc: 0.90116 |  0:00:49s\n",
      "epoch 32 | loss: 0.36331 | val_0_auc: 0.89724 |  0:00:50s\n",
      "epoch 33 | loss: 0.38198 | val_0_auc: 0.89811 |  0:00:52s\n",
      "epoch 34 | loss: 0.37345 | val_0_auc: 0.89332 |  0:00:53s\n",
      "epoch 35 | loss: 0.38568 | val_0_auc: 0.90015 |  0:00:55s\n",
      "epoch 36 | loss: 0.39147 | val_0_auc: 0.89753 |  0:00:56s\n",
      "epoch 37 | loss: 0.3663  | val_0_auc: 0.89564 |  0:00:58s\n",
      "epoch 38 | loss: 0.3737  | val_0_auc: 0.89158 |  0:01:00s\n",
      "epoch 39 | loss: 0.37742 | val_0_auc: 0.89099 |  0:01:01s\n",
      "epoch 40 | loss: 0.37482 | val_0_auc: 0.87901 |  0:01:03s\n",
      "epoch 41 | loss: 0.37378 | val_0_auc: 0.89739 |  0:01:04s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.90116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.73872 | val_0_auc: 0.76601 |  0:00:01s\n",
      "epoch 1  | loss: 0.54129 | val_0_auc: 0.71888 |  0:00:03s\n",
      "epoch 2  | loss: 0.48884 | val_0_auc: 0.76296 |  0:00:04s\n",
      "epoch 3  | loss: 0.46313 | val_0_auc: 0.80922 |  0:00:06s\n",
      "epoch 4  | loss: 0.49178 | val_0_auc: 0.80566 |  0:00:07s\n",
      "epoch 5  | loss: 0.46184 | val_0_auc: 0.82019 |  0:00:09s\n",
      "epoch 6  | loss: 0.43258 | val_0_auc: 0.80261 |  0:00:10s\n",
      "epoch 7  | loss: 0.44133 | val_0_auc: 0.82905 |  0:00:12s\n",
      "epoch 8  | loss: 0.4319  | val_0_auc: 0.84372 |  0:00:13s\n",
      "epoch 9  | loss: 0.43744 | val_0_auc: 0.83842 |  0:00:15s\n",
      "epoch 10 | loss: 0.41901 | val_0_auc: 0.85563 |  0:00:16s\n",
      "epoch 11 | loss: 0.41791 | val_0_auc: 0.85476 |  0:00:18s\n",
      "epoch 12 | loss: 0.40907 | val_0_auc: 0.84619 |  0:00:19s\n",
      "epoch 13 | loss: 0.3973  | val_0_auc: 0.86028 |  0:00:21s\n",
      "epoch 14 | loss: 0.43164 | val_0_auc: 0.84401 |  0:00:22s\n",
      "epoch 15 | loss: 0.42826 | val_0_auc: 0.8305  |  0:00:24s\n",
      "epoch 16 | loss: 0.42404 | val_0_auc: 0.86173 |  0:00:25s\n",
      "epoch 17 | loss: 0.4074  | val_0_auc: 0.87044 |  0:00:27s\n",
      "epoch 18 | loss: 0.41582 | val_0_auc: 0.87858 |  0:00:29s\n",
      "epoch 19 | loss: 0.43837 | val_0_auc: 0.86362 |  0:00:30s\n",
      "epoch 20 | loss: 0.4121  | val_0_auc: 0.86885 |  0:00:32s\n",
      "epoch 21 | loss: 0.40504 | val_0_auc: 0.86957 |  0:00:33s\n",
      "epoch 22 | loss: 0.40984 | val_0_auc: 0.85577 |  0:00:35s\n",
      "epoch 23 | loss: 0.39372 | val_0_auc: 0.86478 |  0:00:36s\n",
      "epoch 24 | loss: 0.4094  | val_0_auc: 0.87959 |  0:00:38s\n",
      "epoch 25 | loss: 0.42293 | val_0_auc: 0.85243 |  0:00:39s\n",
      "epoch 26 | loss: 0.41051 | val_0_auc: 0.86086 |  0:00:41s\n",
      "epoch 27 | loss: 0.40944 | val_0_auc: 0.85316 |  0:00:42s\n",
      "epoch 28 | loss: 0.40061 | val_0_auc: 0.85962 |  0:00:44s\n",
      "epoch 29 | loss: 0.39757 | val_0_auc: 0.85752 |  0:00:46s\n",
      "epoch 30 | loss: 0.40948 | val_0_auc: 0.8459  |  0:00:47s\n",
      "epoch 31 | loss: 0.38881 | val_0_auc: 0.8719  |  0:00:49s\n",
      "epoch 32 | loss: 0.41883 | val_0_auc: 0.8716  |  0:00:50s\n",
      "epoch 33 | loss: 0.42822 | val_0_auc: 0.86826 |  0:00:52s\n",
      "epoch 34 | loss: 0.39932 | val_0_auc: 0.87088 |  0:00:53s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.87959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55985 | val_0_auc: 0.79942 |  0:00:00s\n",
      "epoch 1  | loss: 0.38174 | val_0_auc: 0.84256 |  0:00:01s\n",
      "epoch 2  | loss: 0.39789 | val_0_auc: 0.85773 |  0:00:02s\n",
      "epoch 3  | loss: 0.38382 | val_0_auc: 0.86195 |  0:00:03s\n",
      "epoch 4  | loss: 0.41007 | val_0_auc: 0.85091 |  0:00:03s\n",
      "epoch 5  | loss: 0.39826 | val_0_auc: 0.84103 |  0:00:04s\n",
      "epoch 6  | loss: 0.37241 | val_0_auc: 0.8345  |  0:00:05s\n",
      "epoch 7  | loss: 0.38416 | val_0_auc: 0.8374  |  0:00:05s\n",
      "epoch 8  | loss: 0.36562 | val_0_auc: 0.85272 |  0:00:06s\n",
      "epoch 9  | loss: 0.39696 | val_0_auc: 0.86681 |  0:00:07s\n",
      "epoch 10 | loss: 0.38429 | val_0_auc: 0.87698 |  0:00:08s\n",
      "epoch 11 | loss: 0.36466 | val_0_auc: 0.88932 |  0:00:08s\n",
      "epoch 12 | loss: 0.39066 | val_0_auc: 0.87117 |  0:00:09s\n",
      "epoch 13 | loss: 0.37105 | val_0_auc: 0.87044 |  0:00:10s\n",
      "epoch 14 | loss: 0.36937 | val_0_auc: 0.88279 |  0:00:11s\n",
      "epoch 15 | loss: 0.37156 | val_0_auc: 0.88126 |  0:00:11s\n",
      "epoch 16 | loss: 0.36672 | val_0_auc: 0.8533  |  0:00:12s\n",
      "epoch 17 | loss: 0.37532 | val_0_auc: 0.87233 |  0:00:13s\n",
      "epoch 18 | loss: 0.35088 | val_0_auc: 0.87124 |  0:00:14s\n",
      "epoch 19 | loss: 0.3693  | val_0_auc: 0.87691 |  0:00:15s\n",
      "epoch 20 | loss: 0.35789 | val_0_auc: 0.86318 |  0:00:15s\n",
      "epoch 21 | loss: 0.34116 | val_0_auc: 0.85962 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.88932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53834 | val_0_auc: 0.82854 |  0:00:00s\n",
      "epoch 1  | loss: 0.44216 | val_0_auc: 0.79129 |  0:00:01s\n",
      "epoch 2  | loss: 0.41271 | val_0_auc: 0.81235 |  0:00:02s\n",
      "epoch 3  | loss: 0.42467 | val_0_auc: 0.83544 |  0:00:03s\n",
      "epoch 4  | loss: 0.42671 | val_0_auc: 0.85679 |  0:00:03s\n",
      "epoch 5  | loss: 0.40967 | val_0_auc: 0.8398  |  0:00:04s\n",
      "epoch 6  | loss: 0.40136 | val_0_auc: 0.83123 |  0:00:05s\n",
      "epoch 7  | loss: 0.40909 | val_0_auc: 0.86245 |  0:00:06s\n",
      "epoch 8  | loss: 0.39729 | val_0_auc: 0.84343 |  0:00:07s\n",
      "epoch 9  | loss: 0.40415 | val_0_auc: 0.8398  |  0:00:07s\n",
      "epoch 10 | loss: 0.40806 | val_0_auc: 0.81365 |  0:00:08s\n",
      "epoch 11 | loss: 0.40016 | val_0_auc: 0.83602 |  0:00:09s\n",
      "epoch 12 | loss: 0.38602 | val_0_auc: 0.87204 |  0:00:09s\n",
      "epoch 13 | loss: 0.41575 | val_0_auc: 0.87669 |  0:00:10s\n",
      "epoch 14 | loss: 0.39025 | val_0_auc: 0.85737 |  0:00:11s\n",
      "epoch 15 | loss: 0.40497 | val_0_auc: 0.8642  |  0:00:12s\n",
      "epoch 16 | loss: 0.37952 | val_0_auc: 0.85948 |  0:00:12s\n",
      "epoch 17 | loss: 0.36778 | val_0_auc: 0.87037 |  0:00:13s\n",
      "epoch 18 | loss: 0.38697 | val_0_auc: 0.85577 |  0:00:14s\n",
      "epoch 19 | loss: 0.37294 | val_0_auc: 0.85447 |  0:00:15s\n",
      "epoch 20 | loss: 0.37144 | val_0_auc: 0.86841 |  0:00:15s\n",
      "epoch 21 | loss: 0.37069 | val_0_auc: 0.8594  |  0:00:16s\n",
      "epoch 22 | loss: 0.36403 | val_0_auc: 0.84227 |  0:00:17s\n",
      "epoch 23 | loss: 0.36027 | val_0_auc: 0.84503 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.87669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58451 | val_0_auc: 0.8342  |  0:00:00s\n",
      "epoch 1  | loss: 0.49178 | val_0_auc: 0.86231 |  0:00:01s\n",
      "epoch 2  | loss: 0.4116  | val_0_auc: 0.8366  |  0:00:02s\n",
      "epoch 3  | loss: 0.40556 | val_0_auc: 0.81917 |  0:00:02s\n",
      "epoch 4  | loss: 0.40865 | val_0_auc: 0.848   |  0:00:03s\n",
      "epoch 5  | loss: 0.40807 | val_0_auc: 0.82004 |  0:00:04s\n",
      "epoch 6  | loss: 0.41034 | val_0_auc: 0.82571 |  0:00:05s\n",
      "epoch 7  | loss: 0.41808 | val_0_auc: 0.8045  |  0:00:06s\n",
      "epoch 8  | loss: 0.43095 | val_0_auc: 0.81656 |  0:00:06s\n",
      "epoch 9  | loss: 0.39915 | val_0_auc: 0.81757 |  0:00:07s\n",
      "epoch 10 | loss: 0.38574 | val_0_auc: 0.83297 |  0:00:08s\n",
      "epoch 11 | loss: 0.39328 | val_0_auc: 0.83079 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.86231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52663 | val_0_auc: 0.85301 |  0:00:00s\n",
      "epoch 1  | loss: 0.47171 | val_0_auc: 0.83079 |  0:00:01s\n",
      "epoch 2  | loss: 0.44397 | val_0_auc: 0.81278 |  0:00:02s\n",
      "epoch 3  | loss: 0.39836 | val_0_auc: 0.77023 |  0:00:03s\n",
      "epoch 4  | loss: 0.42866 | val_0_auc: 0.7939  |  0:00:03s\n",
      "epoch 5  | loss: 0.41119 | val_0_auc: 0.83675 |  0:00:04s\n",
      "epoch 6  | loss: 0.40638 | val_0_auc: 0.81474 |  0:00:05s\n",
      "epoch 7  | loss: 0.43584 | val_0_auc: 0.80574 |  0:00:06s\n",
      "epoch 8  | loss: 0.42088 | val_0_auc: 0.84031 |  0:00:07s\n",
      "epoch 9  | loss: 0.39075 | val_0_auc: 0.86797 |  0:00:07s\n",
      "epoch 10 | loss: 0.37208 | val_0_auc: 0.88112 |  0:00:08s\n",
      "epoch 11 | loss: 0.39148 | val_0_auc: 0.86187 |  0:00:09s\n",
      "epoch 12 | loss: 0.38044 | val_0_auc: 0.85723 |  0:00:10s\n",
      "epoch 13 | loss: 0.39506 | val_0_auc: 0.84713 |  0:00:10s\n",
      "epoch 14 | loss: 0.3967  | val_0_auc: 0.84132 |  0:00:11s\n",
      "epoch 15 | loss: 0.4021  | val_0_auc: 0.88184 |  0:00:13s\n",
      "epoch 16 | loss: 0.37349 | val_0_auc: 0.88301 |  0:00:14s\n",
      "epoch 17 | loss: 0.38731 | val_0_auc: 0.87662 |  0:00:15s\n",
      "epoch 18 | loss: 0.37593 | val_0_auc: 0.87996 |  0:00:16s\n",
      "epoch 19 | loss: 0.38104 | val_0_auc: 0.87603 |  0:00:16s\n",
      "epoch 20 | loss: 0.38322 | val_0_auc: 0.88192 |  0:00:17s\n",
      "epoch 21 | loss: 0.37902 | val_0_auc: 0.88351 |  0:00:18s\n",
      "epoch 22 | loss: 0.37544 | val_0_auc: 0.88322 |  0:00:19s\n",
      "epoch 23 | loss: 0.39834 | val_0_auc: 0.86855 |  0:00:19s\n",
      "epoch 24 | loss: 0.37798 | val_0_auc: 0.87647 |  0:00:20s\n",
      "epoch 25 | loss: 0.38159 | val_0_auc: 0.87393 |  0:00:21s\n",
      "epoch 26 | loss: 0.39072 | val_0_auc: 0.87211 |  0:00:22s\n",
      "epoch 27 | loss: 0.37108 | val_0_auc: 0.88562 |  0:00:22s\n",
      "epoch 28 | loss: 0.39013 | val_0_auc: 0.8748  |  0:00:23s\n",
      "epoch 29 | loss: 0.37122 | val_0_auc: 0.88853 |  0:00:24s\n",
      "epoch 30 | loss: 0.37187 | val_0_auc: 0.88163 |  0:00:24s\n",
      "epoch 31 | loss: 0.3791  | val_0_auc: 0.8634  |  0:00:25s\n",
      "epoch 32 | loss: 0.38764 | val_0_auc: 0.8886  |  0:00:26s\n",
      "epoch 33 | loss: 0.37351 | val_0_auc: 0.88533 |  0:00:27s\n",
      "epoch 34 | loss: 0.38618 | val_0_auc: 0.8862  |  0:00:28s\n",
      "epoch 35 | loss: 0.37996 | val_0_auc: 0.89267 |  0:00:28s\n",
      "epoch 36 | loss: 0.38381 | val_0_auc: 0.89412 |  0:00:29s\n",
      "epoch 37 | loss: 0.37179 | val_0_auc: 0.88003 |  0:00:30s\n",
      "epoch 38 | loss: 0.38287 | val_0_auc: 0.86739 |  0:00:30s\n",
      "epoch 39 | loss: 0.36602 | val_0_auc: 0.88773 |  0:00:31s\n",
      "epoch 40 | loss: 0.35822 | val_0_auc: 0.89971 |  0:00:32s\n",
      "epoch 41 | loss: 0.36114 | val_0_auc: 0.88068 |  0:00:33s\n",
      "epoch 42 | loss: 0.35712 | val_0_auc: 0.8833  |  0:00:33s\n",
      "epoch 43 | loss: 0.36495 | val_0_auc: 0.88686 |  0:00:34s\n",
      "epoch 44 | loss: 0.36438 | val_0_auc: 0.88482 |  0:00:35s\n",
      "epoch 45 | loss: 0.36112 | val_0_auc: 0.88112 |  0:00:36s\n",
      "epoch 46 | loss: 0.37579 | val_0_auc: 0.88076 |  0:00:37s\n",
      "epoch 47 | loss: 0.38436 | val_0_auc: 0.88214 |  0:00:37s\n",
      "epoch 48 | loss: 0.3593  | val_0_auc: 0.8817  |  0:00:38s\n",
      "epoch 49 | loss: 0.35742 | val_0_auc: 0.88635 |  0:00:39s\n",
      "epoch 50 | loss: 0.35503 | val_0_auc: 0.89143 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.89971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61727 | val_0_auc: 0.81017 |  0:00:00s\n",
      "epoch 1  | loss: 0.46373 | val_0_auc: 0.82498 |  0:00:01s\n",
      "epoch 2  | loss: 0.42243 | val_0_auc: 0.77858 |  0:00:02s\n",
      "epoch 3  | loss: 0.43182 | val_0_auc: 0.81511 |  0:00:03s\n",
      "epoch 4  | loss: 0.39922 | val_0_auc: 0.88148 |  0:00:03s\n",
      "epoch 5  | loss: 0.40025 | val_0_auc: 0.8854  |  0:00:04s\n",
      "epoch 6  | loss: 0.43189 | val_0_auc: 0.87567 |  0:00:05s\n",
      "epoch 7  | loss: 0.3885  | val_0_auc: 0.86318 |  0:00:06s\n",
      "epoch 8  | loss: 0.40952 | val_0_auc: 0.8719  |  0:00:06s\n",
      "epoch 9  | loss: 0.40709 | val_0_auc: 0.86732 |  0:00:07s\n",
      "epoch 10 | loss: 0.40512 | val_0_auc: 0.87226 |  0:00:08s\n",
      "epoch 11 | loss: 0.42471 | val_0_auc: 0.88707 |  0:00:08s\n",
      "epoch 12 | loss: 0.40844 | val_0_auc: 0.84757 |  0:00:09s\n",
      "epoch 13 | loss: 0.40662 | val_0_auc: 0.85229 |  0:00:10s\n",
      "epoch 14 | loss: 0.40155 | val_0_auc: 0.86071 |  0:00:11s\n",
      "epoch 15 | loss: 0.40632 | val_0_auc: 0.8902  |  0:00:11s\n",
      "epoch 16 | loss: 0.3848  | val_0_auc: 0.87959 |  0:00:12s\n",
      "epoch 17 | loss: 0.40733 | val_0_auc: 0.89121 |  0:00:13s\n",
      "epoch 18 | loss: 0.39275 | val_0_auc: 0.89673 |  0:00:14s\n",
      "epoch 19 | loss: 0.40359 | val_0_auc: 0.88279 |  0:00:14s\n",
      "epoch 20 | loss: 0.42643 | val_0_auc: 0.87175 |  0:00:15s\n",
      "epoch 21 | loss: 0.40396 | val_0_auc: 0.8687  |  0:00:16s\n",
      "epoch 22 | loss: 0.40098 | val_0_auc: 0.87335 |  0:00:17s\n",
      "epoch 23 | loss: 0.41052 | val_0_auc: 0.87567 |  0:00:17s\n",
      "epoch 24 | loss: 0.39746 | val_0_auc: 0.86195 |  0:00:18s\n",
      "epoch 25 | loss: 0.39499 | val_0_auc: 0.86754 |  0:00:19s\n",
      "epoch 26 | loss: 0.38914 | val_0_auc: 0.86957 |  0:00:19s\n",
      "epoch 27 | loss: 0.40511 | val_0_auc: 0.89346 |  0:00:20s\n",
      "epoch 28 | loss: 0.37955 | val_0_auc: 0.89572 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.89673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.67491 | val_0_auc: 0.76732 |  0:00:01s\n",
      "epoch 1  | loss: 0.56773 | val_0_auc: 0.83137 |  0:00:02s\n",
      "epoch 2  | loss: 0.46249 | val_0_auc: 0.83065 |  0:00:03s\n",
      "epoch 3  | loss: 0.40824 | val_0_auc: 0.79768 |  0:00:05s\n",
      "epoch 4  | loss: 0.39125 | val_0_auc: 0.86507 |  0:00:06s\n",
      "epoch 5  | loss: 0.40241 | val_0_auc: 0.84212 |  0:00:07s\n",
      "epoch 6  | loss: 0.43506 | val_0_auc: 0.84081 |  0:00:09s\n",
      "epoch 7  | loss: 0.43017 | val_0_auc: 0.8244  |  0:00:10s\n",
      "epoch 8  | loss: 0.40686 | val_0_auc: 0.8289  |  0:00:11s\n",
      "epoch 9  | loss: 0.40977 | val_0_auc: 0.85534 |  0:00:12s\n",
      "epoch 10 | loss: 0.4269  | val_0_auc: 0.86173 |  0:00:14s\n",
      "epoch 11 | loss: 0.39429 | val_0_auc: 0.8533  |  0:00:15s\n",
      "epoch 12 | loss: 0.39567 | val_0_auc: 0.84488 |  0:00:16s\n",
      "epoch 13 | loss: 0.38608 | val_0_auc: 0.82861 |  0:00:17s\n",
      "epoch 14 | loss: 0.40415 | val_0_auc: 0.82266 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.86507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64889 | val_0_auc: 0.76892 |  0:00:01s\n",
      "epoch 1  | loss: 0.59237 | val_0_auc: 0.78649 |  0:00:02s\n",
      "epoch 2  | loss: 0.45449 | val_0_auc: 0.80218 |  0:00:03s\n",
      "epoch 3  | loss: 0.46181 | val_0_auc: 0.79419 |  0:00:05s\n",
      "epoch 4  | loss: 0.40579 | val_0_auc: 0.81118 |  0:00:06s\n",
      "epoch 5  | loss: 0.39616 | val_0_auc: 0.83486 |  0:00:07s\n",
      "epoch 6  | loss: 0.44539 | val_0_auc: 0.84517 |  0:00:08s\n",
      "epoch 7  | loss: 0.42403 | val_0_auc: 0.84299 |  0:00:10s\n",
      "epoch 8  | loss: 0.43598 | val_0_auc: 0.86449 |  0:00:11s\n",
      "epoch 9  | loss: 0.4262  | val_0_auc: 0.8504  |  0:00:12s\n",
      "epoch 10 | loss: 0.42731 | val_0_auc: 0.83159 |  0:00:13s\n",
      "epoch 11 | loss: 0.40802 | val_0_auc: 0.84212 |  0:00:15s\n",
      "epoch 12 | loss: 0.43293 | val_0_auc: 0.85025 |  0:00:16s\n",
      "epoch 13 | loss: 0.40437 | val_0_auc: 0.85113 |  0:00:17s\n",
      "epoch 14 | loss: 0.40002 | val_0_auc: 0.85301 |  0:00:19s\n",
      "epoch 15 | loss: 0.40112 | val_0_auc: 0.86914 |  0:00:20s\n",
      "epoch 16 | loss: 0.39999 | val_0_auc: 0.84633 |  0:00:21s\n",
      "epoch 17 | loss: 0.38371 | val_0_auc: 0.85701 |  0:00:22s\n",
      "epoch 18 | loss: 0.38851 | val_0_auc: 0.86376 |  0:00:24s\n",
      "epoch 19 | loss: 0.39771 | val_0_auc: 0.8809  |  0:00:25s\n",
      "epoch 20 | loss: 0.38721 | val_0_auc: 0.87364 |  0:00:26s\n",
      "epoch 21 | loss: 0.37139 | val_0_auc: 0.87959 |  0:00:27s\n",
      "epoch 22 | loss: 0.38286 | val_0_auc: 0.88381 |  0:00:29s\n",
      "epoch 23 | loss: 0.37324 | val_0_auc: 0.90044 |  0:00:30s\n",
      "epoch 24 | loss: 0.39491 | val_0_auc: 0.89085 |  0:00:31s\n",
      "epoch 25 | loss: 0.39555 | val_0_auc: 0.86914 |  0:00:32s\n",
      "epoch 26 | loss: 0.39322 | val_0_auc: 0.8841  |  0:00:34s\n",
      "epoch 27 | loss: 0.38354 | val_0_auc: 0.89063 |  0:00:35s\n",
      "epoch 28 | loss: 0.40631 | val_0_auc: 0.88424 |  0:00:36s\n",
      "epoch 29 | loss: 0.38599 | val_0_auc: 0.8748  |  0:00:38s\n",
      "epoch 30 | loss: 0.38405 | val_0_auc: 0.88308 |  0:00:39s\n",
      "epoch 31 | loss: 0.37907 | val_0_auc: 0.88453 |  0:00:40s\n",
      "epoch 32 | loss: 0.38695 | val_0_auc: 0.87596 |  0:00:41s\n",
      "epoch 33 | loss: 0.39166 | val_0_auc: 0.87139 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.90044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.67462 | val_0_auc: 0.67015 |  0:00:01s\n",
      "epoch 1  | loss: 0.52646 | val_0_auc: 0.7024  |  0:00:02s\n",
      "epoch 2  | loss: 0.53118 | val_0_auc: 0.80203 |  0:00:04s\n",
      "epoch 3  | loss: 0.44755 | val_0_auc: 0.83036 |  0:00:05s\n",
      "epoch 4  | loss: 0.42421 | val_0_auc: 0.82237 |  0:00:06s\n",
      "epoch 5  | loss: 0.41447 | val_0_auc: 0.84473 |  0:00:07s\n",
      "epoch 6  | loss: 0.4216  | val_0_auc: 0.84001 |  0:00:09s\n",
      "epoch 7  | loss: 0.40548 | val_0_auc: 0.79956 |  0:00:10s\n",
      "epoch 8  | loss: 0.40937 | val_0_auc: 0.76747 |  0:00:11s\n",
      "epoch 9  | loss: 0.43341 | val_0_auc: 0.84394 |  0:00:13s\n",
      "epoch 10 | loss: 0.37775 | val_0_auc: 0.87988 |  0:00:14s\n",
      "epoch 11 | loss: 0.41427 | val_0_auc: 0.84982 |  0:00:15s\n",
      "epoch 12 | loss: 0.42335 | val_0_auc: 0.85185 |  0:00:16s\n",
      "epoch 13 | loss: 0.42762 | val_0_auc: 0.86275 |  0:00:18s\n",
      "epoch 14 | loss: 0.39814 | val_0_auc: 0.84691 |  0:00:19s\n",
      "epoch 15 | loss: 0.3972  | val_0_auc: 0.85708 |  0:00:20s\n",
      "epoch 16 | loss: 0.40071 | val_0_auc: 0.84314 |  0:00:21s\n",
      "epoch 17 | loss: 0.39694 | val_0_auc: 0.84096 |  0:00:23s\n",
      "epoch 18 | loss: 0.388   | val_0_auc: 0.8565  |  0:00:24s\n",
      "epoch 19 | loss: 0.40072 | val_0_auc: 0.85534 |  0:00:25s\n",
      "epoch 20 | loss: 0.38111 | val_0_auc: 0.8411  |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.87988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.81771 | val_0_auc: 0.80683 |  0:00:01s\n",
      "epoch 1  | loss: 0.52698 | val_0_auc: 0.84256 |  0:00:02s\n",
      "epoch 2  | loss: 0.42938 | val_0_auc: 0.83602 |  0:00:03s\n",
      "epoch 3  | loss: 0.42913 | val_0_auc: 0.85635 |  0:00:05s\n",
      "epoch 4  | loss: 0.41587 | val_0_auc: 0.852   |  0:00:06s\n",
      "epoch 5  | loss: 0.40655 | val_0_auc: 0.84023 |  0:00:07s\n",
      "epoch 6  | loss: 0.41478 | val_0_auc: 0.84749 |  0:00:08s\n",
      "epoch 7  | loss: 0.37128 | val_0_auc: 0.84256 |  0:00:10s\n",
      "epoch 8  | loss: 0.43019 | val_0_auc: 0.84749 |  0:00:11s\n",
      "epoch 9  | loss: 0.40536 | val_0_auc: 0.85476 |  0:00:12s\n",
      "epoch 10 | loss: 0.379   | val_0_auc: 0.84532 |  0:00:13s\n",
      "epoch 11 | loss: 0.42269 | val_0_auc: 0.861   |  0:00:15s\n",
      "epoch 12 | loss: 0.3917  | val_0_auc: 0.86333 |  0:00:16s\n",
      "epoch 13 | loss: 0.38516 | val_0_auc: 0.84735 |  0:00:17s\n",
      "epoch 14 | loss: 0.40005 | val_0_auc: 0.86144 |  0:00:19s\n",
      "epoch 15 | loss: 0.38301 | val_0_auc: 0.88337 |  0:00:20s\n",
      "epoch 16 | loss: 0.38971 | val_0_auc: 0.85708 |  0:00:21s\n",
      "epoch 17 | loss: 0.37394 | val_0_auc: 0.86347 |  0:00:22s\n",
      "epoch 18 | loss: 0.39304 | val_0_auc: 0.85984 |  0:00:24s\n",
      "epoch 19 | loss: 0.38633 | val_0_auc: 0.87073 |  0:00:25s\n",
      "epoch 20 | loss: 0.37211 | val_0_auc: 0.85839 |  0:00:26s\n",
      "epoch 21 | loss: 0.36099 | val_0_auc: 0.87466 |  0:00:27s\n",
      "epoch 22 | loss: 0.36989 | val_0_auc: 0.87509 |  0:00:29s\n",
      "epoch 23 | loss: 0.35801 | val_0_auc: 0.85969 |  0:00:30s\n",
      "epoch 24 | loss: 0.3463  | val_0_auc: 0.87451 |  0:00:31s\n",
      "epoch 25 | loss: 0.38596 | val_0_auc: 0.88555 |  0:00:33s\n",
      "epoch 26 | loss: 0.35951 | val_0_auc: 0.88163 |  0:00:34s\n",
      "epoch 27 | loss: 0.35463 | val_0_auc: 0.88003 |  0:00:35s\n",
      "epoch 28 | loss: 0.35514 | val_0_auc: 0.88598 |  0:00:36s\n",
      "epoch 29 | loss: 0.38369 | val_0_auc: 0.86086 |  0:00:38s\n",
      "epoch 30 | loss: 0.39169 | val_0_auc: 0.878   |  0:00:39s\n",
      "epoch 31 | loss: 0.40853 | val_0_auc: 0.88351 |  0:00:40s\n",
      "epoch 32 | loss: 0.37793 | val_0_auc: 0.88642 |  0:00:42s\n",
      "epoch 33 | loss: 0.37548 | val_0_auc: 0.88642 |  0:00:43s\n",
      "epoch 34 | loss: 0.3829  | val_0_auc: 0.87015 |  0:00:44s\n",
      "epoch 35 | loss: 0.3667  | val_0_auc: 0.87044 |  0:00:45s\n",
      "epoch 36 | loss: 0.39968 | val_0_auc: 0.87843 |  0:00:47s\n",
      "epoch 37 | loss: 0.36309 | val_0_auc: 0.89136 |  0:00:48s\n",
      "epoch 38 | loss: 0.37994 | val_0_auc: 0.89361 |  0:00:49s\n",
      "epoch 39 | loss: 0.37731 | val_0_auc: 0.89463 |  0:00:50s\n",
      "epoch 40 | loss: 0.38443 | val_0_auc: 0.87763 |  0:00:52s\n",
      "epoch 41 | loss: 0.39035 | val_0_auc: 0.88359 |  0:00:53s\n",
      "epoch 42 | loss: 0.34039 | val_0_auc: 0.89172 |  0:00:54s\n",
      "epoch 43 | loss: 0.37521 | val_0_auc: 0.87923 |  0:00:55s\n",
      "epoch 44 | loss: 0.35811 | val_0_auc: 0.8695  |  0:00:57s\n",
      "epoch 45 | loss: 0.3596  | val_0_auc: 0.8748  |  0:00:58s\n",
      "epoch 46 | loss: 0.39517 | val_0_auc: 0.87407 |  0:00:59s\n",
      "epoch 47 | loss: 0.37062 | val_0_auc: 0.89107 |  0:01:00s\n",
      "epoch 48 | loss: 0.37392 | val_0_auc: 0.89484 |  0:01:02s\n",
      "epoch 49 | loss: 0.3613  | val_0_auc: 0.89804 |  0:01:03s\n",
      "epoch 50 | loss: 0.371   | val_0_auc: 0.88627 |  0:01:04s\n",
      "epoch 51 | loss: 0.36225 | val_0_auc: 0.88613 |  0:01:06s\n",
      "epoch 52 | loss: 0.38632 | val_0_auc: 0.88076 |  0:01:07s\n",
      "epoch 53 | loss: 0.36538 | val_0_auc: 0.86943 |  0:01:08s\n",
      "epoch 54 | loss: 0.38241 | val_0_auc: 0.85062 |  0:01:09s\n",
      "epoch 55 | loss: 0.35809 | val_0_auc: 0.85476 |  0:01:11s\n",
      "epoch 56 | loss: 0.38087 | val_0_auc: 0.8719  |  0:01:12s\n",
      "epoch 57 | loss: 0.35902 | val_0_auc: 0.86318 |  0:01:13s\n",
      "epoch 58 | loss: 0.36797 | val_0_auc: 0.86754 |  0:01:15s\n",
      "epoch 59 | loss: 0.3599  | val_0_auc: 0.85309 |  0:01:16s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_auc = 0.89804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.75394 | val_0_auc: 0.72317 |  0:00:01s\n",
      "epoch 1  | loss: 0.58535 | val_0_auc: 0.84691 |  0:00:02s\n",
      "epoch 2  | loss: 0.46172 | val_0_auc: 0.53558 |  0:00:03s\n",
      "epoch 3  | loss: 0.48137 | val_0_auc: 0.83261 |  0:00:05s\n",
      "epoch 4  | loss: 0.46047 | val_0_auc: 0.7971  |  0:00:06s\n",
      "epoch 5  | loss: 0.45674 | val_0_auc: 0.84633 |  0:00:07s\n",
      "epoch 6  | loss: 0.45769 | val_0_auc: 0.81017 |  0:00:08s\n",
      "epoch 7  | loss: 0.42922 | val_0_auc: 0.83689 |  0:00:10s\n",
      "epoch 8  | loss: 0.42607 | val_0_auc: 0.84503 |  0:00:11s\n",
      "epoch 9  | loss: 0.43099 | val_0_auc: 0.85991 |  0:00:12s\n",
      "epoch 10 | loss: 0.41614 | val_0_auc: 0.83399 |  0:00:14s\n",
      "epoch 11 | loss: 0.43464 | val_0_auc: 0.84473 |  0:00:15s\n",
      "epoch 12 | loss: 0.4534  | val_0_auc: 0.852   |  0:00:16s\n",
      "epoch 13 | loss: 0.4237  | val_0_auc: 0.86224 |  0:00:18s\n",
      "epoch 14 | loss: 0.40445 | val_0_auc: 0.86696 |  0:00:19s\n",
      "epoch 15 | loss: 0.41282 | val_0_auc: 0.8581  |  0:00:20s\n",
      "epoch 16 | loss: 0.41544 | val_0_auc: 0.84081 |  0:00:22s\n",
      "epoch 17 | loss: 0.43261 | val_0_auc: 0.87059 |  0:00:23s\n",
      "epoch 18 | loss: 0.41959 | val_0_auc: 0.85621 |  0:00:24s\n",
      "epoch 19 | loss: 0.42368 | val_0_auc: 0.86623 |  0:00:26s\n",
      "epoch 20 | loss: 0.41084 | val_0_auc: 0.87553 |  0:00:27s\n",
      "epoch 21 | loss: 0.39086 | val_0_auc: 0.87611 |  0:00:28s\n",
      "epoch 22 | loss: 0.40426 | val_0_auc: 0.85919 |  0:00:29s\n",
      "epoch 23 | loss: 0.42183 | val_0_auc: 0.8671  |  0:00:31s\n",
      "epoch 24 | loss: 0.41457 | val_0_auc: 0.8748  |  0:00:32s\n",
      "epoch 25 | loss: 0.40034 | val_0_auc: 0.88598 |  0:00:33s\n",
      "epoch 26 | loss: 0.39682 | val_0_auc: 0.88903 |  0:00:34s\n",
      "epoch 27 | loss: 0.37975 | val_0_auc: 0.88337 |  0:00:36s\n",
      "epoch 28 | loss: 0.41111 | val_0_auc: 0.87814 |  0:00:37s\n",
      "epoch 29 | loss: 0.41978 | val_0_auc: 0.89993 |  0:00:38s\n",
      "epoch 30 | loss: 0.417   | val_0_auc: 0.8902  |  0:00:39s\n",
      "epoch 31 | loss: 0.40647 | val_0_auc: 0.88192 |  0:00:41s\n",
      "epoch 32 | loss: 0.37983 | val_0_auc: 0.89484 |  0:00:42s\n",
      "epoch 33 | loss: 0.40422 | val_0_auc: 0.87683 |  0:00:43s\n",
      "epoch 34 | loss: 0.40541 | val_0_auc: 0.88838 |  0:00:45s\n",
      "epoch 35 | loss: 0.41729 | val_0_auc: 0.88664 |  0:00:46s\n",
      "epoch 36 | loss: 0.39087 | val_0_auc: 0.88693 |  0:00:47s\n",
      "epoch 37 | loss: 0.40541 | val_0_auc: 0.90073 |  0:00:49s\n",
      "epoch 38 | loss: 0.37602 | val_0_auc: 0.88635 |  0:00:50s\n",
      "epoch 39 | loss: 0.40964 | val_0_auc: 0.89804 |  0:00:51s\n",
      "epoch 40 | loss: 0.41998 | val_0_auc: 0.87872 |  0:00:52s\n",
      "epoch 41 | loss: 0.39325 | val_0_auc: 0.88954 |  0:00:54s\n",
      "epoch 42 | loss: 0.39882 | val_0_auc: 0.89898 |  0:00:55s\n",
      "epoch 43 | loss: 0.40278 | val_0_auc: 0.88969 |  0:00:56s\n",
      "epoch 44 | loss: 0.4139  | val_0_auc: 0.87436 |  0:00:58s\n",
      "epoch 45 | loss: 0.3937  | val_0_auc: 0.88722 |  0:00:59s\n",
      "epoch 46 | loss: 0.40923 | val_0_auc: 0.85919 |  0:01:00s\n",
      "epoch 47 | loss: 0.37575 | val_0_auc: 0.86848 |  0:01:01s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.90073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.49761 | val_0_auc: 0.84633 |  0:00:00s\n",
      "epoch 1  | loss: 0.42293 | val_0_auc: 0.85265 |  0:00:01s\n",
      "epoch 2  | loss: 0.41589 | val_0_auc: 0.76209 |  0:00:02s\n",
      "epoch 3  | loss: 0.40303 | val_0_auc: 0.79884 |  0:00:03s\n",
      "epoch 4  | loss: 0.40767 | val_0_auc: 0.77386 |  0:00:04s\n",
      "epoch 5  | loss: 0.39761 | val_0_auc: 0.8093  |  0:00:05s\n",
      "epoch 6  | loss: 0.42937 | val_0_auc: 0.77778 |  0:00:06s\n",
      "epoch 7  | loss: 0.40358 | val_0_auc: 0.85236 |  0:00:06s\n",
      "epoch 8  | loss: 0.38043 | val_0_auc: 0.85359 |  0:00:07s\n",
      "epoch 9  | loss: 0.39595 | val_0_auc: 0.86768 |  0:00:08s\n",
      "epoch 10 | loss: 0.37747 | val_0_auc: 0.85969 |  0:00:09s\n",
      "epoch 11 | loss: 0.36931 | val_0_auc: 0.88344 |  0:00:10s\n",
      "epoch 12 | loss: 0.39474 | val_0_auc: 0.89753 |  0:00:11s\n",
      "epoch 13 | loss: 0.39667 | val_0_auc: 0.88751 |  0:00:11s\n",
      "epoch 14 | loss: 0.40433 | val_0_auc: 0.87291 |  0:00:12s\n",
      "epoch 15 | loss: 0.38207 | val_0_auc: 0.86797 |  0:00:13s\n",
      "epoch 16 | loss: 0.36438 | val_0_auc: 0.85127 |  0:00:14s\n",
      "epoch 17 | loss: 0.36176 | val_0_auc: 0.87625 |  0:00:15s\n",
      "epoch 18 | loss: 0.3861  | val_0_auc: 0.87509 |  0:00:16s\n",
      "epoch 19 | loss: 0.36356 | val_0_auc: 0.878   |  0:00:17s\n",
      "epoch 20 | loss: 0.38666 | val_0_auc: 0.87059 |  0:00:18s\n",
      "epoch 21 | loss: 0.37052 | val_0_auc: 0.86521 |  0:00:18s\n",
      "epoch 22 | loss: 0.38547 | val_0_auc: 0.86086 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.89753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54983 | val_0_auc: 0.80065 |  0:00:00s\n",
      "epoch 1  | loss: 0.46404 | val_0_auc: 0.83007 |  0:00:01s\n",
      "epoch 2  | loss: 0.4081  | val_0_auc: 0.8459  |  0:00:02s\n",
      "epoch 3  | loss: 0.424   | val_0_auc: 0.83007 |  0:00:03s\n",
      "epoch 4  | loss: 0.38874 | val_0_auc: 0.82745 |  0:00:04s\n",
      "epoch 5  | loss: 0.40878 | val_0_auc: 0.82789 |  0:00:05s\n",
      "epoch 6  | loss: 0.41408 | val_0_auc: 0.83457 |  0:00:05s\n",
      "epoch 7  | loss: 0.43956 | val_0_auc: 0.85098 |  0:00:06s\n",
      "epoch 8  | loss: 0.39385 | val_0_auc: 0.86899 |  0:00:07s\n",
      "epoch 9  | loss: 0.42211 | val_0_auc: 0.8658  |  0:00:08s\n",
      "epoch 10 | loss: 0.44761 | val_0_auc: 0.85882 |  0:00:09s\n",
      "epoch 11 | loss: 0.38895 | val_0_auc: 0.86362 |  0:00:10s\n",
      "epoch 12 | loss: 0.38737 | val_0_auc: 0.86623 |  0:00:11s\n",
      "epoch 13 | loss: 0.3975  | val_0_auc: 0.86863 |  0:00:12s\n",
      "epoch 14 | loss: 0.39731 | val_0_auc: 0.87262 |  0:00:12s\n",
      "epoch 15 | loss: 0.40894 | val_0_auc: 0.86899 |  0:00:13s\n",
      "epoch 16 | loss: 0.38258 | val_0_auc: 0.87988 |  0:00:14s\n",
      "epoch 17 | loss: 0.40256 | val_0_auc: 0.88286 |  0:00:15s\n",
      "epoch 18 | loss: 0.37568 | val_0_auc: 0.88627 |  0:00:16s\n",
      "epoch 19 | loss: 0.37839 | val_0_auc: 0.88308 |  0:00:17s\n",
      "epoch 20 | loss: 0.42207 | val_0_auc: 0.8841  |  0:00:18s\n",
      "epoch 21 | loss: 0.39656 | val_0_auc: 0.874   |  0:00:18s\n",
      "epoch 22 | loss: 0.40961 | val_0_auc: 0.88794 |  0:00:19s\n",
      "epoch 23 | loss: 0.35744 | val_0_auc: 0.89245 |  0:00:20s\n",
      "epoch 24 | loss: 0.38206 | val_0_auc: 0.90436 |  0:00:21s\n",
      "epoch 25 | loss: 0.39326 | val_0_auc: 0.89971 |  0:00:22s\n",
      "epoch 26 | loss: 0.37378 | val_0_auc: 0.90378 |  0:00:23s\n",
      "epoch 27 | loss: 0.37721 | val_0_auc: 0.90356 |  0:00:24s\n",
      "epoch 28 | loss: 0.38481 | val_0_auc: 0.90632 |  0:00:24s\n",
      "epoch 29 | loss: 0.39845 | val_0_auc: 0.90269 |  0:00:25s\n",
      "epoch 30 | loss: 0.37188 | val_0_auc: 0.90487 |  0:00:26s\n",
      "epoch 31 | loss: 0.38767 | val_0_auc: 0.90167 |  0:00:27s\n",
      "epoch 32 | loss: 0.37801 | val_0_auc: 0.89441 |  0:00:28s\n",
      "epoch 33 | loss: 0.3905  | val_0_auc: 0.89637 |  0:00:29s\n",
      "epoch 34 | loss: 0.39061 | val_0_auc: 0.8907  |  0:00:30s\n",
      "epoch 35 | loss: 0.37925 | val_0_auc: 0.89935 |  0:00:30s\n",
      "epoch 36 | loss: 0.38375 | val_0_auc: 0.90472 |  0:00:31s\n",
      "epoch 37 | loss: 0.38016 | val_0_auc: 0.90298 |  0:00:32s\n",
      "epoch 38 | loss: 0.36866 | val_0_auc: 0.90153 |  0:00:33s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.90632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54815 | val_0_auc: 0.71852 |  0:00:00s\n",
      "epoch 1  | loss: 0.45688 | val_0_auc: 0.71184 |  0:00:02s\n",
      "epoch 2  | loss: 0.41601 | val_0_auc: 0.86195 |  0:00:03s\n",
      "epoch 3  | loss: 0.43223 | val_0_auc: 0.80755 |  0:00:03s\n",
      "epoch 4  | loss: 0.43541 | val_0_auc: 0.83776 |  0:00:04s\n",
      "epoch 5  | loss: 0.39856 | val_0_auc: 0.81409 |  0:00:05s\n",
      "epoch 6  | loss: 0.41153 | val_0_auc: 0.77008 |  0:00:06s\n",
      "epoch 7  | loss: 0.4074  | val_0_auc: 0.80915 |  0:00:07s\n",
      "epoch 8  | loss: 0.39923 | val_0_auc: 0.83588 |  0:00:08s\n",
      "epoch 9  | loss: 0.40285 | val_0_auc: 0.83515 |  0:00:09s\n",
      "epoch 10 | loss: 0.41995 | val_0_auc: 0.81612 |  0:00:09s\n",
      "epoch 11 | loss: 0.40181 | val_0_auc: 0.83762 |  0:00:10s\n",
      "epoch 12 | loss: 0.41324 | val_0_auc: 0.86921 |  0:00:11s\n",
      "epoch 13 | loss: 0.4042  | val_0_auc: 0.85984 |  0:00:12s\n",
      "epoch 14 | loss: 0.3797  | val_0_auc: 0.85054 |  0:00:13s\n",
      "epoch 15 | loss: 0.42217 | val_0_auc: 0.83834 |  0:00:14s\n",
      "epoch 16 | loss: 0.37248 | val_0_auc: 0.85338 |  0:00:15s\n",
      "epoch 17 | loss: 0.40109 | val_0_auc: 0.82295 |  0:00:15s\n",
      "epoch 18 | loss: 0.40007 | val_0_auc: 0.88642 |  0:00:16s\n",
      "epoch 19 | loss: 0.41903 | val_0_auc: 0.88991 |  0:00:17s\n",
      "epoch 20 | loss: 0.41672 | val_0_auc: 0.84851 |  0:00:18s\n",
      "epoch 21 | loss: 0.38859 | val_0_auc: 0.85476 |  0:00:19s\n",
      "epoch 22 | loss: 0.39743 | val_0_auc: 0.85715 |  0:00:20s\n",
      "epoch 23 | loss: 0.39437 | val_0_auc: 0.86652 |  0:00:21s\n",
      "epoch 24 | loss: 0.39958 | val_0_auc: 0.8724  |  0:00:22s\n",
      "epoch 25 | loss: 0.38349 | val_0_auc: 0.87887 |  0:00:22s\n",
      "epoch 26 | loss: 0.3829  | val_0_auc: 0.86696 |  0:00:23s\n",
      "epoch 27 | loss: 0.37362 | val_0_auc: 0.86565 |  0:00:24s\n",
      "epoch 28 | loss: 0.39829 | val_0_auc: 0.86848 |  0:00:25s\n",
      "epoch 29 | loss: 0.38693 | val_0_auc: 0.89644 |  0:00:26s\n",
      "epoch 30 | loss: 0.37246 | val_0_auc: 0.88765 |  0:00:27s\n",
      "epoch 31 | loss: 0.37868 | val_0_auc: 0.87952 |  0:00:28s\n",
      "epoch 32 | loss: 0.38015 | val_0_auc: 0.88519 |  0:00:29s\n",
      "epoch 33 | loss: 0.38367 | val_0_auc: 0.88119 |  0:00:29s\n",
      "epoch 34 | loss: 0.40773 | val_0_auc: 0.86783 |  0:00:30s\n",
      "epoch 35 | loss: 0.39082 | val_0_auc: 0.8549  |  0:00:31s\n",
      "epoch 36 | loss: 0.40936 | val_0_auc: 0.82106 |  0:00:32s\n",
      "epoch 37 | loss: 0.40266 | val_0_auc: 0.85381 |  0:00:33s\n",
      "epoch 38 | loss: 0.39415 | val_0_auc: 0.86383 |  0:00:34s\n",
      "epoch 39 | loss: 0.37617 | val_0_auc: 0.87284 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.89644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56629 | val_0_auc: 0.78126 |  0:00:00s\n",
      "epoch 1  | loss: 0.4739  | val_0_auc: 0.84096 |  0:00:01s\n",
      "epoch 2  | loss: 0.40358 | val_0_auc: 0.81917 |  0:00:02s\n",
      "epoch 3  | loss: 0.4318  | val_0_auc: 0.73101 |  0:00:03s\n",
      "epoch 4  | loss: 0.43047 | val_0_auc: 0.79564 |  0:00:04s\n",
      "epoch 5  | loss: 0.38961 | val_0_auc: 0.80639 |  0:00:05s\n",
      "epoch 6  | loss: 0.41009 | val_0_auc: 0.77436 |  0:00:05s\n",
      "epoch 7  | loss: 0.39809 | val_0_auc: 0.84996 |  0:00:06s\n",
      "epoch 8  | loss: 0.38088 | val_0_auc: 0.79172 |  0:00:07s\n",
      "epoch 9  | loss: 0.412   | val_0_auc: 0.80508 |  0:00:08s\n",
      "epoch 10 | loss: 0.36682 | val_0_auc: 0.85287 |  0:00:09s\n",
      "epoch 11 | loss: 0.38723 | val_0_auc: 0.82527 |  0:00:10s\n",
      "epoch 12 | loss: 0.379   | val_0_auc: 0.83014 |  0:00:11s\n",
      "epoch 13 | loss: 0.39214 | val_0_auc: 0.8419  |  0:00:12s\n",
      "epoch 14 | loss: 0.36983 | val_0_auc: 0.83609 |  0:00:12s\n",
      "epoch 15 | loss: 0.41075 | val_0_auc: 0.81126 |  0:00:13s\n",
      "epoch 16 | loss: 0.35538 | val_0_auc: 0.83348 |  0:00:14s\n",
      "epoch 17 | loss: 0.37895 | val_0_auc: 0.86318 |  0:00:15s\n",
      "epoch 18 | loss: 0.37487 | val_0_auc: 0.82956 |  0:00:16s\n",
      "epoch 19 | loss: 0.38825 | val_0_auc: 0.85962 |  0:00:17s\n",
      "epoch 20 | loss: 0.40186 | val_0_auc: 0.85969 |  0:00:18s\n",
      "epoch 21 | loss: 0.38266 | val_0_auc: 0.83682 |  0:00:19s\n",
      "epoch 22 | loss: 0.36969 | val_0_auc: 0.84444 |  0:00:19s\n",
      "epoch 23 | loss: 0.36813 | val_0_auc: 0.87553 |  0:00:20s\n",
      "epoch 24 | loss: 0.38265 | val_0_auc: 0.87088 |  0:00:21s\n",
      "epoch 25 | loss: 0.36629 | val_0_auc: 0.878   |  0:00:22s\n",
      "epoch 26 | loss: 0.36121 | val_0_auc: 0.85606 |  0:00:23s\n",
      "epoch 27 | loss: 0.34679 | val_0_auc: 0.83784 |  0:00:24s\n",
      "epoch 28 | loss: 0.36722 | val_0_auc: 0.8504  |  0:00:25s\n",
      "epoch 29 | loss: 0.34415 | val_0_auc: 0.85868 |  0:00:25s\n",
      "epoch 30 | loss: 0.3643  | val_0_auc: 0.86347 |  0:00:26s\n",
      "epoch 31 | loss: 0.3902  | val_0_auc: 0.88257 |  0:00:27s\n",
      "epoch 32 | loss: 0.36352 | val_0_auc: 0.878   |  0:00:28s\n",
      "epoch 33 | loss: 0.36066 | val_0_auc: 0.83137 |  0:00:29s\n",
      "epoch 34 | loss: 0.39134 | val_0_auc: 0.8902  |  0:00:30s\n",
      "epoch 35 | loss: 0.37273 | val_0_auc: 0.85367 |  0:00:30s\n",
      "epoch 36 | loss: 0.38197 | val_0_auc: 0.84989 |  0:00:31s\n",
      "epoch 37 | loss: 0.36598 | val_0_auc: 0.86187 |  0:00:32s\n",
      "epoch 38 | loss: 0.37223 | val_0_auc: 0.861   |  0:00:33s\n",
      "epoch 39 | loss: 0.37225 | val_0_auc: 0.84938 |  0:00:34s\n",
      "epoch 40 | loss: 0.36554 | val_0_auc: 0.87291 |  0:00:35s\n",
      "epoch 41 | loss: 0.36284 | val_0_auc: 0.85773 |  0:00:35s\n",
      "epoch 42 | loss: 0.34833 | val_0_auc: 0.86333 |  0:00:36s\n",
      "epoch 43 | loss: 0.34765 | val_0_auc: 0.89775 |  0:00:37s\n",
      "epoch 44 | loss: 0.36134 | val_0_auc: 0.88715 |  0:00:38s\n",
      "epoch 45 | loss: 0.35184 | val_0_auc: 0.88046 |  0:00:39s\n",
      "epoch 46 | loss: 0.37739 | val_0_auc: 0.89194 |  0:00:40s\n",
      "epoch 47 | loss: 0.36322 | val_0_auc: 0.88381 |  0:00:40s\n",
      "epoch 48 | loss: 0.35848 | val_0_auc: 0.87248 |  0:00:41s\n",
      "epoch 49 | loss: 0.34394 | val_0_auc: 0.87088 |  0:00:42s\n",
      "epoch 50 | loss: 0.3578  | val_0_auc: 0.86681 |  0:00:43s\n",
      "epoch 51 | loss: 0.36558 | val_0_auc: 0.85911 |  0:00:44s\n",
      "epoch 52 | loss: 0.33988 | val_0_auc: 0.87611 |  0:00:45s\n",
      "epoch 53 | loss: 0.36712 | val_0_auc: 0.86086 |  0:00:46s\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.89775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56225 | val_0_auc: 0.82462 |  0:00:01s\n",
      "epoch 1  | loss: 0.45865 | val_0_auc: 0.76391 |  0:00:02s\n",
      "epoch 2  | loss: 0.44545 | val_0_auc: 0.83007 |  0:00:03s\n",
      "epoch 3  | loss: 0.41293 | val_0_auc: 0.7968  |  0:00:03s\n",
      "epoch 4  | loss: 0.43953 | val_0_auc: 0.84125 |  0:00:04s\n",
      "epoch 5  | loss: 0.43924 | val_0_auc: 0.84125 |  0:00:05s\n",
      "epoch 6  | loss: 0.44252 | val_0_auc: 0.83341 |  0:00:06s\n",
      "epoch 7  | loss: 0.40813 | val_0_auc: 0.86478 |  0:00:07s\n",
      "epoch 8  | loss: 0.43437 | val_0_auc: 0.84691 |  0:00:08s\n",
      "epoch 9  | loss: 0.3987  | val_0_auc: 0.86797 |  0:00:09s\n",
      "epoch 10 | loss: 0.41058 | val_0_auc: 0.85969 |  0:00:09s\n",
      "epoch 11 | loss: 0.39569 | val_0_auc: 0.86115 |  0:00:10s\n",
      "epoch 12 | loss: 0.42722 | val_0_auc: 0.85679 |  0:00:11s\n",
      "epoch 13 | loss: 0.4075  | val_0_auc: 0.85084 |  0:00:12s\n",
      "epoch 14 | loss: 0.40357 | val_0_auc: 0.83617 |  0:00:13s\n",
      "epoch 15 | loss: 0.42749 | val_0_auc: 0.82629 |  0:00:14s\n",
      "epoch 16 | loss: 0.39523 | val_0_auc: 0.86768 |  0:00:15s\n",
      "epoch 17 | loss: 0.40245 | val_0_auc: 0.87967 |  0:00:15s\n",
      "epoch 18 | loss: 0.40338 | val_0_auc: 0.89179 |  0:00:16s\n",
      "epoch 19 | loss: 0.41773 | val_0_auc: 0.87284 |  0:00:17s\n",
      "epoch 20 | loss: 0.39909 | val_0_auc: 0.86304 |  0:00:18s\n",
      "epoch 21 | loss: 0.41527 | val_0_auc: 0.87596 |  0:00:19s\n",
      "epoch 22 | loss: 0.40402 | val_0_auc: 0.88511 |  0:00:20s\n",
      "epoch 23 | loss: 0.40901 | val_0_auc: 0.87553 |  0:00:20s\n",
      "epoch 24 | loss: 0.40856 | val_0_auc: 0.88722 |  0:00:21s\n",
      "epoch 25 | loss: 0.40443 | val_0_auc: 0.90109 |  0:00:22s\n",
      "epoch 26 | loss: 0.42186 | val_0_auc: 0.88206 |  0:00:23s\n",
      "epoch 27 | loss: 0.40276 | val_0_auc: 0.88148 |  0:00:24s\n",
      "epoch 28 | loss: 0.38314 | val_0_auc: 0.88105 |  0:00:25s\n",
      "epoch 29 | loss: 0.39442 | val_0_auc: 0.88221 |  0:00:26s\n",
      "epoch 30 | loss: 0.41375 | val_0_auc: 0.87378 |  0:00:27s\n",
      "epoch 31 | loss: 0.39277 | val_0_auc: 0.88308 |  0:00:27s\n",
      "epoch 32 | loss: 0.38365 | val_0_auc: 0.8748  |  0:00:28s\n",
      "epoch 33 | loss: 0.40914 | val_0_auc: 0.87393 |  0:00:29s\n",
      "epoch 34 | loss: 0.40226 | val_0_auc: 0.88947 |  0:00:30s\n",
      "epoch 35 | loss: 0.38697 | val_0_auc: 0.89223 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.90109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53007 | val_0_auc: 0.82956 |  0:00:00s\n",
      "epoch 1  | loss: 0.42684 | val_0_auc: 0.85795 |  0:00:01s\n",
      "epoch 2  | loss: 0.42663 | val_0_auc: 0.81104 |  0:00:02s\n",
      "epoch 3  | loss: 0.39999 | val_0_auc: 0.8337  |  0:00:03s\n",
      "epoch 4  | loss: 0.42667 | val_0_auc: 0.84038 |  0:00:04s\n",
      "epoch 5  | loss: 0.40183 | val_0_auc: 0.85708 |  0:00:05s\n",
      "epoch 6  | loss: 0.39965 | val_0_auc: 0.84924 |  0:00:06s\n",
      "epoch 7  | loss: 0.39557 | val_0_auc: 0.84953 |  0:00:07s\n",
      "epoch 8  | loss: 0.38988 | val_0_auc: 0.8427  |  0:00:08s\n",
      "epoch 9  | loss: 0.38891 | val_0_auc: 0.78388 |  0:00:08s\n",
      "epoch 10 | loss: 0.40054 | val_0_auc: 0.86405 |  0:00:09s\n",
      "epoch 11 | loss: 0.37808 | val_0_auc: 0.85592 |  0:00:10s\n",
      "epoch 12 | loss: 0.39338 | val_0_auc: 0.8581  |  0:00:11s\n",
      "epoch 13 | loss: 0.38418 | val_0_auc: 0.85243 |  0:00:12s\n",
      "epoch 14 | loss: 0.40728 | val_0_auc: 0.86187 |  0:00:13s\n",
      "epoch 15 | loss: 0.4059  | val_0_auc: 0.85737 |  0:00:14s\n",
      "epoch 16 | loss: 0.37146 | val_0_auc: 0.85853 |  0:00:14s\n",
      "epoch 17 | loss: 0.38566 | val_0_auc: 0.86652 |  0:00:15s\n",
      "epoch 18 | loss: 0.37904 | val_0_auc: 0.86376 |  0:00:16s\n",
      "epoch 19 | loss: 0.36709 | val_0_auc: 0.86216 |  0:00:17s\n",
      "epoch 20 | loss: 0.38956 | val_0_auc: 0.85766 |  0:00:18s\n",
      "epoch 21 | loss: 0.38111 | val_0_auc: 0.8594  |  0:00:19s\n",
      "epoch 22 | loss: 0.38257 | val_0_auc: 0.86144 |  0:00:20s\n",
      "epoch 23 | loss: 0.37176 | val_0_auc: 0.852   |  0:00:20s\n",
      "epoch 24 | loss: 0.38496 | val_0_auc: 0.87248 |  0:00:21s\n",
      "epoch 25 | loss: 0.37832 | val_0_auc: 0.88105 |  0:00:22s\n",
      "epoch 26 | loss: 0.37694 | val_0_auc: 0.88845 |  0:00:23s\n",
      "epoch 27 | loss: 0.38707 | val_0_auc: 0.88293 |  0:00:24s\n",
      "epoch 28 | loss: 0.37547 | val_0_auc: 0.88816 |  0:00:25s\n",
      "epoch 29 | loss: 0.38583 | val_0_auc: 0.8695  |  0:00:26s\n",
      "epoch 30 | loss: 0.35717 | val_0_auc: 0.87938 |  0:00:26s\n",
      "epoch 31 | loss: 0.3669  | val_0_auc: 0.88163 |  0:00:27s\n",
      "epoch 32 | loss: 0.36426 | val_0_auc: 0.88395 |  0:00:28s\n",
      "epoch 33 | loss: 0.40456 | val_0_auc: 0.88627 |  0:00:29s\n",
      "epoch 34 | loss: 0.37468 | val_0_auc: 0.887   |  0:00:30s\n",
      "epoch 35 | loss: 0.37393 | val_0_auc: 0.8732  |  0:00:31s\n",
      "epoch 36 | loss: 0.37439 | val_0_auc: 0.86892 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.88845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54934 | val_0_auc: 0.77618 |  0:00:00s\n",
      "epoch 1  | loss: 0.44326 | val_0_auc: 0.8154  |  0:00:01s\n",
      "epoch 2  | loss: 0.4325  | val_0_auc: 0.80378 |  0:00:02s\n",
      "epoch 3  | loss: 0.4101  | val_0_auc: 0.83413 |  0:00:03s\n",
      "epoch 4  | loss: 0.42769 | val_0_auc: 0.82927 |  0:00:04s\n",
      "epoch 5  | loss: 0.4259  | val_0_auc: 0.84372 |  0:00:05s\n",
      "epoch 6  | loss: 0.41957 | val_0_auc: 0.83457 |  0:00:05s\n",
      "epoch 7  | loss: 0.41356 | val_0_auc: 0.84633 |  0:00:06s\n",
      "epoch 8  | loss: 0.39521 | val_0_auc: 0.81975 |  0:00:07s\n",
      "epoch 9  | loss: 0.39984 | val_0_auc: 0.84343 |  0:00:08s\n",
      "epoch 10 | loss: 0.39675 | val_0_auc: 0.84967 |  0:00:09s\n",
      "epoch 11 | loss: 0.3957  | val_0_auc: 0.85781 |  0:00:10s\n",
      "epoch 12 | loss: 0.40518 | val_0_auc: 0.87945 |  0:00:11s\n",
      "epoch 13 | loss: 0.41702 | val_0_auc: 0.87778 |  0:00:11s\n",
      "epoch 14 | loss: 0.39468 | val_0_auc: 0.84495 |  0:00:12s\n",
      "epoch 15 | loss: 0.4131  | val_0_auc: 0.87865 |  0:00:13s\n",
      "epoch 16 | loss: 0.3799  | val_0_auc: 0.88635 |  0:00:14s\n",
      "epoch 17 | loss: 0.39722 | val_0_auc: 0.88765 |  0:00:15s\n",
      "epoch 18 | loss: 0.39021 | val_0_auc: 0.88715 |  0:00:16s\n",
      "epoch 19 | loss: 0.38686 | val_0_auc: 0.8793  |  0:00:16s\n",
      "epoch 20 | loss: 0.41442 | val_0_auc: 0.87378 |  0:00:17s\n",
      "epoch 21 | loss: 0.40218 | val_0_auc: 0.84749 |  0:00:18s\n",
      "epoch 22 | loss: 0.39378 | val_0_auc: 0.83936 |  0:00:19s\n",
      "epoch 23 | loss: 0.37573 | val_0_auc: 0.85577 |  0:00:20s\n",
      "epoch 24 | loss: 0.40132 | val_0_auc: 0.87647 |  0:00:21s\n",
      "epoch 25 | loss: 0.39848 | val_0_auc: 0.89216 |  0:00:21s\n",
      "epoch 26 | loss: 0.39891 | val_0_auc: 0.88155 |  0:00:22s\n",
      "epoch 27 | loss: 0.38841 | val_0_auc: 0.88693 |  0:00:23s\n",
      "epoch 28 | loss: 0.40424 | val_0_auc: 0.88932 |  0:00:24s\n",
      "epoch 29 | loss: 0.39856 | val_0_auc: 0.87858 |  0:00:25s\n",
      "epoch 30 | loss: 0.37625 | val_0_auc: 0.89005 |  0:00:26s\n",
      "epoch 31 | loss: 0.38864 | val_0_auc: 0.88155 |  0:00:27s\n",
      "epoch 32 | loss: 0.3885  | val_0_auc: 0.88308 |  0:00:27s\n",
      "epoch 33 | loss: 0.39791 | val_0_auc: 0.87487 |  0:00:28s\n",
      "epoch 34 | loss: 0.40831 | val_0_auc: 0.88736 |  0:00:29s\n",
      "epoch 35 | loss: 0.37715 | val_0_auc: 0.88482 |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.89216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55354 | val_0_auc: 0.81532 |  0:00:00s\n",
      "epoch 1  | loss: 0.43894 | val_0_auc: 0.74154 |  0:00:01s\n",
      "epoch 2  | loss: 0.41976 | val_0_auc: 0.79506 |  0:00:02s\n",
      "epoch 3  | loss: 0.4192  | val_0_auc: 0.81641 |  0:00:03s\n",
      "epoch 4  | loss: 0.44137 | val_0_auc: 0.76572 |  0:00:04s\n",
      "epoch 5  | loss: 0.41497 | val_0_auc: 0.76013 |  0:00:04s\n",
      "epoch 6  | loss: 0.41365 | val_0_auc: 0.77502 |  0:00:05s\n",
      "epoch 7  | loss: 0.38515 | val_0_auc: 0.80755 |  0:00:06s\n",
      "epoch 8  | loss: 0.41153 | val_0_auc: 0.83108 |  0:00:07s\n",
      "epoch 9  | loss: 0.408   | val_0_auc: 0.81707 |  0:00:08s\n",
      "epoch 10 | loss: 0.40952 | val_0_auc: 0.78141 |  0:00:09s\n",
      "epoch 11 | loss: 0.41187 | val_0_auc: 0.80537 |  0:00:09s\n",
      "epoch 12 | loss: 0.42858 | val_0_auc: 0.82389 |  0:00:10s\n",
      "epoch 13 | loss: 0.42286 | val_0_auc: 0.83036 |  0:00:11s\n",
      "epoch 14 | loss: 0.39841 | val_0_auc: 0.83007 |  0:00:12s\n",
      "epoch 15 | loss: 0.44021 | val_0_auc: 0.83682 |  0:00:13s\n",
      "epoch 16 | loss: 0.38294 | val_0_auc: 0.83863 |  0:00:14s\n",
      "epoch 17 | loss: 0.41349 | val_0_auc: 0.82338 |  0:00:15s\n",
      "epoch 18 | loss: 0.40105 | val_0_auc: 0.84895 |  0:00:15s\n",
      "epoch 19 | loss: 0.43011 | val_0_auc: 0.85192 |  0:00:16s\n",
      "epoch 20 | loss: 0.42407 | val_0_auc: 0.8313  |  0:00:17s\n",
      "epoch 21 | loss: 0.39883 | val_0_auc: 0.84198 |  0:00:18s\n",
      "epoch 22 | loss: 0.39395 | val_0_auc: 0.83725 |  0:00:19s\n",
      "epoch 23 | loss: 0.37362 | val_0_auc: 0.84408 |  0:00:20s\n",
      "epoch 24 | loss: 0.39904 | val_0_auc: 0.84227 |  0:00:21s\n",
      "epoch 25 | loss: 0.38847 | val_0_auc: 0.85309 |  0:00:22s\n",
      "epoch 26 | loss: 0.38315 | val_0_auc: 0.85323 |  0:00:22s\n",
      "epoch 27 | loss: 0.37708 | val_0_auc: 0.85788 |  0:00:23s\n",
      "epoch 28 | loss: 0.39415 | val_0_auc: 0.86151 |  0:00:24s\n",
      "epoch 29 | loss: 0.40229 | val_0_auc: 0.86855 |  0:00:25s\n",
      "epoch 30 | loss: 0.39109 | val_0_auc: 0.85113 |  0:00:26s\n",
      "epoch 31 | loss: 0.38647 | val_0_auc: 0.85868 |  0:00:27s\n",
      "epoch 32 | loss: 0.37161 | val_0_auc: 0.86536 |  0:00:28s\n",
      "epoch 33 | loss: 0.39184 | val_0_auc: 0.85069 |  0:00:29s\n",
      "epoch 34 | loss: 0.39782 | val_0_auc: 0.8772  |  0:00:30s\n",
      "epoch 35 | loss: 0.39564 | val_0_auc: 0.87662 |  0:00:31s\n",
      "epoch 36 | loss: 0.40895 | val_0_auc: 0.87328 |  0:00:32s\n",
      "epoch 37 | loss: 0.37911 | val_0_auc: 0.88824 |  0:00:33s\n",
      "epoch 38 | loss: 0.3934  | val_0_auc: 0.89274 |  0:00:34s\n",
      "epoch 39 | loss: 0.38736 | val_0_auc: 0.88962 |  0:00:35s\n",
      "epoch 40 | loss: 0.37795 | val_0_auc: 0.87204 |  0:00:36s\n",
      "epoch 41 | loss: 0.3917  | val_0_auc: 0.88155 |  0:00:37s\n",
      "epoch 42 | loss: 0.36948 | val_0_auc: 0.87204 |  0:00:38s\n",
      "epoch 43 | loss: 0.36736 | val_0_auc: 0.87683 |  0:00:38s\n",
      "epoch 44 | loss: 0.386   | val_0_auc: 0.85948 |  0:00:39s\n",
      "epoch 45 | loss: 0.37428 | val_0_auc: 0.87633 |  0:00:40s\n",
      "epoch 46 | loss: 0.36284 | val_0_auc: 0.87814 |  0:00:41s\n",
      "epoch 47 | loss: 0.37769 | val_0_auc: 0.8886  |  0:00:42s\n",
      "epoch 48 | loss: 0.37587 | val_0_auc: 0.88584 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.89274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57008 | val_0_auc: 0.77894 |  0:00:00s\n",
      "epoch 1  | loss: 0.49219 | val_0_auc: 0.82542 |  0:00:01s\n",
      "epoch 2  | loss: 0.41479 | val_0_auc: 0.80341 |  0:00:02s\n",
      "epoch 3  | loss: 0.41938 | val_0_auc: 0.82164 |  0:00:03s\n",
      "epoch 4  | loss: 0.43438 | val_0_auc: 0.81627 |  0:00:04s\n",
      "epoch 5  | loss: 0.38231 | val_0_auc: 0.85432 |  0:00:05s\n",
      "epoch 6  | loss: 0.41116 | val_0_auc: 0.80465 |  0:00:06s\n",
      "epoch 7  | loss: 0.38295 | val_0_auc: 0.83646 |  0:00:07s\n",
      "epoch 8  | loss: 0.38432 | val_0_auc: 0.87328 |  0:00:08s\n",
      "epoch 9  | loss: 0.39896 | val_0_auc: 0.84139 |  0:00:09s\n",
      "epoch 10 | loss: 0.38251 | val_0_auc: 0.87938 |  0:00:10s\n",
      "epoch 11 | loss: 0.39278 | val_0_auc: 0.8573  |  0:00:11s\n",
      "epoch 12 | loss: 0.40077 | val_0_auc: 0.86202 |  0:00:12s\n",
      "epoch 13 | loss: 0.40815 | val_0_auc: 0.86594 |  0:00:12s\n",
      "epoch 14 | loss: 0.37665 | val_0_auc: 0.86405 |  0:00:13s\n",
      "epoch 15 | loss: 0.43698 | val_0_auc: 0.84662 |  0:00:14s\n",
      "epoch 16 | loss: 0.36659 | val_0_auc: 0.86914 |  0:00:15s\n",
      "epoch 17 | loss: 0.40691 | val_0_auc: 0.86042 |  0:00:16s\n",
      "epoch 18 | loss: 0.38031 | val_0_auc: 0.88337 |  0:00:17s\n",
      "epoch 19 | loss: 0.39124 | val_0_auc: 0.8732  |  0:00:18s\n",
      "epoch 20 | loss: 0.39334 | val_0_auc: 0.8655  |  0:00:19s\n",
      "epoch 21 | loss: 0.38429 | val_0_auc: 0.8671  |  0:00:20s\n",
      "epoch 22 | loss: 0.38625 | val_0_auc: 0.85505 |  0:00:21s\n",
      "epoch 23 | loss: 0.37595 | val_0_auc: 0.87698 |  0:00:22s\n",
      "epoch 24 | loss: 0.38947 | val_0_auc: 0.89085 |  0:00:23s\n",
      "epoch 25 | loss: 0.37009 | val_0_auc: 0.90051 |  0:00:24s\n",
      "epoch 26 | loss: 0.37235 | val_0_auc: 0.8878  |  0:00:24s\n",
      "epoch 27 | loss: 0.35613 | val_0_auc: 0.89274 |  0:00:25s\n",
      "epoch 28 | loss: 0.36766 | val_0_auc: 0.88606 |  0:00:26s\n",
      "epoch 29 | loss: 0.35923 | val_0_auc: 0.87901 |  0:00:27s\n",
      "epoch 30 | loss: 0.37393 | val_0_auc: 0.8809  |  0:00:28s\n",
      "epoch 31 | loss: 0.37189 | val_0_auc: 0.88468 |  0:00:29s\n",
      "epoch 32 | loss: 0.3684  | val_0_auc: 0.8886  |  0:00:30s\n",
      "epoch 33 | loss: 0.35851 | val_0_auc: 0.86826 |  0:00:31s\n",
      "epoch 34 | loss: 0.39278 | val_0_auc: 0.87466 |  0:00:32s\n",
      "epoch 35 | loss: 0.37248 | val_0_auc: 0.88061 |  0:00:33s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.90051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58935 | val_0_auc: 0.71126 |  0:00:00s\n",
      "epoch 1  | loss: 0.46974 | val_0_auc: 0.85817 |  0:00:01s\n",
      "epoch 2  | loss: 0.44006 | val_0_auc: 0.84582 |  0:00:02s\n",
      "epoch 3  | loss: 0.44073 | val_0_auc: 0.85381 |  0:00:03s\n",
      "epoch 4  | loss: 0.43426 | val_0_auc: 0.83224 |  0:00:04s\n",
      "epoch 5  | loss: 0.44775 | val_0_auc: 0.82033 |  0:00:05s\n",
      "epoch 6  | loss: 0.43959 | val_0_auc: 0.87545 |  0:00:06s\n",
      "epoch 7  | loss: 0.4147  | val_0_auc: 0.8658  |  0:00:07s\n",
      "epoch 8  | loss: 0.43534 | val_0_auc: 0.86071 |  0:00:08s\n",
      "epoch 9  | loss: 0.40497 | val_0_auc: 0.85882 |  0:00:09s\n",
      "epoch 10 | loss: 0.41919 | val_0_auc: 0.85969 |  0:00:10s\n",
      "epoch 11 | loss: 0.40507 | val_0_auc: 0.86057 |  0:00:11s\n",
      "epoch 12 | loss: 0.42531 | val_0_auc: 0.86318 |  0:00:12s\n",
      "epoch 13 | loss: 0.38528 | val_0_auc: 0.861   |  0:00:13s\n",
      "epoch 14 | loss: 0.40736 | val_0_auc: 0.84517 |  0:00:14s\n",
      "epoch 15 | loss: 0.43423 | val_0_auc: 0.83166 |  0:00:15s\n",
      "epoch 16 | loss: 0.41962 | val_0_auc: 0.86492 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.87545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.99148 | val_0_auc: 0.75178 |  0:00:01s\n",
      "epoch 1  | loss: 0.70101 | val_0_auc: 0.86028 |  0:00:03s\n",
      "epoch 2  | loss: 0.47642 | val_0_auc: 0.87974 |  0:00:06s\n",
      "epoch 3  | loss: 0.42965 | val_0_auc: 0.86202 |  0:00:09s\n",
      "epoch 4  | loss: 0.41837 | val_0_auc: 0.81786 |  0:00:11s\n",
      "epoch 5  | loss: 0.41515 | val_0_auc: 0.84924 |  0:00:13s\n",
      "epoch 6  | loss: 0.39381 | val_0_auc: 0.81481 |  0:00:15s\n",
      "epoch 7  | loss: 0.38716 | val_0_auc: 0.77952 |  0:00:17s\n",
      "epoch 8  | loss: 0.41481 | val_0_auc: 0.7085  |  0:00:19s\n",
      "epoch 9  | loss: 0.37955 | val_0_auc: 0.80421 |  0:00:20s\n",
      "epoch 10 | loss: 0.3998  | val_0_auc: 0.83805 |  0:00:22s\n",
      "epoch 11 | loss: 0.41395 | val_0_auc: 0.84488 |  0:00:24s\n",
      "epoch 12 | loss: 0.36723 | val_0_auc: 0.84227 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.87974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.22667 | val_0_auc: 0.66841 |  0:00:01s\n",
      "epoch 1  | loss: 0.67483 | val_0_auc: 0.81409 |  0:00:03s\n",
      "epoch 2  | loss: 0.49156 | val_0_auc: 0.82716 |  0:00:05s\n",
      "epoch 3  | loss: 0.47453 | val_0_auc: 0.83007 |  0:00:07s\n",
      "epoch 4  | loss: 0.4568  | val_0_auc: 0.7955  |  0:00:09s\n",
      "epoch 5  | loss: 0.43037 | val_0_auc: 0.86187 |  0:00:11s\n",
      "epoch 6  | loss: 0.42037 | val_0_auc: 0.82614 |  0:00:12s\n",
      "epoch 7  | loss: 0.38891 | val_0_auc: 0.83675 |  0:00:14s\n",
      "epoch 8  | loss: 0.41366 | val_0_auc: 0.85403 |  0:00:16s\n",
      "epoch 9  | loss: 0.43325 | val_0_auc: 0.84328 |  0:00:18s\n",
      "epoch 10 | loss: 0.42004 | val_0_auc: 0.81845 |  0:00:20s\n",
      "epoch 11 | loss: 0.43005 | val_0_auc: 0.85229 |  0:00:21s\n",
      "epoch 12 | loss: 0.38836 | val_0_auc: 0.86754 |  0:00:23s\n",
      "epoch 13 | loss: 0.41077 | val_0_auc: 0.84924 |  0:00:25s\n",
      "epoch 14 | loss: 0.40659 | val_0_auc: 0.86812 |  0:00:27s\n",
      "epoch 15 | loss: 0.38718 | val_0_auc: 0.86638 |  0:00:29s\n",
      "epoch 16 | loss: 0.39787 | val_0_auc: 0.8671  |  0:00:31s\n",
      "epoch 17 | loss: 0.40195 | val_0_auc: 0.86565 |  0:00:32s\n",
      "epoch 18 | loss: 0.40773 | val_0_auc: 0.87959 |  0:00:34s\n",
      "epoch 19 | loss: 0.40657 | val_0_auc: 0.86812 |  0:00:36s\n",
      "epoch 20 | loss: 0.41832 | val_0_auc: 0.87567 |  0:00:38s\n",
      "epoch 21 | loss: 0.39866 | val_0_auc: 0.88381 |  0:00:39s\n",
      "epoch 22 | loss: 0.37664 | val_0_auc: 0.88511 |  0:00:41s\n",
      "epoch 23 | loss: 0.39314 | val_0_auc: 0.88395 |  0:00:43s\n",
      "epoch 24 | loss: 0.38809 | val_0_auc: 0.87436 |  0:00:45s\n",
      "epoch 25 | loss: 0.38059 | val_0_auc: 0.8748  |  0:00:47s\n",
      "epoch 26 | loss: 0.39375 | val_0_auc: 0.8703  |  0:00:48s\n",
      "epoch 27 | loss: 0.38589 | val_0_auc: 0.88511 |  0:00:50s\n",
      "epoch 28 | loss: 0.386   | val_0_auc: 0.86783 |  0:00:52s\n",
      "epoch 29 | loss: 0.35479 | val_0_auc: 0.87131 |  0:00:54s\n",
      "epoch 30 | loss: 0.37229 | val_0_auc: 0.887   |  0:00:56s\n",
      "epoch 31 | loss: 0.38304 | val_0_auc: 0.88322 |  0:00:58s\n",
      "epoch 32 | loss: 0.38423 | val_0_auc: 0.88773 |  0:01:00s\n",
      "epoch 33 | loss: 0.38612 | val_0_auc: 0.89586 |  0:01:01s\n",
      "epoch 34 | loss: 0.37577 | val_0_auc: 0.8931  |  0:01:03s\n",
      "epoch 35 | loss: 0.37311 | val_0_auc: 0.88192 |  0:01:05s\n",
      "epoch 36 | loss: 0.3768  | val_0_auc: 0.89441 |  0:01:07s\n",
      "epoch 37 | loss: 0.37886 | val_0_auc: 0.89296 |  0:01:09s\n",
      "epoch 38 | loss: 0.38939 | val_0_auc: 0.89063 |  0:01:10s\n",
      "epoch 39 | loss: 0.4094  | val_0_auc: 0.90007 |  0:01:12s\n",
      "epoch 40 | loss: 0.37492 | val_0_auc: 0.89644 |  0:01:14s\n",
      "epoch 41 | loss: 0.42027 | val_0_auc: 0.89513 |  0:01:16s\n",
      "epoch 42 | loss: 0.36969 | val_0_auc: 0.88642 |  0:01:18s\n",
      "epoch 43 | loss: 0.38907 | val_0_auc: 0.88656 |  0:01:20s\n",
      "epoch 44 | loss: 0.38364 | val_0_auc: 0.87843 |  0:01:21s\n",
      "epoch 45 | loss: 0.39278 | val_0_auc: 0.878   |  0:01:23s\n",
      "epoch 46 | loss: 0.3816  | val_0_auc: 0.87945 |  0:01:25s\n",
      "epoch 47 | loss: 0.3885  | val_0_auc: 0.89165 |  0:01:27s\n",
      "epoch 48 | loss: 0.36993 | val_0_auc: 0.89267 |  0:01:29s\n",
      "epoch 49 | loss: 0.36008 | val_0_auc: 0.88424 |  0:01:31s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.90007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.00245 | val_0_auc: 0.84982 |  0:00:01s\n",
      "epoch 1  | loss: 0.61922 | val_0_auc: 0.85171 |  0:00:03s\n",
      "epoch 2  | loss: 0.5265  | val_0_auc: 0.77502 |  0:00:05s\n",
      "epoch 3  | loss: 0.44369 | val_0_auc: 0.84314 |  0:00:07s\n",
      "epoch 4  | loss: 0.42872 | val_0_auc: 0.81351 |  0:00:09s\n",
      "epoch 5  | loss: 0.42953 | val_0_auc: 0.86086 |  0:00:11s\n",
      "epoch 6  | loss: 0.40665 | val_0_auc: 0.84808 |  0:00:13s\n",
      "epoch 7  | loss: 0.42166 | val_0_auc: 0.8289  |  0:00:14s\n",
      "epoch 8  | loss: 0.40791 | val_0_auc: 0.81888 |  0:00:16s\n",
      "epoch 9  | loss: 0.43901 | val_0_auc: 0.83399 |  0:00:18s\n",
      "epoch 10 | loss: 0.39509 | val_0_auc: 0.85374 |  0:00:20s\n",
      "epoch 11 | loss: 0.40677 | val_0_auc: 0.84227 |  0:00:22s\n",
      "epoch 12 | loss: 0.43373 | val_0_auc: 0.84488 |  0:00:23s\n",
      "epoch 13 | loss: 0.40576 | val_0_auc: 0.85461 |  0:00:25s\n",
      "epoch 14 | loss: 0.406   | val_0_auc: 0.84967 |  0:00:27s\n",
      "epoch 15 | loss: 0.39613 | val_0_auc: 0.85708 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.86086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.1265  | val_0_auc: 0.82542 |  0:00:02s\n",
      "epoch 1  | loss: 0.62856 | val_0_auc: 0.70799 |  0:00:03s\n",
      "epoch 2  | loss: 0.55776 | val_0_auc: 0.81757 |  0:00:05s\n",
      "epoch 3  | loss: 0.43487 | val_0_auc: 0.80748 |  0:00:07s\n",
      "epoch 4  | loss: 0.41403 | val_0_auc: 0.80886 |  0:00:09s\n",
      "epoch 5  | loss: 0.39683 | val_0_auc: 0.82694 |  0:00:11s\n",
      "epoch 6  | loss: 0.4225  | val_0_auc: 0.82629 |  0:00:13s\n",
      "epoch 7  | loss: 0.41855 | val_0_auc: 0.8459  |  0:00:15s\n",
      "epoch 8  | loss: 0.41035 | val_0_auc: 0.85127 |  0:00:16s\n",
      "epoch 9  | loss: 0.42969 | val_0_auc: 0.86202 |  0:00:18s\n",
      "epoch 10 | loss: 0.39535 | val_0_auc: 0.87001 |  0:00:20s\n",
      "epoch 11 | loss: 0.37671 | val_0_auc: 0.82469 |  0:00:22s\n",
      "epoch 12 | loss: 0.40224 | val_0_auc: 0.8297  |  0:00:24s\n",
      "epoch 13 | loss: 0.39539 | val_0_auc: 0.86696 |  0:00:26s\n",
      "epoch 14 | loss: 0.37259 | val_0_auc: 0.87466 |  0:00:27s\n",
      "epoch 15 | loss: 0.39049 | val_0_auc: 0.87407 |  0:00:29s\n",
      "epoch 16 | loss: 0.36238 | val_0_auc: 0.87553 |  0:00:31s\n",
      "epoch 17 | loss: 0.37823 | val_0_auc: 0.86616 |  0:00:33s\n",
      "epoch 18 | loss: 0.3838  | val_0_auc: 0.88017 |  0:00:35s\n",
      "epoch 19 | loss: 0.38543 | val_0_auc: 0.88889 |  0:00:36s\n",
      "epoch 20 | loss: 0.39207 | val_0_auc: 0.87538 |  0:00:38s\n",
      "epoch 21 | loss: 0.37894 | val_0_auc: 0.85229 |  0:00:40s\n",
      "epoch 22 | loss: 0.39499 | val_0_auc: 0.84837 |  0:00:42s\n",
      "epoch 23 | loss: 0.38694 | val_0_auc: 0.86434 |  0:00:43s\n",
      "epoch 24 | loss: 0.38402 | val_0_auc: 0.86318 |  0:00:45s\n",
      "epoch 25 | loss: 0.37089 | val_0_auc: 0.88264 |  0:00:47s\n",
      "epoch 26 | loss: 0.38812 | val_0_auc: 0.87473 |  0:00:49s\n",
      "epoch 27 | loss: 0.38758 | val_0_auc: 0.87117 |  0:00:51s\n",
      "epoch 28 | loss: 0.39295 | val_0_auc: 0.8655  |  0:00:53s\n",
      "epoch 29 | loss: 0.35366 | val_0_auc: 0.87509 |  0:00:55s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.88889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.07681 | val_0_auc: 0.23399 |  0:00:01s\n",
      "epoch 1  | loss: 0.62233 | val_0_auc: 0.77545 |  0:00:03s\n",
      "epoch 2  | loss: 0.50268 | val_0_auc: 0.83704 |  0:00:05s\n",
      "epoch 3  | loss: 0.49164 | val_0_auc: 0.81162 |  0:00:08s\n",
      "epoch 4  | loss: 0.45839 | val_0_auc: 0.83631 |  0:00:09s\n",
      "epoch 5  | loss: 0.4525  | val_0_auc: 0.83544 |  0:00:11s\n",
      "epoch 6  | loss: 0.43519 | val_0_auc: 0.84517 |  0:00:13s\n",
      "epoch 7  | loss: 0.46189 | val_0_auc: 0.86797 |  0:00:15s\n",
      "epoch 8  | loss: 0.41312 | val_0_auc: 0.84953 |  0:00:17s\n",
      "epoch 9  | loss: 0.41968 | val_0_auc: 0.8427  |  0:00:19s\n",
      "epoch 10 | loss: 0.41249 | val_0_auc: 0.81089 |  0:00:21s\n",
      "epoch 11 | loss: 0.42692 | val_0_auc: 0.86957 |  0:00:23s\n",
      "epoch 12 | loss: 0.44378 | val_0_auc: 0.80828 |  0:00:25s\n",
      "epoch 13 | loss: 0.41806 | val_0_auc: 0.83951 |  0:00:27s\n",
      "epoch 14 | loss: 0.39061 | val_0_auc: 0.86478 |  0:00:29s\n",
      "epoch 15 | loss: 0.42172 | val_0_auc: 0.86739 |  0:00:31s\n",
      "epoch 16 | loss: 0.42292 | val_0_auc: 0.86812 |  0:00:33s\n",
      "epoch 17 | loss: 0.41854 | val_0_auc: 0.87858 |  0:00:35s\n",
      "epoch 18 | loss: 0.40985 | val_0_auc: 0.87785 |  0:00:37s\n",
      "epoch 19 | loss: 0.41849 | val_0_auc: 0.89267 |  0:00:39s\n",
      "epoch 20 | loss: 0.41299 | val_0_auc: 0.86245 |  0:00:41s\n",
      "epoch 21 | loss: 0.38759 | val_0_auc: 0.89267 |  0:00:43s\n",
      "epoch 22 | loss: 0.40795 | val_0_auc: 0.88395 |  0:00:45s\n",
      "epoch 23 | loss: 0.39391 | val_0_auc: 0.90182 |  0:00:47s\n",
      "epoch 24 | loss: 0.41396 | val_0_auc: 0.87001 |  0:00:49s\n",
      "epoch 25 | loss: 0.40029 | val_0_auc: 0.88642 |  0:00:51s\n",
      "epoch 26 | loss: 0.42444 | val_0_auc: 0.90123 |  0:00:53s\n",
      "epoch 27 | loss: 0.39172 | val_0_auc: 0.89034 |  0:00:55s\n",
      "epoch 28 | loss: 0.38688 | val_0_auc: 0.8902  |  0:00:57s\n",
      "epoch 29 | loss: 0.39869 | val_0_auc: 0.89833 |  0:00:59s\n",
      "epoch 30 | loss: 0.39436 | val_0_auc: 0.89746 |  0:01:01s\n",
      "epoch 31 | loss: 0.40214 | val_0_auc: 0.8976  |  0:01:03s\n",
      "epoch 32 | loss: 0.39916 | val_0_auc: 0.88831 |  0:01:05s\n",
      "epoch 33 | loss: 0.39662 | val_0_auc: 0.89804 |  0:01:07s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.90182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.03386 | val_0_auc: 0.69034 |  0:00:01s\n",
      "epoch 1  | loss: 0.60396 | val_0_auc: 0.77269 |  0:00:03s\n",
      "epoch 2  | loss: 0.48724 | val_0_auc: 0.82564 |  0:00:04s\n",
      "epoch 3  | loss: 0.40944 | val_0_auc: 0.81699 |  0:00:06s\n",
      "epoch 4  | loss: 0.42163 | val_0_auc: 0.81917 |  0:00:08s\n",
      "epoch 5  | loss: 0.42078 | val_0_auc: 0.82687 |  0:00:09s\n",
      "epoch 6  | loss: 0.39428 | val_0_auc: 0.82614 |  0:00:11s\n",
      "epoch 7  | loss: 0.39196 | val_0_auc: 0.80232 |  0:00:12s\n",
      "epoch 8  | loss: 0.48293 | val_0_auc: 0.82789 |  0:00:14s\n",
      "epoch 9  | loss: 0.39612 | val_0_auc: 0.83036 |  0:00:16s\n",
      "epoch 10 | loss: 0.41253 | val_0_auc: 0.80683 |  0:00:17s\n",
      "epoch 11 | loss: 0.39625 | val_0_auc: 0.81786 |  0:00:19s\n",
      "epoch 12 | loss: 0.42972 | val_0_auc: 0.85534 |  0:00:21s\n",
      "epoch 13 | loss: 0.3963  | val_0_auc: 0.85084 |  0:00:22s\n",
      "epoch 14 | loss: 0.40617 | val_0_auc: 0.8472  |  0:00:24s\n",
      "epoch 15 | loss: 0.39348 | val_0_auc: 0.85403 |  0:00:25s\n",
      "epoch 16 | loss: 0.37167 | val_0_auc: 0.86028 |  0:00:27s\n",
      "epoch 17 | loss: 0.38073 | val_0_auc: 0.84808 |  0:00:29s\n",
      "epoch 18 | loss: 0.38615 | val_0_auc: 0.86957 |  0:00:30s\n",
      "epoch 19 | loss: 0.38988 | val_0_auc: 0.85737 |  0:00:32s\n",
      "epoch 20 | loss: 0.40019 | val_0_auc: 0.86275 |  0:00:33s\n",
      "epoch 21 | loss: 0.37736 | val_0_auc: 0.85679 |  0:00:35s\n",
      "epoch 22 | loss: 0.37844 | val_0_auc: 0.85171 |  0:00:37s\n",
      "epoch 23 | loss: 0.39412 | val_0_auc: 0.85752 |  0:00:38s\n",
      "epoch 24 | loss: 0.37465 | val_0_auc: 0.85258 |  0:00:40s\n",
      "epoch 25 | loss: 0.3661  | val_0_auc: 0.86333 |  0:00:41s\n",
      "epoch 26 | loss: 0.37364 | val_0_auc: 0.86725 |  0:00:43s\n",
      "epoch 27 | loss: 0.35274 | val_0_auc: 0.8687  |  0:00:45s\n",
      "epoch 28 | loss: 0.37133 | val_0_auc: 0.88264 |  0:00:46s\n",
      "epoch 29 | loss: 0.36658 | val_0_auc: 0.87988 |  0:00:48s\n",
      "epoch 30 | loss: 0.36995 | val_0_auc: 0.88627 |  0:00:49s\n",
      "epoch 31 | loss: 0.37543 | val_0_auc: 0.8732  |  0:00:51s\n",
      "epoch 32 | loss: 0.36873 | val_0_auc: 0.86826 |  0:00:53s\n",
      "epoch 33 | loss: 0.37419 | val_0_auc: 0.88439 |  0:00:54s\n",
      "epoch 34 | loss: 0.37575 | val_0_auc: 0.88322 |  0:00:56s\n",
      "epoch 35 | loss: 0.36085 | val_0_auc: 0.88526 |  0:00:57s\n",
      "epoch 36 | loss: 0.36798 | val_0_auc: 0.88366 |  0:00:59s\n",
      "epoch 37 | loss: 0.35813 | val_0_auc: 0.89049 |  0:01:01s\n",
      "epoch 38 | loss: 0.36884 | val_0_auc: 0.87088 |  0:01:02s\n",
      "epoch 39 | loss: 0.36555 | val_0_auc: 0.87829 |  0:01:04s\n",
      "epoch 40 | loss: 0.36977 | val_0_auc: 0.88497 |  0:01:05s\n",
      "epoch 41 | loss: 0.36527 | val_0_auc: 0.88845 |  0:01:07s\n",
      "epoch 42 | loss: 0.35247 | val_0_auc: 0.88381 |  0:01:08s\n",
      "epoch 43 | loss: 0.37477 | val_0_auc: 0.887   |  0:01:10s\n",
      "epoch 44 | loss: 0.35294 | val_0_auc: 0.88845 |  0:01:12s\n",
      "epoch 45 | loss: 0.34841 | val_0_auc: 0.88802 |  0:01:13s\n",
      "epoch 46 | loss: 0.37673 | val_0_auc: 0.88526 |  0:01:15s\n",
      "epoch 47 | loss: 0.36481 | val_0_auc: 0.89586 |  0:01:16s\n",
      "epoch 48 | loss: 0.35689 | val_0_auc: 0.89092 |  0:01:18s\n",
      "epoch 49 | loss: 0.36379 | val_0_auc: 0.89586 |  0:01:20s\n",
      "epoch 50 | loss: 0.35719 | val_0_auc: 0.88439 |  0:01:21s\n",
      "epoch 51 | loss: 0.35967 | val_0_auc: 0.88686 |  0:01:23s\n",
      "epoch 52 | loss: 0.36994 | val_0_auc: 0.8902  |  0:01:25s\n",
      "epoch 53 | loss: 0.36127 | val_0_auc: 0.88308 |  0:01:26s\n",
      "epoch 54 | loss: 0.35554 | val_0_auc: 0.89259 |  0:01:28s\n",
      "epoch 55 | loss: 0.36974 | val_0_auc: 0.88243 |  0:01:29s\n",
      "epoch 56 | loss: 0.36672 | val_0_auc: 0.88489 |  0:01:31s\n",
      "epoch 57 | loss: 0.35445 | val_0_auc: 0.88809 |  0:01:33s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.89586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.15754 | val_0_auc: 0.82745 |  0:00:01s\n",
      "epoch 1  | loss: 0.60884 | val_0_auc: 0.64909 |  0:00:03s\n",
      "epoch 2  | loss: 0.5855  | val_0_auc: 0.84415 |  0:00:04s\n",
      "epoch 3  | loss: 0.436   | val_0_auc: 0.81089 |  0:00:05s\n",
      "epoch 4  | loss: 0.50101 | val_0_auc: 0.8154  |  0:00:07s\n",
      "epoch 5  | loss: 0.44294 | val_0_auc: 0.79441 |  0:00:08s\n",
      "epoch 6  | loss: 0.49909 | val_0_auc: 0.83987 |  0:00:10s\n",
      "epoch 7  | loss: 0.45709 | val_0_auc: 0.85214 |  0:00:11s\n",
      "epoch 8  | loss: 0.43005 | val_0_auc: 0.8411  |  0:00:13s\n",
      "epoch 9  | loss: 0.39975 | val_0_auc: 0.82919 |  0:00:14s\n",
      "epoch 10 | loss: 0.40393 | val_0_auc: 0.8122  |  0:00:16s\n",
      "epoch 11 | loss: 0.40961 | val_0_auc: 0.82948 |  0:00:17s\n",
      "epoch 12 | loss: 0.42131 | val_0_auc: 0.86797 |  0:00:19s\n",
      "epoch 13 | loss: 0.42589 | val_0_auc: 0.85396 |  0:00:20s\n",
      "epoch 14 | loss: 0.41188 | val_0_auc: 0.85948 |  0:00:21s\n",
      "epoch 15 | loss: 0.3968  | val_0_auc: 0.87625 |  0:00:23s\n",
      "epoch 16 | loss: 0.41716 | val_0_auc: 0.87625 |  0:00:24s\n",
      "epoch 17 | loss: 0.38735 | val_0_auc: 0.86202 |  0:00:26s\n",
      "epoch 18 | loss: 0.39004 | val_0_auc: 0.88279 |  0:00:27s\n",
      "epoch 19 | loss: 0.40998 | val_0_auc: 0.87872 |  0:00:29s\n",
      "epoch 20 | loss: 0.40233 | val_0_auc: 0.81322 |  0:00:30s\n",
      "epoch 21 | loss: 0.38021 | val_0_auc: 0.86855 |  0:00:32s\n",
      "epoch 22 | loss: 0.39816 | val_0_auc: 0.88932 |  0:00:33s\n",
      "epoch 23 | loss: 0.40379 | val_0_auc: 0.87153 |  0:00:34s\n",
      "epoch 24 | loss: 0.40957 | val_0_auc: 0.86202 |  0:00:36s\n",
      "epoch 25 | loss: 0.38632 | val_0_auc: 0.79005 |  0:00:37s\n",
      "epoch 26 | loss: 0.39877 | val_0_auc: 0.86935 |  0:00:39s\n",
      "epoch 27 | loss: 0.37811 | val_0_auc: 0.87422 |  0:00:40s\n",
      "epoch 28 | loss: 0.36717 | val_0_auc: 0.8833  |  0:00:42s\n",
      "epoch 29 | loss: 0.38468 | val_0_auc: 0.87313 |  0:00:43s\n",
      "epoch 30 | loss: 0.3781  | val_0_auc: 0.88206 |  0:00:45s\n",
      "epoch 31 | loss: 0.3842  | val_0_auc: 0.8793  |  0:00:46s\n",
      "epoch 32 | loss: 0.38818 | val_0_auc: 0.86768 |  0:00:48s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.88932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.08485 | val_0_auc: 0.85679 |  0:00:01s\n",
      "epoch 1  | loss: 0.58824 | val_0_auc: 0.81438 |  0:00:02s\n",
      "epoch 2  | loss: 0.49377 | val_0_auc: 0.83457 |  0:00:04s\n",
      "epoch 3  | loss: 0.49166 | val_0_auc: 0.81612 |  0:00:06s\n",
      "epoch 4  | loss: 0.4731  | val_0_auc: 0.79216 |  0:00:07s\n",
      "epoch 5  | loss: 0.44652 | val_0_auc: 0.8398  |  0:00:08s\n",
      "epoch 6  | loss: 0.44283 | val_0_auc: 0.73885 |  0:00:10s\n",
      "epoch 7  | loss: 0.4029  | val_0_auc: 0.85229 |  0:00:11s\n",
      "epoch 8  | loss: 0.46141 | val_0_auc: 0.85548 |  0:00:13s\n",
      "epoch 9  | loss: 0.46154 | val_0_auc: 0.82716 |  0:00:14s\n",
      "epoch 10 | loss: 0.46849 | val_0_auc: 0.81656 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.85679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.1524  | val_0_auc: 0.83007 |  0:00:01s\n",
      "epoch 1  | loss: 0.54287 | val_0_auc: 0.82571 |  0:00:02s\n",
      "epoch 2  | loss: 0.56421 | val_0_auc: 0.85287 |  0:00:04s\n",
      "epoch 3  | loss: 0.52756 | val_0_auc: 0.83072 |  0:00:05s\n",
      "epoch 4  | loss: 0.45737 | val_0_auc: 0.83195 |  0:00:07s\n",
      "epoch 5  | loss: 0.47017 | val_0_auc: 0.83776 |  0:00:08s\n",
      "epoch 6  | loss: 0.42803 | val_0_auc: 0.85084 |  0:00:10s\n",
      "epoch 7  | loss: 0.42277 | val_0_auc: 0.80203 |  0:00:11s\n",
      "epoch 8  | loss: 0.45105 | val_0_auc: 0.82113 |  0:00:12s\n",
      "epoch 9  | loss: 0.39728 | val_0_auc: 0.82382 |  0:00:14s\n",
      "epoch 10 | loss: 0.43716 | val_0_auc: 0.84154 |  0:00:15s\n",
      "epoch 11 | loss: 0.4018  | val_0_auc: 0.85258 |  0:00:17s\n",
      "epoch 12 | loss: 0.39919 | val_0_auc: 0.86398 |  0:00:18s\n",
      "epoch 13 | loss: 0.40348 | val_0_auc: 0.86696 |  0:00:20s\n",
      "epoch 14 | loss: 0.40856 | val_0_auc: 0.87349 |  0:00:22s\n",
      "epoch 15 | loss: 0.39516 | val_0_auc: 0.87291 |  0:00:23s\n",
      "epoch 16 | loss: 0.41202 | val_0_auc: 0.88918 |  0:00:24s\n",
      "epoch 17 | loss: 0.40188 | val_0_auc: 0.8841  |  0:00:26s\n",
      "epoch 18 | loss: 0.40044 | val_0_auc: 0.88577 |  0:00:27s\n",
      "epoch 19 | loss: 0.39688 | val_0_auc: 0.89499 |  0:00:29s\n",
      "epoch 20 | loss: 0.39086 | val_0_auc: 0.87654 |  0:00:30s\n",
      "epoch 21 | loss: 0.39986 | val_0_auc: 0.88598 |  0:00:32s\n",
      "epoch 22 | loss: 0.36638 | val_0_auc: 0.8915  |  0:00:33s\n",
      "epoch 23 | loss: 0.38198 | val_0_auc: 0.86841 |  0:00:35s\n",
      "epoch 24 | loss: 0.3624  | val_0_auc: 0.88991 |  0:00:36s\n",
      "epoch 25 | loss: 0.41155 | val_0_auc: 0.89455 |  0:00:37s\n",
      "epoch 26 | loss: 0.41612 | val_0_auc: 0.89731 |  0:00:39s\n",
      "epoch 27 | loss: 0.38391 | val_0_auc: 0.89332 |  0:00:40s\n",
      "epoch 28 | loss: 0.39313 | val_0_auc: 0.87814 |  0:00:42s\n",
      "epoch 29 | loss: 0.4014  | val_0_auc: 0.86703 |  0:00:43s\n",
      "epoch 30 | loss: 0.42812 | val_0_auc: 0.88148 |  0:00:44s\n",
      "epoch 31 | loss: 0.42098 | val_0_auc: 0.87313 |  0:00:46s\n",
      "epoch 32 | loss: 0.41051 | val_0_auc: 0.89281 |  0:00:47s\n",
      "epoch 33 | loss: 0.39517 | val_0_auc: 0.89906 |  0:00:49s\n",
      "epoch 34 | loss: 0.42508 | val_0_auc: 0.88417 |  0:00:50s\n",
      "epoch 35 | loss: 0.38289 | val_0_auc: 0.88257 |  0:00:52s\n",
      "epoch 36 | loss: 0.40724 | val_0_auc: 0.88562 |  0:00:53s\n",
      "epoch 37 | loss: 0.38298 | val_0_auc: 0.87625 |  0:00:54s\n",
      "epoch 38 | loss: 0.39153 | val_0_auc: 0.87066 |  0:00:56s\n",
      "epoch 39 | loss: 0.39749 | val_0_auc: 0.87712 |  0:00:57s\n",
      "epoch 40 | loss: 0.42077 | val_0_auc: 0.89956 |  0:00:59s\n",
      "epoch 41 | loss: 0.41335 | val_0_auc: 0.89005 |  0:01:00s\n",
      "epoch 42 | loss: 0.42298 | val_0_auc: 0.86696 |  0:01:02s\n",
      "epoch 43 | loss: 0.40429 | val_0_auc: 0.8809  |  0:01:03s\n",
      "epoch 44 | loss: 0.39988 | val_0_auc: 0.89455 |  0:01:05s\n",
      "epoch 45 | loss: 0.40221 | val_0_auc: 0.88279 |  0:01:06s\n",
      "epoch 46 | loss: 0.39068 | val_0_auc: 0.87553 |  0:01:08s\n",
      "epoch 47 | loss: 0.37859 | val_0_auc: 0.88947 |  0:01:09s\n",
      "epoch 48 | loss: 0.36922 | val_0_auc: 0.90654 |  0:01:10s\n",
      "epoch 49 | loss: 0.37321 | val_0_auc: 0.91075 |  0:01:12s\n",
      "epoch 50 | loss: 0.39155 | val_0_auc: 0.90015 |  0:01:13s\n",
      "epoch 51 | loss: 0.38097 | val_0_auc: 0.89651 |  0:01:15s\n",
      "epoch 52 | loss: 0.37791 | val_0_auc: 0.89542 |  0:01:16s\n",
      "epoch 53 | loss: 0.36716 | val_0_auc: 0.89717 |  0:01:18s\n",
      "epoch 54 | loss: 0.3791  | val_0_auc: 0.9053  |  0:01:19s\n",
      "epoch 55 | loss: 0.37597 | val_0_auc: 0.89412 |  0:01:21s\n",
      "epoch 56 | loss: 0.40106 | val_0_auc: 0.90261 |  0:01:22s\n",
      "epoch 57 | loss: 0.3767  | val_0_auc: 0.89172 |  0:01:24s\n",
      "epoch 58 | loss: 0.38686 | val_0_auc: 0.89049 |  0:01:25s\n",
      "epoch 59 | loss: 0.38984 | val_0_auc: 0.8886  |  0:01:27s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_0_auc = 0.91075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.26593 | val_0_auc: 0.80073 |  0:00:01s\n",
      "epoch 1  | loss: 0.64746 | val_0_auc: 0.69412 |  0:00:02s\n",
      "epoch 2  | loss: 0.58095 | val_0_auc: 0.77226 |  0:00:04s\n",
      "epoch 3  | loss: 0.499   | val_0_auc: 0.85359 |  0:00:05s\n",
      "epoch 4  | loss: 0.48797 | val_0_auc: 0.78184 |  0:00:07s\n",
      "epoch 5  | loss: 0.47573 | val_0_auc: 0.76354 |  0:00:08s\n",
      "epoch 6  | loss: 0.4638  | val_0_auc: 0.83529 |  0:00:10s\n",
      "epoch 7  | loss: 0.45863 | val_0_auc: 0.85004 |  0:00:11s\n",
      "epoch 8  | loss: 0.48836 | val_0_auc: 0.81728 |  0:00:13s\n",
      "epoch 9  | loss: 0.46083 | val_0_auc: 0.87102 |  0:00:14s\n",
      "epoch 10 | loss: 0.4504  | val_0_auc: 0.8719  |  0:00:16s\n",
      "epoch 11 | loss: 0.42705 | val_0_auc: 0.85926 |  0:00:17s\n",
      "epoch 12 | loss: 0.45193 | val_0_auc: 0.86812 |  0:00:18s\n",
      "epoch 13 | loss: 0.41135 | val_0_auc: 0.8228  |  0:00:20s\n",
      "epoch 14 | loss: 0.43607 | val_0_auc: 0.78751 |  0:00:21s\n",
      "epoch 15 | loss: 0.41586 | val_0_auc: 0.79826 |  0:00:23s\n",
      "epoch 16 | loss: 0.44618 | val_0_auc: 0.79208 |  0:00:24s\n",
      "epoch 17 | loss: 0.45168 | val_0_auc: 0.80944 |  0:00:25s\n",
      "epoch 18 | loss: 0.4424  | val_0_auc: 0.78635 |  0:00:27s\n",
      "epoch 19 | loss: 0.42127 | val_0_auc: 0.84285 |  0:00:28s\n",
      "epoch 20 | loss: 0.42284 | val_0_auc: 0.8342  |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.93834 | val_0_auc: 0.85694 |  0:00:01s\n",
      "epoch 1  | loss: 0.65488 | val_0_auc: 0.82033 |  0:00:03s\n",
      "epoch 2  | loss: 0.48388 | val_0_auc: 0.82469 |  0:00:05s\n",
      "epoch 3  | loss: 0.44834 | val_0_auc: 0.81249 |  0:00:07s\n",
      "epoch 4  | loss: 0.41997 | val_0_auc: 0.81627 |  0:00:08s\n",
      "epoch 5  | loss: 0.41286 | val_0_auc: 0.86129 |  0:00:10s\n",
      "epoch 6  | loss: 0.43907 | val_0_auc: 0.85389 |  0:00:12s\n",
      "epoch 7  | loss: 0.38467 | val_0_auc: 0.87059 |  0:00:14s\n",
      "epoch 8  | loss: 0.42752 | val_0_auc: 0.84822 |  0:00:15s\n",
      "epoch 9  | loss: 0.38986 | val_0_auc: 0.83893 |  0:00:17s\n",
      "epoch 10 | loss: 0.41603 | val_0_auc: 0.86173 |  0:00:19s\n",
      "epoch 11 | loss: 0.42586 | val_0_auc: 0.85084 |  0:00:21s\n",
      "epoch 12 | loss: 0.36186 | val_0_auc: 0.86696 |  0:00:23s\n",
      "epoch 13 | loss: 0.37485 | val_0_auc: 0.8719  |  0:00:24s\n",
      "epoch 14 | loss: 0.37082 | val_0_auc: 0.86652 |  0:00:26s\n",
      "epoch 15 | loss: 0.37979 | val_0_auc: 0.86144 |  0:00:28s\n",
      "epoch 16 | loss: 0.41106 | val_0_auc: 0.87538 |  0:00:30s\n",
      "epoch 17 | loss: 0.38362 | val_0_auc: 0.87073 |  0:00:31s\n",
      "epoch 18 | loss: 0.40011 | val_0_auc: 0.8671  |  0:00:33s\n",
      "epoch 19 | loss: 0.3848  | val_0_auc: 0.87466 |  0:00:35s\n",
      "epoch 20 | loss: 0.38487 | val_0_auc: 0.86028 |  0:00:37s\n",
      "epoch 21 | loss: 0.3847  | val_0_auc: 0.88453 |  0:00:38s\n",
      "epoch 22 | loss: 0.36943 | val_0_auc: 0.8748  |  0:00:40s\n",
      "epoch 23 | loss: 0.37431 | val_0_auc: 0.86275 |  0:00:42s\n",
      "epoch 24 | loss: 0.3765  | val_0_auc: 0.8764  |  0:00:44s\n",
      "epoch 25 | loss: 0.37527 | val_0_auc: 0.88598 |  0:00:46s\n",
      "epoch 26 | loss: 0.36872 | val_0_auc: 0.8931  |  0:00:48s\n",
      "epoch 27 | loss: 0.37845 | val_0_auc: 0.88947 |  0:00:50s\n",
      "epoch 28 | loss: 0.35645 | val_0_auc: 0.88366 |  0:00:52s\n",
      "epoch 29 | loss: 0.35082 | val_0_auc: 0.89136 |  0:00:53s\n",
      "epoch 30 | loss: 0.3484  | val_0_auc: 0.89383 |  0:00:55s\n",
      "epoch 31 | loss: 0.36437 | val_0_auc: 0.89092 |  0:00:57s\n",
      "epoch 32 | loss: 0.34685 | val_0_auc: 0.90138 |  0:00:59s\n",
      "epoch 33 | loss: 0.35532 | val_0_auc: 0.89005 |  0:01:01s\n",
      "epoch 34 | loss: 0.37061 | val_0_auc: 0.88983 |  0:01:03s\n",
      "epoch 35 | loss: 0.37236 | val_0_auc: 0.87226 |  0:01:04s\n",
      "epoch 36 | loss: 0.37935 | val_0_auc: 0.88744 |  0:01:06s\n",
      "epoch 37 | loss: 0.35137 | val_0_auc: 0.88947 |  0:01:08s\n",
      "epoch 38 | loss: 0.3534  | val_0_auc: 0.89346 |  0:01:10s\n",
      "epoch 39 | loss: 0.34933 | val_0_auc: 0.88787 |  0:01:12s\n",
      "epoch 40 | loss: 0.35097 | val_0_auc: 0.8841  |  0:01:13s\n",
      "epoch 41 | loss: 0.37198 | val_0_auc: 0.87567 |  0:01:15s\n",
      "epoch 42 | loss: 0.36652 | val_0_auc: 0.86783 |  0:01:17s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.87981 | val_0_auc: 0.79608 |  0:00:01s\n",
      "epoch 1  | loss: 0.69512 | val_0_auc: 0.80203 |  0:00:03s\n",
      "epoch 2  | loss: 0.55494 | val_0_auc: 0.75984 |  0:00:05s\n",
      "epoch 3  | loss: 0.44925 | val_0_auc: 0.81743 |  0:00:07s\n",
      "epoch 4  | loss: 0.42821 | val_0_auc: 0.84081 |  0:00:09s\n",
      "epoch 5  | loss: 0.42084 | val_0_auc: 0.8382  |  0:00:11s\n",
      "epoch 6  | loss: 0.40806 | val_0_auc: 0.82876 |  0:00:12s\n",
      "epoch 7  | loss: 0.39741 | val_0_auc: 0.84561 |  0:00:14s\n",
      "epoch 8  | loss: 0.4162  | val_0_auc: 0.85897 |  0:00:16s\n",
      "epoch 9  | loss: 0.40786 | val_0_auc: 0.84648 |  0:00:18s\n",
      "epoch 10 | loss: 0.40011 | val_0_auc: 0.85679 |  0:00:20s\n",
      "epoch 11 | loss: 0.41116 | val_0_auc: 0.85127 |  0:00:22s\n",
      "epoch 12 | loss: 0.41142 | val_0_auc: 0.85577 |  0:00:23s\n",
      "epoch 13 | loss: 0.40439 | val_0_auc: 0.86855 |  0:00:25s\n",
      "epoch 14 | loss: 0.38303 | val_0_auc: 0.87102 |  0:00:27s\n",
      "epoch 15 | loss: 0.38989 | val_0_auc: 0.86449 |  0:00:29s\n",
      "epoch 16 | loss: 0.40612 | val_0_auc: 0.87553 |  0:00:31s\n",
      "epoch 17 | loss: 0.4093  | val_0_auc: 0.88351 |  0:00:33s\n",
      "epoch 18 | loss: 0.39683 | val_0_auc: 0.86972 |  0:00:35s\n",
      "epoch 19 | loss: 0.39445 | val_0_auc: 0.86652 |  0:00:37s\n",
      "epoch 20 | loss: 0.38609 | val_0_auc: 0.87625 |  0:00:38s\n",
      "epoch 21 | loss: 0.38381 | val_0_auc: 0.87654 |  0:00:40s\n",
      "epoch 22 | loss: 0.37531 | val_0_auc: 0.87916 |  0:00:42s\n",
      "epoch 23 | loss: 0.40626 | val_0_auc: 0.89027 |  0:00:44s\n",
      "epoch 24 | loss: 0.39389 | val_0_auc: 0.86471 |  0:00:46s\n",
      "epoch 25 | loss: 0.38656 | val_0_auc: 0.88322 |  0:00:48s\n",
      "epoch 26 | loss: 0.37711 | val_0_auc: 0.88533 |  0:00:49s\n",
      "epoch 27 | loss: 0.38058 | val_0_auc: 0.89739 |  0:00:51s\n",
      "epoch 28 | loss: 0.38989 | val_0_auc: 0.89775 |  0:00:53s\n",
      "epoch 29 | loss: 0.3569  | val_0_auc: 0.89005 |  0:00:55s\n",
      "epoch 30 | loss: 0.36893 | val_0_auc: 0.89971 |  0:00:57s\n",
      "epoch 31 | loss: 0.37126 | val_0_auc: 0.89572 |  0:00:59s\n",
      "epoch 32 | loss: 0.35594 | val_0_auc: 0.90196 |  0:01:00s\n",
      "epoch 33 | loss: 0.37946 | val_0_auc: 0.89702 |  0:01:02s\n",
      "epoch 34 | loss: 0.36887 | val_0_auc: 0.89368 |  0:01:04s\n",
      "epoch 35 | loss: 0.38452 | val_0_auc: 0.89397 |  0:01:06s\n",
      "epoch 36 | loss: 0.3659  | val_0_auc: 0.89804 |  0:01:08s\n",
      "epoch 37 | loss: 0.36786 | val_0_auc: 0.89179 |  0:01:10s\n",
      "epoch 38 | loss: 0.38366 | val_0_auc: 0.88962 |  0:01:11s\n",
      "epoch 39 | loss: 0.38443 | val_0_auc: 0.90094 |  0:01:13s\n",
      "epoch 40 | loss: 0.38734 | val_0_auc: 0.88976 |  0:01:15s\n",
      "epoch 41 | loss: 0.40274 | val_0_auc: 0.89542 |  0:01:17s\n",
      "epoch 42 | loss: 0.37898 | val_0_auc: 0.89237 |  0:01:19s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.0388  | val_0_auc: 0.55701 |  0:00:01s\n",
      "epoch 1  | loss: 0.69118 | val_0_auc: 0.80755 |  0:00:03s\n",
      "epoch 2  | loss: 0.55898 | val_0_auc: 0.83893 |  0:00:05s\n",
      "epoch 3  | loss: 0.46017 | val_0_auc: 0.84459 |  0:00:07s\n",
      "epoch 4  | loss: 0.411   | val_0_auc: 0.82658 |  0:00:09s\n",
      "epoch 5  | loss: 0.42867 | val_0_auc: 0.84125 |  0:00:11s\n",
      "epoch 6  | loss: 0.39906 | val_0_auc: 0.83529 |  0:00:12s\n",
      "epoch 7  | loss: 0.4254  | val_0_auc: 0.84989 |  0:00:14s\n",
      "epoch 8  | loss: 0.40973 | val_0_auc: 0.82803 |  0:00:16s\n",
      "epoch 9  | loss: 0.42343 | val_0_auc: 0.85824 |  0:00:18s\n",
      "epoch 10 | loss: 0.39933 | val_0_auc: 0.85621 |  0:00:20s\n",
      "epoch 11 | loss: 0.40763 | val_0_auc: 0.84168 |  0:00:22s\n",
      "epoch 12 | loss: 0.42861 | val_0_auc: 0.8459  |  0:00:24s\n",
      "epoch 13 | loss: 0.39834 | val_0_auc: 0.86333 |  0:00:26s\n",
      "epoch 14 | loss: 0.39828 | val_0_auc: 0.86224 |  0:00:28s\n",
      "epoch 15 | loss: 0.37251 | val_0_auc: 0.84909 |  0:00:29s\n",
      "epoch 16 | loss: 0.40894 | val_0_auc: 0.82847 |  0:00:31s\n",
      "epoch 17 | loss: 0.42441 | val_0_auc: 0.88468 |  0:00:33s\n",
      "epoch 18 | loss: 0.40373 | val_0_auc: 0.86173 |  0:00:35s\n",
      "epoch 19 | loss: 0.40064 | val_0_auc: 0.87015 |  0:00:37s\n",
      "epoch 20 | loss: 0.38424 | val_0_auc: 0.87204 |  0:00:39s\n",
      "epoch 21 | loss: 0.4008  | val_0_auc: 0.88119 |  0:00:41s\n",
      "epoch 22 | loss: 0.40498 | val_0_auc: 0.88526 |  0:00:43s\n",
      "epoch 23 | loss: 0.37088 | val_0_auc: 0.8902  |  0:00:44s\n",
      "epoch 24 | loss: 0.39075 | val_0_auc: 0.88148 |  0:00:46s\n",
      "epoch 25 | loss: 0.40444 | val_0_auc: 0.88584 |  0:00:48s\n",
      "epoch 26 | loss: 0.38789 | val_0_auc: 0.8841  |  0:00:50s\n",
      "epoch 27 | loss: 0.39301 | val_0_auc: 0.89237 |  0:00:52s\n",
      "epoch 28 | loss: 0.38279 | val_0_auc: 0.89049 |  0:00:54s\n",
      "epoch 29 | loss: 0.34318 | val_0_auc: 0.89281 |  0:00:55s\n",
      "epoch 30 | loss: 0.38272 | val_0_auc: 0.88816 |  0:00:57s\n",
      "epoch 31 | loss: 0.38309 | val_0_auc: 0.88991 |  0:00:59s\n",
      "epoch 32 | loss: 0.38979 | val_0_auc: 0.8963  |  0:01:01s\n",
      "epoch 33 | loss: 0.39291 | val_0_auc: 0.88642 |  0:01:03s\n",
      "epoch 34 | loss: 0.40015 | val_0_auc: 0.89993 |  0:01:05s\n",
      "epoch 35 | loss: 0.39323 | val_0_auc: 0.89383 |  0:01:07s\n",
      "epoch 36 | loss: 0.37556 | val_0_auc: 0.88773 |  0:01:09s\n",
      "epoch 37 | loss: 0.36768 | val_0_auc: 0.8963  |  0:01:11s\n",
      "epoch 38 | loss: 0.38882 | val_0_auc: 0.88017 |  0:01:13s\n",
      "epoch 39 | loss: 0.38826 | val_0_auc: 0.88991 |  0:01:15s\n",
      "epoch 40 | loss: 0.3687  | val_0_auc: 0.87959 |  0:01:17s\n",
      "epoch 41 | loss: 0.40578 | val_0_auc: 0.88744 |  0:01:19s\n",
      "epoch 42 | loss: 0.37161 | val_0_auc: 0.8963  |  0:01:21s\n",
      "epoch 43 | loss: 0.38311 | val_0_auc: 0.88206 |  0:01:23s\n",
      "epoch 44 | loss: 0.3943  | val_0_auc: 0.88932 |  0:01:25s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.89993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.10295 | val_0_auc: 0.82876 |  0:00:02s\n",
      "epoch 1  | loss: 0.59583 | val_0_auc: 0.72593 |  0:00:03s\n",
      "epoch 2  | loss: 0.50652 | val_0_auc: 0.81772 |  0:00:05s\n",
      "epoch 3  | loss: 0.41618 | val_0_auc: 0.85773 |  0:00:07s\n",
      "epoch 4  | loss: 0.40233 | val_0_auc: 0.84982 |  0:00:09s\n",
      "epoch 5  | loss: 0.4062  | val_0_auc: 0.86652 |  0:00:11s\n",
      "epoch 6  | loss: 0.43766 | val_0_auc: 0.86594 |  0:00:13s\n",
      "epoch 7  | loss: 0.41843 | val_0_auc: 0.85476 |  0:00:14s\n",
      "epoch 8  | loss: 0.39    | val_0_auc: 0.87654 |  0:00:16s\n",
      "epoch 9  | loss: 0.436   | val_0_auc: 0.8732  |  0:00:18s\n",
      "epoch 10 | loss: 0.38401 | val_0_auc: 0.8841  |  0:00:20s\n",
      "epoch 11 | loss: 0.37398 | val_0_auc: 0.86362 |  0:00:22s\n",
      "epoch 12 | loss: 0.41128 | val_0_auc: 0.85476 |  0:00:24s\n",
      "epoch 13 | loss: 0.40293 | val_0_auc: 0.85577 |  0:00:25s\n",
      "epoch 14 | loss: 0.3848  | val_0_auc: 0.87117 |  0:00:27s\n",
      "epoch 15 | loss: 0.39876 | val_0_auc: 0.86333 |  0:00:29s\n",
      "epoch 16 | loss: 0.38351 | val_0_auc: 0.86594 |  0:00:31s\n",
      "epoch 17 | loss: 0.39829 | val_0_auc: 0.8703  |  0:00:33s\n",
      "epoch 18 | loss: 0.39226 | val_0_auc: 0.87872 |  0:00:35s\n",
      "epoch 19 | loss: 0.38979 | val_0_auc: 0.87291 |  0:00:36s\n",
      "epoch 20 | loss: 0.40739 | val_0_auc: 0.8748  |  0:00:38s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.07992 | val_0_auc: 0.56166 |  0:00:02s\n",
      "epoch 1  | loss: 0.6382  | val_0_auc: 0.79753 |  0:00:03s\n",
      "epoch 2  | loss: 0.51824 | val_0_auc: 0.81859 |  0:00:05s\n",
      "epoch 3  | loss: 0.49603 | val_0_auc: 0.80741 |  0:00:07s\n",
      "epoch 4  | loss: 0.44113 | val_0_auc: 0.83442 |  0:00:09s\n",
      "epoch 5  | loss: 0.43901 | val_0_auc: 0.84532 |  0:00:11s\n",
      "epoch 6  | loss: 0.4228  | val_0_auc: 0.85897 |  0:00:13s\n",
      "epoch 7  | loss: 0.46651 | val_0_auc: 0.87015 |  0:00:15s\n",
      "epoch 8  | loss: 0.43469 | val_0_auc: 0.84575 |  0:00:17s\n",
      "epoch 9  | loss: 0.43257 | val_0_auc: 0.84081 |  0:00:18s\n",
      "epoch 10 | loss: 0.43038 | val_0_auc: 0.88279 |  0:00:20s\n",
      "epoch 11 | loss: 0.43821 | val_0_auc: 0.88322 |  0:00:22s\n",
      "epoch 12 | loss: 0.43433 | val_0_auc: 0.8764  |  0:00:24s\n",
      "epoch 13 | loss: 0.41695 | val_0_auc: 0.87451 |  0:00:26s\n",
      "epoch 14 | loss: 0.40637 | val_0_auc: 0.86289 |  0:00:28s\n",
      "epoch 15 | loss: 0.43037 | val_0_auc: 0.85679 |  0:00:30s\n",
      "epoch 16 | loss: 0.43113 | val_0_auc: 0.87204 |  0:00:32s\n",
      "epoch 17 | loss: 0.41784 | val_0_auc: 0.85606 |  0:00:33s\n",
      "epoch 18 | loss: 0.40654 | val_0_auc: 0.86928 |  0:00:35s\n",
      "epoch 19 | loss: 0.40521 | val_0_auc: 0.87654 |  0:00:37s\n",
      "epoch 20 | loss: 0.41127 | val_0_auc: 0.86928 |  0:00:39s\n",
      "epoch 21 | loss: 0.39478 | val_0_auc: 0.88003 |  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.88322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6035  | val_0_auc: 0.79274 |  0:00:01s\n",
      "epoch 1  | loss: 0.43631 | val_0_auc: 0.76471 |  0:00:02s\n",
      "epoch 2  | loss: 0.41118 | val_0_auc: 0.80276 |  0:00:03s\n",
      "epoch 3  | loss: 0.42497 | val_0_auc: 0.84938 |  0:00:04s\n",
      "epoch 4  | loss: 0.40068 | val_0_auc: 0.84328 |  0:00:05s\n",
      "epoch 5  | loss: 0.41579 | val_0_auc: 0.81685 |  0:00:06s\n",
      "epoch 6  | loss: 0.4018  | val_0_auc: 0.83203 |  0:00:07s\n",
      "epoch 7  | loss: 0.42425 | val_0_auc: 0.81351 |  0:00:09s\n",
      "epoch 8  | loss: 0.39053 | val_0_auc: 0.80748 |  0:00:10s\n",
      "epoch 9  | loss: 0.3906  | val_0_auc: 0.82578 |  0:00:11s\n",
      "epoch 10 | loss: 0.38007 | val_0_auc: 0.82912 |  0:00:12s\n",
      "epoch 11 | loss: 0.39559 | val_0_auc: 0.85933 |  0:00:13s\n",
      "epoch 12 | loss: 0.38559 | val_0_auc: 0.85338 |  0:00:14s\n",
      "epoch 13 | loss: 0.41045 | val_0_auc: 0.85054 |  0:00:15s\n",
      "epoch 14 | loss: 0.38566 | val_0_auc: 0.84118 |  0:00:16s\n",
      "epoch 15 | loss: 0.38791 | val_0_auc: 0.83457 |  0:00:17s\n",
      "epoch 16 | loss: 0.37754 | val_0_auc: 0.85287 |  0:00:19s\n",
      "epoch 17 | loss: 0.37786 | val_0_auc: 0.8374  |  0:00:20s\n",
      "epoch 18 | loss: 0.38873 | val_0_auc: 0.84735 |  0:00:21s\n",
      "epoch 19 | loss: 0.37822 | val_0_auc: 0.84815 |  0:00:22s\n",
      "epoch 20 | loss: 0.3692  | val_0_auc: 0.8488  |  0:00:23s\n",
      "epoch 21 | loss: 0.37393 | val_0_auc: 0.85316 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.85933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59602 | val_0_auc: 0.68381 |  0:00:01s\n",
      "epoch 1  | loss: 0.47622 | val_0_auc: 0.63224 |  0:00:02s\n",
      "epoch 2  | loss: 0.44447 | val_0_auc: 0.81438 |  0:00:03s\n",
      "epoch 3  | loss: 0.45234 | val_0_auc: 0.85359 |  0:00:04s\n",
      "epoch 4  | loss: 0.4257  | val_0_auc: 0.84444 |  0:00:05s\n",
      "epoch 5  | loss: 0.42196 | val_0_auc: 0.85098 |  0:00:07s\n",
      "epoch 6  | loss: 0.42558 | val_0_auc: 0.84154 |  0:00:09s\n",
      "epoch 7  | loss: 0.44404 | val_0_auc: 0.82629 |  0:00:10s\n",
      "epoch 8  | loss: 0.40325 | val_0_auc: 0.83145 |  0:00:12s\n",
      "epoch 9  | loss: 0.427   | val_0_auc: 0.84248 |  0:00:13s\n",
      "epoch 10 | loss: 0.40908 | val_0_auc: 0.85468 |  0:00:14s\n",
      "epoch 11 | loss: 0.42133 | val_0_auc: 0.85788 |  0:00:15s\n",
      "epoch 12 | loss: 0.40436 | val_0_auc: 0.8541  |  0:00:16s\n",
      "epoch 13 | loss: 0.41627 | val_0_auc: 0.85352 |  0:00:17s\n",
      "epoch 14 | loss: 0.3794  | val_0_auc: 0.86006 |  0:00:18s\n",
      "epoch 15 | loss: 0.38354 | val_0_auc: 0.85352 |  0:00:20s\n",
      "epoch 16 | loss: 0.3891  | val_0_auc: 0.86623 |  0:00:21s\n",
      "epoch 17 | loss: 0.3783  | val_0_auc: 0.861   |  0:00:22s\n",
      "epoch 18 | loss: 0.38006 | val_0_auc: 0.87771 |  0:00:23s\n",
      "epoch 19 | loss: 0.38781 | val_0_auc: 0.87531 |  0:00:24s\n",
      "epoch 20 | loss: 0.3792  | val_0_auc: 0.86725 |  0:00:25s\n",
      "epoch 21 | loss: 0.37341 | val_0_auc: 0.85882 |  0:00:26s\n",
      "epoch 22 | loss: 0.41709 | val_0_auc: 0.8655  |  0:00:27s\n",
      "epoch 23 | loss: 0.37243 | val_0_auc: 0.85991 |  0:00:28s\n",
      "epoch 24 | loss: 0.38863 | val_0_auc: 0.87386 |  0:00:29s\n",
      "epoch 25 | loss: 0.41697 | val_0_auc: 0.86565 |  0:00:30s\n",
      "epoch 26 | loss: 0.39106 | val_0_auc: 0.85635 |  0:00:31s\n",
      "epoch 27 | loss: 0.3949  | val_0_auc: 0.8634  |  0:00:33s\n",
      "epoch 28 | loss: 0.41282 | val_0_auc: 0.83442 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.87771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59076 | val_0_auc: 0.69339 |  0:00:01s\n",
      "epoch 1  | loss: 0.51339 | val_0_auc: 0.86289 |  0:00:02s\n",
      "epoch 2  | loss: 0.41755 | val_0_auc: 0.84372 |  0:00:03s\n",
      "epoch 3  | loss: 0.49712 | val_0_auc: 0.8374  |  0:00:04s\n",
      "epoch 4  | loss: 0.42216 | val_0_auc: 0.84357 |  0:00:05s\n",
      "epoch 5  | loss: 0.46099 | val_0_auc: 0.81511 |  0:00:06s\n",
      "epoch 6  | loss: 0.44904 | val_0_auc: 0.84227 |  0:00:07s\n",
      "epoch 7  | loss: 0.44764 | val_0_auc: 0.84212 |  0:00:09s\n",
      "epoch 8  | loss: 0.41123 | val_0_auc: 0.81249 |  0:00:10s\n",
      "epoch 9  | loss: 0.41785 | val_0_auc: 0.79855 |  0:00:11s\n",
      "epoch 10 | loss: 0.41583 | val_0_auc: 0.86187 |  0:00:12s\n",
      "epoch 11 | loss: 0.42672 | val_0_auc: 0.83057 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.86289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57796 | val_0_auc: 0.78344 |  0:00:01s\n",
      "epoch 1  | loss: 0.50591 | val_0_auc: 0.84706 |  0:00:02s\n",
      "epoch 2  | loss: 0.43849 | val_0_auc: 0.80131 |  0:00:03s\n",
      "epoch 3  | loss: 0.47737 | val_0_auc: 0.83355 |  0:00:04s\n",
      "epoch 4  | loss: 0.40168 | val_0_auc: 0.78591 |  0:00:05s\n",
      "epoch 5  | loss: 0.41065 | val_0_auc: 0.76819 |  0:00:06s\n",
      "epoch 6  | loss: 0.42938 | val_0_auc: 0.78548 |  0:00:07s\n",
      "epoch 7  | loss: 0.40585 | val_0_auc: 0.84764 |  0:00:09s\n",
      "epoch 8  | loss: 0.43126 | val_0_auc: 0.84975 |  0:00:10s\n",
      "epoch 9  | loss: 0.41681 | val_0_auc: 0.8565  |  0:00:11s\n",
      "epoch 10 | loss: 0.39658 | val_0_auc: 0.86013 |  0:00:12s\n",
      "epoch 11 | loss: 0.43769 | val_0_auc: 0.80465 |  0:00:13s\n",
      "epoch 12 | loss: 0.41051 | val_0_auc: 0.80944 |  0:00:14s\n",
      "epoch 13 | loss: 0.39713 | val_0_auc: 0.82564 |  0:00:15s\n",
      "epoch 14 | loss: 0.42139 | val_0_auc: 0.82317 |  0:00:16s\n",
      "epoch 15 | loss: 0.40156 | val_0_auc: 0.83849 |  0:00:18s\n",
      "epoch 16 | loss: 0.40336 | val_0_auc: 0.8297  |  0:00:19s\n",
      "epoch 17 | loss: 0.39629 | val_0_auc: 0.83827 |  0:00:20s\n",
      "epoch 18 | loss: 0.40026 | val_0_auc: 0.83086 |  0:00:21s\n",
      "epoch 19 | loss: 0.37835 | val_0_auc: 0.83725 |  0:00:22s\n",
      "epoch 20 | loss: 0.40665 | val_0_auc: 0.83849 |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.86013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6272  | val_0_auc: 0.76609 |  0:00:01s\n",
      "epoch 1  | loss: 0.46985 | val_0_auc: 0.80784 |  0:00:02s\n",
      "epoch 2  | loss: 0.47237 | val_0_auc: 0.84067 |  0:00:03s\n",
      "epoch 3  | loss: 0.48192 | val_0_auc: 0.74604 |  0:00:04s\n",
      "epoch 4  | loss: 0.44814 | val_0_auc: 0.75846 |  0:00:05s\n",
      "epoch 5  | loss: 0.47235 | val_0_auc: 0.83282 |  0:00:06s\n",
      "epoch 6  | loss: 0.43597 | val_0_auc: 0.85817 |  0:00:07s\n",
      "epoch 7  | loss: 0.42714 | val_0_auc: 0.82309 |  0:00:08s\n",
      "epoch 8  | loss: 0.45033 | val_0_auc: 0.82919 |  0:00:09s\n",
      "epoch 9  | loss: 0.44488 | val_0_auc: 0.83442 |  0:00:10s\n",
      "epoch 10 | loss: 0.40745 | val_0_auc: 0.8594  |  0:00:11s\n",
      "epoch 11 | loss: 0.40766 | val_0_auc: 0.83195 |  0:00:12s\n",
      "epoch 12 | loss: 0.4261  | val_0_auc: 0.84038 |  0:00:14s\n",
      "epoch 13 | loss: 0.41934 | val_0_auc: 0.85113 |  0:00:15s\n",
      "epoch 14 | loss: 0.41698 | val_0_auc: 0.84394 |  0:00:16s\n",
      "epoch 15 | loss: 0.41601 | val_0_auc: 0.85054 |  0:00:17s\n",
      "epoch 16 | loss: 0.41668 | val_0_auc: 0.84996 |  0:00:18s\n",
      "epoch 17 | loss: 0.40989 | val_0_auc: 0.84386 |  0:00:19s\n",
      "epoch 18 | loss: 0.42806 | val_0_auc: 0.84423 |  0:00:20s\n",
      "epoch 19 | loss: 0.41226 | val_0_auc: 0.85389 |  0:00:21s\n",
      "epoch 20 | loss: 0.40627 | val_0_auc: 0.8549  |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.51132 | val_0_auc: 0.87102 |  0:00:00s\n",
      "epoch 1  | loss: 0.40324 | val_0_auc: 0.83588 |  0:00:01s\n",
      "epoch 2  | loss: 0.39811 | val_0_auc: 0.81089 |  0:00:02s\n",
      "epoch 3  | loss: 0.39034 | val_0_auc: 0.82672 |  0:00:02s\n",
      "epoch 4  | loss: 0.41127 | val_0_auc: 0.84517 |  0:00:03s\n",
      "epoch 5  | loss: 0.39608 | val_0_auc: 0.84851 |  0:00:04s\n",
      "epoch 6  | loss: 0.38585 | val_0_auc: 0.83486 |  0:00:05s\n",
      "epoch 7  | loss: 0.38119 | val_0_auc: 0.85926 |  0:00:05s\n",
      "epoch 8  | loss: 0.36726 | val_0_auc: 0.84633 |  0:00:06s\n",
      "epoch 9  | loss: 0.3972  | val_0_auc: 0.82934 |  0:00:07s\n",
      "epoch 10 | loss: 0.38945 | val_0_auc: 0.82309 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.87102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57315 | val_0_auc: 0.81206 |  0:00:00s\n",
      "epoch 1  | loss: 0.43939 | val_0_auc: 0.83776 |  0:00:01s\n",
      "epoch 2  | loss: 0.42481 | val_0_auc: 0.83341 |  0:00:02s\n",
      "epoch 3  | loss: 0.3955  | val_0_auc: 0.83834 |  0:00:02s\n",
      "epoch 4  | loss: 0.41313 | val_0_auc: 0.83384 |  0:00:03s\n",
      "epoch 5  | loss: 0.40176 | val_0_auc: 0.83951 |  0:00:04s\n",
      "epoch 6  | loss: 0.38609 | val_0_auc: 0.83457 |  0:00:05s\n",
      "epoch 7  | loss: 0.40416 | val_0_auc: 0.8642  |  0:00:05s\n",
      "epoch 8  | loss: 0.40283 | val_0_auc: 0.8366  |  0:00:06s\n",
      "epoch 9  | loss: 0.40912 | val_0_auc: 0.85824 |  0:00:07s\n",
      "epoch 10 | loss: 0.39544 | val_0_auc: 0.85258 |  0:00:07s\n",
      "epoch 11 | loss: 0.4196  | val_0_auc: 0.80973 |  0:00:08s\n",
      "epoch 12 | loss: 0.38157 | val_0_auc: 0.83907 |  0:00:09s\n",
      "epoch 13 | loss: 0.39979 | val_0_auc: 0.8411  |  0:00:10s\n",
      "epoch 14 | loss: 0.3911  | val_0_auc: 0.84503 |  0:00:10s\n",
      "epoch 15 | loss: 0.43316 | val_0_auc: 0.86623 |  0:00:11s\n",
      "epoch 16 | loss: 0.4061  | val_0_auc: 0.88627 |  0:00:12s\n",
      "epoch 17 | loss: 0.38182 | val_0_auc: 0.89092 |  0:00:13s\n",
      "epoch 18 | loss: 0.40105 | val_0_auc: 0.8886  |  0:00:13s\n",
      "epoch 19 | loss: 0.39626 | val_0_auc: 0.87364 |  0:00:14s\n",
      "epoch 20 | loss: 0.38197 | val_0_auc: 0.86492 |  0:00:15s\n",
      "epoch 21 | loss: 0.39752 | val_0_auc: 0.83769 |  0:00:16s\n",
      "epoch 22 | loss: 0.38298 | val_0_auc: 0.86885 |  0:00:16s\n",
      "epoch 23 | loss: 0.37669 | val_0_auc: 0.86391 |  0:00:17s\n",
      "epoch 24 | loss: 0.371   | val_0_auc: 0.86732 |  0:00:18s\n",
      "epoch 25 | loss: 0.39113 | val_0_auc: 0.87698 |  0:00:19s\n",
      "epoch 26 | loss: 0.38199 | val_0_auc: 0.87248 |  0:00:19s\n",
      "epoch 27 | loss: 0.37776 | val_0_auc: 0.88214 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.89092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52127 | val_0_auc: 0.86057 |  0:00:00s\n",
      "epoch 1  | loss: 0.43675 | val_0_auc: 0.86826 |  0:00:01s\n",
      "epoch 2  | loss: 0.40981 | val_0_auc: 0.86405 |  0:00:02s\n",
      "epoch 3  | loss: 0.39886 | val_0_auc: 0.79971 |  0:00:02s\n",
      "epoch 4  | loss: 0.40614 | val_0_auc: 0.8183  |  0:00:03s\n",
      "epoch 5  | loss: 0.37629 | val_0_auc: 0.85301 |  0:00:04s\n",
      "epoch 6  | loss: 0.39018 | val_0_auc: 0.87335 |  0:00:05s\n",
      "epoch 7  | loss: 0.42007 | val_0_auc: 0.86507 |  0:00:05s\n",
      "epoch 8  | loss: 0.42326 | val_0_auc: 0.86906 |  0:00:06s\n",
      "epoch 9  | loss: 0.39252 | val_0_auc: 0.86659 |  0:00:07s\n",
      "epoch 10 | loss: 0.37856 | val_0_auc: 0.87269 |  0:00:08s\n",
      "epoch 11 | loss: 0.3674  | val_0_auc: 0.8764  |  0:00:08s\n",
      "epoch 12 | loss: 0.38242 | val_0_auc: 0.87545 |  0:00:09s\n",
      "epoch 13 | loss: 0.38204 | val_0_auc: 0.85105 |  0:00:10s\n",
      "epoch 14 | loss: 0.40425 | val_0_auc: 0.86855 |  0:00:10s\n",
      "epoch 15 | loss: 0.41017 | val_0_auc: 0.87262 |  0:00:11s\n",
      "epoch 16 | loss: 0.40481 | val_0_auc: 0.88126 |  0:00:12s\n",
      "epoch 17 | loss: 0.38465 | val_0_auc: 0.88715 |  0:00:13s\n",
      "epoch 18 | loss: 0.38314 | val_0_auc: 0.88526 |  0:00:13s\n",
      "epoch 19 | loss: 0.37652 | val_0_auc: 0.88751 |  0:00:14s\n",
      "epoch 20 | loss: 0.37605 | val_0_auc: 0.88366 |  0:00:15s\n",
      "epoch 21 | loss: 0.38316 | val_0_auc: 0.87262 |  0:00:16s\n",
      "epoch 22 | loss: 0.38859 | val_0_auc: 0.88918 |  0:00:16s\n",
      "epoch 23 | loss: 0.37197 | val_0_auc: 0.89012 |  0:00:17s\n",
      "epoch 24 | loss: 0.39165 | val_0_auc: 0.88206 |  0:00:18s\n",
      "epoch 25 | loss: 0.3717  | val_0_auc: 0.88845 |  0:00:19s\n",
      "epoch 26 | loss: 0.37232 | val_0_auc: 0.89005 |  0:00:19s\n",
      "epoch 27 | loss: 0.37216 | val_0_auc: 0.8833  |  0:00:20s\n",
      "epoch 28 | loss: 0.38017 | val_0_auc: 0.88649 |  0:00:21s\n",
      "epoch 29 | loss: 0.37534 | val_0_auc: 0.89615 |  0:00:22s\n",
      "epoch 30 | loss: 0.37534 | val_0_auc: 0.89332 |  0:00:22s\n",
      "epoch 31 | loss: 0.37899 | val_0_auc: 0.89107 |  0:00:23s\n",
      "epoch 32 | loss: 0.36879 | val_0_auc: 0.90073 |  0:00:24s\n",
      "epoch 33 | loss: 0.37233 | val_0_auc: 0.89172 |  0:00:25s\n",
      "epoch 34 | loss: 0.37161 | val_0_auc: 0.89027 |  0:00:25s\n",
      "epoch 35 | loss: 0.37987 | val_0_auc: 0.89361 |  0:00:26s\n",
      "epoch 36 | loss: 0.38702 | val_0_auc: 0.88715 |  0:00:27s\n",
      "epoch 37 | loss: 0.37225 | val_0_auc: 0.89346 |  0:00:28s\n",
      "epoch 38 | loss: 0.3678  | val_0_auc: 0.88177 |  0:00:28s\n",
      "epoch 39 | loss: 0.37409 | val_0_auc: 0.88773 |  0:00:29s\n",
      "epoch 40 | loss: 0.37262 | val_0_auc: 0.88395 |  0:00:30s\n",
      "epoch 41 | loss: 0.35755 | val_0_auc: 0.87654 |  0:00:31s\n",
      "epoch 42 | loss: 0.35529 | val_0_auc: 0.8764  |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53138 | val_0_auc: 0.81264 |  0:00:00s\n",
      "epoch 1  | loss: 0.49107 | val_0_auc: 0.78214 |  0:00:01s\n",
      "epoch 2  | loss: 0.45212 | val_0_auc: 0.82353 |  0:00:02s\n",
      "epoch 3  | loss: 0.40218 | val_0_auc: 0.81133 |  0:00:03s\n",
      "epoch 4  | loss: 0.42695 | val_0_auc: 0.83007 |  0:00:03s\n",
      "epoch 5  | loss: 0.39361 | val_0_auc: 0.8427  |  0:00:04s\n",
      "epoch 6  | loss: 0.38476 | val_0_auc: 0.81293 |  0:00:05s\n",
      "epoch 7  | loss: 0.43285 | val_0_auc: 0.86391 |  0:00:06s\n",
      "epoch 8  | loss: 0.41142 | val_0_auc: 0.87683 |  0:00:07s\n",
      "epoch 9  | loss: 0.38329 | val_0_auc: 0.87204 |  0:00:07s\n",
      "epoch 10 | loss: 0.36103 | val_0_auc: 0.87952 |  0:00:08s\n",
      "epoch 11 | loss: 0.37254 | val_0_auc: 0.84924 |  0:00:09s\n",
      "epoch 12 | loss: 0.37212 | val_0_auc: 0.86434 |  0:00:10s\n",
      "epoch 13 | loss: 0.36069 | val_0_auc: 0.87901 |  0:00:11s\n",
      "epoch 14 | loss: 0.3857  | val_0_auc: 0.87175 |  0:00:11s\n",
      "epoch 15 | loss: 0.37437 | val_0_auc: 0.87683 |  0:00:12s\n",
      "epoch 16 | loss: 0.38772 | val_0_auc: 0.87524 |  0:00:13s\n",
      "epoch 17 | loss: 0.37606 | val_0_auc: 0.86471 |  0:00:14s\n",
      "epoch 18 | loss: 0.37101 | val_0_auc: 0.87001 |  0:00:14s\n",
      "epoch 19 | loss: 0.38613 | val_0_auc: 0.87393 |  0:00:15s\n",
      "epoch 20 | loss: 0.38463 | val_0_auc: 0.88126 |  0:00:16s\n",
      "epoch 21 | loss: 0.37956 | val_0_auc: 0.8785  |  0:00:17s\n",
      "epoch 22 | loss: 0.35935 | val_0_auc: 0.8825  |  0:00:18s\n",
      "epoch 23 | loss: 0.37491 | val_0_auc: 0.88802 |  0:00:19s\n",
      "epoch 24 | loss: 0.36467 | val_0_auc: 0.88555 |  0:00:19s\n",
      "epoch 25 | loss: 0.39439 | val_0_auc: 0.89325 |  0:00:20s\n",
      "epoch 26 | loss: 0.36968 | val_0_auc: 0.89964 |  0:00:21s\n",
      "epoch 27 | loss: 0.36656 | val_0_auc: 0.8947  |  0:00:22s\n",
      "epoch 28 | loss: 0.36193 | val_0_auc: 0.89339 |  0:00:22s\n",
      "epoch 29 | loss: 0.35818 | val_0_auc: 0.89572 |  0:00:23s\n",
      "epoch 30 | loss: 0.38359 | val_0_auc: 0.87495 |  0:00:24s\n",
      "epoch 31 | loss: 0.39332 | val_0_auc: 0.88417 |  0:00:25s\n",
      "epoch 32 | loss: 0.38671 | val_0_auc: 0.8992  |  0:00:25s\n",
      "epoch 33 | loss: 0.37774 | val_0_auc: 0.87153 |  0:00:26s\n",
      "epoch 34 | loss: 0.38244 | val_0_auc: 0.87139 |  0:00:27s\n",
      "epoch 35 | loss: 0.37769 | val_0_auc: 0.88686 |  0:00:28s\n",
      "epoch 36 | loss: 0.39211 | val_0_auc: 0.86057 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58795 | val_0_auc: 0.86899 |  0:00:00s\n",
      "epoch 1  | loss: 0.47194 | val_0_auc: 0.8549  |  0:00:01s\n",
      "epoch 2  | loss: 0.41989 | val_0_auc: 0.8411  |  0:00:02s\n",
      "epoch 3  | loss: 0.41414 | val_0_auc: 0.8504  |  0:00:02s\n",
      "epoch 4  | loss: 0.4112  | val_0_auc: 0.86347 |  0:00:03s\n",
      "epoch 5  | loss: 0.41658 | val_0_auc: 0.85418 |  0:00:04s\n",
      "epoch 6  | loss: 0.44078 | val_0_auc: 0.84067 |  0:00:05s\n",
      "epoch 7  | loss: 0.39339 | val_0_auc: 0.83631 |  0:00:05s\n",
      "epoch 8  | loss: 0.42806 | val_0_auc: 0.81409 |  0:00:06s\n",
      "epoch 9  | loss: 0.39357 | val_0_auc: 0.81235 |  0:00:07s\n",
      "epoch 10 | loss: 0.41073 | val_0_auc: 0.81656 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.86899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65942 | val_0_auc: 0.53319 |  0:00:01s\n",
      "epoch 1  | loss: 0.53167 | val_0_auc: 0.77589 |  0:00:02s\n",
      "epoch 2  | loss: 0.44256 | val_0_auc: 0.81743 |  0:00:04s\n",
      "epoch 3  | loss: 0.41331 | val_0_auc: 0.84648 |  0:00:05s\n",
      "epoch 4  | loss: 0.39289 | val_0_auc: 0.84851 |  0:00:06s\n",
      "epoch 5  | loss: 0.40513 | val_0_auc: 0.89107 |  0:00:07s\n",
      "epoch 6  | loss: 0.39895 | val_0_auc: 0.87262 |  0:00:09s\n",
      "epoch 7  | loss: 0.40124 | val_0_auc: 0.85505 |  0:00:10s\n",
      "epoch 8  | loss: 0.39538 | val_0_auc: 0.86318 |  0:00:11s\n",
      "epoch 9  | loss: 0.37149 | val_0_auc: 0.83893 |  0:00:12s\n",
      "epoch 10 | loss: 0.39721 | val_0_auc: 0.85156 |  0:00:14s\n",
      "epoch 11 | loss: 0.37018 | val_0_auc: 0.85868 |  0:00:15s\n",
      "epoch 12 | loss: 0.38209 | val_0_auc: 0.83036 |  0:00:16s\n",
      "epoch 13 | loss: 0.37125 | val_0_auc: 0.80189 |  0:00:17s\n",
      "epoch 14 | loss: 0.38912 | val_0_auc: 0.7984  |  0:00:19s\n",
      "epoch 15 | loss: 0.37051 | val_0_auc: 0.86696 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.89107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6943  | val_0_auc: 0.82099 |  0:00:01s\n",
      "epoch 1  | loss: 0.49625 | val_0_auc: 0.84619 |  0:00:02s\n",
      "epoch 2  | loss: 0.45661 | val_0_auc: 0.81394 |  0:00:03s\n",
      "epoch 3  | loss: 0.44781 | val_0_auc: 0.87829 |  0:00:05s\n",
      "epoch 4  | loss: 0.42339 | val_0_auc: 0.8488  |  0:00:06s\n",
      "epoch 5  | loss: 0.39992 | val_0_auc: 0.84706 |  0:00:07s\n",
      "epoch 6  | loss: 0.41778 | val_0_auc: 0.84967 |  0:00:09s\n",
      "epoch 7  | loss: 0.42225 | val_0_auc: 0.85142 |  0:00:10s\n",
      "epoch 8  | loss: 0.40071 | val_0_auc: 0.86231 |  0:00:11s\n",
      "epoch 9  | loss: 0.3913  | val_0_auc: 0.85766 |  0:00:12s\n",
      "epoch 10 | loss: 0.37606 | val_0_auc: 0.85374 |  0:00:14s\n",
      "epoch 11 | loss: 0.39659 | val_0_auc: 0.87001 |  0:00:15s\n",
      "epoch 12 | loss: 0.40684 | val_0_auc: 0.85955 |  0:00:16s\n",
      "epoch 13 | loss: 0.39645 | val_0_auc: 0.86507 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.87829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64407 | val_0_auc: 0.76442 |  0:00:01s\n",
      "epoch 1  | loss: 0.55679 | val_0_auc: 0.77284 |  0:00:02s\n",
      "epoch 2  | loss: 0.4997  | val_0_auc: 0.83602 |  0:00:04s\n",
      "epoch 3  | loss: 0.44379 | val_0_auc: 0.84677 |  0:00:05s\n",
      "epoch 4  | loss: 0.41545 | val_0_auc: 0.84604 |  0:00:06s\n",
      "epoch 5  | loss: 0.41114 | val_0_auc: 0.85214 |  0:00:07s\n",
      "epoch 6  | loss: 0.44348 | val_0_auc: 0.84662 |  0:00:09s\n",
      "epoch 7  | loss: 0.40292 | val_0_auc: 0.87858 |  0:00:10s\n",
      "epoch 8  | loss: 0.41035 | val_0_auc: 0.84735 |  0:00:11s\n",
      "epoch 9  | loss: 0.40217 | val_0_auc: 0.85911 |  0:00:13s\n",
      "epoch 10 | loss: 0.36964 | val_0_auc: 0.85127 |  0:00:14s\n",
      "epoch 11 | loss: 0.38851 | val_0_auc: 0.85577 |  0:00:15s\n",
      "epoch 12 | loss: 0.41629 | val_0_auc: 0.83036 |  0:00:17s\n",
      "epoch 13 | loss: 0.40338 | val_0_auc: 0.84227 |  0:00:18s\n",
      "epoch 14 | loss: 0.3968  | val_0_auc: 0.8366  |  0:00:19s\n",
      "epoch 15 | loss: 0.3939  | val_0_auc: 0.85563 |  0:00:20s\n",
      "epoch 16 | loss: 0.39642 | val_0_auc: 0.84808 |  0:00:22s\n",
      "epoch 17 | loss: 0.40051 | val_0_auc: 0.84009 |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.87858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.83283 | val_0_auc: 0.88468 |  0:00:01s\n",
      "epoch 1  | loss: 0.47947 | val_0_auc: 0.71605 |  0:00:02s\n",
      "epoch 2  | loss: 0.43429 | val_0_auc: 0.87683 |  0:00:03s\n",
      "epoch 3  | loss: 0.42063 | val_0_auc: 0.88555 |  0:00:05s\n",
      "epoch 4  | loss: 0.38356 | val_0_auc: 0.87204 |  0:00:06s\n",
      "epoch 5  | loss: 0.3853  | val_0_auc: 0.88264 |  0:00:07s\n",
      "epoch 6  | loss: 0.40615 | val_0_auc: 0.83108 |  0:00:08s\n",
      "epoch 7  | loss: 0.37347 | val_0_auc: 0.85054 |  0:00:10s\n",
      "epoch 8  | loss: 0.41576 | val_0_auc: 0.80886 |  0:00:11s\n",
      "epoch 9  | loss: 0.41604 | val_0_auc: 0.87451 |  0:00:12s\n",
      "epoch 10 | loss: 0.37526 | val_0_auc: 0.85868 |  0:00:14s\n",
      "epoch 11 | loss: 0.42237 | val_0_auc: 0.88046 |  0:00:15s\n",
      "epoch 12 | loss: 0.40907 | val_0_auc: 0.86812 |  0:00:16s\n",
      "epoch 13 | loss: 0.39957 | val_0_auc: 0.87843 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.88555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.78324 | val_0_auc: 0.70138 |  0:00:01s\n",
      "epoch 1  | loss: 0.58574 | val_0_auc: 0.80871 |  0:00:02s\n",
      "epoch 2  | loss: 0.49004 | val_0_auc: 0.8093  |  0:00:04s\n",
      "epoch 3  | loss: 0.45088 | val_0_auc: 0.84343 |  0:00:05s\n",
      "epoch 4  | loss: 0.43796 | val_0_auc: 0.8138  |  0:00:06s\n",
      "epoch 5  | loss: 0.44348 | val_0_auc: 0.82745 |  0:00:08s\n",
      "epoch 6  | loss: 0.43159 | val_0_auc: 0.82397 |  0:00:09s\n",
      "epoch 7  | loss: 0.39823 | val_0_auc: 0.84851 |  0:00:10s\n",
      "epoch 8  | loss: 0.4077  | val_0_auc: 0.83079 |  0:00:12s\n",
      "epoch 9  | loss: 0.43098 | val_0_auc: 0.84444 |  0:00:13s\n",
      "epoch 10 | loss: 0.41108 | val_0_auc: 0.81917 |  0:00:14s\n",
      "epoch 11 | loss: 0.41833 | val_0_auc: 0.84372 |  0:00:16s\n",
      "epoch 12 | loss: 0.43209 | val_0_auc: 0.86943 |  0:00:17s\n",
      "epoch 13 | loss: 0.39829 | val_0_auc: 0.87538 |  0:00:18s\n",
      "epoch 14 | loss: 0.38486 | val_0_auc: 0.86914 |  0:00:20s\n",
      "epoch 15 | loss: 0.39995 | val_0_auc: 0.86609 |  0:00:21s\n",
      "epoch 16 | loss: 0.41142 | val_0_auc: 0.86289 |  0:00:22s\n",
      "epoch 17 | loss: 0.41524 | val_0_auc: 0.85258 |  0:00:24s\n",
      "epoch 18 | loss: 0.42769 | val_0_auc: 0.86144 |  0:00:25s\n",
      "epoch 19 | loss: 0.41213 | val_0_auc: 0.86594 |  0:00:26s\n",
      "epoch 20 | loss: 0.40457 | val_0_auc: 0.85752 |  0:00:27s\n",
      "epoch 21 | loss: 0.38893 | val_0_auc: 0.87509 |  0:00:28s\n",
      "epoch 22 | loss: 0.41503 | val_0_auc: 0.87495 |  0:00:30s\n",
      "epoch 23 | loss: 0.43067 | val_0_auc: 0.87858 |  0:00:31s\n",
      "epoch 24 | loss: 0.41189 | val_0_auc: 0.88584 |  0:00:32s\n",
      "epoch 25 | loss: 0.38671 | val_0_auc: 0.88758 |  0:00:33s\n",
      "epoch 26 | loss: 0.41526 | val_0_auc: 0.89078 |  0:00:35s\n",
      "epoch 27 | loss: 0.38264 | val_0_auc: 0.88555 |  0:00:36s\n",
      "epoch 28 | loss: 0.40867 | val_0_auc: 0.88642 |  0:00:37s\n",
      "epoch 29 | loss: 0.38673 | val_0_auc: 0.87466 |  0:00:38s\n",
      "epoch 30 | loss: 0.39529 | val_0_auc: 0.86899 |  0:00:39s\n",
      "epoch 31 | loss: 0.38858 | val_0_auc: 0.87015 |  0:00:41s\n",
      "epoch 32 | loss: 0.38402 | val_0_auc: 0.86623 |  0:00:42s\n",
      "epoch 33 | loss: 0.39921 | val_0_auc: 0.8825  |  0:00:43s\n",
      "epoch 34 | loss: 0.39974 | val_0_auc: 0.88221 |  0:00:44s\n",
      "epoch 35 | loss: 0.3972  | val_0_auc: 0.88918 |  0:00:46s\n",
      "epoch 36 | loss: 0.36802 | val_0_auc: 0.88424 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60003 | val_0_auc: 0.75062 |  0:00:01s\n",
      "epoch 1  | loss: 0.47845 | val_0_auc: 0.85781 |  0:00:02s\n",
      "epoch 2  | loss: 0.40272 | val_0_auc: 0.85563 |  0:00:03s\n",
      "epoch 3  | loss: 0.42734 | val_0_auc: 0.85795 |  0:00:04s\n",
      "epoch 4  | loss: 0.40063 | val_0_auc: 0.84256 |  0:00:05s\n",
      "epoch 5  | loss: 0.39623 | val_0_auc: 0.83907 |  0:00:06s\n",
      "epoch 6  | loss: 0.401   | val_0_auc: 0.82607 |  0:00:07s\n",
      "epoch 7  | loss: 0.37961 | val_0_auc: 0.84938 |  0:00:08s\n",
      "epoch 8  | loss: 0.38772 | val_0_auc: 0.86129 |  0:00:10s\n",
      "epoch 9  | loss: 0.37653 | val_0_auc: 0.85984 |  0:00:11s\n",
      "epoch 10 | loss: 0.40541 | val_0_auc: 0.85192 |  0:00:12s\n",
      "epoch 11 | loss: 0.37469 | val_0_auc: 0.82672 |  0:00:13s\n",
      "epoch 12 | loss: 0.39644 | val_0_auc: 0.83675 |  0:00:14s\n",
      "epoch 13 | loss: 0.3618  | val_0_auc: 0.87545 |  0:00:15s\n",
      "epoch 14 | loss: 0.41282 | val_0_auc: 0.84386 |  0:00:17s\n",
      "epoch 15 | loss: 0.36464 | val_0_auc: 0.83689 |  0:00:18s\n",
      "epoch 16 | loss: 0.37053 | val_0_auc: 0.85221 |  0:00:19s\n",
      "epoch 17 | loss: 0.36393 | val_0_auc: 0.85287 |  0:00:20s\n",
      "epoch 18 | loss: 0.36252 | val_0_auc: 0.84895 |  0:00:21s\n",
      "epoch 19 | loss: 0.34817 | val_0_auc: 0.81699 |  0:00:23s\n",
      "epoch 20 | loss: 0.36883 | val_0_auc: 0.85134 |  0:00:24s\n",
      "epoch 21 | loss: 0.34963 | val_0_auc: 0.8337  |  0:00:25s\n",
      "epoch 22 | loss: 0.36334 | val_0_auc: 0.83159 |  0:00:26s\n",
      "epoch 23 | loss: 0.36439 | val_0_auc: 0.85258 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.87545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57328 | val_0_auc: 0.76275 |  0:00:01s\n",
      "epoch 1  | loss: 0.40391 | val_0_auc: 0.83399 |  0:00:02s\n",
      "epoch 2  | loss: 0.42978 | val_0_auc: 0.83014 |  0:00:03s\n",
      "epoch 3  | loss: 0.40948 | val_0_auc: 0.8427  |  0:00:04s\n",
      "epoch 4  | loss: 0.39616 | val_0_auc: 0.84662 |  0:00:06s\n",
      "epoch 5  | loss: 0.41326 | val_0_auc: 0.8472  |  0:00:07s\n",
      "epoch 6  | loss: 0.3971  | val_0_auc: 0.8772  |  0:00:08s\n",
      "epoch 7  | loss: 0.39797 | val_0_auc: 0.86071 |  0:00:09s\n",
      "epoch 8  | loss: 0.40416 | val_0_auc: 0.84706 |  0:00:10s\n",
      "epoch 9  | loss: 0.41218 | val_0_auc: 0.83544 |  0:00:11s\n",
      "epoch 10 | loss: 0.41746 | val_0_auc: 0.81728 |  0:00:13s\n",
      "epoch 11 | loss: 0.39589 | val_0_auc: 0.86667 |  0:00:14s\n",
      "epoch 12 | loss: 0.38731 | val_0_auc: 0.88017 |  0:00:15s\n",
      "epoch 13 | loss: 0.39643 | val_0_auc: 0.88671 |  0:00:16s\n",
      "epoch 14 | loss: 0.40316 | val_0_auc: 0.87988 |  0:00:18s\n",
      "epoch 15 | loss: 0.39266 | val_0_auc: 0.88359 |  0:00:19s\n",
      "epoch 16 | loss: 0.39442 | val_0_auc: 0.87654 |  0:00:20s\n",
      "epoch 17 | loss: 0.37906 | val_0_auc: 0.88475 |  0:00:21s\n",
      "epoch 18 | loss: 0.37807 | val_0_auc: 0.88439 |  0:00:22s\n",
      "epoch 19 | loss: 0.36845 | val_0_auc: 0.87669 |  0:00:24s\n",
      "epoch 20 | loss: 0.3884  | val_0_auc: 0.88046 |  0:00:25s\n",
      "epoch 21 | loss: 0.40004 | val_0_auc: 0.89252 |  0:00:26s\n",
      "epoch 22 | loss: 0.38664 | val_0_auc: 0.87814 |  0:00:27s\n",
      "epoch 23 | loss: 0.37974 | val_0_auc: 0.88874 |  0:00:28s\n",
      "epoch 24 | loss: 0.39802 | val_0_auc: 0.89165 |  0:00:30s\n",
      "epoch 25 | loss: 0.38344 | val_0_auc: 0.88831 |  0:00:31s\n",
      "epoch 26 | loss: 0.38425 | val_0_auc: 0.88497 |  0:00:32s\n",
      "epoch 27 | loss: 0.39666 | val_0_auc: 0.86405 |  0:00:33s\n",
      "epoch 28 | loss: 0.38416 | val_0_auc: 0.88221 |  0:00:34s\n",
      "epoch 29 | loss: 0.36829 | val_0_auc: 0.87364 |  0:00:35s\n",
      "epoch 30 | loss: 0.37284 | val_0_auc: 0.88105 |  0:00:36s\n",
      "epoch 31 | loss: 0.38549 | val_0_auc: 0.878   |  0:00:37s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.89252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61802 | val_0_auc: 0.83268 |  0:00:01s\n",
      "epoch 1  | loss: 0.45819 | val_0_auc: 0.81496 |  0:00:02s\n",
      "epoch 2  | loss: 0.43244 | val_0_auc: 0.84089 |  0:00:03s\n",
      "epoch 3  | loss: 0.44732 | val_0_auc: 0.83951 |  0:00:04s\n",
      "epoch 4  | loss: 0.41707 | val_0_auc: 0.84575 |  0:00:05s\n",
      "epoch 5  | loss: 0.42354 | val_0_auc: 0.84706 |  0:00:06s\n",
      "epoch 6  | loss: 0.41148 | val_0_auc: 0.85011 |  0:00:07s\n",
      "epoch 7  | loss: 0.42184 | val_0_auc: 0.86507 |  0:00:09s\n",
      "epoch 8  | loss: 0.40532 | val_0_auc: 0.84125 |  0:00:10s\n",
      "epoch 9  | loss: 0.43118 | val_0_auc: 0.82992 |  0:00:11s\n",
      "epoch 10 | loss: 0.40965 | val_0_auc: 0.85069 |  0:00:12s\n",
      "epoch 11 | loss: 0.4074  | val_0_auc: 0.80973 |  0:00:13s\n",
      "epoch 12 | loss: 0.43774 | val_0_auc: 0.86768 |  0:00:14s\n",
      "epoch 13 | loss: 0.40083 | val_0_auc: 0.85127 |  0:00:15s\n",
      "epoch 14 | loss: 0.40311 | val_0_auc: 0.85999 |  0:00:17s\n",
      "epoch 15 | loss: 0.39545 | val_0_auc: 0.85897 |  0:00:18s\n",
      "epoch 16 | loss: 0.39542 | val_0_auc: 0.8687  |  0:00:19s\n",
      "epoch 17 | loss: 0.40168 | val_0_auc: 0.85853 |  0:00:20s\n",
      "epoch 18 | loss: 0.39718 | val_0_auc: 0.86354 |  0:00:21s\n",
      "epoch 19 | loss: 0.38695 | val_0_auc: 0.86587 |  0:00:22s\n",
      "epoch 20 | loss: 0.38713 | val_0_auc: 0.88243 |  0:00:23s\n",
      "epoch 21 | loss: 0.40156 | val_0_auc: 0.87473 |  0:00:25s\n",
      "epoch 22 | loss: 0.39058 | val_0_auc: 0.87211 |  0:00:26s\n",
      "epoch 23 | loss: 0.38794 | val_0_auc: 0.88206 |  0:00:27s\n",
      "epoch 24 | loss: 0.39515 | val_0_auc: 0.87168 |  0:00:28s\n",
      "epoch 25 | loss: 0.39331 | val_0_auc: 0.87843 |  0:00:29s\n",
      "epoch 26 | loss: 0.37874 | val_0_auc: 0.86906 |  0:00:30s\n",
      "epoch 27 | loss: 0.39063 | val_0_auc: 0.87654 |  0:00:31s\n",
      "epoch 28 | loss: 0.36343 | val_0_auc: 0.88381 |  0:00:32s\n",
      "epoch 29 | loss: 0.36409 | val_0_auc: 0.88598 |  0:00:33s\n",
      "epoch 30 | loss: 0.38941 | val_0_auc: 0.89746 |  0:00:35s\n",
      "epoch 31 | loss: 0.37138 | val_0_auc: 0.89528 |  0:00:36s\n",
      "epoch 32 | loss: 0.39524 | val_0_auc: 0.89078 |  0:00:37s\n",
      "epoch 33 | loss: 0.39911 | val_0_auc: 0.9024  |  0:00:38s\n",
      "epoch 34 | loss: 0.38057 | val_0_auc: 0.90458 |  0:00:39s\n",
      "epoch 35 | loss: 0.3918  | val_0_auc: 0.87829 |  0:00:40s\n",
      "epoch 36 | loss: 0.38302 | val_0_auc: 0.878   |  0:00:41s\n",
      "epoch 37 | loss: 0.37657 | val_0_auc: 0.88279 |  0:00:42s\n",
      "epoch 38 | loss: 0.3773  | val_0_auc: 0.8793  |  0:00:43s\n",
      "epoch 39 | loss: 0.3716  | val_0_auc: 0.87175 |  0:00:45s\n",
      "epoch 40 | loss: 0.38897 | val_0_auc: 0.87378 |  0:00:46s\n",
      "epoch 41 | loss: 0.4064  | val_0_auc: 0.87451 |  0:00:47s\n",
      "epoch 42 | loss: 0.37954 | val_0_auc: 0.88417 |  0:00:48s\n",
      "epoch 43 | loss: 0.38422 | val_0_auc: 0.88155 |  0:00:49s\n",
      "epoch 44 | loss: 0.36957 | val_0_auc: 0.87233 |  0:00:50s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.90458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55748 | val_0_auc: 0.76747 |  0:00:01s\n",
      "epoch 1  | loss: 0.41087 | val_0_auc: 0.75861 |  0:00:02s\n",
      "epoch 2  | loss: 0.40889 | val_0_auc: 0.81118 |  0:00:03s\n",
      "epoch 3  | loss: 0.40986 | val_0_auc: 0.84198 |  0:00:04s\n",
      "epoch 4  | loss: 0.38855 | val_0_auc: 0.82934 |  0:00:05s\n",
      "epoch 5  | loss: 0.39474 | val_0_auc: 0.79731 |  0:00:06s\n",
      "epoch 6  | loss: 0.40156 | val_0_auc: 0.78918 |  0:00:08s\n",
      "epoch 7  | loss: 0.432   | val_0_auc: 0.82752 |  0:00:09s\n",
      "epoch 8  | loss: 0.3792  | val_0_auc: 0.80341 |  0:00:10s\n",
      "epoch 9  | loss: 0.39125 | val_0_auc: 0.84452 |  0:00:11s\n",
      "epoch 10 | loss: 0.37283 | val_0_auc: 0.84924 |  0:00:12s\n",
      "epoch 11 | loss: 0.38378 | val_0_auc: 0.86725 |  0:00:13s\n",
      "epoch 12 | loss: 0.4044  | val_0_auc: 0.8655  |  0:00:14s\n",
      "epoch 13 | loss: 0.38359 | val_0_auc: 0.87219 |  0:00:16s\n",
      "epoch 14 | loss: 0.39403 | val_0_auc: 0.85773 |  0:00:17s\n",
      "epoch 15 | loss: 0.41312 | val_0_auc: 0.83922 |  0:00:18s\n",
      "epoch 16 | loss: 0.38265 | val_0_auc: 0.85156 |  0:00:19s\n",
      "epoch 17 | loss: 0.39931 | val_0_auc: 0.85548 |  0:00:20s\n",
      "epoch 18 | loss: 0.39687 | val_0_auc: 0.8671  |  0:00:21s\n",
      "epoch 19 | loss: 0.36515 | val_0_auc: 0.86812 |  0:00:22s\n",
      "epoch 20 | loss: 0.39033 | val_0_auc: 0.86318 |  0:00:23s\n",
      "epoch 21 | loss: 0.39384 | val_0_auc: 0.87001 |  0:00:25s\n",
      "epoch 22 | loss: 0.38619 | val_0_auc: 0.88468 |  0:00:26s\n",
      "epoch 23 | loss: 0.38242 | val_0_auc: 0.88744 |  0:00:27s\n",
      "epoch 24 | loss: 0.36978 | val_0_auc: 0.87451 |  0:00:28s\n",
      "epoch 25 | loss: 0.38677 | val_0_auc: 0.8854  |  0:00:29s\n",
      "epoch 26 | loss: 0.3765  | val_0_auc: 0.88562 |  0:00:30s\n",
      "epoch 27 | loss: 0.3822  | val_0_auc: 0.8971  |  0:00:31s\n",
      "epoch 28 | loss: 0.35167 | val_0_auc: 0.88439 |  0:00:32s\n",
      "epoch 29 | loss: 0.37283 | val_0_auc: 0.88802 |  0:00:34s\n",
      "epoch 30 | loss: 0.36014 | val_0_auc: 0.8963  |  0:00:35s\n",
      "epoch 31 | loss: 0.37916 | val_0_auc: 0.88787 |  0:00:36s\n",
      "epoch 32 | loss: 0.3769  | val_0_auc: 0.88214 |  0:00:37s\n",
      "epoch 33 | loss: 0.3663  | val_0_auc: 0.89339 |  0:00:38s\n",
      "epoch 34 | loss: 0.36548 | val_0_auc: 0.88751 |  0:00:39s\n",
      "epoch 35 | loss: 0.36308 | val_0_auc: 0.87429 |  0:00:40s\n",
      "epoch 36 | loss: 0.3933  | val_0_auc: 0.87923 |  0:00:41s\n",
      "epoch 37 | loss: 0.36533 | val_0_auc: 0.88199 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59148 | val_0_auc: 0.81656 |  0:00:01s\n",
      "epoch 1  | loss: 0.48508 | val_0_auc: 0.80842 |  0:00:02s\n",
      "epoch 2  | loss: 0.44603 | val_0_auc: 0.86057 |  0:00:03s\n",
      "epoch 3  | loss: 0.43679 | val_0_auc: 0.86623 |  0:00:04s\n",
      "epoch 4  | loss: 0.43315 | val_0_auc: 0.86057 |  0:00:05s\n",
      "epoch 5  | loss: 0.42552 | val_0_auc: 0.86398 |  0:00:06s\n",
      "epoch 6  | loss: 0.40856 | val_0_auc: 0.86601 |  0:00:08s\n",
      "epoch 7  | loss: 0.44886 | val_0_auc: 0.86536 |  0:00:09s\n",
      "epoch 8  | loss: 0.44628 | val_0_auc: 0.88017 |  0:00:10s\n",
      "epoch 9  | loss: 0.41853 | val_0_auc: 0.87364 |  0:00:11s\n",
      "epoch 10 | loss: 0.428   | val_0_auc: 0.86609 |  0:00:12s\n",
      "epoch 11 | loss: 0.42078 | val_0_auc: 0.85454 |  0:00:13s\n",
      "epoch 12 | loss: 0.40401 | val_0_auc: 0.84495 |  0:00:14s\n",
      "epoch 13 | loss: 0.40596 | val_0_auc: 0.87117 |  0:00:16s\n",
      "epoch 14 | loss: 0.40724 | val_0_auc: 0.87872 |  0:00:17s\n",
      "epoch 15 | loss: 0.40664 | val_0_auc: 0.87393 |  0:00:18s\n",
      "epoch 16 | loss: 0.40469 | val_0_auc: 0.87611 |  0:00:19s\n",
      "epoch 17 | loss: 0.41803 | val_0_auc: 0.88003 |  0:00:20s\n",
      "epoch 18 | loss: 0.40819 | val_0_auc: 0.88293 |  0:00:21s\n",
      "epoch 19 | loss: 0.43215 | val_0_auc: 0.87829 |  0:00:23s\n",
      "epoch 20 | loss: 0.40608 | val_0_auc: 0.87938 |  0:00:24s\n",
      "epoch 21 | loss: 0.38988 | val_0_auc: 0.88315 |  0:00:25s\n",
      "epoch 22 | loss: 0.40408 | val_0_auc: 0.88184 |  0:00:26s\n",
      "epoch 23 | loss: 0.39985 | val_0_auc: 0.89136 |  0:00:27s\n",
      "epoch 24 | loss: 0.39276 | val_0_auc: 0.87872 |  0:00:28s\n",
      "epoch 25 | loss: 0.40559 | val_0_auc: 0.87829 |  0:00:30s\n",
      "epoch 26 | loss: 0.40074 | val_0_auc: 0.87785 |  0:00:31s\n",
      "epoch 27 | loss: 0.39587 | val_0_auc: 0.89521 |  0:00:32s\n",
      "epoch 28 | loss: 0.40609 | val_0_auc: 0.88816 |  0:00:33s\n",
      "epoch 29 | loss: 0.40229 | val_0_auc: 0.89325 |  0:00:34s\n",
      "epoch 30 | loss: 0.43409 | val_0_auc: 0.89085 |  0:00:36s\n",
      "epoch 31 | loss: 0.40708 | val_0_auc: 0.89506 |  0:00:37s\n",
      "epoch 32 | loss: 0.4022  | val_0_auc: 0.87959 |  0:00:38s\n",
      "epoch 33 | loss: 0.39381 | val_0_auc: 0.8902  |  0:00:39s\n",
      "epoch 34 | loss: 0.39569 | val_0_auc: 0.88308 |  0:00:40s\n",
      "epoch 35 | loss: 0.39351 | val_0_auc: 0.87538 |  0:00:41s\n",
      "epoch 36 | loss: 0.40697 | val_0_auc: 0.87712 |  0:00:43s\n",
      "epoch 37 | loss: 0.3935  | val_0_auc: 0.88991 |  0:00:44s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.89521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.07253 | val_0_auc: 0.79608 |  0:00:01s\n",
      "epoch 1  | loss: 0.57778 | val_0_auc: 0.72404 |  0:00:03s\n",
      "epoch 2  | loss: 0.49704 | val_0_auc: 0.81961 |  0:00:04s\n",
      "epoch 3  | loss: 0.42184 | val_0_auc: 0.82556 |  0:00:06s\n",
      "epoch 4  | loss: 0.39    | val_0_auc: 0.8183  |  0:00:08s\n",
      "epoch 5  | loss: 0.40245 | val_0_auc: 0.84909 |  0:00:09s\n",
      "epoch 6  | loss: 0.39301 | val_0_auc: 0.80523 |  0:00:11s\n",
      "epoch 7  | loss: 0.39713 | val_0_auc: 0.83573 |  0:00:12s\n",
      "epoch 8  | loss: 0.44315 | val_0_auc: 0.82426 |  0:00:14s\n",
      "epoch 9  | loss: 0.37757 | val_0_auc: 0.81612 |  0:00:15s\n",
      "epoch 10 | loss: 0.38788 | val_0_auc: 0.81111 |  0:00:17s\n",
      "epoch 11 | loss: 0.39043 | val_0_auc: 0.85752 |  0:00:19s\n",
      "epoch 12 | loss: 0.4098  | val_0_auc: 0.79935 |  0:00:20s\n",
      "epoch 13 | loss: 0.38568 | val_0_auc: 0.84212 |  0:00:22s\n",
      "epoch 14 | loss: 0.38436 | val_0_auc: 0.84662 |  0:00:23s\n",
      "epoch 15 | loss: 0.39032 | val_0_auc: 0.8594  |  0:00:24s\n",
      "epoch 16 | loss: 0.39783 | val_0_auc: 0.85359 |  0:00:26s\n",
      "epoch 17 | loss: 0.38181 | val_0_auc: 0.84895 |  0:00:28s\n",
      "epoch 18 | loss: 0.38404 | val_0_auc: 0.86028 |  0:00:29s\n",
      "epoch 19 | loss: 0.38597 | val_0_auc: 0.88569 |  0:00:31s\n",
      "epoch 20 | loss: 0.39191 | val_0_auc: 0.87916 |  0:00:32s\n",
      "epoch 21 | loss: 0.36625 | val_0_auc: 0.86986 |  0:00:33s\n",
      "epoch 22 | loss: 0.3792  | val_0_auc: 0.87073 |  0:00:35s\n",
      "epoch 23 | loss: 0.38853 | val_0_auc: 0.88322 |  0:00:36s\n",
      "epoch 24 | loss: 0.38191 | val_0_auc: 0.878   |  0:00:38s\n",
      "epoch 25 | loss: 0.35161 | val_0_auc: 0.88032 |  0:00:39s\n",
      "epoch 26 | loss: 0.37849 | val_0_auc: 0.89688 |  0:00:41s\n",
      "epoch 27 | loss: 0.36917 | val_0_auc: 0.88686 |  0:00:42s\n",
      "epoch 28 | loss: 0.36704 | val_0_auc: 0.8841  |  0:00:44s\n",
      "epoch 29 | loss: 0.36195 | val_0_auc: 0.8915  |  0:00:45s\n",
      "epoch 30 | loss: 0.37093 | val_0_auc: 0.88874 |  0:00:46s\n",
      "epoch 31 | loss: 0.36351 | val_0_auc: 0.88293 |  0:00:48s\n",
      "epoch 32 | loss: 0.36652 | val_0_auc: 0.88686 |  0:00:49s\n",
      "epoch 33 | loss: 0.36724 | val_0_auc: 0.89572 |  0:00:51s\n",
      "epoch 34 | loss: 0.37208 | val_0_auc: 0.88874 |  0:00:52s\n",
      "epoch 35 | loss: 0.35951 | val_0_auc: 0.89513 |  0:00:54s\n",
      "epoch 36 | loss: 0.37465 | val_0_auc: 0.89877 |  0:00:55s\n",
      "epoch 37 | loss: 0.35435 | val_0_auc: 0.887   |  0:00:57s\n",
      "epoch 38 | loss: 0.36863 | val_0_auc: 0.88206 |  0:00:58s\n",
      "epoch 39 | loss: 0.35223 | val_0_auc: 0.88439 |  0:00:59s\n",
      "epoch 40 | loss: 0.3514  | val_0_auc: 0.87887 |  0:01:01s\n",
      "epoch 41 | loss: 0.36736 | val_0_auc: 0.87495 |  0:01:02s\n",
      "epoch 42 | loss: 0.35123 | val_0_auc: 0.87364 |  0:01:04s\n",
      "epoch 43 | loss: 0.36208 | val_0_auc: 0.89586 |  0:01:05s\n",
      "epoch 44 | loss: 0.35747 | val_0_auc: 0.88671 |  0:01:07s\n",
      "epoch 45 | loss: 0.33888 | val_0_auc: 0.88395 |  0:01:08s\n",
      "epoch 46 | loss: 0.3719  | val_0_auc: 0.88555 |  0:01:10s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.89877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.00272 | val_0_auc: 0.78555 |  0:00:01s\n",
      "epoch 1  | loss: 0.54674 | val_0_auc: 0.84662 |  0:00:02s\n",
      "epoch 2  | loss: 0.51514 | val_0_auc: 0.85098 |  0:00:04s\n",
      "epoch 3  | loss: 0.47448 | val_0_auc: 0.82019 |  0:00:05s\n",
      "epoch 4  | loss: 0.41743 | val_0_auc: 0.8716  |  0:00:07s\n",
      "epoch 5  | loss: 0.41717 | val_0_auc: 0.85156 |  0:00:08s\n",
      "epoch 6  | loss: 0.39919 | val_0_auc: 0.82629 |  0:00:10s\n",
      "epoch 7  | loss: 0.39647 | val_0_auc: 0.85606 |  0:00:11s\n",
      "epoch 8  | loss: 0.43597 | val_0_auc: 0.84764 |  0:00:12s\n",
      "epoch 9  | loss: 0.40294 | val_0_auc: 0.84575 |  0:00:14s\n",
      "epoch 10 | loss: 0.39693 | val_0_auc: 0.82106 |  0:00:15s\n",
      "epoch 11 | loss: 0.40137 | val_0_auc: 0.85534 |  0:00:17s\n",
      "epoch 12 | loss: 0.41108 | val_0_auc: 0.86478 |  0:00:18s\n",
      "epoch 13 | loss: 0.42072 | val_0_auc: 0.86071 |  0:00:20s\n",
      "epoch 14 | loss: 0.39028 | val_0_auc: 0.86144 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.8716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.14749 | val_0_auc: 0.83312 |  0:00:01s\n",
      "epoch 1  | loss: 0.52159 | val_0_auc: 0.79477 |  0:00:02s\n",
      "epoch 2  | loss: 0.51902 | val_0_auc: 0.80189 |  0:00:04s\n",
      "epoch 3  | loss: 0.44058 | val_0_auc: 0.85418 |  0:00:05s\n",
      "epoch 4  | loss: 0.46816 | val_0_auc: 0.85534 |  0:00:07s\n",
      "epoch 5  | loss: 0.4355  | val_0_auc: 0.85505 |  0:00:08s\n",
      "epoch 6  | loss: 0.41541 | val_0_auc: 0.86928 |  0:00:10s\n",
      "epoch 7  | loss: 0.39322 | val_0_auc: 0.84241 |  0:00:11s\n",
      "epoch 8  | loss: 0.40401 | val_0_auc: 0.85766 |  0:00:13s\n",
      "epoch 9  | loss: 0.39297 | val_0_auc: 0.84285 |  0:00:14s\n",
      "epoch 10 | loss: 0.44    | val_0_auc: 0.84837 |  0:00:16s\n",
      "epoch 11 | loss: 0.41483 | val_0_auc: 0.8138  |  0:00:17s\n",
      "epoch 12 | loss: 0.4024  | val_0_auc: 0.85432 |  0:00:19s\n",
      "epoch 13 | loss: 0.40662 | val_0_auc: 0.87073 |  0:00:20s\n",
      "epoch 14 | loss: 0.39951 | val_0_auc: 0.86957 |  0:00:21s\n",
      "epoch 15 | loss: 0.38309 | val_0_auc: 0.852   |  0:00:23s\n",
      "epoch 16 | loss: 0.43507 | val_0_auc: 0.8244  |  0:00:24s\n",
      "epoch 17 | loss: 0.40907 | val_0_auc: 0.86609 |  0:00:26s\n",
      "epoch 18 | loss: 0.40871 | val_0_auc: 0.87669 |  0:00:27s\n",
      "epoch 19 | loss: 0.38846 | val_0_auc: 0.87248 |  0:00:29s\n",
      "epoch 20 | loss: 0.39666 | val_0_auc: 0.86158 |  0:00:30s\n",
      "epoch 21 | loss: 0.40723 | val_0_auc: 0.87771 |  0:00:32s\n",
      "epoch 22 | loss: 0.39153 | val_0_auc: 0.87204 |  0:00:33s\n",
      "epoch 23 | loss: 0.38825 | val_0_auc: 0.87378 |  0:00:35s\n",
      "epoch 24 | loss: 0.40038 | val_0_auc: 0.88264 |  0:00:36s\n",
      "epoch 25 | loss: 0.38641 | val_0_auc: 0.88381 |  0:00:38s\n",
      "epoch 26 | loss: 0.39384 | val_0_auc: 0.85781 |  0:00:39s\n",
      "epoch 27 | loss: 0.37008 | val_0_auc: 0.86376 |  0:00:41s\n",
      "epoch 28 | loss: 0.39588 | val_0_auc: 0.87204 |  0:00:42s\n",
      "epoch 29 | loss: 0.394   | val_0_auc: 0.89237 |  0:00:43s\n",
      "epoch 30 | loss: 0.37143 | val_0_auc: 0.89136 |  0:00:45s\n",
      "epoch 31 | loss: 0.37214 | val_0_auc: 0.88715 |  0:00:46s\n",
      "epoch 32 | loss: 0.40707 | val_0_auc: 0.87858 |  0:00:48s\n",
      "epoch 33 | loss: 0.39518 | val_0_auc: 0.8886  |  0:00:49s\n",
      "epoch 34 | loss: 0.40801 | val_0_auc: 0.88715 |  0:00:51s\n",
      "epoch 35 | loss: 0.37218 | val_0_auc: 0.87814 |  0:00:52s\n",
      "epoch 36 | loss: 0.39516 | val_0_auc: 0.88584 |  0:00:54s\n",
      "epoch 37 | loss: 0.38036 | val_0_auc: 0.88003 |  0:00:55s\n",
      "epoch 38 | loss: 0.38373 | val_0_auc: 0.87364 |  0:00:56s\n",
      "epoch 39 | loss: 0.38474 | val_0_auc: 0.8748  |  0:00:58s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.89237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.99438 | val_0_auc: 0.82992 |  0:00:01s\n",
      "epoch 1  | loss: 0.51584 | val_0_auc: 0.84561 |  0:00:02s\n",
      "epoch 2  | loss: 0.43755 | val_0_auc: 0.80639 |  0:00:04s\n",
      "epoch 3  | loss: 0.42598 | val_0_auc: 0.85519 |  0:00:05s\n",
      "epoch 4  | loss: 0.40567 | val_0_auc: 0.86783 |  0:00:07s\n",
      "epoch 5  | loss: 0.44061 | val_0_auc: 0.85752 |  0:00:08s\n",
      "epoch 6  | loss: 0.38264 | val_0_auc: 0.87175 |  0:00:09s\n",
      "epoch 7  | loss: 0.42636 | val_0_auc: 0.84067 |  0:00:11s\n",
      "epoch 8  | loss: 0.42574 | val_0_auc: 0.85418 |  0:00:12s\n",
      "epoch 9  | loss: 0.38916 | val_0_auc: 0.83181 |  0:00:14s\n",
      "epoch 10 | loss: 0.41815 | val_0_auc: 0.86216 |  0:00:16s\n",
      "epoch 11 | loss: 0.36903 | val_0_auc: 0.8594  |  0:00:17s\n",
      "epoch 12 | loss: 0.38473 | val_0_auc: 0.86754 |  0:00:19s\n",
      "epoch 13 | loss: 0.39518 | val_0_auc: 0.86754 |  0:00:20s\n",
      "epoch 14 | loss: 0.37406 | val_0_auc: 0.85606 |  0:00:22s\n",
      "epoch 15 | loss: 0.36213 | val_0_auc: 0.87741 |  0:00:23s\n",
      "epoch 16 | loss: 0.38869 | val_0_auc: 0.86957 |  0:00:25s\n",
      "epoch 17 | loss: 0.38029 | val_0_auc: 0.87538 |  0:00:27s\n",
      "epoch 18 | loss: 0.3851  | val_0_auc: 0.87945 |  0:00:28s\n",
      "epoch 19 | loss: 0.38499 | val_0_auc: 0.87669 |  0:00:30s\n",
      "epoch 20 | loss: 0.37483 | val_0_auc: 0.87625 |  0:00:32s\n",
      "epoch 21 | loss: 0.37835 | val_0_auc: 0.88686 |  0:00:33s\n",
      "epoch 22 | loss: 0.37276 | val_0_auc: 0.90472 |  0:00:35s\n",
      "epoch 23 | loss: 0.38557 | val_0_auc: 0.87829 |  0:00:36s\n",
      "epoch 24 | loss: 0.38896 | val_0_auc: 0.86957 |  0:00:37s\n",
      "epoch 25 | loss: 0.37939 | val_0_auc: 0.89005 |  0:00:39s\n",
      "epoch 26 | loss: 0.38242 | val_0_auc: 0.86739 |  0:00:41s\n",
      "epoch 27 | loss: 0.36213 | val_0_auc: 0.86042 |  0:00:42s\n",
      "epoch 28 | loss: 0.37725 | val_0_auc: 0.8642  |  0:00:43s\n",
      "epoch 29 | loss: 0.38243 | val_0_auc: 0.87901 |  0:00:45s\n",
      "epoch 30 | loss: 0.38409 | val_0_auc: 0.88322 |  0:00:46s\n",
      "epoch 31 | loss: 0.3776  | val_0_auc: 0.88163 |  0:00:48s\n",
      "epoch 32 | loss: 0.37739 | val_0_auc: 0.87495 |  0:00:49s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.90472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.97295 | val_0_auc: 0.44459 |  0:00:01s\n",
      "epoch 1  | loss: 0.5743  | val_0_auc: 0.71474 |  0:00:02s\n",
      "epoch 2  | loss: 0.48487 | val_0_auc: 0.77807 |  0:00:04s\n",
      "epoch 3  | loss: 0.46019 | val_0_auc: 0.80842 |  0:00:05s\n",
      "epoch 4  | loss: 0.47827 | val_0_auc: 0.83747 |  0:00:07s\n",
      "epoch 5  | loss: 0.44053 | val_0_auc: 0.85403 |  0:00:08s\n",
      "epoch 6  | loss: 0.42475 | val_0_auc: 0.8703  |  0:00:10s\n",
      "epoch 7  | loss: 0.44374 | val_0_auc: 0.85171 |  0:00:11s\n",
      "epoch 8  | loss: 0.45165 | val_0_auc: 0.83166 |  0:00:13s\n",
      "epoch 9  | loss: 0.45428 | val_0_auc: 0.82411 |  0:00:14s\n",
      "epoch 10 | loss: 0.42841 | val_0_auc: 0.84314 |  0:00:16s\n",
      "epoch 11 | loss: 0.43296 | val_0_auc: 0.8565  |  0:00:18s\n",
      "epoch 12 | loss: 0.42219 | val_0_auc: 0.85374 |  0:00:19s\n",
      "epoch 13 | loss: 0.40106 | val_0_auc: 0.85635 |  0:00:21s\n",
      "epoch 14 | loss: 0.43036 | val_0_auc: 0.8658  |  0:00:23s\n",
      "epoch 15 | loss: 0.39561 | val_0_auc: 0.82309 |  0:00:24s\n",
      "epoch 16 | loss: 0.41935 | val_0_auc: 0.85287 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57561 | val_0_auc: 0.80261 |  0:00:00s\n",
      "epoch 1  | loss: 0.448   | val_0_auc: 0.81903 |  0:00:01s\n",
      "epoch 2  | loss: 0.4058  | val_0_auc: 0.85882 |  0:00:02s\n",
      "epoch 3  | loss: 0.39613 | val_0_auc: 0.81249 |  0:00:03s\n",
      "epoch 4  | loss: 0.40878 | val_0_auc: 0.81656 |  0:00:04s\n",
      "epoch 5  | loss: 0.3965  | val_0_auc: 0.79695 |  0:00:04s\n",
      "epoch 6  | loss: 0.39114 | val_0_auc: 0.80944 |  0:00:05s\n",
      "epoch 7  | loss: 0.3717  | val_0_auc: 0.81576 |  0:00:06s\n",
      "epoch 8  | loss: 0.3712  | val_0_auc: 0.82869 |  0:00:07s\n",
      "epoch 9  | loss: 0.39129 | val_0_auc: 0.82433 |  0:00:08s\n",
      "epoch 10 | loss: 0.38171 | val_0_auc: 0.77466 |  0:00:08s\n",
      "epoch 11 | loss: 0.39485 | val_0_auc: 0.83123 |  0:00:09s\n",
      "epoch 12 | loss: 0.37565 | val_0_auc: 0.85265 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.85882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56867 | val_0_auc: 0.78853 |  0:00:00s\n",
      "epoch 1  | loss: 0.46773 | val_0_auc: 0.71939 |  0:00:01s\n",
      "epoch 2  | loss: 0.42798 | val_0_auc: 0.76964 |  0:00:02s\n",
      "epoch 3  | loss: 0.4297  | val_0_auc: 0.84895 |  0:00:03s\n",
      "epoch 4  | loss: 0.39587 | val_0_auc: 0.84009 |  0:00:04s\n",
      "epoch 5  | loss: 0.40358 | val_0_auc: 0.86289 |  0:00:04s\n",
      "epoch 6  | loss: 0.40092 | val_0_auc: 0.82796 |  0:00:05s\n",
      "epoch 7  | loss: 0.41409 | val_0_auc: 0.85454 |  0:00:06s\n",
      "epoch 8  | loss: 0.43657 | val_0_auc: 0.84096 |  0:00:07s\n",
      "epoch 9  | loss: 0.41433 | val_0_auc: 0.84415 |  0:00:08s\n",
      "epoch 10 | loss: 0.39943 | val_0_auc: 0.81678 |  0:00:08s\n",
      "epoch 11 | loss: 0.41352 | val_0_auc: 0.82171 |  0:00:09s\n",
      "epoch 12 | loss: 0.39255 | val_0_auc: 0.8427  |  0:00:10s\n",
      "epoch 13 | loss: 0.40009 | val_0_auc: 0.84415 |  0:00:11s\n",
      "epoch 14 | loss: 0.38893 | val_0_auc: 0.82484 |  0:00:11s\n",
      "epoch 15 | loss: 0.40753 | val_0_auc: 0.81467 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.86289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56004 | val_0_auc: 0.74539 |  0:00:00s\n",
      "epoch 1  | loss: 0.45674 | val_0_auc: 0.81975 |  0:00:01s\n",
      "epoch 2  | loss: 0.45768 | val_0_auc: 0.75919 |  0:00:02s\n",
      "epoch 3  | loss: 0.41868 | val_0_auc: 0.79913 |  0:00:02s\n",
      "epoch 4  | loss: 0.40435 | val_0_auc: 0.80959 |  0:00:03s\n",
      "epoch 5  | loss: 0.40143 | val_0_auc: 0.79361 |  0:00:04s\n",
      "epoch 6  | loss: 0.40856 | val_0_auc: 0.84183 |  0:00:05s\n",
      "epoch 7  | loss: 0.41336 | val_0_auc: 0.83166 |  0:00:05s\n",
      "epoch 8  | loss: 0.39805 | val_0_auc: 0.82963 |  0:00:06s\n",
      "epoch 9  | loss: 0.39271 | val_0_auc: 0.83253 |  0:00:07s\n",
      "epoch 10 | loss: 0.37681 | val_0_auc: 0.83529 |  0:00:08s\n",
      "epoch 11 | loss: 0.38916 | val_0_auc: 0.83551 |  0:00:09s\n",
      "epoch 12 | loss: 0.37778 | val_0_auc: 0.85904 |  0:00:09s\n",
      "epoch 13 | loss: 0.39492 | val_0_auc: 0.86601 |  0:00:10s\n",
      "epoch 14 | loss: 0.40927 | val_0_auc: 0.87393 |  0:00:11s\n",
      "epoch 15 | loss: 0.40266 | val_0_auc: 0.85955 |  0:00:12s\n",
      "epoch 16 | loss: 0.39199 | val_0_auc: 0.84771 |  0:00:13s\n",
      "epoch 17 | loss: 0.38132 | val_0_auc: 0.86144 |  0:00:13s\n",
      "epoch 18 | loss: 0.38354 | val_0_auc: 0.86674 |  0:00:14s\n",
      "epoch 19 | loss: 0.39002 | val_0_auc: 0.86848 |  0:00:15s\n",
      "epoch 20 | loss: 0.37855 | val_0_auc: 0.86768 |  0:00:16s\n",
      "epoch 21 | loss: 0.3896  | val_0_auc: 0.87066 |  0:00:16s\n",
      "epoch 22 | loss: 0.39616 | val_0_auc: 0.86739 |  0:00:17s\n",
      "epoch 23 | loss: 0.38106 | val_0_auc: 0.87858 |  0:00:18s\n",
      "epoch 24 | loss: 0.38689 | val_0_auc: 0.83348 |  0:00:19s\n",
      "epoch 25 | loss: 0.41019 | val_0_auc: 0.85708 |  0:00:19s\n",
      "epoch 26 | loss: 0.38225 | val_0_auc: 0.82985 |  0:00:20s\n",
      "epoch 27 | loss: 0.38044 | val_0_auc: 0.88148 |  0:00:21s\n",
      "epoch 28 | loss: 0.38658 | val_0_auc: 0.87727 |  0:00:22s\n",
      "epoch 29 | loss: 0.40634 | val_0_auc: 0.86848 |  0:00:22s\n",
      "epoch 30 | loss: 0.39631 | val_0_auc: 0.87306 |  0:00:23s\n",
      "epoch 31 | loss: 0.38328 | val_0_auc: 0.86434 |  0:00:24s\n",
      "epoch 32 | loss: 0.37865 | val_0_auc: 0.87458 |  0:00:25s\n",
      "epoch 33 | loss: 0.37617 | val_0_auc: 0.85744 |  0:00:26s\n",
      "epoch 34 | loss: 0.38054 | val_0_auc: 0.84996 |  0:00:26s\n",
      "epoch 35 | loss: 0.41061 | val_0_auc: 0.87589 |  0:00:27s\n",
      "epoch 36 | loss: 0.40469 | val_0_auc: 0.86158 |  0:00:28s\n",
      "epoch 37 | loss: 0.3559  | val_0_auc: 0.88925 |  0:00:28s\n",
      "epoch 38 | loss: 0.37983 | val_0_auc: 0.8854  |  0:00:29s\n",
      "epoch 39 | loss: 0.38438 | val_0_auc: 0.87836 |  0:00:30s\n",
      "epoch 40 | loss: 0.38473 | val_0_auc: 0.88664 |  0:00:31s\n",
      "epoch 41 | loss: 0.37419 | val_0_auc: 0.87858 |  0:00:32s\n",
      "epoch 42 | loss: 0.37054 | val_0_auc: 0.87836 |  0:00:32s\n",
      "epoch 43 | loss: 0.36702 | val_0_auc: 0.88293 |  0:00:33s\n",
      "epoch 44 | loss: 0.3691  | val_0_auc: 0.87444 |  0:00:34s\n",
      "epoch 45 | loss: 0.357   | val_0_auc: 0.87277 |  0:00:35s\n",
      "epoch 46 | loss: 0.38364 | val_0_auc: 0.86696 |  0:00:35s\n",
      "epoch 47 | loss: 0.38167 | val_0_auc: 0.88402 |  0:00:36s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.88925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54669 | val_0_auc: 0.70298 |  0:00:00s\n",
      "epoch 1  | loss: 0.50454 | val_0_auc: 0.56979 |  0:00:01s\n",
      "epoch 2  | loss: 0.47673 | val_0_auc: 0.7496  |  0:00:02s\n",
      "epoch 3  | loss: 0.43367 | val_0_auc: 0.83457 |  0:00:03s\n",
      "epoch 4  | loss: 0.44866 | val_0_auc: 0.81685 |  0:00:03s\n",
      "epoch 5  | loss: 0.41048 | val_0_auc: 0.82062 |  0:00:04s\n",
      "epoch 6  | loss: 0.40727 | val_0_auc: 0.83457 |  0:00:05s\n",
      "epoch 7  | loss: 0.42618 | val_0_auc: 0.79717 |  0:00:06s\n",
      "epoch 8  | loss: 0.41475 | val_0_auc: 0.85461 |  0:00:06s\n",
      "epoch 9  | loss: 0.39598 | val_0_auc: 0.84459 |  0:00:07s\n",
      "epoch 10 | loss: 0.39343 | val_0_auc: 0.81845 |  0:00:08s\n",
      "epoch 11 | loss: 0.40702 | val_0_auc: 0.82534 |  0:00:09s\n",
      "epoch 12 | loss: 0.37515 | val_0_auc: 0.82142 |  0:00:10s\n",
      "epoch 13 | loss: 0.36994 | val_0_auc: 0.86057 |  0:00:10s\n",
      "epoch 14 | loss: 0.41165 | val_0_auc: 0.88482 |  0:00:11s\n",
      "epoch 15 | loss: 0.38917 | val_0_auc: 0.85781 |  0:00:12s\n",
      "epoch 16 | loss: 0.40896 | val_0_auc: 0.86202 |  0:00:12s\n",
      "epoch 17 | loss: 0.38206 | val_0_auc: 0.86376 |  0:00:13s\n",
      "epoch 18 | loss: 0.39686 | val_0_auc: 0.86914 |  0:00:14s\n",
      "epoch 19 | loss: 0.38158 | val_0_auc: 0.85694 |  0:00:15s\n",
      "epoch 20 | loss: 0.38127 | val_0_auc: 0.86514 |  0:00:16s\n",
      "epoch 21 | loss: 0.38025 | val_0_auc: 0.8756  |  0:00:16s\n",
      "epoch 22 | loss: 0.38222 | val_0_auc: 0.86587 |  0:00:17s\n",
      "epoch 23 | loss: 0.39478 | val_0_auc: 0.85556 |  0:00:18s\n",
      "epoch 24 | loss: 0.37207 | val_0_auc: 0.87262 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.88482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62977 | val_0_auc: 0.82382 |  0:00:00s\n",
      "epoch 1  | loss: 0.464   | val_0_auc: 0.85403 |  0:00:01s\n",
      "epoch 2  | loss: 0.43582 | val_0_auc: 0.85737 |  0:00:02s\n",
      "epoch 3  | loss: 0.41893 | val_0_auc: 0.82832 |  0:00:03s\n",
      "epoch 4  | loss: 0.41432 | val_0_auc: 0.83805 |  0:00:03s\n",
      "epoch 5  | loss: 0.42401 | val_0_auc: 0.85461 |  0:00:04s\n",
      "epoch 6  | loss: 0.46671 | val_0_auc: 0.83101 |  0:00:05s\n",
      "epoch 7  | loss: 0.41951 | val_0_auc: 0.83065 |  0:00:05s\n",
      "epoch 8  | loss: 0.43311 | val_0_auc: 0.84568 |  0:00:06s\n",
      "epoch 9  | loss: 0.41226 | val_0_auc: 0.84597 |  0:00:07s\n",
      "epoch 10 | loss: 0.40514 | val_0_auc: 0.84473 |  0:00:08s\n",
      "epoch 11 | loss: 0.42236 | val_0_auc: 0.86129 |  0:00:09s\n",
      "epoch 12 | loss: 0.41183 | val_0_auc: 0.85752 |  0:00:09s\n",
      "epoch 13 | loss: 0.40445 | val_0_auc: 0.86202 |  0:00:10s\n",
      "epoch 14 | loss: 0.40433 | val_0_auc: 0.89107 |  0:00:11s\n",
      "epoch 15 | loss: 0.41117 | val_0_auc: 0.88177 |  0:00:12s\n",
      "epoch 16 | loss: 0.39507 | val_0_auc: 0.86231 |  0:00:12s\n",
      "epoch 17 | loss: 0.40921 | val_0_auc: 0.86391 |  0:00:13s\n",
      "epoch 18 | loss: 0.3876  | val_0_auc: 0.8655  |  0:00:14s\n",
      "epoch 19 | loss: 0.3992  | val_0_auc: 0.85839 |  0:00:14s\n",
      "epoch 20 | loss: 0.40621 | val_0_auc: 0.87669 |  0:00:15s\n",
      "epoch 21 | loss: 0.38433 | val_0_auc: 0.87495 |  0:00:16s\n",
      "epoch 22 | loss: 0.37905 | val_0_auc: 0.88497 |  0:00:17s\n",
      "epoch 23 | loss: 0.39373 | val_0_auc: 0.88453 |  0:00:17s\n",
      "epoch 24 | loss: 0.38885 | val_0_auc: 0.86739 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.89107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.8335  | val_0_auc: 0.80196 |  0:00:01s\n",
      "epoch 1  | loss: 0.49969 | val_0_auc: 0.62041 |  0:00:02s\n",
      "epoch 2  | loss: 0.46622 | val_0_auc: 0.84176 |  0:00:03s\n",
      "epoch 3  | loss: 0.41125 | val_0_auc: 0.85214 |  0:00:04s\n",
      "epoch 4  | loss: 0.41415 | val_0_auc: 0.81627 |  0:00:06s\n",
      "epoch 5  | loss: 0.39838 | val_0_auc: 0.82629 |  0:00:07s\n",
      "epoch 6  | loss: 0.40513 | val_0_auc: 0.82164 |  0:00:08s\n",
      "epoch 7  | loss: 0.39619 | val_0_auc: 0.687   |  0:00:09s\n",
      "epoch 8  | loss: 0.40968 | val_0_auc: 0.72752 |  0:00:10s\n",
      "epoch 9  | loss: 0.39202 | val_0_auc: 0.84386 |  0:00:12s\n",
      "epoch 10 | loss: 0.37238 | val_0_auc: 0.85592 |  0:00:13s\n",
      "epoch 11 | loss: 0.40703 | val_0_auc: 0.86848 |  0:00:14s\n",
      "epoch 12 | loss: 0.38801 | val_0_auc: 0.85185 |  0:00:16s\n",
      "epoch 13 | loss: 0.38328 | val_0_auc: 0.86289 |  0:00:17s\n",
      "epoch 14 | loss: 0.37964 | val_0_auc: 0.84045 |  0:00:18s\n",
      "epoch 15 | loss: 0.39171 | val_0_auc: 0.84176 |  0:00:19s\n",
      "epoch 16 | loss: 0.37522 | val_0_auc: 0.87255 |  0:00:20s\n",
      "epoch 17 | loss: 0.35653 | val_0_auc: 0.81402 |  0:00:22s\n",
      "epoch 18 | loss: 0.36976 | val_0_auc: 0.82578 |  0:00:23s\n",
      "epoch 19 | loss: 0.3578  | val_0_auc: 0.86674 |  0:00:24s\n",
      "epoch 20 | loss: 0.36665 | val_0_auc: 0.87589 |  0:00:26s\n",
      "epoch 21 | loss: 0.35679 | val_0_auc: 0.86587 |  0:00:27s\n",
      "epoch 22 | loss: 0.3703  | val_0_auc: 0.85367 |  0:00:29s\n",
      "epoch 23 | loss: 0.36696 | val_0_auc: 0.8642  |  0:00:30s\n",
      "epoch 24 | loss: 0.36553 | val_0_auc: 0.8711  |  0:00:31s\n",
      "epoch 25 | loss: 0.36277 | val_0_auc: 0.89005 |  0:00:32s\n",
      "epoch 26 | loss: 0.37629 | val_0_auc: 0.89463 |  0:00:34s\n",
      "epoch 27 | loss: 0.38393 | val_0_auc: 0.88192 |  0:00:35s\n",
      "epoch 28 | loss: 0.37399 | val_0_auc: 0.88214 |  0:00:36s\n",
      "epoch 29 | loss: 0.36357 | val_0_auc: 0.87415 |  0:00:37s\n",
      "epoch 30 | loss: 0.37737 | val_0_auc: 0.88315 |  0:00:38s\n",
      "epoch 31 | loss: 0.36632 | val_0_auc: 0.86667 |  0:00:40s\n",
      "epoch 32 | loss: 0.36652 | val_0_auc: 0.88083 |  0:00:41s\n",
      "epoch 33 | loss: 0.36561 | val_0_auc: 0.88722 |  0:00:42s\n",
      "epoch 34 | loss: 0.38472 | val_0_auc: 0.88105 |  0:00:43s\n",
      "epoch 35 | loss: 0.35798 | val_0_auc: 0.88533 |  0:00:45s\n",
      "epoch 36 | loss: 0.37392 | val_0_auc: 0.88482 |  0:00:46s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76727 | val_0_auc: 0.8382  |  0:00:01s\n",
      "epoch 1  | loss: 0.49254 | val_0_auc: 0.77008 |  0:00:02s\n",
      "epoch 2  | loss: 0.47399 | val_0_auc: 0.86049 |  0:00:03s\n",
      "epoch 3  | loss: 0.4413  | val_0_auc: 0.86834 |  0:00:04s\n",
      "epoch 4  | loss: 0.42799 | val_0_auc: 0.88497 |  0:00:07s\n",
      "epoch 5  | loss: 0.44848 | val_0_auc: 0.8618  |  0:00:09s\n",
      "epoch 6  | loss: 0.44959 | val_0_auc: 0.84749 |  0:00:10s\n",
      "epoch 7  | loss: 0.42134 | val_0_auc: 0.83675 |  0:00:11s\n",
      "epoch 8  | loss: 0.41356 | val_0_auc: 0.85301 |  0:00:13s\n",
      "epoch 9  | loss: 0.40518 | val_0_auc: 0.82956 |  0:00:14s\n",
      "epoch 10 | loss: 0.40323 | val_0_auc: 0.82121 |  0:00:15s\n",
      "epoch 11 | loss: 0.43613 | val_0_auc: 0.84626 |  0:00:16s\n",
      "epoch 12 | loss: 0.41579 | val_0_auc: 0.85345 |  0:00:18s\n",
      "epoch 13 | loss: 0.40522 | val_0_auc: 0.84256 |  0:00:19s\n",
      "epoch 14 | loss: 0.41659 | val_0_auc: 0.84415 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.88497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.85776 | val_0_auc: 0.81612 |  0:00:01s\n",
      "epoch 1  | loss: 0.4659  | val_0_auc: 0.81808 |  0:00:02s\n",
      "epoch 2  | loss: 0.43812 | val_0_auc: 0.87654 |  0:00:03s\n",
      "epoch 3  | loss: 0.44073 | val_0_auc: 0.83704 |  0:00:05s\n",
      "epoch 4  | loss: 0.43216 | val_0_auc: 0.78925 |  0:00:06s\n",
      "epoch 5  | loss: 0.43916 | val_0_auc: 0.82455 |  0:00:07s\n",
      "epoch 6  | loss: 0.40411 | val_0_auc: 0.83537 |  0:00:08s\n",
      "epoch 7  | loss: 0.42494 | val_0_auc: 0.83871 |  0:00:10s\n",
      "epoch 8  | loss: 0.41414 | val_0_auc: 0.84822 |  0:00:11s\n",
      "epoch 9  | loss: 0.41441 | val_0_auc: 0.86521 |  0:00:12s\n",
      "epoch 10 | loss: 0.41429 | val_0_auc: 0.85301 |  0:00:13s\n",
      "epoch 11 | loss: 0.45314 | val_0_auc: 0.81598 |  0:00:15s\n",
      "epoch 12 | loss: 0.44693 | val_0_auc: 0.8435  |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.87654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80445 | val_0_auc: 0.64967 |  0:00:01s\n",
      "epoch 1  | loss: 0.48654 | val_0_auc: 0.80479 |  0:00:02s\n",
      "epoch 2  | loss: 0.45419 | val_0_auc: 0.82774 |  0:00:03s\n",
      "epoch 3  | loss: 0.41798 | val_0_auc: 0.84415 |  0:00:04s\n",
      "epoch 4  | loss: 0.41013 | val_0_auc: 0.85069 |  0:00:06s\n",
      "epoch 5  | loss: 0.41609 | val_0_auc: 0.8809  |  0:00:07s\n",
      "epoch 6  | loss: 0.4029  | val_0_auc: 0.86899 |  0:00:08s\n",
      "epoch 7  | loss: 0.4205  | val_0_auc: 0.88076 |  0:00:09s\n",
      "epoch 8  | loss: 0.39792 | val_0_auc: 0.83689 |  0:00:11s\n",
      "epoch 9  | loss: 0.40387 | val_0_auc: 0.88141 |  0:00:12s\n",
      "epoch 10 | loss: 0.39818 | val_0_auc: 0.82055 |  0:00:13s\n",
      "epoch 11 | loss: 0.43225 | val_0_auc: 0.81612 |  0:00:14s\n",
      "epoch 12 | loss: 0.4655  | val_0_auc: 0.78998 |  0:00:16s\n",
      "epoch 13 | loss: 0.39913 | val_0_auc: 0.81024 |  0:00:17s\n",
      "epoch 14 | loss: 0.3969  | val_0_auc: 0.86529 |  0:00:18s\n",
      "epoch 15 | loss: 0.41366 | val_0_auc: 0.86718 |  0:00:19s\n",
      "epoch 16 | loss: 0.39301 | val_0_auc: 0.84793 |  0:00:20s\n",
      "epoch 17 | loss: 0.41037 | val_0_auc: 0.81656 |  0:00:22s\n",
      "epoch 18 | loss: 0.40023 | val_0_auc: 0.85054 |  0:00:23s\n",
      "epoch 19 | loss: 0.40698 | val_0_auc: 0.85468 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.88141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.93446 | val_0_auc: 0.76231 |  0:00:01s\n",
      "epoch 1  | loss: 0.52246 | val_0_auc: 0.79216 |  0:00:02s\n",
      "epoch 2  | loss: 0.4329  | val_0_auc: 0.77516 |  0:00:03s\n",
      "epoch 3  | loss: 0.43902 | val_0_auc: 0.76543 |  0:00:04s\n",
      "epoch 4  | loss: 0.44285 | val_0_auc: 0.81445 |  0:00:06s\n",
      "epoch 5  | loss: 0.42694 | val_0_auc: 0.86086 |  0:00:07s\n",
      "epoch 6  | loss: 0.43222 | val_0_auc: 0.81009 |  0:00:08s\n",
      "epoch 7  | loss: 0.42428 | val_0_auc: 0.79484 |  0:00:09s\n",
      "epoch 8  | loss: 0.40525 | val_0_auc: 0.81518 |  0:00:11s\n",
      "epoch 9  | loss: 0.412   | val_0_auc: 0.79339 |  0:00:12s\n",
      "epoch 10 | loss: 0.42746 | val_0_auc: 0.81961 |  0:00:13s\n",
      "epoch 11 | loss: 0.42708 | val_0_auc: 0.87255 |  0:00:14s\n",
      "epoch 12 | loss: 0.3978  | val_0_auc: 0.85977 |  0:00:15s\n",
      "epoch 13 | loss: 0.40451 | val_0_auc: 0.87778 |  0:00:17s\n",
      "epoch 14 | loss: 0.3843  | val_0_auc: 0.84815 |  0:00:18s\n",
      "epoch 15 | loss: 0.43648 | val_0_auc: 0.86536 |  0:00:19s\n",
      "epoch 16 | loss: 0.40515 | val_0_auc: 0.87248 |  0:00:20s\n",
      "epoch 17 | loss: 0.40245 | val_0_auc: 0.8732  |  0:00:22s\n",
      "epoch 18 | loss: 0.40608 | val_0_auc: 0.88584 |  0:00:23s\n",
      "epoch 19 | loss: 0.37843 | val_0_auc: 0.88061 |  0:00:24s\n",
      "epoch 20 | loss: 0.39182 | val_0_auc: 0.8841  |  0:00:25s\n",
      "epoch 21 | loss: 0.4096  | val_0_auc: 0.88417 |  0:00:27s\n",
      "epoch 22 | loss: 0.39142 | val_0_auc: 0.87284 |  0:00:28s\n",
      "epoch 23 | loss: 0.37835 | val_0_auc: 0.87923 |  0:00:29s\n",
      "epoch 24 | loss: 0.40119 | val_0_auc: 0.87567 |  0:00:30s\n",
      "epoch 25 | loss: 0.41208 | val_0_auc: 0.88453 |  0:00:32s\n",
      "epoch 26 | loss: 0.39761 | val_0_auc: 0.88402 |  0:00:33s\n",
      "epoch 27 | loss: 0.39161 | val_0_auc: 0.89281 |  0:00:34s\n",
      "epoch 28 | loss: 0.39149 | val_0_auc: 0.87858 |  0:00:35s\n",
      "epoch 29 | loss: 0.39327 | val_0_auc: 0.88533 |  0:00:37s\n",
      "epoch 30 | loss: 0.39818 | val_0_auc: 0.86993 |  0:00:38s\n",
      "epoch 31 | loss: 0.40299 | val_0_auc: 0.86797 |  0:00:39s\n",
      "epoch 32 | loss: 0.39379 | val_0_auc: 0.87015 |  0:00:40s\n",
      "epoch 33 | loss: 0.39492 | val_0_auc: 0.861   |  0:00:42s\n",
      "epoch 34 | loss: 0.39493 | val_0_auc: 0.88816 |  0:00:43s\n",
      "epoch 35 | loss: 0.37726 | val_0_auc: 0.88519 |  0:00:44s\n",
      "epoch 36 | loss: 0.40876 | val_0_auc: 0.88293 |  0:00:45s\n",
      "epoch 37 | loss: 0.39873 | val_0_auc: 0.87945 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.89281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.01717 | val_0_auc: 0.74553 |  0:00:01s\n",
      "epoch 1  | loss: 0.53802 | val_0_auc: 0.77197 |  0:00:02s\n",
      "epoch 2  | loss: 0.47976 | val_0_auc: 0.79608 |  0:00:03s\n",
      "epoch 3  | loss: 0.47677 | val_0_auc: 0.77255 |  0:00:05s\n",
      "epoch 4  | loss: 0.43896 | val_0_auc: 0.82469 |  0:00:06s\n",
      "epoch 5  | loss: 0.41038 | val_0_auc: 0.87771 |  0:00:07s\n",
      "epoch 6  | loss: 0.40252 | val_0_auc: 0.80276 |  0:00:09s\n",
      "epoch 7  | loss: 0.42442 | val_0_auc: 0.73508 |  0:00:10s\n",
      "epoch 8  | loss: 0.39692 | val_0_auc: 0.79637 |  0:00:11s\n",
      "epoch 9  | loss: 0.3941  | val_0_auc: 0.81532 |  0:00:13s\n",
      "epoch 10 | loss: 0.42739 | val_0_auc: 0.85432 |  0:00:14s\n",
      "epoch 11 | loss: 0.41602 | val_0_auc: 0.83326 |  0:00:15s\n",
      "epoch 12 | loss: 0.42147 | val_0_auc: 0.84749 |  0:00:17s\n",
      "epoch 13 | loss: 0.3982  | val_0_auc: 0.86071 |  0:00:18s\n",
      "epoch 14 | loss: 0.40386 | val_0_auc: 0.75853 |  0:00:19s\n",
      "epoch 15 | loss: 0.40331 | val_0_auc: 0.75534 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.87771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.83946 | val_0_auc: 0.78206 |  0:00:01s\n",
      "epoch 1  | loss: 0.52826 | val_0_auc: 0.74488 |  0:00:02s\n",
      "epoch 2  | loss: 0.4771  | val_0_auc: 0.76514 |  0:00:03s\n",
      "epoch 3  | loss: 0.47237 | val_0_auc: 0.74742 |  0:00:05s\n",
      "epoch 4  | loss: 0.43931 | val_0_auc: 0.82397 |  0:00:06s\n",
      "epoch 5  | loss: 0.43513 | val_0_auc: 0.79724 |  0:00:08s\n",
      "epoch 6  | loss: 0.44341 | val_0_auc: 0.84401 |  0:00:09s\n",
      "epoch 7  | loss: 0.43624 | val_0_auc: 0.8719  |  0:00:10s\n",
      "epoch 8  | loss: 0.41729 | val_0_auc: 0.8671  |  0:00:11s\n",
      "epoch 9  | loss: 0.41463 | val_0_auc: 0.89601 |  0:00:13s\n",
      "epoch 10 | loss: 0.40184 | val_0_auc: 0.87509 |  0:00:14s\n",
      "epoch 11 | loss: 0.4115  | val_0_auc: 0.87117 |  0:00:15s\n",
      "epoch 12 | loss: 0.43064 | val_0_auc: 0.87349 |  0:00:17s\n",
      "epoch 13 | loss: 0.39756 | val_0_auc: 0.84735 |  0:00:18s\n",
      "epoch 14 | loss: 0.39316 | val_0_auc: 0.85156 |  0:00:19s\n",
      "epoch 15 | loss: 0.41775 | val_0_auc: 0.87364 |  0:00:20s\n",
      "epoch 16 | loss: 0.40812 | val_0_auc: 0.87451 |  0:00:22s\n",
      "epoch 17 | loss: 0.3885  | val_0_auc: 0.86086 |  0:00:23s\n",
      "epoch 18 | loss: 0.39151 | val_0_auc: 0.88221 |  0:00:24s\n",
      "epoch 19 | loss: 0.38251 | val_0_auc: 0.87553 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.89601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.74338 | val_0_auc: 0.83326 |  0:00:01s\n",
      "epoch 1  | loss: 0.63834 | val_0_auc: 0.65882 |  0:00:02s\n",
      "epoch 2  | loss: 0.52043 | val_0_auc: 0.80421 |  0:00:03s\n",
      "epoch 3  | loss: 0.45793 | val_0_auc: 0.78591 |  0:00:05s\n",
      "epoch 4  | loss: 0.43778 | val_0_auc: 0.82789 |  0:00:06s\n",
      "epoch 5  | loss: 0.44918 | val_0_auc: 0.81881 |  0:00:07s\n",
      "epoch 6  | loss: 0.4742  | val_0_auc: 0.75577 |  0:00:08s\n",
      "epoch 7  | loss: 0.41939 | val_0_auc: 0.79833 |  0:00:10s\n",
      "epoch 8  | loss: 0.43364 | val_0_auc: 0.74815 |  0:00:11s\n",
      "epoch 9  | loss: 0.44482 | val_0_auc: 0.7634  |  0:00:12s\n",
      "epoch 10 | loss: 0.39446 | val_0_auc: 0.80334 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.83326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.77574 | val_0_auc: 0.72353 |  0:00:01s\n",
      "epoch 1  | loss: 0.54156 | val_0_auc: 0.51634 |  0:00:02s\n",
      "epoch 2  | loss: 0.52787 | val_0_auc: 0.75403 |  0:00:03s\n",
      "epoch 3  | loss: 0.4525  | val_0_auc: 0.74553 |  0:00:05s\n",
      "epoch 4  | loss: 0.44365 | val_0_auc: 0.81409 |  0:00:06s\n",
      "epoch 5  | loss: 0.4051  | val_0_auc: 0.77255 |  0:00:07s\n",
      "epoch 6  | loss: 0.42377 | val_0_auc: 0.80668 |  0:00:09s\n",
      "epoch 7  | loss: 0.38485 | val_0_auc: 0.85178 |  0:00:10s\n",
      "epoch 8  | loss: 0.45766 | val_0_auc: 0.83174 |  0:00:11s\n",
      "epoch 9  | loss: 0.42958 | val_0_auc: 0.83914 |  0:00:12s\n",
      "epoch 10 | loss: 0.40933 | val_0_auc: 0.85694 |  0:00:14s\n",
      "epoch 11 | loss: 0.44866 | val_0_auc: 0.85156 |  0:00:15s\n",
      "epoch 12 | loss: 0.41774 | val_0_auc: 0.8459  |  0:00:16s\n",
      "epoch 13 | loss: 0.38584 | val_0_auc: 0.82781 |  0:00:18s\n",
      "epoch 14 | loss: 0.39891 | val_0_auc: 0.8159  |  0:00:19s\n",
      "epoch 15 | loss: 0.40039 | val_0_auc: 0.84503 |  0:00:20s\n",
      "epoch 16 | loss: 0.40251 | val_0_auc: 0.8528  |  0:00:22s\n",
      "epoch 17 | loss: 0.42313 | val_0_auc: 0.8321  |  0:00:23s\n",
      "epoch 18 | loss: 0.39476 | val_0_auc: 0.87444 |  0:00:24s\n",
      "epoch 19 | loss: 0.40156 | val_0_auc: 0.85701 |  0:00:26s\n",
      "epoch 20 | loss: 0.39771 | val_0_auc: 0.82927 |  0:00:27s\n",
      "epoch 21 | loss: 0.37575 | val_0_auc: 0.86238 |  0:00:28s\n",
      "epoch 22 | loss: 0.38018 | val_0_auc: 0.86209 |  0:00:29s\n",
      "epoch 23 | loss: 0.37666 | val_0_auc: 0.80138 |  0:00:31s\n",
      "epoch 24 | loss: 0.39448 | val_0_auc: 0.84096 |  0:00:32s\n",
      "epoch 25 | loss: 0.38639 | val_0_auc: 0.85977 |  0:00:34s\n",
      "epoch 26 | loss: 0.37949 | val_0_auc: 0.86064 |  0:00:35s\n",
      "epoch 27 | loss: 0.36971 | val_0_auc: 0.85723 |  0:00:36s\n",
      "epoch 28 | loss: 0.36683 | val_0_auc: 0.86993 |  0:00:38s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.87444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.73862 | val_0_auc: 0.85512 |  0:00:01s\n",
      "epoch 1  | loss: 0.61955 | val_0_auc: 0.7968  |  0:00:03s\n",
      "epoch 2  | loss: 0.49646 | val_0_auc: 0.81874 |  0:00:05s\n",
      "epoch 3  | loss: 0.48633 | val_0_auc: 0.8008  |  0:00:07s\n",
      "epoch 4  | loss: 0.43774 | val_0_auc: 0.82462 |  0:00:09s\n",
      "epoch 5  | loss: 0.45229 | val_0_auc: 0.81423 |  0:00:11s\n",
      "epoch 6  | loss: 0.45604 | val_0_auc: 0.79535 |  0:00:13s\n",
      "epoch 7  | loss: 0.42335 | val_0_auc: 0.84546 |  0:00:14s\n",
      "epoch 8  | loss: 0.44029 | val_0_auc: 0.83609 |  0:00:15s\n",
      "epoch 9  | loss: 0.43927 | val_0_auc: 0.83057 |  0:00:17s\n",
      "epoch 10 | loss: 0.43332 | val_0_auc: 0.8138  |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.85512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64292 | val_0_auc: 0.84568 |  0:00:01s\n",
      "epoch 1  | loss: 0.55445 | val_0_auc: 0.81569 |  0:00:03s\n",
      "epoch 2  | loss: 0.49044 | val_0_auc: 0.74031 |  0:00:05s\n",
      "epoch 3  | loss: 0.42527 | val_0_auc: 0.79855 |  0:00:07s\n",
      "epoch 4  | loss: 0.43733 | val_0_auc: 0.86885 |  0:00:08s\n",
      "epoch 5  | loss: 0.43949 | val_0_auc: 0.82426 |  0:00:10s\n",
      "epoch 6  | loss: 0.41154 | val_0_auc: 0.84227 |  0:00:12s\n",
      "epoch 7  | loss: 0.44286 | val_0_auc: 0.85185 |  0:00:13s\n",
      "epoch 8  | loss: 0.43429 | val_0_auc: 0.85592 |  0:00:15s\n",
      "epoch 9  | loss: 0.4092  | val_0_auc: 0.84256 |  0:00:17s\n",
      "epoch 10 | loss: 0.42453 | val_0_auc: 0.8122  |  0:00:19s\n",
      "epoch 11 | loss: 0.41699 | val_0_auc: 0.80712 |  0:00:20s\n",
      "epoch 12 | loss: 0.38712 | val_0_auc: 0.81852 |  0:00:22s\n",
      "epoch 13 | loss: 0.37152 | val_0_auc: 0.8581  |  0:00:24s\n",
      "epoch 14 | loss: 0.42737 | val_0_auc: 0.83602 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.86885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.69175 | val_0_auc: 0.38693 |  0:00:01s\n",
      "epoch 1  | loss: 0.72067 | val_0_auc: 0.7313  |  0:00:03s\n",
      "epoch 2  | loss: 0.49636 | val_0_auc: 0.82426 |  0:00:05s\n",
      "epoch 3  | loss: 0.4526  | val_0_auc: 0.82542 |  0:00:07s\n",
      "epoch 4  | loss: 0.45011 | val_0_auc: 0.78853 |  0:00:09s\n",
      "epoch 5  | loss: 0.4284  | val_0_auc: 0.8472  |  0:00:10s\n",
      "epoch 6  | loss: 0.45571 | val_0_auc: 0.84154 |  0:00:12s\n",
      "epoch 7  | loss: 0.43535 | val_0_auc: 0.82135 |  0:00:13s\n",
      "epoch 8  | loss: 0.42209 | val_0_auc: 0.85911 |  0:00:15s\n",
      "epoch 9  | loss: 0.4002  | val_0_auc: 0.85432 |  0:00:17s\n",
      "epoch 10 | loss: 0.44368 | val_0_auc: 0.87146 |  0:00:19s\n",
      "epoch 11 | loss: 0.40947 | val_0_auc: 0.88017 |  0:00:20s\n",
      "epoch 12 | loss: 0.37062 | val_0_auc: 0.88816 |  0:00:22s\n",
      "epoch 13 | loss: 0.41574 | val_0_auc: 0.85955 |  0:00:24s\n",
      "epoch 14 | loss: 0.39294 | val_0_auc: 0.85969 |  0:00:26s\n",
      "epoch 15 | loss: 0.41127 | val_0_auc: 0.87044 |  0:00:27s\n",
      "epoch 16 | loss: 0.39569 | val_0_auc: 0.84619 |  0:00:29s\n",
      "epoch 17 | loss: 0.39124 | val_0_auc: 0.8841  |  0:00:31s\n",
      "epoch 18 | loss: 0.41025 | val_0_auc: 0.86289 |  0:00:32s\n",
      "epoch 19 | loss: 0.38155 | val_0_auc: 0.89005 |  0:00:34s\n",
      "epoch 20 | loss: 0.42744 | val_0_auc: 0.87008 |  0:00:36s\n",
      "epoch 21 | loss: 0.38375 | val_0_auc: 0.88693 |  0:00:37s\n",
      "epoch 22 | loss: 0.38145 | val_0_auc: 0.88068 |  0:00:39s\n",
      "epoch 23 | loss: 0.41939 | val_0_auc: 0.87843 |  0:00:41s\n",
      "epoch 24 | loss: 0.40609 | val_0_auc: 0.88511 |  0:00:42s\n",
      "epoch 25 | loss: 0.39379 | val_0_auc: 0.87843 |  0:00:44s\n",
      "epoch 26 | loss: 0.40777 | val_0_auc: 0.8703  |  0:00:46s\n",
      "epoch 27 | loss: 0.40084 | val_0_auc: 0.89877 |  0:00:48s\n",
      "epoch 28 | loss: 0.38878 | val_0_auc: 0.89993 |  0:00:49s\n",
      "epoch 29 | loss: 0.37193 | val_0_auc: 0.88105 |  0:00:51s\n",
      "epoch 30 | loss: 0.40052 | val_0_auc: 0.87916 |  0:00:53s\n",
      "epoch 31 | loss: 0.40289 | val_0_auc: 0.88003 |  0:00:54s\n",
      "epoch 32 | loss: 0.38919 | val_0_auc: 0.88032 |  0:00:56s\n",
      "epoch 33 | loss: 0.40149 | val_0_auc: 0.88192 |  0:00:58s\n",
      "epoch 34 | loss: 0.39137 | val_0_auc: 0.88497 |  0:00:59s\n",
      "epoch 35 | loss: 0.40537 | val_0_auc: 0.88555 |  0:01:01s\n",
      "epoch 36 | loss: 0.37467 | val_0_auc: 0.87814 |  0:01:03s\n",
      "epoch 37 | loss: 0.40417 | val_0_auc: 0.8825  |  0:01:04s\n",
      "epoch 38 | loss: 0.37282 | val_0_auc: 0.89252 |  0:01:06s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.89993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.73685 | val_0_auc: 0.66216 |  0:00:01s\n",
      "epoch 1  | loss: 0.52833 | val_0_auc: 0.84996 |  0:00:03s\n",
      "epoch 2  | loss: 0.51551 | val_0_auc: 0.80174 |  0:00:04s\n",
      "epoch 3  | loss: 0.45369 | val_0_auc: 0.77894 |  0:00:06s\n",
      "epoch 4  | loss: 0.46713 | val_0_auc: 0.83268 |  0:00:08s\n",
      "epoch 5  | loss: 0.42999 | val_0_auc: 0.85999 |  0:00:09s\n",
      "epoch 6  | loss: 0.41774 | val_0_auc: 0.8642  |  0:00:11s\n",
      "epoch 7  | loss: 0.42725 | val_0_auc: 0.84793 |  0:00:12s\n",
      "epoch 8  | loss: 0.4222  | val_0_auc: 0.83326 |  0:00:14s\n",
      "epoch 9  | loss: 0.41331 | val_0_auc: 0.84154 |  0:00:16s\n",
      "epoch 10 | loss: 0.42937 | val_0_auc: 0.83457 |  0:00:17s\n",
      "epoch 11 | loss: 0.43378 | val_0_auc: 0.82716 |  0:00:19s\n",
      "epoch 12 | loss: 0.44129 | val_0_auc: 0.85432 |  0:00:21s\n",
      "epoch 13 | loss: 0.43178 | val_0_auc: 0.85846 |  0:00:23s\n",
      "epoch 14 | loss: 0.41927 | val_0_auc: 0.8382  |  0:00:24s\n",
      "epoch 15 | loss: 0.45422 | val_0_auc: 0.85781 |  0:00:26s\n",
      "epoch 16 | loss: 0.43655 | val_0_auc: 0.86609 |  0:00:28s\n",
      "epoch 17 | loss: 0.38884 | val_0_auc: 0.88003 |  0:00:30s\n",
      "epoch 18 | loss: 0.41722 | val_0_auc: 0.85047 |  0:00:31s\n",
      "epoch 19 | loss: 0.3825  | val_0_auc: 0.85868 |  0:00:33s\n",
      "epoch 20 | loss: 0.4006  | val_0_auc: 0.88504 |  0:00:35s\n",
      "epoch 21 | loss: 0.39353 | val_0_auc: 0.88381 |  0:00:37s\n",
      "epoch 22 | loss: 0.39176 | val_0_auc: 0.87495 |  0:00:39s\n",
      "epoch 23 | loss: 0.40013 | val_0_auc: 0.87335 |  0:00:40s\n",
      "epoch 24 | loss: 0.39153 | val_0_auc: 0.86042 |  0:00:42s\n",
      "epoch 25 | loss: 0.38032 | val_0_auc: 0.88831 |  0:00:44s\n",
      "epoch 26 | loss: 0.41753 | val_0_auc: 0.88627 |  0:00:46s\n",
      "epoch 27 | loss: 0.40573 | val_0_auc: 0.8963  |  0:00:47s\n",
      "epoch 28 | loss: 0.38633 | val_0_auc: 0.87524 |  0:00:49s\n",
      "epoch 29 | loss: 0.40083 | val_0_auc: 0.86855 |  0:00:51s\n",
      "epoch 30 | loss: 0.41139 | val_0_auc: 0.84285 |  0:00:52s\n",
      "epoch 31 | loss: 0.39119 | val_0_auc: 0.8504  |  0:00:54s\n",
      "epoch 32 | loss: 0.39887 | val_0_auc: 0.87386 |  0:00:55s\n",
      "epoch 33 | loss: 0.41099 | val_0_auc: 0.86391 |  0:00:57s\n",
      "epoch 34 | loss: 0.39574 | val_0_auc: 0.85904 |  0:00:59s\n",
      "epoch 35 | loss: 0.39    | val_0_auc: 0.88046 |  0:01:00s\n",
      "epoch 36 | loss: 0.40304 | val_0_auc: 0.86783 |  0:01:02s\n",
      "epoch 37 | loss: 0.41134 | val_0_auc: 0.87407 |  0:01:04s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.73841 | val_0_auc: 0.73849 |  0:00:01s\n",
      "epoch 1  | loss: 0.53943 | val_0_auc: 0.83341 |  0:00:03s\n",
      "epoch 2  | loss: 0.54545 | val_0_auc: 0.81946 |  0:00:05s\n",
      "epoch 3  | loss: 0.43532 | val_0_auc: 0.81757 |  0:00:06s\n",
      "epoch 4  | loss: 0.41157 | val_0_auc: 0.82019 |  0:00:08s\n",
      "epoch 5  | loss: 0.40644 | val_0_auc: 0.85011 |  0:00:10s\n",
      "epoch 6  | loss: 0.39722 | val_0_auc: 0.85156 |  0:00:11s\n",
      "epoch 7  | loss: 0.43483 | val_0_auc: 0.87451 |  0:00:13s\n",
      "epoch 8  | loss: 0.41365 | val_0_auc: 0.85214 |  0:00:15s\n",
      "epoch 9  | loss: 0.39187 | val_0_auc: 0.87088 |  0:00:16s\n",
      "epoch 10 | loss: 0.42634 | val_0_auc: 0.87291 |  0:00:18s\n",
      "epoch 11 | loss: 0.40135 | val_0_auc: 0.85389 |  0:00:20s\n",
      "epoch 12 | loss: 0.40591 | val_0_auc: 0.88206 |  0:00:22s\n",
      "epoch 13 | loss: 0.43589 | val_0_auc: 0.8825  |  0:00:23s\n",
      "epoch 14 | loss: 0.42888 | val_0_auc: 0.86885 |  0:00:25s\n",
      "epoch 15 | loss: 0.44794 | val_0_auc: 0.8793  |  0:00:27s\n",
      "epoch 16 | loss: 0.40072 | val_0_auc: 0.88816 |  0:00:28s\n",
      "epoch 17 | loss: 0.39664 | val_0_auc: 0.85839 |  0:00:30s\n",
      "epoch 18 | loss: 0.37807 | val_0_auc: 0.87095 |  0:00:32s\n",
      "epoch 19 | loss: 0.39382 | val_0_auc: 0.88206 |  0:00:33s\n",
      "epoch 20 | loss: 0.40536 | val_0_auc: 0.87393 |  0:00:35s\n",
      "epoch 21 | loss: 0.40262 | val_0_auc: 0.88076 |  0:00:37s\n",
      "epoch 22 | loss: 0.38008 | val_0_auc: 0.87698 |  0:00:38s\n",
      "epoch 23 | loss: 0.39287 | val_0_auc: 0.87814 |  0:00:40s\n",
      "epoch 24 | loss: 0.3911  | val_0_auc: 0.88366 |  0:00:42s\n",
      "epoch 25 | loss: 0.38621 | val_0_auc: 0.87349 |  0:00:43s\n",
      "epoch 26 | loss: 0.39113 | val_0_auc: 0.86245 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.88816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72506 | val_0_auc: 0.41307 |  0:00:01s\n",
      "epoch 1  | loss: 0.61286 | val_0_auc: 0.84967 |  0:00:03s\n",
      "epoch 2  | loss: 0.50333 | val_0_auc: 0.83312 |  0:00:04s\n",
      "epoch 3  | loss: 0.45626 | val_0_auc: 0.83399 |  0:00:06s\n",
      "epoch 4  | loss: 0.42392 | val_0_auc: 0.86013 |  0:00:08s\n",
      "epoch 5  | loss: 0.49315 | val_0_auc: 0.83849 |  0:00:10s\n",
      "epoch 6  | loss: 0.46918 | val_0_auc: 0.826   |  0:00:11s\n",
      "epoch 7  | loss: 0.48235 | val_0_auc: 0.84699 |  0:00:13s\n",
      "epoch 8  | loss: 0.43912 | val_0_auc: 0.83007 |  0:00:15s\n",
      "epoch 9  | loss: 0.48452 | val_0_auc: 0.85389 |  0:00:16s\n",
      "epoch 10 | loss: 0.42858 | val_0_auc: 0.85926 |  0:00:18s\n",
      "epoch 11 | loss: 0.4351  | val_0_auc: 0.84038 |  0:00:20s\n",
      "epoch 12 | loss: 0.43669 | val_0_auc: 0.87538 |  0:00:21s\n",
      "epoch 13 | loss: 0.45074 | val_0_auc: 0.87495 |  0:00:23s\n",
      "epoch 14 | loss: 0.46367 | val_0_auc: 0.8581  |  0:00:25s\n",
      "epoch 15 | loss: 0.41295 | val_0_auc: 0.82948 |  0:00:26s\n",
      "epoch 16 | loss: 0.41516 | val_0_auc: 0.86783 |  0:00:28s\n",
      "epoch 17 | loss: 0.44136 | val_0_auc: 0.86405 |  0:00:30s\n",
      "epoch 18 | loss: 0.40764 | val_0_auc: 0.85911 |  0:00:31s\n",
      "epoch 19 | loss: 0.40017 | val_0_auc: 0.86885 |  0:00:33s\n",
      "epoch 20 | loss: 0.41353 | val_0_auc: 0.84067 |  0:00:35s\n",
      "epoch 21 | loss: 0.41004 | val_0_auc: 0.8854  |  0:00:36s\n",
      "epoch 22 | loss: 0.41805 | val_0_auc: 0.88322 |  0:00:38s\n",
      "epoch 23 | loss: 0.42136 | val_0_auc: 0.90748 |  0:00:40s\n",
      "epoch 24 | loss: 0.4161  | val_0_auc: 0.90109 |  0:00:42s\n",
      "epoch 25 | loss: 0.40056 | val_0_auc: 0.89949 |  0:00:43s\n",
      "epoch 26 | loss: 0.40676 | val_0_auc: 0.87211 |  0:00:45s\n",
      "epoch 27 | loss: 0.4027  | val_0_auc: 0.89717 |  0:00:47s\n",
      "epoch 28 | loss: 0.39961 | val_0_auc: 0.87538 |  0:00:48s\n",
      "epoch 29 | loss: 0.42163 | val_0_auc: 0.90269 |  0:00:50s\n",
      "epoch 30 | loss: 0.4385  | val_0_auc: 0.90094 |  0:00:52s\n",
      "epoch 31 | loss: 0.40771 | val_0_auc: 0.88903 |  0:00:53s\n",
      "epoch 32 | loss: 0.42033 | val_0_auc: 0.90036 |  0:00:55s\n",
      "epoch 33 | loss: 0.39942 | val_0_auc: 0.887   |  0:00:57s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.90748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63056 | val_0_auc: 0.77959 |  0:00:01s\n",
      "epoch 1  | loss: 0.45636 | val_0_auc: 0.85156 |  0:00:02s\n",
      "epoch 2  | loss: 0.44294 | val_0_auc: 0.75076 |  0:00:03s\n",
      "epoch 3  | loss: 0.4037  | val_0_auc: 0.8655  |  0:00:05s\n",
      "epoch 4  | loss: 0.3774  | val_0_auc: 0.85795 |  0:00:06s\n",
      "epoch 5  | loss: 0.39007 | val_0_auc: 0.70675 |  0:00:07s\n",
      "epoch 6  | loss: 0.42279 | val_0_auc: 0.79942 |  0:00:09s\n",
      "epoch 7  | loss: 0.41458 | val_0_auc: 0.82193 |  0:00:10s\n",
      "epoch 8  | loss: 0.3819  | val_0_auc: 0.83747 |  0:00:11s\n",
      "epoch 9  | loss: 0.41463 | val_0_auc: 0.87872 |  0:00:12s\n",
      "epoch 10 | loss: 0.39411 | val_0_auc: 0.87538 |  0:00:14s\n",
      "epoch 11 | loss: 0.38418 | val_0_auc: 0.87073 |  0:00:15s\n",
      "epoch 12 | loss: 0.37574 | val_0_auc: 0.85737 |  0:00:16s\n",
      "epoch 13 | loss: 0.40297 | val_0_auc: 0.86609 |  0:00:18s\n",
      "epoch 14 | loss: 0.366   | val_0_auc: 0.86057 |  0:00:19s\n",
      "epoch 15 | loss: 0.36984 | val_0_auc: 0.85476 |  0:00:20s\n",
      "epoch 16 | loss: 0.3738  | val_0_auc: 0.84764 |  0:00:22s\n",
      "epoch 17 | loss: 0.38359 | val_0_auc: 0.84604 |  0:00:23s\n",
      "epoch 18 | loss: 0.37952 | val_0_auc: 0.85969 |  0:00:24s\n",
      "epoch 19 | loss: 0.3627  | val_0_auc: 0.84895 |  0:00:25s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.87872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59064 | val_0_auc: 0.77204 |  0:00:01s\n",
      "epoch 1  | loss: 0.45517 | val_0_auc: 0.787   |  0:00:02s\n",
      "epoch 2  | loss: 0.43252 | val_0_auc: 0.8236  |  0:00:03s\n",
      "epoch 3  | loss: 0.41287 | val_0_auc: 0.81184 |  0:00:05s\n",
      "epoch 4  | loss: 0.4265  | val_0_auc: 0.83442 |  0:00:06s\n",
      "epoch 5  | loss: 0.41747 | val_0_auc: 0.83827 |  0:00:07s\n",
      "epoch 6  | loss: 0.44666 | val_0_auc: 0.8366  |  0:00:09s\n",
      "epoch 7  | loss: 0.42624 | val_0_auc: 0.82353 |  0:00:10s\n",
      "epoch 8  | loss: 0.41571 | val_0_auc: 0.83297 |  0:00:11s\n",
      "epoch 9  | loss: 0.40601 | val_0_auc: 0.86245 |  0:00:13s\n",
      "epoch 10 | loss: 0.40293 | val_0_auc: 0.85461 |  0:00:14s\n",
      "epoch 11 | loss: 0.39191 | val_0_auc: 0.85955 |  0:00:15s\n",
      "epoch 12 | loss: 0.38776 | val_0_auc: 0.86638 |  0:00:17s\n",
      "epoch 13 | loss: 0.40053 | val_0_auc: 0.86688 |  0:00:18s\n",
      "epoch 14 | loss: 0.38365 | val_0_auc: 0.88715 |  0:00:19s\n",
      "epoch 15 | loss: 0.38902 | val_0_auc: 0.87495 |  0:00:21s\n",
      "epoch 16 | loss: 0.38976 | val_0_auc: 0.8711  |  0:00:22s\n",
      "epoch 17 | loss: 0.38131 | val_0_auc: 0.86507 |  0:00:23s\n",
      "epoch 18 | loss: 0.37952 | val_0_auc: 0.88272 |  0:00:25s\n",
      "epoch 19 | loss: 0.36507 | val_0_auc: 0.87378 |  0:00:26s\n",
      "epoch 20 | loss: 0.37241 | val_0_auc: 0.86906 |  0:00:27s\n",
      "epoch 21 | loss: 0.37794 | val_0_auc: 0.88744 |  0:00:28s\n",
      "epoch 22 | loss: 0.38771 | val_0_auc: 0.88301 |  0:00:30s\n",
      "epoch 23 | loss: 0.3836  | val_0_auc: 0.88569 |  0:00:31s\n",
      "epoch 24 | loss: 0.3804  | val_0_auc: 0.88301 |  0:00:33s\n",
      "epoch 25 | loss: 0.38834 | val_0_auc: 0.89179 |  0:00:34s\n",
      "epoch 26 | loss: 0.40337 | val_0_auc: 0.8695  |  0:00:35s\n",
      "epoch 27 | loss: 0.4008  | val_0_auc: 0.90167 |  0:00:37s\n",
      "epoch 28 | loss: 0.40252 | val_0_auc: 0.89237 |  0:00:38s\n",
      "epoch 29 | loss: 0.38624 | val_0_auc: 0.88773 |  0:00:39s\n",
      "epoch 30 | loss: 0.39708 | val_0_auc: 0.88308 |  0:00:41s\n",
      "epoch 31 | loss: 0.37491 | val_0_auc: 0.8886  |  0:00:42s\n",
      "epoch 32 | loss: 0.39356 | val_0_auc: 0.89397 |  0:00:43s\n",
      "epoch 33 | loss: 0.36641 | val_0_auc: 0.89935 |  0:00:44s\n",
      "epoch 34 | loss: 0.3738  | val_0_auc: 0.88489 |  0:00:46s\n",
      "epoch 35 | loss: 0.37981 | val_0_auc: 0.86725 |  0:00:47s\n",
      "epoch 36 | loss: 0.39009 | val_0_auc: 0.8809  |  0:00:48s\n",
      "epoch 37 | loss: 0.39216 | val_0_auc: 0.88381 |  0:00:49s\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.90167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60572 | val_0_auc: 0.74946 |  0:00:01s\n",
      "epoch 1  | loss: 0.4825  | val_0_auc: 0.48279 |  0:00:02s\n",
      "epoch 2  | loss: 0.47553 | val_0_auc: 0.8679  |  0:00:03s\n",
      "epoch 3  | loss: 0.45927 | val_0_auc: 0.78199 |  0:00:05s\n",
      "epoch 4  | loss: 0.41739 | val_0_auc: 0.86028 |  0:00:06s\n",
      "epoch 5  | loss: 0.41098 | val_0_auc: 0.85534 |  0:00:07s\n",
      "epoch 6  | loss: 0.42519 | val_0_auc: 0.81699 |  0:00:09s\n",
      "epoch 7  | loss: 0.4219  | val_0_auc: 0.84401 |  0:00:10s\n",
      "epoch 8  | loss: 0.41746 | val_0_auc: 0.8398  |  0:00:11s\n",
      "epoch 9  | loss: 0.41876 | val_0_auc: 0.81707 |  0:00:13s\n",
      "epoch 10 | loss: 0.40605 | val_0_auc: 0.85069 |  0:00:14s\n",
      "epoch 11 | loss: 0.40616 | val_0_auc: 0.85461 |  0:00:15s\n",
      "epoch 12 | loss: 0.3787  | val_0_auc: 0.8756  |  0:00:16s\n",
      "epoch 13 | loss: 0.39197 | val_0_auc: 0.88083 |  0:00:18s\n",
      "epoch 14 | loss: 0.38473 | val_0_auc: 0.87335 |  0:00:19s\n",
      "epoch 15 | loss: 0.40129 | val_0_auc: 0.8658  |  0:00:20s\n",
      "epoch 16 | loss: 0.38969 | val_0_auc: 0.86238 |  0:00:21s\n",
      "epoch 17 | loss: 0.39533 | val_0_auc: 0.85221 |  0:00:23s\n",
      "epoch 18 | loss: 0.40276 | val_0_auc: 0.86267 |  0:00:24s\n",
      "epoch 19 | loss: 0.37799 | val_0_auc: 0.86253 |  0:00:26s\n",
      "epoch 20 | loss: 0.41741 | val_0_auc: 0.87582 |  0:00:27s\n",
      "epoch 21 | loss: 0.38218 | val_0_auc: 0.87538 |  0:00:28s\n",
      "epoch 22 | loss: 0.41547 | val_0_auc: 0.87088 |  0:00:29s\n",
      "epoch 23 | loss: 0.39838 | val_0_auc: 0.86107 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65409 | val_0_auc: 0.48649 |  0:00:01s\n",
      "epoch 1  | loss: 0.56829 | val_0_auc: 0.81743 |  0:00:02s\n",
      "epoch 2  | loss: 0.47242 | val_0_auc: 0.72033 |  0:00:03s\n",
      "epoch 3  | loss: 0.41734 | val_0_auc: 0.75367 |  0:00:05s\n",
      "epoch 4  | loss: 0.44223 | val_0_auc: 0.79245 |  0:00:06s\n",
      "epoch 5  | loss: 0.44333 | val_0_auc: 0.80298 |  0:00:07s\n",
      "epoch 6  | loss: 0.41543 | val_0_auc: 0.8061  |  0:00:09s\n",
      "epoch 7  | loss: 0.42021 | val_0_auc: 0.82447 |  0:00:10s\n",
      "epoch 8  | loss: 0.40962 | val_0_auc: 0.8313  |  0:00:11s\n",
      "epoch 9  | loss: 0.3943  | val_0_auc: 0.86071 |  0:00:13s\n",
      "epoch 10 | loss: 0.40653 | val_0_auc: 0.86478 |  0:00:14s\n",
      "epoch 11 | loss: 0.40594 | val_0_auc: 0.86899 |  0:00:15s\n",
      "epoch 12 | loss: 0.36785 | val_0_auc: 0.85396 |  0:00:17s\n",
      "epoch 13 | loss: 0.39163 | val_0_auc: 0.86282 |  0:00:18s\n",
      "epoch 14 | loss: 0.39016 | val_0_auc: 0.86333 |  0:00:19s\n",
      "epoch 15 | loss: 0.38491 | val_0_auc: 0.8366  |  0:00:21s\n",
      "epoch 16 | loss: 0.36979 | val_0_auc: 0.85265 |  0:00:22s\n",
      "epoch 17 | loss: 0.40467 | val_0_auc: 0.86137 |  0:00:23s\n",
      "epoch 18 | loss: 0.36127 | val_0_auc: 0.86013 |  0:00:25s\n",
      "epoch 19 | loss: 0.36846 | val_0_auc: 0.84546 |  0:00:26s\n",
      "epoch 20 | loss: 0.38326 | val_0_auc: 0.84575 |  0:00:27s\n",
      "epoch 21 | loss: 0.38181 | val_0_auc: 0.84365 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.86899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63349 | val_0_auc: 0.24604 |  0:00:01s\n",
      "epoch 1  | loss: 0.48417 | val_0_auc: 0.71278 |  0:00:02s\n",
      "epoch 2  | loss: 0.46433 | val_0_auc: 0.75468 |  0:00:04s\n",
      "epoch 3  | loss: 0.47588 | val_0_auc: 0.81569 |  0:00:05s\n",
      "epoch 4  | loss: 0.47243 | val_0_auc: 0.85251 |  0:00:06s\n",
      "epoch 5  | loss: 0.4375  | val_0_auc: 0.84604 |  0:00:07s\n",
      "epoch 6  | loss: 0.41484 | val_0_auc: 0.84503 |  0:00:09s\n",
      "epoch 7  | loss: 0.4179  | val_0_auc: 0.82302 |  0:00:10s\n",
      "epoch 8  | loss: 0.42253 | val_0_auc: 0.84582 |  0:00:12s\n",
      "epoch 9  | loss: 0.4232  | val_0_auc: 0.84125 |  0:00:13s\n",
      "epoch 10 | loss: 0.39676 | val_0_auc: 0.85853 |  0:00:14s\n",
      "epoch 11 | loss: 0.42457 | val_0_auc: 0.85483 |  0:00:15s\n",
      "epoch 12 | loss: 0.40661 | val_0_auc: 0.84597 |  0:00:17s\n",
      "epoch 13 | loss: 0.40392 | val_0_auc: 0.86209 |  0:00:18s\n",
      "epoch 14 | loss: 0.42176 | val_0_auc: 0.84924 |  0:00:19s\n",
      "epoch 15 | loss: 0.41381 | val_0_auc: 0.83588 |  0:00:21s\n",
      "epoch 16 | loss: 0.42395 | val_0_auc: 0.80421 |  0:00:22s\n",
      "epoch 17 | loss: 0.43766 | val_0_auc: 0.83319 |  0:00:23s\n",
      "epoch 18 | loss: 0.43276 | val_0_auc: 0.85076 |  0:00:25s\n",
      "epoch 19 | loss: 0.40505 | val_0_auc: 0.86761 |  0:00:26s\n",
      "epoch 20 | loss: 0.41331 | val_0_auc: 0.88519 |  0:00:27s\n",
      "epoch 21 | loss: 0.42565 | val_0_auc: 0.88264 |  0:00:28s\n",
      "epoch 22 | loss: 0.3871  | val_0_auc: 0.88243 |  0:00:30s\n",
      "epoch 23 | loss: 0.39262 | val_0_auc: 0.87785 |  0:00:31s\n",
      "epoch 24 | loss: 0.39381 | val_0_auc: 0.88119 |  0:00:32s\n",
      "epoch 25 | loss: 0.39389 | val_0_auc: 0.88606 |  0:00:34s\n",
      "epoch 26 | loss: 0.39498 | val_0_auc: 0.88243 |  0:00:35s\n",
      "epoch 27 | loss: 0.40167 | val_0_auc: 0.90167 |  0:00:36s\n",
      "epoch 28 | loss: 0.4063  | val_0_auc: 0.91227 |  0:00:37s\n",
      "epoch 29 | loss: 0.42263 | val_0_auc: 0.89296 |  0:00:39s\n",
      "epoch 30 | loss: 0.3998  | val_0_auc: 0.90007 |  0:00:40s\n",
      "epoch 31 | loss: 0.40422 | val_0_auc: 0.87146 |  0:00:42s\n",
      "epoch 32 | loss: 0.40006 | val_0_auc: 0.86848 |  0:00:43s\n",
      "epoch 33 | loss: 0.4024  | val_0_auc: 0.9037  |  0:00:44s\n",
      "epoch 34 | loss: 0.40804 | val_0_auc: 0.90712 |  0:00:46s\n",
      "epoch 35 | loss: 0.37426 | val_0_auc: 0.91198 |  0:00:47s\n",
      "epoch 36 | loss: 0.39585 | val_0_auc: 0.91053 |  0:00:48s\n",
      "epoch 37 | loss: 0.39894 | val_0_auc: 0.90044 |  0:00:50s\n",
      "epoch 38 | loss: 0.41325 | val_0_auc: 0.91038 |  0:00:51s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.91227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71614 | val_0_auc: 0.69542 |  0:00:01s\n",
      "epoch 1  | loss: 0.54563 | val_0_auc: 0.84837 |  0:00:03s\n",
      "epoch 2  | loss: 0.50862 | val_0_auc: 0.73232 |  0:00:04s\n",
      "epoch 3  | loss: 0.50223 | val_0_auc: 0.78736 |  0:00:06s\n",
      "epoch 4  | loss: 0.44438 | val_0_auc: 0.7923  |  0:00:07s\n",
      "epoch 5  | loss: 0.39106 | val_0_auc: 0.82861 |  0:00:09s\n",
      "epoch 6  | loss: 0.46129 | val_0_auc: 0.83972 |  0:00:11s\n",
      "epoch 7  | loss: 0.41204 | val_0_auc: 0.81133 |  0:00:12s\n",
      "epoch 8  | loss: 0.40215 | val_0_auc: 0.84386 |  0:00:14s\n",
      "epoch 9  | loss: 0.39528 | val_0_auc: 0.81307 |  0:00:15s\n",
      "epoch 10 | loss: 0.38328 | val_0_auc: 0.8098  |  0:00:17s\n",
      "epoch 11 | loss: 0.41511 | val_0_auc: 0.84227 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.84837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76733 | val_0_auc: 0.85497 |  0:00:01s\n",
      "epoch 1  | loss: 0.50813 | val_0_auc: 0.6931  |  0:00:03s\n",
      "epoch 2  | loss: 0.46701 | val_0_auc: 0.70123 |  0:00:04s\n",
      "epoch 3  | loss: 0.46088 | val_0_auc: 0.77647 |  0:00:06s\n",
      "epoch 4  | loss: 0.43568 | val_0_auc: 0.83457 |  0:00:08s\n",
      "epoch 5  | loss: 0.43669 | val_0_auc: 0.83399 |  0:00:09s\n",
      "epoch 6  | loss: 0.46232 | val_0_auc: 0.83951 |  0:00:11s\n",
      "epoch 7  | loss: 0.42383 | val_0_auc: 0.85447 |  0:00:13s\n",
      "epoch 8  | loss: 0.4285  | val_0_auc: 0.84372 |  0:00:14s\n",
      "epoch 9  | loss: 0.41621 | val_0_auc: 0.83907 |  0:00:16s\n",
      "epoch 10 | loss: 0.40463 | val_0_auc: 0.83355 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.85497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.74305 | val_0_auc: 0.852   |  0:00:01s\n",
      "epoch 1  | loss: 0.57667 | val_0_auc: 0.84641 |  0:00:03s\n",
      "epoch 2  | loss: 0.49041 | val_0_auc: 0.83239 |  0:00:04s\n",
      "epoch 3  | loss: 0.45959 | val_0_auc: 0.6963  |  0:00:06s\n",
      "epoch 4  | loss: 0.4566  | val_0_auc: 0.86049 |  0:00:08s\n",
      "epoch 5  | loss: 0.42495 | val_0_auc: 0.80545 |  0:00:09s\n",
      "epoch 6  | loss: 0.43487 | val_0_auc: 0.82963 |  0:00:11s\n",
      "epoch 7  | loss: 0.42257 | val_0_auc: 0.79579 |  0:00:13s\n",
      "epoch 8  | loss: 0.41645 | val_0_auc: 0.82593 |  0:00:14s\n",
      "epoch 9  | loss: 0.40222 | val_0_auc: 0.81649 |  0:00:16s\n",
      "epoch 10 | loss: 0.41902 | val_0_auc: 0.83595 |  0:00:18s\n",
      "epoch 11 | loss: 0.39115 | val_0_auc: 0.86899 |  0:00:19s\n",
      "epoch 12 | loss: 0.40803 | val_0_auc: 0.84691 |  0:00:21s\n",
      "epoch 13 | loss: 0.41537 | val_0_auc: 0.83399 |  0:00:22s\n",
      "epoch 14 | loss: 0.42086 | val_0_auc: 0.85853 |  0:00:24s\n",
      "epoch 15 | loss: 0.38971 | val_0_auc: 0.88119 |  0:00:26s\n",
      "epoch 16 | loss: 0.42171 | val_0_auc: 0.87422 |  0:00:27s\n",
      "epoch 17 | loss: 0.383   | val_0_auc: 0.86841 |  0:00:29s\n",
      "epoch 18 | loss: 0.39324 | val_0_auc: 0.85664 |  0:00:30s\n",
      "epoch 19 | loss: 0.38039 | val_0_auc: 0.87567 |  0:00:32s\n",
      "epoch 20 | loss: 0.39358 | val_0_auc: 0.87596 |  0:00:34s\n",
      "epoch 21 | loss: 0.39247 | val_0_auc: 0.89049 |  0:00:35s\n",
      "epoch 22 | loss: 0.40699 | val_0_auc: 0.87741 |  0:00:37s\n",
      "epoch 23 | loss: 0.38376 | val_0_auc: 0.84764 |  0:00:38s\n",
      "epoch 24 | loss: 0.37918 | val_0_auc: 0.85643 |  0:00:40s\n",
      "epoch 25 | loss: 0.37351 | val_0_auc: 0.8626  |  0:00:42s\n",
      "epoch 26 | loss: 0.39867 | val_0_auc: 0.89274 |  0:00:43s\n",
      "epoch 27 | loss: 0.3717  | val_0_auc: 0.89114 |  0:00:45s\n",
      "epoch 28 | loss: 0.37677 | val_0_auc: 0.88206 |  0:00:46s\n",
      "epoch 29 | loss: 0.37317 | val_0_auc: 0.87081 |  0:00:48s\n",
      "epoch 30 | loss: 0.37329 | val_0_auc: 0.87364 |  0:00:50s\n",
      "epoch 31 | loss: 0.42178 | val_0_auc: 0.87124 |  0:00:51s\n",
      "epoch 32 | loss: 0.38944 | val_0_auc: 0.86529 |  0:00:53s\n",
      "epoch 33 | loss: 0.37979 | val_0_auc: 0.87102 |  0:00:55s\n",
      "epoch 34 | loss: 0.37927 | val_0_auc: 0.85984 |  0:00:56s\n",
      "epoch 35 | loss: 0.37461 | val_0_auc: 0.85933 |  0:00:58s\n",
      "epoch 36 | loss: 0.36857 | val_0_auc: 0.86107 |  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76143 | val_0_auc: 0.82484 |  0:00:01s\n",
      "epoch 1  | loss: 0.53192 | val_0_auc: 0.86783 |  0:00:03s\n",
      "epoch 2  | loss: 0.50355 | val_0_auc: 0.85577 |  0:00:04s\n",
      "epoch 3  | loss: 0.45653 | val_0_auc: 0.86304 |  0:00:06s\n",
      "epoch 4  | loss: 0.43407 | val_0_auc: 0.87901 |  0:00:08s\n",
      "epoch 5  | loss: 0.48266 | val_0_auc: 0.84619 |  0:00:09s\n",
      "epoch 6  | loss: 0.49194 | val_0_auc: 0.84989 |  0:00:11s\n",
      "epoch 7  | loss: 0.41672 | val_0_auc: 0.81126 |  0:00:12s\n",
      "epoch 8  | loss: 0.44121 | val_0_auc: 0.83566 |  0:00:14s\n",
      "epoch 9  | loss: 0.40633 | val_0_auc: 0.83805 |  0:00:16s\n",
      "epoch 10 | loss: 0.39023 | val_0_auc: 0.86187 |  0:00:17s\n",
      "epoch 11 | loss: 0.38965 | val_0_auc: 0.85171 |  0:00:19s\n",
      "epoch 12 | loss: 0.41776 | val_0_auc: 0.85519 |  0:00:20s\n",
      "epoch 13 | loss: 0.37946 | val_0_auc: 0.85621 |  0:00:22s\n",
      "epoch 14 | loss: 0.41009 | val_0_auc: 0.86623 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.87901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71488 | val_0_auc: 0.30871 |  0:00:01s\n",
      "epoch 1  | loss: 0.49506 | val_0_auc: 0.69746 |  0:00:03s\n",
      "epoch 2  | loss: 0.50417 | val_0_auc: 0.80508 |  0:00:04s\n",
      "epoch 3  | loss: 0.4429  | val_0_auc: 0.8488  |  0:00:06s\n",
      "epoch 4  | loss: 0.45746 | val_0_auc: 0.82048 |  0:00:08s\n",
      "epoch 5  | loss: 0.45097 | val_0_auc: 0.84372 |  0:00:09s\n",
      "epoch 6  | loss: 0.44657 | val_0_auc: 0.87059 |  0:00:11s\n",
      "epoch 7  | loss: 0.41494 | val_0_auc: 0.85374 |  0:00:12s\n",
      "epoch 8  | loss: 0.41289 | val_0_auc: 0.85142 |  0:00:14s\n",
      "epoch 9  | loss: 0.42751 | val_0_auc: 0.84938 |  0:00:16s\n",
      "epoch 10 | loss: 0.40897 | val_0_auc: 0.83863 |  0:00:17s\n",
      "epoch 11 | loss: 0.40469 | val_0_auc: 0.85606 |  0:00:19s\n",
      "epoch 12 | loss: 0.42142 | val_0_auc: 0.85999 |  0:00:20s\n",
      "epoch 13 | loss: 0.42533 | val_0_auc: 0.88272 |  0:00:22s\n",
      "epoch 14 | loss: 0.41    | val_0_auc: 0.87233 |  0:00:24s\n",
      "epoch 15 | loss: 0.40507 | val_0_auc: 0.85882 |  0:00:25s\n",
      "epoch 16 | loss: 0.40879 | val_0_auc: 0.84241 |  0:00:27s\n",
      "epoch 17 | loss: 0.40088 | val_0_auc: 0.85301 |  0:00:29s\n",
      "epoch 18 | loss: 0.40859 | val_0_auc: 0.84488 |  0:00:30s\n",
      "epoch 19 | loss: 0.40051 | val_0_auc: 0.88439 |  0:00:32s\n",
      "epoch 20 | loss: 0.42626 | val_0_auc: 0.88613 |  0:00:33s\n",
      "epoch 21 | loss: 0.43649 | val_0_auc: 0.88148 |  0:00:35s\n",
      "epoch 22 | loss: 0.40201 | val_0_auc: 0.8488  |  0:00:37s\n",
      "epoch 23 | loss: 0.41224 | val_0_auc: 0.86391 |  0:00:38s\n",
      "epoch 24 | loss: 0.39148 | val_0_auc: 0.88773 |  0:00:40s\n",
      "epoch 25 | loss: 0.42027 | val_0_auc: 0.88555 |  0:00:41s\n",
      "epoch 26 | loss: 0.4083  | val_0_auc: 0.89513 |  0:00:43s\n",
      "epoch 27 | loss: 0.41492 | val_0_auc: 0.878   |  0:00:45s\n",
      "epoch 28 | loss: 0.41109 | val_0_auc: 0.89005 |  0:00:46s\n",
      "epoch 29 | loss: 0.40549 | val_0_auc: 0.89557 |  0:00:48s\n",
      "epoch 30 | loss: 0.40605 | val_0_auc: 0.90385 |  0:00:50s\n",
      "epoch 31 | loss: 0.41301 | val_0_auc: 0.88962 |  0:00:51s\n",
      "epoch 32 | loss: 0.40259 | val_0_auc: 0.89906 |  0:00:53s\n",
      "epoch 33 | loss: 0.42088 | val_0_auc: 0.88627 |  0:00:54s\n",
      "epoch 34 | loss: 0.40582 | val_0_auc: 0.89317 |  0:00:56s\n",
      "epoch 35 | loss: 0.40051 | val_0_auc: 0.88649 |  0:00:58s\n",
      "epoch 36 | loss: 0.39161 | val_0_auc: 0.88831 |  0:00:59s\n",
      "epoch 37 | loss: 0.40292 | val_0_auc: 0.88489 |  0:01:01s\n",
      "epoch 38 | loss: 0.4011  | val_0_auc: 0.88715 |  0:01:02s\n",
      "epoch 39 | loss: 0.40409 | val_0_auc: 0.88991 |  0:01:04s\n",
      "epoch 40 | loss: 0.39517 | val_0_auc: 0.88896 |  0:01:06s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.90385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59482 | val_0_auc: 0.71779 |  0:00:00s\n",
      "epoch 1  | loss: 0.51394 | val_0_auc: 0.7167  |  0:00:01s\n",
      "epoch 2  | loss: 0.4396  | val_0_auc: 0.7589  |  0:00:02s\n",
      "epoch 3  | loss: 0.42143 | val_0_auc: 0.85752 |  0:00:03s\n",
      "epoch 4  | loss: 0.40351 | val_0_auc: 0.88337 |  0:00:04s\n",
      "epoch 5  | loss: 0.39802 | val_0_auc: 0.86028 |  0:00:05s\n",
      "epoch 6  | loss: 0.41156 | val_0_auc: 0.826   |  0:00:06s\n",
      "epoch 7  | loss: 0.41366 | val_0_auc: 0.86376 |  0:00:07s\n",
      "epoch 8  | loss: 0.36963 | val_0_auc: 0.80959 |  0:00:08s\n",
      "epoch 9  | loss: 0.40531 | val_0_auc: 0.84626 |  0:00:09s\n",
      "epoch 10 | loss: 0.39168 | val_0_auc: 0.83362 |  0:00:10s\n",
      "epoch 11 | loss: 0.39168 | val_0_auc: 0.82171 |  0:00:11s\n",
      "epoch 12 | loss: 0.38484 | val_0_auc: 0.83304 |  0:00:11s\n",
      "epoch 13 | loss: 0.38455 | val_0_auc: 0.81452 |  0:00:12s\n",
      "epoch 14 | loss: 0.38166 | val_0_auc: 0.80748 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.88337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55569 | val_0_auc: 0.77545 |  0:00:00s\n",
      "epoch 1  | loss: 0.45021 | val_0_auc: 0.82338 |  0:00:01s\n",
      "epoch 2  | loss: 0.45867 | val_0_auc: 0.84001 |  0:00:02s\n",
      "epoch 3  | loss: 0.44297 | val_0_auc: 0.8154  |  0:00:03s\n",
      "epoch 4  | loss: 0.42091 | val_0_auc: 0.83123 |  0:00:04s\n",
      "epoch 5  | loss: 0.43237 | val_0_auc: 0.84256 |  0:00:05s\n",
      "epoch 6  | loss: 0.42754 | val_0_auc: 0.82026 |  0:00:06s\n",
      "epoch 7  | loss: 0.40181 | val_0_auc: 0.82992 |  0:00:07s\n",
      "epoch 8  | loss: 0.39552 | val_0_auc: 0.8358  |  0:00:08s\n",
      "epoch 9  | loss: 0.42012 | val_0_auc: 0.84089 |  0:00:09s\n",
      "epoch 10 | loss: 0.39309 | val_0_auc: 0.79477 |  0:00:09s\n",
      "epoch 11 | loss: 0.40469 | val_0_auc: 0.85512 |  0:00:10s\n",
      "epoch 12 | loss: 0.38851 | val_0_auc: 0.85171 |  0:00:11s\n",
      "epoch 13 | loss: 0.39265 | val_0_auc: 0.86122 |  0:00:12s\n",
      "epoch 14 | loss: 0.4188  | val_0_auc: 0.8618  |  0:00:13s\n",
      "epoch 15 | loss: 0.38107 | val_0_auc: 0.86325 |  0:00:14s\n",
      "epoch 16 | loss: 0.40981 | val_0_auc: 0.84866 |  0:00:15s\n",
      "epoch 17 | loss: 0.43173 | val_0_auc: 0.86558 |  0:00:16s\n",
      "epoch 18 | loss: 0.37334 | val_0_auc: 0.86841 |  0:00:17s\n",
      "epoch 19 | loss: 0.39982 | val_0_auc: 0.86035 |  0:00:18s\n",
      "epoch 20 | loss: 0.40163 | val_0_auc: 0.86616 |  0:00:18s\n",
      "epoch 21 | loss: 0.39124 | val_0_auc: 0.87567 |  0:00:20s\n",
      "epoch 22 | loss: 0.40618 | val_0_auc: 0.8894  |  0:00:21s\n",
      "epoch 23 | loss: 0.38183 | val_0_auc: 0.89477 |  0:00:22s\n",
      "epoch 24 | loss: 0.39709 | val_0_auc: 0.88315 |  0:00:23s\n",
      "epoch 25 | loss: 0.37782 | val_0_auc: 0.87691 |  0:00:24s\n",
      "epoch 26 | loss: 0.40265 | val_0_auc: 0.87545 |  0:00:25s\n",
      "epoch 27 | loss: 0.38192 | val_0_auc: 0.88025 |  0:00:26s\n",
      "epoch 28 | loss: 0.37584 | val_0_auc: 0.88867 |  0:00:27s\n",
      "epoch 29 | loss: 0.39435 | val_0_auc: 0.89114 |  0:00:27s\n",
      "epoch 30 | loss: 0.37776 | val_0_auc: 0.89455 |  0:00:28s\n",
      "epoch 31 | loss: 0.37845 | val_0_auc: 0.88519 |  0:00:29s\n",
      "epoch 32 | loss: 0.39893 | val_0_auc: 0.87008 |  0:00:30s\n",
      "epoch 33 | loss: 0.37032 | val_0_auc: 0.85461 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.89477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58125 | val_0_auc: 0.84793 |  0:00:00s\n",
      "epoch 1  | loss: 0.46878 | val_0_auc: 0.82832 |  0:00:01s\n",
      "epoch 2  | loss: 0.44155 | val_0_auc: 0.83929 |  0:00:02s\n",
      "epoch 3  | loss: 0.43537 | val_0_auc: 0.79521 |  0:00:03s\n",
      "epoch 4  | loss: 0.42675 | val_0_auc: 0.82542 |  0:00:04s\n",
      "epoch 5  | loss: 0.40675 | val_0_auc: 0.80799 |  0:00:04s\n",
      "epoch 6  | loss: 0.44695 | val_0_auc: 0.81467 |  0:00:05s\n",
      "epoch 7  | loss: 0.42412 | val_0_auc: 0.79158 |  0:00:06s\n",
      "epoch 8  | loss: 0.41862 | val_0_auc: 0.80871 |  0:00:07s\n",
      "epoch 9  | loss: 0.42983 | val_0_auc: 0.80755 |  0:00:08s\n",
      "epoch 10 | loss: 0.39478 | val_0_auc: 0.78519 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.84793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59399 | val_0_auc: 0.7154  |  0:00:00s\n",
      "epoch 1  | loss: 0.51927 | val_0_auc: 0.7955  |  0:00:01s\n",
      "epoch 2  | loss: 0.43997 | val_0_auc: 0.80871 |  0:00:02s\n",
      "epoch 3  | loss: 0.427   | val_0_auc: 0.83972 |  0:00:03s\n",
      "epoch 4  | loss: 0.41813 | val_0_auc: 0.84539 |  0:00:04s\n",
      "epoch 5  | loss: 0.3991  | val_0_auc: 0.84292 |  0:00:04s\n",
      "epoch 6  | loss: 0.41871 | val_0_auc: 0.813   |  0:00:05s\n",
      "epoch 7  | loss: 0.40009 | val_0_auc: 0.84749 |  0:00:06s\n",
      "epoch 8  | loss: 0.40209 | val_0_auc: 0.83384 |  0:00:07s\n",
      "epoch 9  | loss: 0.37943 | val_0_auc: 0.85251 |  0:00:08s\n",
      "epoch 10 | loss: 0.39045 | val_0_auc: 0.82367 |  0:00:09s\n",
      "epoch 11 | loss: 0.39208 | val_0_auc: 0.80951 |  0:00:09s\n",
      "epoch 12 | loss: 0.39114 | val_0_auc: 0.8215  |  0:00:10s\n",
      "epoch 13 | loss: 0.41365 | val_0_auc: 0.82694 |  0:00:11s\n",
      "epoch 14 | loss: 0.38203 | val_0_auc: 0.83362 |  0:00:12s\n",
      "epoch 15 | loss: 0.389   | val_0_auc: 0.8467  |  0:00:13s\n",
      "epoch 16 | loss: 0.37748 | val_0_auc: 0.85171 |  0:00:14s\n",
      "epoch 17 | loss: 0.39343 | val_0_auc: 0.85686 |  0:00:15s\n",
      "epoch 18 | loss: 0.38462 | val_0_auc: 0.86267 |  0:00:16s\n",
      "epoch 19 | loss: 0.37736 | val_0_auc: 0.86006 |  0:00:16s\n",
      "epoch 20 | loss: 0.39064 | val_0_auc: 0.87407 |  0:00:17s\n",
      "epoch 21 | loss: 0.37026 | val_0_auc: 0.86797 |  0:00:18s\n",
      "epoch 22 | loss: 0.37767 | val_0_auc: 0.85171 |  0:00:19s\n",
      "epoch 23 | loss: 0.39161 | val_0_auc: 0.8955  |  0:00:20s\n",
      "epoch 24 | loss: 0.39434 | val_0_auc: 0.89513 |  0:00:20s\n",
      "epoch 25 | loss: 0.39727 | val_0_auc: 0.89499 |  0:00:21s\n",
      "epoch 26 | loss: 0.39306 | val_0_auc: 0.87407 |  0:00:22s\n",
      "epoch 27 | loss: 0.37556 | val_0_auc: 0.88765 |  0:00:23s\n",
      "epoch 28 | loss: 0.37952 | val_0_auc: 0.87683 |  0:00:24s\n",
      "epoch 29 | loss: 0.37947 | val_0_auc: 0.88061 |  0:00:24s\n",
      "epoch 30 | loss: 0.382   | val_0_auc: 0.89078 |  0:00:25s\n",
      "epoch 31 | loss: 0.38092 | val_0_auc: 0.8817  |  0:00:26s\n",
      "epoch 32 | loss: 0.37258 | val_0_auc: 0.85556 |  0:00:27s\n",
      "epoch 33 | loss: 0.37092 | val_0_auc: 0.83965 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.8955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72799 | val_0_auc: 0.85548 |  0:00:00s\n",
      "epoch 1  | loss: 0.48821 | val_0_auc: 0.8045  |  0:00:01s\n",
      "epoch 2  | loss: 0.42123 | val_0_auc: 0.80813 |  0:00:02s\n",
      "epoch 3  | loss: 0.4595  | val_0_auc: 0.79361 |  0:00:03s\n",
      "epoch 4  | loss: 0.41038 | val_0_auc: 0.79121 |  0:00:04s\n",
      "epoch 5  | loss: 0.4007  | val_0_auc: 0.82803 |  0:00:04s\n",
      "epoch 6  | loss: 0.42952 | val_0_auc: 0.83893 |  0:00:05s\n",
      "epoch 7  | loss: 0.42948 | val_0_auc: 0.84735 |  0:00:06s\n",
      "epoch 8  | loss: 0.4407  | val_0_auc: 0.86304 |  0:00:07s\n",
      "epoch 9  | loss: 0.42796 | val_0_auc: 0.85701 |  0:00:08s\n",
      "epoch 10 | loss: 0.40535 | val_0_auc: 0.8581  |  0:00:09s\n",
      "epoch 11 | loss: 0.43108 | val_0_auc: 0.84168 |  0:00:10s\n",
      "epoch 12 | loss: 0.40323 | val_0_auc: 0.85084 |  0:00:11s\n",
      "epoch 13 | loss: 0.41691 | val_0_auc: 0.83791 |  0:00:12s\n",
      "epoch 14 | loss: 0.41214 | val_0_auc: 0.84808 |  0:00:12s\n",
      "epoch 15 | loss: 0.4039  | val_0_auc: 0.84473 |  0:00:13s\n",
      "epoch 16 | loss: 0.40197 | val_0_auc: 0.86122 |  0:00:14s\n",
      "epoch 17 | loss: 0.38148 | val_0_auc: 0.88177 |  0:00:15s\n",
      "epoch 18 | loss: 0.41461 | val_0_auc: 0.89702 |  0:00:16s\n",
      "epoch 19 | loss: 0.40613 | val_0_auc: 0.89179 |  0:00:17s\n",
      "epoch 20 | loss: 0.40269 | val_0_auc: 0.8963  |  0:00:18s\n",
      "epoch 21 | loss: 0.40156 | val_0_auc: 0.8886  |  0:00:19s\n",
      "epoch 22 | loss: 0.38653 | val_0_auc: 0.88046 |  0:00:20s\n",
      "epoch 23 | loss: 0.41265 | val_0_auc: 0.88032 |  0:00:21s\n",
      "epoch 24 | loss: 0.40405 | val_0_auc: 0.87858 |  0:00:21s\n",
      "epoch 25 | loss: 0.40737 | val_0_auc: 0.88105 |  0:00:22s\n",
      "epoch 26 | loss: 0.40535 | val_0_auc: 0.87393 |  0:00:23s\n",
      "epoch 27 | loss: 0.38758 | val_0_auc: 0.88656 |  0:00:24s\n",
      "epoch 28 | loss: 0.40093 | val_0_auc: 0.87908 |  0:00:25s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.89702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61736 | val_0_auc: 0.83282 |  0:00:00s\n",
      "epoch 1  | loss: 0.45081 | val_0_auc: 0.83021 |  0:00:01s\n",
      "epoch 2  | loss: 0.39298 | val_0_auc: 0.81496 |  0:00:02s\n",
      "epoch 3  | loss: 0.39826 | val_0_auc: 0.82404 |  0:00:03s\n",
      "epoch 4  | loss: 0.41057 | val_0_auc: 0.8297  |  0:00:04s\n",
      "epoch 5  | loss: 0.41003 | val_0_auc: 0.84619 |  0:00:05s\n",
      "epoch 6  | loss: 0.38193 | val_0_auc: 0.85374 |  0:00:06s\n",
      "epoch 7  | loss: 0.3917  | val_0_auc: 0.8549  |  0:00:06s\n",
      "epoch 8  | loss: 0.3965  | val_0_auc: 0.85345 |  0:00:07s\n",
      "epoch 9  | loss: 0.40379 | val_0_auc: 0.87335 |  0:00:08s\n",
      "epoch 10 | loss: 0.38609 | val_0_auc: 0.86275 |  0:00:09s\n",
      "epoch 11 | loss: 0.3714  | val_0_auc: 0.86187 |  0:00:10s\n",
      "epoch 12 | loss: 0.38431 | val_0_auc: 0.87335 |  0:00:11s\n",
      "epoch 13 | loss: 0.38173 | val_0_auc: 0.88453 |  0:00:12s\n",
      "epoch 14 | loss: 0.38224 | val_0_auc: 0.87712 |  0:00:13s\n",
      "epoch 15 | loss: 0.3844  | val_0_auc: 0.86318 |  0:00:14s\n",
      "epoch 16 | loss: 0.38667 | val_0_auc: 0.86376 |  0:00:14s\n",
      "epoch 17 | loss: 0.36948 | val_0_auc: 0.8472  |  0:00:15s\n",
      "epoch 18 | loss: 0.37898 | val_0_auc: 0.85418 |  0:00:16s\n",
      "epoch 19 | loss: 0.36612 | val_0_auc: 0.84808 |  0:00:17s\n",
      "epoch 20 | loss: 0.39261 | val_0_auc: 0.84655 |  0:00:18s\n",
      "epoch 21 | loss: 0.39339 | val_0_auc: 0.87407 |  0:00:19s\n",
      "epoch 22 | loss: 0.37604 | val_0_auc: 0.87821 |  0:00:20s\n",
      "epoch 23 | loss: 0.3728  | val_0_auc: 0.88337 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59973 | val_0_auc: 0.77429 |  0:00:00s\n",
      "epoch 1  | loss: 0.48683 | val_0_auc: 0.74503 |  0:00:01s\n",
      "epoch 2  | loss: 0.42696 | val_0_auc: 0.7602  |  0:00:02s\n",
      "epoch 3  | loss: 0.43533 | val_0_auc: 0.75628 |  0:00:03s\n",
      "epoch 4  | loss: 0.42694 | val_0_auc: 0.82948 |  0:00:04s\n",
      "epoch 5  | loss: 0.42308 | val_0_auc: 0.78998 |  0:00:05s\n",
      "epoch 6  | loss: 0.41669 | val_0_auc: 0.74321 |  0:00:06s\n",
      "epoch 7  | loss: 0.42188 | val_0_auc: 0.80189 |  0:00:07s\n",
      "epoch 8  | loss: 0.40993 | val_0_auc: 0.79782 |  0:00:07s\n",
      "epoch 9  | loss: 0.39894 | val_0_auc: 0.852   |  0:00:08s\n",
      "epoch 10 | loss: 0.39061 | val_0_auc: 0.8533  |  0:00:09s\n",
      "epoch 11 | loss: 0.42726 | val_0_auc: 0.85047 |  0:00:10s\n",
      "epoch 12 | loss: 0.39481 | val_0_auc: 0.8642  |  0:00:11s\n",
      "epoch 13 | loss: 0.39839 | val_0_auc: 0.87255 |  0:00:12s\n",
      "epoch 14 | loss: 0.39703 | val_0_auc: 0.84125 |  0:00:13s\n",
      "epoch 15 | loss: 0.41646 | val_0_auc: 0.86543 |  0:00:14s\n",
      "epoch 16 | loss: 0.42088 | val_0_auc: 0.82309 |  0:00:15s\n",
      "epoch 17 | loss: 0.39852 | val_0_auc: 0.84306 |  0:00:15s\n",
      "epoch 18 | loss: 0.37624 | val_0_auc: 0.84873 |  0:00:16s\n",
      "epoch 19 | loss: 0.37395 | val_0_auc: 0.84866 |  0:00:17s\n",
      "epoch 20 | loss: 0.40536 | val_0_auc: 0.85766 |  0:00:18s\n",
      "epoch 21 | loss: 0.38667 | val_0_auc: 0.83994 |  0:00:19s\n",
      "epoch 22 | loss: 0.37893 | val_0_auc: 0.84975 |  0:00:19s\n",
      "epoch 23 | loss: 0.39721 | val_0_auc: 0.86587 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.87255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60614 | val_0_auc: 0.79158 |  0:00:00s\n",
      "epoch 1  | loss: 0.46945 | val_0_auc: 0.83849 |  0:00:01s\n",
      "epoch 2  | loss: 0.45491 | val_0_auc: 0.85113 |  0:00:02s\n",
      "epoch 3  | loss: 0.44257 | val_0_auc: 0.7971  |  0:00:03s\n",
      "epoch 4  | loss: 0.45162 | val_0_auc: 0.76935 |  0:00:04s\n",
      "epoch 5  | loss: 0.42158 | val_0_auc: 0.80537 |  0:00:05s\n",
      "epoch 6  | loss: 0.42096 | val_0_auc: 0.79913 |  0:00:06s\n",
      "epoch 7  | loss: 0.43348 | val_0_auc: 0.85701 |  0:00:07s\n",
      "epoch 8  | loss: 0.41568 | val_0_auc: 0.839   |  0:00:08s\n",
      "epoch 9  | loss: 0.40955 | val_0_auc: 0.83602 |  0:00:09s\n",
      "epoch 10 | loss: 0.44641 | val_0_auc: 0.83166 |  0:00:09s\n",
      "epoch 11 | loss: 0.42982 | val_0_auc: 0.82266 |  0:00:10s\n",
      "epoch 12 | loss: 0.39761 | val_0_auc: 0.82346 |  0:00:11s\n",
      "epoch 13 | loss: 0.38929 | val_0_auc: 0.81111 |  0:00:12s\n",
      "epoch 14 | loss: 0.42659 | val_0_auc: 0.80407 |  0:00:13s\n",
      "epoch 15 | loss: 0.3913  | val_0_auc: 0.81714 |  0:00:14s\n",
      "epoch 16 | loss: 0.40756 | val_0_auc: 0.85105 |  0:00:15s\n",
      "epoch 17 | loss: 0.40313 | val_0_auc: 0.84423 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.85701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59762 | val_0_auc: 0.82135 |  0:00:00s\n",
      "epoch 1  | loss: 0.49836 | val_0_auc: 0.8024  |  0:00:01s\n",
      "epoch 2  | loss: 0.47084 | val_0_auc: 0.80697 |  0:00:02s\n",
      "epoch 3  | loss: 0.43846 | val_0_auc: 0.73246 |  0:00:03s\n",
      "epoch 4  | loss: 0.42708 | val_0_auc: 0.77023 |  0:00:04s\n",
      "epoch 5  | loss: 0.42848 | val_0_auc: 0.82716 |  0:00:05s\n",
      "epoch 6  | loss: 0.43458 | val_0_auc: 0.83682 |  0:00:06s\n",
      "epoch 7  | loss: 0.44538 | val_0_auc: 0.85113 |  0:00:07s\n",
      "epoch 8  | loss: 0.40214 | val_0_auc: 0.85447 |  0:00:08s\n",
      "epoch 9  | loss: 0.40294 | val_0_auc: 0.86536 |  0:00:08s\n",
      "epoch 10 | loss: 0.42643 | val_0_auc: 0.82229 |  0:00:09s\n",
      "epoch 11 | loss: 0.4131  | val_0_auc: 0.84495 |  0:00:10s\n",
      "epoch 12 | loss: 0.42083 | val_0_auc: 0.83965 |  0:00:11s\n",
      "epoch 13 | loss: 0.39375 | val_0_auc: 0.84473 |  0:00:12s\n",
      "epoch 14 | loss: 0.40067 | val_0_auc: 0.83355 |  0:00:13s\n",
      "epoch 15 | loss: 0.38254 | val_0_auc: 0.83028 |  0:00:14s\n",
      "epoch 16 | loss: 0.39365 | val_0_auc: 0.82789 |  0:00:15s\n",
      "epoch 17 | loss: 0.39137 | val_0_auc: 0.81278 |  0:00:16s\n",
      "epoch 18 | loss: 0.41913 | val_0_auc: 0.83021 |  0:00:17s\n",
      "epoch 19 | loss: 0.37802 | val_0_auc: 0.82905 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.86536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55851 | val_0_auc: 0.75265 |  0:00:00s\n",
      "epoch 1  | loss: 0.47234 | val_0_auc: 0.80886 |  0:00:01s\n",
      "epoch 2  | loss: 0.44851 | val_0_auc: 0.8215  |  0:00:02s\n",
      "epoch 3  | loss: 0.45464 | val_0_auc: 0.82672 |  0:00:03s\n",
      "epoch 4  | loss: 0.47559 | val_0_auc: 0.82004 |  0:00:04s\n",
      "epoch 5  | loss: 0.43239 | val_0_auc: 0.81075 |  0:00:05s\n",
      "epoch 6  | loss: 0.42596 | val_0_auc: 0.82571 |  0:00:06s\n",
      "epoch 7  | loss: 0.43107 | val_0_auc: 0.83174 |  0:00:07s\n",
      "epoch 8  | loss: 0.44291 | val_0_auc: 0.7276  |  0:00:08s\n",
      "epoch 9  | loss: 0.41464 | val_0_auc: 0.80639 |  0:00:09s\n",
      "epoch 10 | loss: 0.41903 | val_0_auc: 0.83297 |  0:00:09s\n",
      "epoch 11 | loss: 0.42159 | val_0_auc: 0.82527 |  0:00:10s\n",
      "epoch 12 | loss: 0.41521 | val_0_auc: 0.81097 |  0:00:11s\n",
      "epoch 13 | loss: 0.40645 | val_0_auc: 0.84372 |  0:00:12s\n",
      "epoch 14 | loss: 0.44477 | val_0_auc: 0.87858 |  0:00:13s\n",
      "epoch 15 | loss: 0.43182 | val_0_auc: 0.84096 |  0:00:14s\n",
      "epoch 16 | loss: 0.41592 | val_0_auc: 0.85664 |  0:00:15s\n",
      "epoch 17 | loss: 0.39267 | val_0_auc: 0.88119 |  0:00:15s\n",
      "epoch 18 | loss: 0.40948 | val_0_auc: 0.88017 |  0:00:16s\n",
      "epoch 19 | loss: 0.41404 | val_0_auc: 0.88192 |  0:00:17s\n",
      "epoch 20 | loss: 0.41098 | val_0_auc: 0.87582 |  0:00:18s\n",
      "epoch 21 | loss: 0.40585 | val_0_auc: 0.87233 |  0:00:19s\n",
      "epoch 22 | loss: 0.3982  | val_0_auc: 0.87988 |  0:00:20s\n",
      "epoch 23 | loss: 0.44266 | val_0_auc: 0.8971  |  0:00:21s\n",
      "epoch 24 | loss: 0.41304 | val_0_auc: 0.89637 |  0:00:21s\n",
      "epoch 25 | loss: 0.38746 | val_0_auc: 0.90153 |  0:00:22s\n",
      "epoch 26 | loss: 0.42543 | val_0_auc: 0.86718 |  0:00:23s\n",
      "epoch 27 | loss: 0.43036 | val_0_auc: 0.87306 |  0:00:24s\n",
      "epoch 28 | loss: 0.42361 | val_0_auc: 0.86216 |  0:00:25s\n",
      "epoch 29 | loss: 0.40448 | val_0_auc: 0.86463 |  0:00:26s\n",
      "epoch 30 | loss: 0.43164 | val_0_auc: 0.848   |  0:00:26s\n",
      "epoch 31 | loss: 0.42217 | val_0_auc: 0.87451 |  0:00:27s\n",
      "epoch 32 | loss: 0.42792 | val_0_auc: 0.86151 |  0:00:28s\n",
      "epoch 33 | loss: 0.41585 | val_0_auc: 0.89085 |  0:00:29s\n",
      "epoch 34 | loss: 0.42128 | val_0_auc: 0.88729 |  0:00:30s\n",
      "epoch 35 | loss: 0.41975 | val_0_auc: 0.88373 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.90153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92586 | val_0_auc: 0.80007 |  0:00:01s\n",
      "epoch 1  | loss: 0.57422 | val_0_auc: 0.83522 |  0:00:03s\n",
      "epoch 2  | loss: 0.45744 | val_0_auc: 0.80654 |  0:00:05s\n",
      "epoch 3  | loss: 0.4308  | val_0_auc: 0.82571 |  0:00:06s\n",
      "epoch 4  | loss: 0.48632 | val_0_auc: 0.81038 |  0:00:08s\n",
      "epoch 5  | loss: 0.44792 | val_0_auc: 0.81046 |  0:00:10s\n",
      "epoch 6  | loss: 0.42287 | val_0_auc: 0.81423 |  0:00:11s\n",
      "epoch 7  | loss: 0.43147 | val_0_auc: 0.7862  |  0:00:13s\n",
      "epoch 8  | loss: 0.42096 | val_0_auc: 0.80516 |  0:00:14s\n",
      "epoch 9  | loss: 0.39635 | val_0_auc: 0.83115 |  0:00:16s\n",
      "epoch 10 | loss: 0.40035 | val_0_auc: 0.82353 |  0:00:18s\n",
      "epoch 11 | loss: 0.40123 | val_0_auc: 0.78765 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.83522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92699 | val_0_auc: 0.80683 |  0:00:01s\n",
      "epoch 1  | loss: 0.79792 | val_0_auc: 0.72331 |  0:00:03s\n",
      "epoch 2  | loss: 0.53378 | val_0_auc: 0.84938 |  0:00:04s\n",
      "epoch 3  | loss: 0.42    | val_0_auc: 0.84749 |  0:00:06s\n",
      "epoch 4  | loss: 0.49464 | val_0_auc: 0.82571 |  0:00:08s\n",
      "epoch 5  | loss: 0.46954 | val_0_auc: 0.88366 |  0:00:09s\n",
      "epoch 6  | loss: 0.4341  | val_0_auc: 0.83428 |  0:00:11s\n",
      "epoch 7  | loss: 0.4267  | val_0_auc: 0.83413 |  0:00:13s\n",
      "epoch 8  | loss: 0.45054 | val_0_auc: 0.87131 |  0:00:14s\n",
      "epoch 9  | loss: 0.42967 | val_0_auc: 0.84198 |  0:00:16s\n",
      "epoch 10 | loss: 0.42282 | val_0_auc: 0.85999 |  0:00:18s\n",
      "epoch 11 | loss: 0.42994 | val_0_auc: 0.87349 |  0:00:19s\n",
      "epoch 12 | loss: 0.41792 | val_0_auc: 0.83486 |  0:00:21s\n",
      "epoch 13 | loss: 0.42351 | val_0_auc: 0.86216 |  0:00:22s\n",
      "epoch 14 | loss: 0.43347 | val_0_auc: 0.85142 |  0:00:24s\n",
      "epoch 15 | loss: 0.40997 | val_0_auc: 0.78315 |  0:00:25s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.88366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.90227 | val_0_auc: 0.81968 |  0:00:01s\n",
      "epoch 1  | loss: 0.58096 | val_0_auc: 0.83602 |  0:00:03s\n",
      "epoch 2  | loss: 0.46102 | val_0_auc: 0.80247 |  0:00:04s\n",
      "epoch 3  | loss: 0.49959 | val_0_auc: 0.80116 |  0:00:06s\n",
      "epoch 4  | loss: 0.47053 | val_0_auc: 0.82484 |  0:00:07s\n",
      "epoch 5  | loss: 0.46932 | val_0_auc: 0.81598 |  0:00:09s\n",
      "epoch 6  | loss: 0.47706 | val_0_auc: 0.81104 |  0:00:10s\n",
      "epoch 7  | loss: 0.46078 | val_0_auc: 0.82266 |  0:00:12s\n",
      "epoch 8  | loss: 0.4931  | val_0_auc: 0.80581 |  0:00:14s\n",
      "epoch 9  | loss: 0.46619 | val_0_auc: 0.81336 |  0:00:15s\n",
      "epoch 10 | loss: 0.46289 | val_0_auc: 0.82934 |  0:00:18s\n",
      "epoch 11 | loss: 0.44398 | val_0_auc: 0.83508 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.83602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.8156  | val_0_auc: 0.76703 |  0:00:01s\n",
      "epoch 1  | loss: 0.53342 | val_0_auc: 0.78344 |  0:00:03s\n",
      "epoch 2  | loss: 0.51465 | val_0_auc: 0.78548 |  0:00:04s\n",
      "epoch 3  | loss: 0.46413 | val_0_auc: 0.79448 |  0:00:06s\n",
      "epoch 4  | loss: 0.47976 | val_0_auc: 0.81685 |  0:00:08s\n",
      "epoch 5  | loss: 0.4659  | val_0_auc: 0.79593 |  0:00:09s\n",
      "epoch 6  | loss: 0.46422 | val_0_auc: 0.86565 |  0:00:11s\n",
      "epoch 7  | loss: 0.48589 | val_0_auc: 0.85781 |  0:00:13s\n",
      "epoch 8  | loss: 0.44923 | val_0_auc: 0.86391 |  0:00:14s\n",
      "epoch 9  | loss: 0.42629 | val_0_auc: 0.83428 |  0:00:16s\n",
      "epoch 10 | loss: 0.43436 | val_0_auc: 0.85359 |  0:00:18s\n",
      "epoch 11 | loss: 0.42608 | val_0_auc: 0.84982 |  0:00:19s\n",
      "epoch 12 | loss: 0.43895 | val_0_auc: 0.85156 |  0:00:21s\n",
      "epoch 13 | loss: 0.39894 | val_0_auc: 0.84604 |  0:00:22s\n",
      "epoch 14 | loss: 0.40052 | val_0_auc: 0.85519 |  0:00:24s\n",
      "epoch 15 | loss: 0.43383 | val_0_auc: 0.85098 |  0:00:26s\n",
      "epoch 16 | loss: 0.38869 | val_0_auc: 0.85882 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.86565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.24715 | val_0_auc: 0.79172 |  0:00:01s\n",
      "epoch 1  | loss: 0.68759 | val_0_auc: 0.81845 |  0:00:03s\n",
      "epoch 2  | loss: 0.53433 | val_0_auc: 0.70748 |  0:00:04s\n",
      "epoch 3  | loss: 0.52426 | val_0_auc: 0.81075 |  0:00:06s\n",
      "epoch 4  | loss: 0.52739 | val_0_auc: 0.8366  |  0:00:08s\n",
      "epoch 5  | loss: 0.49528 | val_0_auc: 0.86144 |  0:00:09s\n",
      "epoch 6  | loss: 0.45384 | val_0_auc: 0.83457 |  0:00:11s\n",
      "epoch 7  | loss: 0.46014 | val_0_auc: 0.85243 |  0:00:12s\n",
      "epoch 8  | loss: 0.42358 | val_0_auc: 0.80305 |  0:00:14s\n",
      "epoch 9  | loss: 0.43235 | val_0_auc: 0.80595 |  0:00:16s\n",
      "epoch 10 | loss: 0.44638 | val_0_auc: 0.83181 |  0:00:17s\n",
      "epoch 11 | loss: 0.44619 | val_0_auc: 0.84706 |  0:00:19s\n",
      "epoch 12 | loss: 0.42557 | val_0_auc: 0.81481 |  0:00:21s\n",
      "epoch 13 | loss: 0.42354 | val_0_auc: 0.81104 |  0:00:22s\n",
      "epoch 14 | loss: 0.42543 | val_0_auc: 0.79041 |  0:00:24s\n",
      "epoch 15 | loss: 0.44233 | val_0_auc: 0.83617 |  0:00:25s\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.86144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.74378 | val_0_auc: 0.78431 |  0:00:01s\n",
      "epoch 1  | loss: 0.46139 | val_0_auc: 0.82106 |  0:00:02s\n",
      "epoch 2  | loss: 0.39592 | val_0_auc: 0.80465 |  0:00:03s\n",
      "epoch 3  | loss: 0.43162 | val_0_auc: 0.83253 |  0:00:04s\n",
      "epoch 4  | loss: 0.43694 | val_0_auc: 0.87582 |  0:00:06s\n",
      "epoch 5  | loss: 0.41454 | val_0_auc: 0.84967 |  0:00:07s\n",
      "epoch 6  | loss: 0.39676 | val_0_auc: 0.82919 |  0:00:08s\n",
      "epoch 7  | loss: 0.39616 | val_0_auc: 0.84662 |  0:00:10s\n",
      "epoch 8  | loss: 0.39003 | val_0_auc: 0.86289 |  0:00:11s\n",
      "epoch 9  | loss: 0.37723 | val_0_auc: 0.8435  |  0:00:12s\n",
      "epoch 10 | loss: 0.36368 | val_0_auc: 0.86253 |  0:00:13s\n",
      "epoch 11 | loss: 0.39602 | val_0_auc: 0.85004 |  0:00:14s\n",
      "epoch 12 | loss: 0.37704 | val_0_auc: 0.83762 |  0:00:16s\n",
      "epoch 13 | loss: 0.37206 | val_0_auc: 0.7923  |  0:00:17s\n",
      "epoch 14 | loss: 0.38297 | val_0_auc: 0.82266 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.87582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.79191 | val_0_auc: 0.82513 |  0:00:01s\n",
      "epoch 1  | loss: 0.43812 | val_0_auc: 0.85512 |  0:00:02s\n",
      "epoch 2  | loss: 0.4333  | val_0_auc: 0.81017 |  0:00:03s\n",
      "epoch 3  | loss: 0.41748 | val_0_auc: 0.83617 |  0:00:04s\n",
      "epoch 4  | loss: 0.44645 | val_0_auc: 0.7618  |  0:00:06s\n",
      "epoch 5  | loss: 0.41517 | val_0_auc: 0.85403 |  0:00:07s\n",
      "epoch 6  | loss: 0.39219 | val_0_auc: 0.8411  |  0:00:08s\n",
      "epoch 7  | loss: 0.41025 | val_0_auc: 0.84023 |  0:00:09s\n",
      "epoch 8  | loss: 0.40312 | val_0_auc: 0.83907 |  0:00:11s\n",
      "epoch 9  | loss: 0.38047 | val_0_auc: 0.84648 |  0:00:12s\n",
      "epoch 10 | loss: 0.39068 | val_0_auc: 0.86492 |  0:00:13s\n",
      "epoch 11 | loss: 0.41857 | val_0_auc: 0.8528  |  0:00:15s\n",
      "epoch 12 | loss: 0.40982 | val_0_auc: 0.84895 |  0:00:16s\n",
      "epoch 13 | loss: 0.3867  | val_0_auc: 0.86275 |  0:00:17s\n",
      "epoch 14 | loss: 0.40614 | val_0_auc: 0.90566 |  0:00:18s\n",
      "epoch 15 | loss: 0.38879 | val_0_auc: 0.89818 |  0:00:20s\n",
      "epoch 16 | loss: 0.38726 | val_0_auc: 0.88134 |  0:00:21s\n",
      "epoch 17 | loss: 0.38429 | val_0_auc: 0.87959 |  0:00:23s\n",
      "epoch 18 | loss: 0.40544 | val_0_auc: 0.85926 |  0:00:24s\n",
      "epoch 19 | loss: 0.39065 | val_0_auc: 0.8825  |  0:00:25s\n",
      "epoch 20 | loss: 0.37202 | val_0_auc: 0.87495 |  0:00:26s\n",
      "epoch 21 | loss: 0.37857 | val_0_auc: 0.87451 |  0:00:28s\n",
      "epoch 22 | loss: 0.38415 | val_0_auc: 0.86311 |  0:00:29s\n",
      "epoch 23 | loss: 0.37651 | val_0_auc: 0.8748  |  0:00:30s\n",
      "epoch 24 | loss: 0.3757  | val_0_auc: 0.90022 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.90566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.75793 | val_0_auc: 0.7971  |  0:00:01s\n",
      "epoch 1  | loss: 0.47282 | val_0_auc: 0.82208 |  0:00:02s\n",
      "epoch 2  | loss: 0.42336 | val_0_auc: 0.82222 |  0:00:03s\n",
      "epoch 3  | loss: 0.39843 | val_0_auc: 0.83936 |  0:00:05s\n",
      "epoch 4  | loss: 0.41565 | val_0_auc: 0.82309 |  0:00:06s\n",
      "epoch 5  | loss: 0.39298 | val_0_auc: 0.81496 |  0:00:08s\n",
      "epoch 6  | loss: 0.40067 | val_0_auc: 0.8207  |  0:00:09s\n",
      "epoch 7  | loss: 0.39394 | val_0_auc: 0.84779 |  0:00:10s\n",
      "epoch 8  | loss: 0.40668 | val_0_auc: 0.80436 |  0:00:12s\n",
      "epoch 9  | loss: 0.40605 | val_0_auc: 0.81946 |  0:00:13s\n",
      "epoch 10 | loss: 0.3873  | val_0_auc: 0.8626  |  0:00:14s\n",
      "epoch 11 | loss: 0.41585 | val_0_auc: 0.82992 |  0:00:16s\n",
      "epoch 12 | loss: 0.41963 | val_0_auc: 0.79564 |  0:00:17s\n",
      "epoch 13 | loss: 0.38792 | val_0_auc: 0.85316 |  0:00:18s\n",
      "epoch 14 | loss: 0.38025 | val_0_auc: 0.8716  |  0:00:20s\n",
      "epoch 15 | loss: 0.3761  | val_0_auc: 0.86536 |  0:00:21s\n",
      "epoch 16 | loss: 0.392   | val_0_auc: 0.86609 |  0:00:22s\n",
      "epoch 17 | loss: 0.38525 | val_0_auc: 0.85069 |  0:00:24s\n",
      "epoch 18 | loss: 0.38548 | val_0_auc: 0.86245 |  0:00:25s\n",
      "epoch 19 | loss: 0.37664 | val_0_auc: 0.85635 |  0:00:26s\n",
      "epoch 20 | loss: 0.37052 | val_0_auc: 0.85025 |  0:00:28s\n",
      "epoch 21 | loss: 0.37235 | val_0_auc: 0.86507 |  0:00:29s\n",
      "epoch 22 | loss: 0.36959 | val_0_auc: 0.87349 |  0:00:30s\n",
      "epoch 23 | loss: 0.39145 | val_0_auc: 0.86986 |  0:00:32s\n",
      "epoch 24 | loss: 0.40507 | val_0_auc: 0.87683 |  0:00:33s\n",
      "epoch 25 | loss: 0.39351 | val_0_auc: 0.86652 |  0:00:34s\n",
      "epoch 26 | loss: 0.38503 | val_0_auc: 0.87858 |  0:00:36s\n",
      "epoch 27 | loss: 0.38186 | val_0_auc: 0.88816 |  0:00:37s\n",
      "epoch 28 | loss: 0.37517 | val_0_auc: 0.88802 |  0:00:39s\n",
      "epoch 29 | loss: 0.38162 | val_0_auc: 0.89528 |  0:00:40s\n",
      "epoch 30 | loss: 0.37071 | val_0_auc: 0.89383 |  0:00:41s\n",
      "epoch 31 | loss: 0.37779 | val_0_auc: 0.90174 |  0:00:42s\n",
      "epoch 32 | loss: 0.37177 | val_0_auc: 0.90247 |  0:00:44s\n",
      "epoch 33 | loss: 0.37982 | val_0_auc: 0.89339 |  0:00:45s\n",
      "epoch 34 | loss: 0.37827 | val_0_auc: 0.90044 |  0:00:46s\n",
      "epoch 35 | loss: 0.36295 | val_0_auc: 0.87785 |  0:00:47s\n",
      "epoch 36 | loss: 0.38057 | val_0_auc: 0.89165 |  0:00:49s\n",
      "epoch 37 | loss: 0.39374 | val_0_auc: 0.88715 |  0:00:50s\n",
      "epoch 38 | loss: 0.39547 | val_0_auc: 0.88046 |  0:00:51s\n",
      "epoch 39 | loss: 0.3887  | val_0_auc: 0.88163 |  0:00:52s\n",
      "epoch 40 | loss: 0.384   | val_0_auc: 0.88105 |  0:00:54s\n",
      "epoch 41 | loss: 0.38316 | val_0_auc: 0.89368 |  0:00:55s\n",
      "epoch 42 | loss: 0.38767 | val_0_auc: 0.88417 |  0:00:56s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80187 | val_0_auc: 0.54815 |  0:00:01s\n",
      "epoch 1  | loss: 0.46447 | val_0_auc: 0.81264 |  0:00:02s\n",
      "epoch 2  | loss: 0.44464 | val_0_auc: 0.77792 |  0:00:03s\n",
      "epoch 3  | loss: 0.41957 | val_0_auc: 0.84473 |  0:00:05s\n",
      "epoch 4  | loss: 0.39793 | val_0_auc: 0.81772 |  0:00:06s\n",
      "epoch 5  | loss: 0.39422 | val_0_auc: 0.75715 |  0:00:07s\n",
      "epoch 6  | loss: 0.38796 | val_0_auc: 0.77553 |  0:00:08s\n",
      "epoch 7  | loss: 0.40369 | val_0_auc: 0.82731 |  0:00:09s\n",
      "epoch 8  | loss: 0.38586 | val_0_auc: 0.82019 |  0:00:10s\n",
      "epoch 9  | loss: 0.40111 | val_0_auc: 0.87059 |  0:00:12s\n",
      "epoch 10 | loss: 0.38129 | val_0_auc: 0.86783 |  0:00:13s\n",
      "epoch 11 | loss: 0.39072 | val_0_auc: 0.83224 |  0:00:14s\n",
      "epoch 12 | loss: 0.4092  | val_0_auc: 0.84212 |  0:00:15s\n",
      "epoch 13 | loss: 0.36413 | val_0_auc: 0.83885 |  0:00:17s\n",
      "epoch 14 | loss: 0.38542 | val_0_auc: 0.88264 |  0:00:18s\n",
      "epoch 15 | loss: 0.37885 | val_0_auc: 0.87538 |  0:00:19s\n",
      "epoch 16 | loss: 0.39739 | val_0_auc: 0.84503 |  0:00:21s\n",
      "epoch 17 | loss: 0.39906 | val_0_auc: 0.85897 |  0:00:22s\n",
      "epoch 18 | loss: 0.39409 | val_0_auc: 0.87567 |  0:00:23s\n",
      "epoch 19 | loss: 0.37878 | val_0_auc: 0.85832 |  0:00:25s\n",
      "epoch 20 | loss: 0.37842 | val_0_auc: 0.84386 |  0:00:26s\n",
      "epoch 21 | loss: 0.36404 | val_0_auc: 0.852   |  0:00:27s\n",
      "epoch 22 | loss: 0.36087 | val_0_auc: 0.85113 |  0:00:29s\n",
      "epoch 23 | loss: 0.37812 | val_0_auc: 0.87654 |  0:00:30s\n",
      "epoch 24 | loss: 0.37588 | val_0_auc: 0.88468 |  0:00:31s\n",
      "epoch 25 | loss: 0.35223 | val_0_auc: 0.88511 |  0:00:33s\n",
      "epoch 26 | loss: 0.37026 | val_0_auc: 0.88758 |  0:00:34s\n",
      "epoch 27 | loss: 0.3628  | val_0_auc: 0.88279 |  0:00:35s\n",
      "epoch 28 | loss: 0.35314 | val_0_auc: 0.85563 |  0:00:37s\n",
      "epoch 29 | loss: 0.36261 | val_0_auc: 0.8854  |  0:00:38s\n",
      "epoch 30 | loss: 0.36777 | val_0_auc: 0.88976 |  0:00:39s\n",
      "epoch 31 | loss: 0.3581  | val_0_auc: 0.90225 |  0:00:40s\n",
      "epoch 32 | loss: 0.34868 | val_0_auc: 0.90458 |  0:00:42s\n",
      "epoch 33 | loss: 0.36835 | val_0_auc: 0.87633 |  0:00:43s\n",
      "epoch 34 | loss: 0.37975 | val_0_auc: 0.86892 |  0:00:44s\n",
      "epoch 35 | loss: 0.35519 | val_0_auc: 0.87509 |  0:00:45s\n",
      "epoch 36 | loss: 0.37029 | val_0_auc: 0.87654 |  0:00:47s\n",
      "epoch 37 | loss: 0.38003 | val_0_auc: 0.90196 |  0:00:48s\n",
      "epoch 38 | loss: 0.3807  | val_0_auc: 0.89717 |  0:00:49s\n",
      "epoch 39 | loss: 0.38127 | val_0_auc: 0.89847 |  0:00:50s\n",
      "epoch 40 | loss: 0.3657  | val_0_auc: 0.88308 |  0:00:51s\n",
      "epoch 41 | loss: 0.37815 | val_0_auc: 0.88991 |  0:00:53s\n",
      "epoch 42 | loss: 0.3721  | val_0_auc: 0.88845 |  0:00:54s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.84395 | val_0_auc: 0.7801  |  0:00:01s\n",
      "epoch 1  | loss: 0.51668 | val_0_auc: 0.82033 |  0:00:02s\n",
      "epoch 2  | loss: 0.45978 | val_0_auc: 0.79898 |  0:00:03s\n",
      "epoch 3  | loss: 0.48197 | val_0_auc: 0.84125 |  0:00:05s\n",
      "epoch 4  | loss: 0.42031 | val_0_auc: 0.8032  |  0:00:06s\n",
      "epoch 5  | loss: 0.43564 | val_0_auc: 0.85476 |  0:00:07s\n",
      "epoch 6  | loss: 0.43569 | val_0_auc: 0.8382  |  0:00:08s\n",
      "epoch 7  | loss: 0.3977  | val_0_auc: 0.85969 |  0:00:09s\n",
      "epoch 8  | loss: 0.40838 | val_0_auc: 0.85694 |  0:00:11s\n",
      "epoch 9  | loss: 0.40648 | val_0_auc: 0.86972 |  0:00:12s\n",
      "epoch 10 | loss: 0.40204 | val_0_auc: 0.87088 |  0:00:13s\n",
      "epoch 11 | loss: 0.42356 | val_0_auc: 0.87015 |  0:00:14s\n",
      "epoch 12 | loss: 0.39079 | val_0_auc: 0.88613 |  0:00:16s\n",
      "epoch 13 | loss: 0.38543 | val_0_auc: 0.88824 |  0:00:17s\n",
      "epoch 14 | loss: 0.37787 | val_0_auc: 0.8716  |  0:00:18s\n",
      "epoch 15 | loss: 0.4295  | val_0_auc: 0.87741 |  0:00:20s\n",
      "epoch 16 | loss: 0.40558 | val_0_auc: 0.88497 |  0:00:21s\n",
      "epoch 17 | loss: 0.40205 | val_0_auc: 0.87908 |  0:00:22s\n",
      "epoch 18 | loss: 0.41434 | val_0_auc: 0.86783 |  0:00:24s\n",
      "epoch 19 | loss: 0.39811 | val_0_auc: 0.88417 |  0:00:25s\n",
      "epoch 20 | loss: 0.40101 | val_0_auc: 0.87923 |  0:00:26s\n",
      "epoch 21 | loss: 0.40507 | val_0_auc: 0.87712 |  0:00:27s\n",
      "epoch 22 | loss: 0.3799  | val_0_auc: 0.86812 |  0:00:28s\n",
      "epoch 23 | loss: 0.37671 | val_0_auc: 0.86768 |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.85096 | val_0_auc: 0.43275 |  0:00:01s\n",
      "epoch 1  | loss: 0.67165 | val_0_auc: 0.78569 |  0:00:03s\n",
      "epoch 2  | loss: 0.4755  | val_0_auc: 0.67945 |  0:00:05s\n",
      "epoch 3  | loss: 0.4557  | val_0_auc: 0.84633 |  0:00:06s\n",
      "epoch 4  | loss: 0.4347  | val_0_auc: 0.83558 |  0:00:08s\n",
      "epoch 5  | loss: 0.44258 | val_0_auc: 0.82716 |  0:00:10s\n",
      "epoch 6  | loss: 0.42832 | val_0_auc: 0.83907 |  0:00:11s\n",
      "epoch 7  | loss: 0.41338 | val_0_auc: 0.8106  |  0:00:13s\n",
      "epoch 8  | loss: 0.38481 | val_0_auc: 0.82382 |  0:00:15s\n",
      "epoch 9  | loss: 0.41548 | val_0_auc: 0.84183 |  0:00:17s\n",
      "epoch 10 | loss: 0.39008 | val_0_auc: 0.85389 |  0:00:18s\n",
      "epoch 11 | loss: 0.39894 | val_0_auc: 0.88134 |  0:00:20s\n",
      "epoch 12 | loss: 0.40994 | val_0_auc: 0.87306 |  0:00:22s\n",
      "epoch 13 | loss: 0.40769 | val_0_auc: 0.87233 |  0:00:24s\n",
      "epoch 14 | loss: 0.38216 | val_0_auc: 0.85984 |  0:00:25s\n",
      "epoch 15 | loss: 0.41614 | val_0_auc: 0.85069 |  0:00:27s\n",
      "epoch 16 | loss: 0.41335 | val_0_auc: 0.85018 |  0:00:29s\n",
      "epoch 17 | loss: 0.40627 | val_0_auc: 0.85272 |  0:00:31s\n",
      "epoch 18 | loss: 0.39958 | val_0_auc: 0.86986 |  0:00:32s\n",
      "epoch 19 | loss: 0.37459 | val_0_auc: 0.85534 |  0:00:34s\n",
      "epoch 20 | loss: 0.39627 | val_0_auc: 0.83667 |  0:00:36s\n",
      "epoch 21 | loss: 0.39406 | val_0_auc: 0.84691 |  0:00:37s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.88134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.95054 | val_0_auc: 0.82658 |  0:00:01s\n",
      "epoch 1  | loss: 0.56034 | val_0_auc: 0.44154 |  0:00:03s\n",
      "epoch 2  | loss: 0.45761 | val_0_auc: 0.74394 |  0:00:04s\n",
      "epoch 3  | loss: 0.47245 | val_0_auc: 0.7114  |  0:00:06s\n",
      "epoch 4  | loss: 0.44195 | val_0_auc: 0.75033 |  0:00:08s\n",
      "epoch 5  | loss: 0.45492 | val_0_auc: 0.85171 |  0:00:09s\n",
      "epoch 6  | loss: 0.42517 | val_0_auc: 0.84154 |  0:00:11s\n",
      "epoch 7  | loss: 0.41425 | val_0_auc: 0.82338 |  0:00:13s\n",
      "epoch 8  | loss: 0.42276 | val_0_auc: 0.83762 |  0:00:14s\n",
      "epoch 9  | loss: 0.44971 | val_0_auc: 0.78824 |  0:00:16s\n",
      "epoch 10 | loss: 0.43443 | val_0_auc: 0.83907 |  0:00:18s\n",
      "epoch 11 | loss: 0.41445 | val_0_auc: 0.84641 |  0:00:19s\n",
      "epoch 12 | loss: 0.4185  | val_0_auc: 0.87596 |  0:00:21s\n",
      "epoch 13 | loss: 0.4249  | val_0_auc: 0.86107 |  0:00:23s\n",
      "epoch 14 | loss: 0.40662 | val_0_auc: 0.8512  |  0:00:24s\n",
      "epoch 15 | loss: 0.44281 | val_0_auc: 0.85839 |  0:00:26s\n",
      "epoch 16 | loss: 0.41287 | val_0_auc: 0.83312 |  0:00:28s\n",
      "epoch 17 | loss: 0.41975 | val_0_auc: 0.88686 |  0:00:29s\n",
      "epoch 18 | loss: 0.4145  | val_0_auc: 0.85999 |  0:00:31s\n",
      "epoch 19 | loss: 0.39128 | val_0_auc: 0.89034 |  0:00:33s\n",
      "epoch 20 | loss: 0.39898 | val_0_auc: 0.88598 |  0:00:34s\n",
      "epoch 21 | loss: 0.41261 | val_0_auc: 0.86928 |  0:00:36s\n",
      "epoch 22 | loss: 0.40255 | val_0_auc: 0.87233 |  0:00:38s\n",
      "epoch 23 | loss: 0.3845  | val_0_auc: 0.87654 |  0:00:39s\n",
      "epoch 24 | loss: 0.39618 | val_0_auc: 0.87335 |  0:00:41s\n",
      "epoch 25 | loss: 0.39773 | val_0_auc: 0.88381 |  0:00:43s\n",
      "epoch 26 | loss: 0.40596 | val_0_auc: 0.89107 |  0:00:44s\n",
      "epoch 27 | loss: 0.39616 | val_0_auc: 0.88802 |  0:00:46s\n",
      "epoch 28 | loss: 0.39049 | val_0_auc: 0.88976 |  0:00:48s\n",
      "epoch 29 | loss: 0.37408 | val_0_auc: 0.89455 |  0:00:50s\n",
      "epoch 30 | loss: 0.40551 | val_0_auc: 0.87916 |  0:00:51s\n",
      "epoch 31 | loss: 0.40867 | val_0_auc: 0.88991 |  0:00:53s\n",
      "epoch 32 | loss: 0.40831 | val_0_auc: 0.89296 |  0:00:55s\n",
      "epoch 33 | loss: 0.38957 | val_0_auc: 0.90312 |  0:00:57s\n",
      "epoch 34 | loss: 0.41859 | val_0_auc: 0.89405 |  0:00:59s\n",
      "epoch 35 | loss: 0.41872 | val_0_auc: 0.87197 |  0:01:00s\n",
      "epoch 36 | loss: 0.39965 | val_0_auc: 0.87611 |  0:01:02s\n",
      "epoch 37 | loss: 0.42655 | val_0_auc: 0.87291 |  0:01:04s\n",
      "epoch 38 | loss: 0.3953  | val_0_auc: 0.8793  |  0:01:06s\n",
      "epoch 39 | loss: 0.41324 | val_0_auc: 0.87095 |  0:01:08s\n",
      "epoch 40 | loss: 0.40424 | val_0_auc: 0.85861 |  0:01:09s\n",
      "epoch 41 | loss: 0.4041  | val_0_auc: 0.87015 |  0:01:11s\n",
      "epoch 42 | loss: 0.39349 | val_0_auc: 0.88569 |  0:01:13s\n",
      "epoch 43 | loss: 0.41653 | val_0_auc: 0.88627 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.90312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72797 | val_0_auc: 0.73174 |  0:00:01s\n",
      "epoch 1  | loss: 0.5798  | val_0_auc: 0.83065 |  0:00:03s\n",
      "epoch 2  | loss: 0.52953 | val_0_auc: 0.77037 |  0:00:05s\n",
      "epoch 3  | loss: 0.4759  | val_0_auc: 0.82861 |  0:00:07s\n",
      "epoch 4  | loss: 0.42452 | val_0_auc: 0.78649 |  0:00:09s\n",
      "epoch 5  | loss: 0.45418 | val_0_auc: 0.8045  |  0:00:10s\n",
      "epoch 6  | loss: 0.42005 | val_0_auc: 0.81554 |  0:00:12s\n",
      "epoch 7  | loss: 0.43891 | val_0_auc: 0.83994 |  0:00:14s\n",
      "epoch 8  | loss: 0.41713 | val_0_auc: 0.83638 |  0:00:16s\n",
      "epoch 9  | loss: 0.41834 | val_0_auc: 0.79405 |  0:00:18s\n",
      "epoch 10 | loss: 0.42891 | val_0_auc: 0.80654 |  0:00:19s\n",
      "epoch 11 | loss: 0.41578 | val_0_auc: 0.83675 |  0:00:21s\n",
      "epoch 12 | loss: 0.41356 | val_0_auc: 0.82948 |  0:00:23s\n",
      "epoch 13 | loss: 0.41278 | val_0_auc: 0.85868 |  0:00:25s\n",
      "epoch 14 | loss: 0.38197 | val_0_auc: 0.84256 |  0:00:27s\n",
      "epoch 15 | loss: 0.41323 | val_0_auc: 0.8321  |  0:00:29s\n",
      "epoch 16 | loss: 0.40919 | val_0_auc: 0.83391 |  0:00:30s\n",
      "epoch 17 | loss: 0.41642 | val_0_auc: 0.82571 |  0:00:32s\n",
      "epoch 18 | loss: 0.43511 | val_0_auc: 0.78991 |  0:00:34s\n",
      "epoch 19 | loss: 0.42345 | val_0_auc: 0.82186 |  0:00:35s\n",
      "epoch 20 | loss: 0.40665 | val_0_auc: 0.86224 |  0:00:37s\n",
      "epoch 21 | loss: 0.39583 | val_0_auc: 0.86688 |  0:00:39s\n",
      "epoch 22 | loss: 0.39103 | val_0_auc: 0.85519 |  0:00:40s\n",
      "epoch 23 | loss: 0.37601 | val_0_auc: 0.86376 |  0:00:42s\n",
      "epoch 24 | loss: 0.39606 | val_0_auc: 0.85563 |  0:00:44s\n",
      "epoch 25 | loss: 0.39706 | val_0_auc: 0.85723 |  0:00:45s\n",
      "epoch 26 | loss: 0.37452 | val_0_auc: 0.85984 |  0:00:47s\n",
      "epoch 27 | loss: 0.38126 | val_0_auc: 0.84691 |  0:00:49s\n",
      "epoch 28 | loss: 0.40012 | val_0_auc: 0.83065 |  0:00:50s\n",
      "epoch 29 | loss: 0.41219 | val_0_auc: 0.8366  |  0:00:52s\n",
      "epoch 30 | loss: 0.42372 | val_0_auc: 0.84328 |  0:00:54s\n",
      "epoch 31 | loss: 0.4085  | val_0_auc: 0.84749 |  0:00:55s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.86688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72904 | val_0_auc: 0.71561 |  0:00:01s\n",
      "epoch 1  | loss: 0.55036 | val_0_auc: 0.79274 |  0:00:03s\n",
      "epoch 2  | loss: 0.49735 | val_0_auc: 0.7467  |  0:00:05s\n",
      "epoch 3  | loss: 0.46207 | val_0_auc: 0.77887 |  0:00:07s\n",
      "epoch 4  | loss: 0.4642  | val_0_auc: 0.83079 |  0:00:08s\n",
      "epoch 5  | loss: 0.39555 | val_0_auc: 0.84779 |  0:00:10s\n",
      "epoch 6  | loss: 0.41855 | val_0_auc: 0.80625 |  0:00:12s\n",
      "epoch 7  | loss: 0.48326 | val_0_auc: 0.79259 |  0:00:13s\n",
      "epoch 8  | loss: 0.43057 | val_0_auc: 0.81438 |  0:00:15s\n",
      "epoch 9  | loss: 0.37585 | val_0_auc: 0.80015 |  0:00:17s\n",
      "epoch 10 | loss: 0.45111 | val_0_auc: 0.83341 |  0:00:19s\n",
      "epoch 11 | loss: 0.42859 | val_0_auc: 0.82179 |  0:00:21s\n",
      "epoch 12 | loss: 0.40103 | val_0_auc: 0.82353 |  0:00:22s\n",
      "epoch 13 | loss: 0.41889 | val_0_auc: 0.83297 |  0:00:24s\n",
      "epoch 14 | loss: 0.41606 | val_0_auc: 0.82397 |  0:00:26s\n",
      "epoch 15 | loss: 0.41906 | val_0_auc: 0.84779 |  0:00:28s\n",
      "epoch 16 | loss: 0.39389 | val_0_auc: 0.85788 |  0:00:30s\n",
      "epoch 17 | loss: 0.39768 | val_0_auc: 0.84285 |  0:00:32s\n",
      "epoch 18 | loss: 0.41527 | val_0_auc: 0.85824 |  0:00:33s\n",
      "epoch 19 | loss: 0.39404 | val_0_auc: 0.85374 |  0:00:35s\n",
      "epoch 20 | loss: 0.38061 | val_0_auc: 0.84415 |  0:00:37s\n",
      "epoch 21 | loss: 0.38876 | val_0_auc: 0.86623 |  0:00:39s\n",
      "epoch 22 | loss: 0.39663 | val_0_auc: 0.86478 |  0:00:41s\n",
      "epoch 23 | loss: 0.38173 | val_0_auc: 0.8549  |  0:00:43s\n",
      "epoch 24 | loss: 0.37798 | val_0_auc: 0.85258 |  0:00:44s\n",
      "epoch 25 | loss: 0.40962 | val_0_auc: 0.87277 |  0:00:46s\n",
      "epoch 26 | loss: 0.38316 | val_0_auc: 0.87335 |  0:00:48s\n",
      "epoch 27 | loss: 0.36982 | val_0_auc: 0.86957 |  0:00:50s\n",
      "epoch 28 | loss: 0.37952 | val_0_auc: 0.88468 |  0:00:52s\n",
      "epoch 29 | loss: 0.37921 | val_0_auc: 0.87044 |  0:00:53s\n",
      "epoch 30 | loss: 0.38673 | val_0_auc: 0.87349 |  0:00:55s\n",
      "epoch 31 | loss: 0.3802  | val_0_auc: 0.87364 |  0:00:57s\n",
      "epoch 32 | loss: 0.37507 | val_0_auc: 0.8809  |  0:00:58s\n",
      "epoch 33 | loss: 0.36723 | val_0_auc: 0.87633 |  0:01:00s\n",
      "epoch 34 | loss: 0.37125 | val_0_auc: 0.87451 |  0:01:01s\n",
      "epoch 35 | loss: 0.3904  | val_0_auc: 0.87901 |  0:01:03s\n",
      "epoch 36 | loss: 0.38067 | val_0_auc: 0.8833  |  0:01:05s\n",
      "epoch 37 | loss: 0.39431 | val_0_auc: 0.88199 |  0:01:06s\n",
      "epoch 38 | loss: 0.3809  | val_0_auc: 0.88867 |  0:01:08s\n",
      "epoch 39 | loss: 0.37514 | val_0_auc: 0.88315 |  0:01:09s\n",
      "epoch 40 | loss: 0.3697  | val_0_auc: 0.88431 |  0:01:11s\n",
      "epoch 41 | loss: 0.37919 | val_0_auc: 0.88577 |  0:01:13s\n",
      "epoch 42 | loss: 0.37676 | val_0_auc: 0.88402 |  0:01:14s\n",
      "epoch 43 | loss: 0.39154 | val_0_auc: 0.88366 |  0:01:16s\n",
      "epoch 44 | loss: 0.39212 | val_0_auc: 0.8801  |  0:01:18s\n",
      "epoch 45 | loss: 0.37965 | val_0_auc: 0.88627 |  0:01:19s\n",
      "epoch 46 | loss: 0.36385 | val_0_auc: 0.88439 |  0:01:21s\n",
      "epoch 47 | loss: 0.37199 | val_0_auc: 0.88845 |  0:01:23s\n",
      "epoch 48 | loss: 0.37862 | val_0_auc: 0.89484 |  0:01:24s\n",
      "epoch 49 | loss: 0.39456 | val_0_auc: 0.88097 |  0:01:26s\n",
      "epoch 50 | loss: 0.35829 | val_0_auc: 0.887   |  0:01:28s\n",
      "epoch 51 | loss: 0.37013 | val_0_auc: 0.88954 |  0:01:30s\n",
      "epoch 52 | loss: 0.37129 | val_0_auc: 0.88853 |  0:01:32s\n",
      "epoch 53 | loss: 0.36458 | val_0_auc: 0.90428 |  0:01:34s\n",
      "epoch 54 | loss: 0.36875 | val_0_auc: 0.89659 |  0:01:35s\n",
      "epoch 55 | loss: 0.38747 | val_0_auc: 0.89448 |  0:01:37s\n",
      "epoch 56 | loss: 0.37737 | val_0_auc: 0.89216 |  0:01:39s\n",
      "epoch 57 | loss: 0.36228 | val_0_auc: 0.9016  |  0:01:40s\n",
      "epoch 58 | loss: 0.36381 | val_0_auc: 0.89898 |  0:01:42s\n",
      "epoch 59 | loss: 0.37326 | val_0_auc: 0.88664 |  0:01:44s\n",
      "epoch 60 | loss: 0.38789 | val_0_auc: 0.88707 |  0:01:45s\n",
      "epoch 61 | loss: 0.36483 | val_0_auc: 0.89143 |  0:01:47s\n",
      "epoch 62 | loss: 0.35071 | val_0_auc: 0.8886  |  0:01:49s\n",
      "epoch 63 | loss: 0.36845 | val_0_auc: 0.89833 |  0:01:51s\n",
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 53 and best_val_0_auc = 0.90428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.87287 | val_0_auc: 0.26739 |  0:00:01s\n",
      "epoch 1  | loss: 0.60941 | val_0_auc: 0.80015 |  0:00:03s\n",
      "epoch 2  | loss: 0.63326 | val_0_auc: 0.79477 |  0:00:05s\n",
      "epoch 3  | loss: 0.49622 | val_0_auc: 0.80654 |  0:00:06s\n",
      "epoch 4  | loss: 0.47299 | val_0_auc: 0.80428 |  0:00:08s\n",
      "epoch 5  | loss: 0.42054 | val_0_auc: 0.79005 |  0:00:10s\n",
      "epoch 6  | loss: 0.44061 | val_0_auc: 0.72927 |  0:00:12s\n",
      "epoch 7  | loss: 0.44169 | val_0_auc: 0.77763 |  0:00:13s\n",
      "epoch 8  | loss: 0.42503 | val_0_auc: 0.81307 |  0:00:15s\n",
      "epoch 9  | loss: 0.38718 | val_0_auc: 0.81728 |  0:00:17s\n",
      "epoch 10 | loss: 0.4289  | val_0_auc: 0.80494 |  0:00:18s\n",
      "epoch 11 | loss: 0.40486 | val_0_auc: 0.78286 |  0:00:20s\n",
      "epoch 12 | loss: 0.42015 | val_0_auc: 0.80058 |  0:00:22s\n",
      "epoch 13 | loss: 0.42623 | val_0_auc: 0.8199  |  0:00:23s\n",
      "epoch 14 | loss: 0.43695 | val_0_auc: 0.82745 |  0:00:25s\n",
      "epoch 15 | loss: 0.42092 | val_0_auc: 0.85868 |  0:00:27s\n",
      "epoch 16 | loss: 0.43814 | val_0_auc: 0.88598 |  0:00:29s\n",
      "epoch 17 | loss: 0.42744 | val_0_auc: 0.87509 |  0:00:30s\n",
      "epoch 18 | loss: 0.41918 | val_0_auc: 0.81917 |  0:00:32s\n",
      "epoch 19 | loss: 0.40906 | val_0_auc: 0.80436 |  0:00:34s\n",
      "epoch 20 | loss: 0.40979 | val_0_auc: 0.85243 |  0:00:35s\n",
      "epoch 21 | loss: 0.39894 | val_0_auc: 0.87727 |  0:00:37s\n",
      "epoch 22 | loss: 0.40719 | val_0_auc: 0.87727 |  0:00:39s\n",
      "epoch 23 | loss: 0.39935 | val_0_auc: 0.87887 |  0:00:40s\n",
      "epoch 24 | loss: 0.41756 | val_0_auc: 0.88395 |  0:00:42s\n",
      "epoch 25 | loss: 0.40799 | val_0_auc: 0.86797 |  0:00:44s\n",
      "epoch 26 | loss: 0.43598 | val_0_auc: 0.87001 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.88598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.52781 | val_0_auc: 0.82905 |  0:00:00s\n",
      "epoch 1  | loss: 0.42293 | val_0_auc: 0.83834 |  0:00:01s\n",
      "epoch 2  | loss: 0.41104 | val_0_auc: 0.77001 |  0:00:02s\n",
      "epoch 3  | loss: 0.37783 | val_0_auc: 0.79434 |  0:00:03s\n",
      "epoch 4  | loss: 0.40528 | val_0_auc: 0.80755 |  0:00:04s\n",
      "epoch 5  | loss: 0.39497 | val_0_auc: 0.8281  |  0:00:05s\n",
      "epoch 6  | loss: 0.39548 | val_0_auc: 0.8459  |  0:00:05s\n",
      "epoch 7  | loss: 0.37291 | val_0_auc: 0.84575 |  0:00:06s\n",
      "epoch 8  | loss: 0.37477 | val_0_auc: 0.82534 |  0:00:07s\n",
      "epoch 9  | loss: 0.38026 | val_0_auc: 0.84336 |  0:00:08s\n",
      "epoch 10 | loss: 0.39077 | val_0_auc: 0.85127 |  0:00:09s\n",
      "epoch 11 | loss: 0.36676 | val_0_auc: 0.84009 |  0:00:10s\n",
      "epoch 12 | loss: 0.38043 | val_0_auc: 0.82672 |  0:00:10s\n",
      "epoch 13 | loss: 0.39209 | val_0_auc: 0.83036 |  0:00:11s\n",
      "epoch 14 | loss: 0.38406 | val_0_auc: 0.82382 |  0:00:12s\n",
      "epoch 15 | loss: 0.37941 | val_0_auc: 0.85243 |  0:00:13s\n",
      "epoch 16 | loss: 0.36166 | val_0_auc: 0.85497 |  0:00:14s\n",
      "epoch 17 | loss: 0.3646  | val_0_auc: 0.85439 |  0:00:15s\n",
      "epoch 18 | loss: 0.36626 | val_0_auc: 0.86209 |  0:00:16s\n",
      "epoch 19 | loss: 0.35821 | val_0_auc: 0.86311 |  0:00:17s\n",
      "epoch 20 | loss: 0.39089 | val_0_auc: 0.84016 |  0:00:18s\n",
      "epoch 21 | loss: 0.37423 | val_0_auc: 0.83725 |  0:00:18s\n",
      "epoch 22 | loss: 0.37373 | val_0_auc: 0.83326 |  0:00:19s\n",
      "epoch 23 | loss: 0.35436 | val_0_auc: 0.85897 |  0:00:20s\n",
      "epoch 24 | loss: 0.34861 | val_0_auc: 0.88649 |  0:00:21s\n",
      "epoch 25 | loss: 0.36433 | val_0_auc: 0.88598 |  0:00:22s\n",
      "epoch 26 | loss: 0.35267 | val_0_auc: 0.88177 |  0:00:23s\n",
      "epoch 27 | loss: 0.37882 | val_0_auc: 0.8854  |  0:00:24s\n",
      "epoch 28 | loss: 0.36542 | val_0_auc: 0.89521 |  0:00:25s\n",
      "epoch 29 | loss: 0.37351 | val_0_auc: 0.88076 |  0:00:26s\n",
      "epoch 30 | loss: 0.35371 | val_0_auc: 0.87698 |  0:00:27s\n",
      "epoch 31 | loss: 0.3628  | val_0_auc: 0.88366 |  0:00:28s\n",
      "epoch 32 | loss: 0.35508 | val_0_auc: 0.88468 |  0:00:29s\n",
      "epoch 33 | loss: 0.39684 | val_0_auc: 0.87495 |  0:00:30s\n",
      "epoch 34 | loss: 0.37478 | val_0_auc: 0.88293 |  0:00:30s\n",
      "epoch 35 | loss: 0.35839 | val_0_auc: 0.88569 |  0:00:31s\n",
      "epoch 36 | loss: 0.36343 | val_0_auc: 0.89027 |  0:00:32s\n",
      "epoch 37 | loss: 0.37077 | val_0_auc: 0.88279 |  0:00:33s\n",
      "epoch 38 | loss: 0.36062 | val_0_auc: 0.87683 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.89521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56005 | val_0_auc: 0.78613 |  0:00:00s\n",
      "epoch 1  | loss: 0.46099 | val_0_auc: 0.83195 |  0:00:01s\n",
      "epoch 2  | loss: 0.40001 | val_0_auc: 0.80712 |  0:00:02s\n",
      "epoch 3  | loss: 0.42619 | val_0_auc: 0.81888 |  0:00:03s\n",
      "epoch 4  | loss: 0.41494 | val_0_auc: 0.7968  |  0:00:04s\n",
      "epoch 5  | loss: 0.38302 | val_0_auc: 0.71024 |  0:00:05s\n",
      "epoch 6  | loss: 0.41439 | val_0_auc: 0.79375 |  0:00:06s\n",
      "epoch 7  | loss: 0.38819 | val_0_auc: 0.85824 |  0:00:07s\n",
      "epoch 8  | loss: 0.39307 | val_0_auc: 0.86725 |  0:00:08s\n",
      "epoch 9  | loss: 0.41351 | val_0_auc: 0.86652 |  0:00:09s\n",
      "epoch 10 | loss: 0.42863 | val_0_auc: 0.85788 |  0:00:10s\n",
      "epoch 11 | loss: 0.39119 | val_0_auc: 0.86231 |  0:00:11s\n",
      "epoch 12 | loss: 0.40139 | val_0_auc: 0.86892 |  0:00:12s\n",
      "epoch 13 | loss: 0.41979 | val_0_auc: 0.88381 |  0:00:12s\n",
      "epoch 14 | loss: 0.38447 | val_0_auc: 0.8642  |  0:00:13s\n",
      "epoch 15 | loss: 0.41194 | val_0_auc: 0.85432 |  0:00:14s\n",
      "epoch 16 | loss: 0.37906 | val_0_auc: 0.87538 |  0:00:15s\n",
      "epoch 17 | loss: 0.38753 | val_0_auc: 0.87785 |  0:00:16s\n",
      "epoch 18 | loss: 0.38413 | val_0_auc: 0.88337 |  0:00:17s\n",
      "epoch 19 | loss: 0.38274 | val_0_auc: 0.86826 |  0:00:18s\n",
      "epoch 20 | loss: 0.411   | val_0_auc: 0.88322 |  0:00:19s\n",
      "epoch 21 | loss: 0.39    | val_0_auc: 0.86899 |  0:00:20s\n",
      "epoch 22 | loss: 0.38223 | val_0_auc: 0.86986 |  0:00:21s\n",
      "epoch 23 | loss: 0.33989 | val_0_auc: 0.88235 |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.51205 | val_0_auc: 0.81547 |  0:00:00s\n",
      "epoch 1  | loss: 0.44679 | val_0_auc: 0.8366  |  0:00:01s\n",
      "epoch 2  | loss: 0.41285 | val_0_auc: 0.76187 |  0:00:02s\n",
      "epoch 3  | loss: 0.41657 | val_0_auc: 0.82847 |  0:00:03s\n",
      "epoch 4  | loss: 0.40698 | val_0_auc: 0.82977 |  0:00:04s\n",
      "epoch 5  | loss: 0.42064 | val_0_auc: 0.82222 |  0:00:05s\n",
      "epoch 6  | loss: 0.42661 | val_0_auc: 0.80465 |  0:00:06s\n",
      "epoch 7  | loss: 0.41161 | val_0_auc: 0.81307 |  0:00:07s\n",
      "epoch 8  | loss: 0.4002  | val_0_auc: 0.85577 |  0:00:08s\n",
      "epoch 9  | loss: 0.40087 | val_0_auc: 0.86333 |  0:00:09s\n",
      "epoch 10 | loss: 0.41614 | val_0_auc: 0.85585 |  0:00:10s\n",
      "epoch 11 | loss: 0.39649 | val_0_auc: 0.86906 |  0:00:11s\n",
      "epoch 12 | loss: 0.39623 | val_0_auc: 0.87037 |  0:00:12s\n",
      "epoch 13 | loss: 0.41041 | val_0_auc: 0.87378 |  0:00:13s\n",
      "epoch 14 | loss: 0.37078 | val_0_auc: 0.87879 |  0:00:13s\n",
      "epoch 15 | loss: 0.42068 | val_0_auc: 0.87879 |  0:00:14s\n",
      "epoch 16 | loss: 0.37113 | val_0_auc: 0.8748  |  0:00:15s\n",
      "epoch 17 | loss: 0.39049 | val_0_auc: 0.87734 |  0:00:17s\n",
      "epoch 18 | loss: 0.36755 | val_0_auc: 0.89107 |  0:00:18s\n",
      "epoch 19 | loss: 0.40474 | val_0_auc: 0.87858 |  0:00:19s\n",
      "epoch 20 | loss: 0.40051 | val_0_auc: 0.88671 |  0:00:20s\n",
      "epoch 21 | loss: 0.38335 | val_0_auc: 0.88264 |  0:00:21s\n",
      "epoch 22 | loss: 0.38862 | val_0_auc: 0.88569 |  0:00:22s\n",
      "epoch 23 | loss: 0.36249 | val_0_auc: 0.88613 |  0:00:23s\n",
      "epoch 24 | loss: 0.38331 | val_0_auc: 0.88177 |  0:00:24s\n",
      "epoch 25 | loss: 0.37481 | val_0_auc: 0.89237 |  0:00:25s\n",
      "epoch 26 | loss: 0.37295 | val_0_auc: 0.87756 |  0:00:26s\n",
      "epoch 27 | loss: 0.35965 | val_0_auc: 0.88192 |  0:00:27s\n",
      "epoch 28 | loss: 0.39543 | val_0_auc: 0.88177 |  0:00:28s\n",
      "epoch 29 | loss: 0.38384 | val_0_auc: 0.88366 |  0:00:29s\n",
      "epoch 30 | loss: 0.37208 | val_0_auc: 0.8947  |  0:00:30s\n",
      "epoch 31 | loss: 0.39144 | val_0_auc: 0.88163 |  0:00:31s\n",
      "epoch 32 | loss: 0.3795  | val_0_auc: 0.85955 |  0:00:32s\n",
      "epoch 33 | loss: 0.38106 | val_0_auc: 0.86449 |  0:00:33s\n",
      "epoch 34 | loss: 0.39371 | val_0_auc: 0.88439 |  0:00:34s\n",
      "epoch 35 | loss: 0.39181 | val_0_auc: 0.88787 |  0:00:35s\n",
      "epoch 36 | loss: 0.38864 | val_0_auc: 0.86754 |  0:00:35s\n",
      "epoch 37 | loss: 0.38227 | val_0_auc: 0.89383 |  0:00:36s\n",
      "epoch 38 | loss: 0.38625 | val_0_auc: 0.88947 |  0:00:37s\n",
      "epoch 39 | loss: 0.36665 | val_0_auc: 0.87814 |  0:00:38s\n",
      "epoch 40 | loss: 0.3792  | val_0_auc: 0.87829 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57119 | val_0_auc: 0.68097 |  0:00:00s\n",
      "epoch 1  | loss: 0.47251 | val_0_auc: 0.83486 |  0:00:01s\n",
      "epoch 2  | loss: 0.40293 | val_0_auc: 0.81242 |  0:00:02s\n",
      "epoch 3  | loss: 0.41866 | val_0_auc: 0.80058 |  0:00:03s\n",
      "epoch 4  | loss: 0.4552  | val_0_auc: 0.81641 |  0:00:04s\n",
      "epoch 5  | loss: 0.40334 | val_0_auc: 0.82048 |  0:00:05s\n",
      "epoch 6  | loss: 0.40256 | val_0_auc: 0.84648 |  0:00:05s\n",
      "epoch 7  | loss: 0.4188  | val_0_auc: 0.84909 |  0:00:06s\n",
      "epoch 8  | loss: 0.39542 | val_0_auc: 0.84103 |  0:00:07s\n",
      "epoch 9  | loss: 0.39213 | val_0_auc: 0.84379 |  0:00:08s\n",
      "epoch 10 | loss: 0.39444 | val_0_auc: 0.86006 |  0:00:09s\n",
      "epoch 11 | loss: 0.39835 | val_0_auc: 0.86863 |  0:00:10s\n",
      "epoch 12 | loss: 0.40132 | val_0_auc: 0.86979 |  0:00:11s\n",
      "epoch 13 | loss: 0.42095 | val_0_auc: 0.84154 |  0:00:11s\n",
      "epoch 14 | loss: 0.37755 | val_0_auc: 0.84866 |  0:00:12s\n",
      "epoch 15 | loss: 0.43069 | val_0_auc: 0.86449 |  0:00:13s\n",
      "epoch 16 | loss: 0.34999 | val_0_auc: 0.86797 |  0:00:14s\n",
      "epoch 17 | loss: 0.41991 | val_0_auc: 0.87495 |  0:00:15s\n",
      "epoch 18 | loss: 0.3944  | val_0_auc: 0.85955 |  0:00:16s\n",
      "epoch 19 | loss: 0.40194 | val_0_auc: 0.82752 |  0:00:16s\n",
      "epoch 20 | loss: 0.40958 | val_0_auc: 0.84749 |  0:00:17s\n",
      "epoch 21 | loss: 0.38689 | val_0_auc: 0.86797 |  0:00:18s\n",
      "epoch 22 | loss: 0.37153 | val_0_auc: 0.87248 |  0:00:19s\n",
      "epoch 23 | loss: 0.35483 | val_0_auc: 0.8764  |  0:00:20s\n",
      "epoch 24 | loss: 0.38828 | val_0_auc: 0.8947  |  0:00:21s\n",
      "epoch 25 | loss: 0.3773  | val_0_auc: 0.88206 |  0:00:22s\n",
      "epoch 26 | loss: 0.35969 | val_0_auc: 0.88061 |  0:00:23s\n",
      "epoch 27 | loss: 0.35638 | val_0_auc: 0.87139 |  0:00:23s\n",
      "epoch 28 | loss: 0.36843 | val_0_auc: 0.89194 |  0:00:24s\n",
      "epoch 29 | loss: 0.37782 | val_0_auc: 0.89753 |  0:00:25s\n",
      "epoch 30 | loss: 0.37538 | val_0_auc: 0.89114 |  0:00:26s\n",
      "epoch 31 | loss: 0.3749  | val_0_auc: 0.89274 |  0:00:27s\n",
      "epoch 32 | loss: 0.37685 | val_0_auc: 0.89695 |  0:00:27s\n",
      "epoch 33 | loss: 0.36992 | val_0_auc: 0.88584 |  0:00:28s\n",
      "epoch 34 | loss: 0.38971 | val_0_auc: 0.89724 |  0:00:29s\n",
      "epoch 35 | loss: 0.39378 | val_0_auc: 0.90516 |  0:00:30s\n",
      "epoch 36 | loss: 0.40557 | val_0_auc: 0.90153 |  0:00:31s\n",
      "epoch 37 | loss: 0.38373 | val_0_auc: 0.89463 |  0:00:32s\n",
      "epoch 38 | loss: 0.3781  | val_0_auc: 0.89637 |  0:00:32s\n",
      "epoch 39 | loss: 0.37886 | val_0_auc: 0.89194 |  0:00:33s\n",
      "epoch 40 | loss: 0.38008 | val_0_auc: 0.89528 |  0:00:34s\n",
      "epoch 41 | loss: 0.3635  | val_0_auc: 0.90261 |  0:00:35s\n",
      "epoch 42 | loss: 0.35249 | val_0_auc: 0.89332 |  0:00:36s\n",
      "epoch 43 | loss: 0.35578 | val_0_auc: 0.89303 |  0:00:37s\n",
      "epoch 44 | loss: 0.3663  | val_0_auc: 0.87836 |  0:00:38s\n",
      "epoch 45 | loss: 0.36424 | val_0_auc: 0.89426 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.90516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55916 | val_0_auc: 0.86739 |  0:00:00s\n",
      "epoch 1  | loss: 0.47136 | val_0_auc: 0.83515 |  0:00:01s\n",
      "epoch 2  | loss: 0.44897 | val_0_auc: 0.8467  |  0:00:02s\n",
      "epoch 3  | loss: 0.41996 | val_0_auc: 0.86776 |  0:00:03s\n",
      "epoch 4  | loss: 0.44591 | val_0_auc: 0.83878 |  0:00:04s\n",
      "epoch 5  | loss: 0.43959 | val_0_auc: 0.81322 |  0:00:05s\n",
      "epoch 6  | loss: 0.44312 | val_0_auc: 0.8093  |  0:00:06s\n",
      "epoch 7  | loss: 0.42421 | val_0_auc: 0.83486 |  0:00:07s\n",
      "epoch 8  | loss: 0.45183 | val_0_auc: 0.81402 |  0:00:08s\n",
      "epoch 9  | loss: 0.40564 | val_0_auc: 0.86594 |  0:00:09s\n",
      "epoch 10 | loss: 0.42156 | val_0_auc: 0.87001 |  0:00:10s\n",
      "epoch 11 | loss: 0.40165 | val_0_auc: 0.8886  |  0:00:11s\n",
      "epoch 12 | loss: 0.40363 | val_0_auc: 0.87734 |  0:00:12s\n",
      "epoch 13 | loss: 0.39554 | val_0_auc: 0.8902  |  0:00:13s\n",
      "epoch 14 | loss: 0.41744 | val_0_auc: 0.88134 |  0:00:13s\n",
      "epoch 15 | loss: 0.43133 | val_0_auc: 0.87415 |  0:00:14s\n",
      "epoch 16 | loss: 0.42025 | val_0_auc: 0.88947 |  0:00:15s\n",
      "epoch 17 | loss: 0.40181 | val_0_auc: 0.87415 |  0:00:16s\n",
      "epoch 18 | loss: 0.39895 | val_0_auc: 0.89063 |  0:00:17s\n",
      "epoch 19 | loss: 0.42428 | val_0_auc: 0.89179 |  0:00:18s\n",
      "epoch 20 | loss: 0.40098 | val_0_auc: 0.89906 |  0:00:19s\n",
      "epoch 21 | loss: 0.41511 | val_0_auc: 0.88235 |  0:00:20s\n",
      "epoch 22 | loss: 0.40857 | val_0_auc: 0.88301 |  0:00:21s\n",
      "epoch 23 | loss: 0.41773 | val_0_auc: 0.87698 |  0:00:22s\n",
      "epoch 24 | loss: 0.40021 | val_0_auc: 0.88548 |  0:00:23s\n",
      "epoch 25 | loss: 0.41564 | val_0_auc: 0.88046 |  0:00:24s\n",
      "epoch 26 | loss: 0.42049 | val_0_auc: 0.86412 |  0:00:25s\n",
      "epoch 27 | loss: 0.4025  | val_0_auc: 0.89259 |  0:00:26s\n",
      "epoch 28 | loss: 0.39541 | val_0_auc: 0.8862  |  0:00:26s\n",
      "epoch 29 | loss: 0.3976  | val_0_auc: 0.89005 |  0:00:27s\n",
      "epoch 30 | loss: 0.41175 | val_0_auc: 0.88511 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.89906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59834 | val_0_auc: 0.77792 |  0:00:00s\n",
      "epoch 1  | loss: 0.46206 | val_0_auc: 0.81772 |  0:00:01s\n",
      "epoch 2  | loss: 0.40687 | val_0_auc: 0.79513 |  0:00:02s\n",
      "epoch 3  | loss: 0.40921 | val_0_auc: 0.81111 |  0:00:03s\n",
      "epoch 4  | loss: 0.40942 | val_0_auc: 0.8321  |  0:00:03s\n",
      "epoch 5  | loss: 0.40474 | val_0_auc: 0.83958 |  0:00:04s\n",
      "epoch 6  | loss: 0.40267 | val_0_auc: 0.85127 |  0:00:05s\n",
      "epoch 7  | loss: 0.39799 | val_0_auc: 0.86463 |  0:00:05s\n",
      "epoch 8  | loss: 0.3793  | val_0_auc: 0.83471 |  0:00:06s\n",
      "epoch 9  | loss: 0.38275 | val_0_auc: 0.78054 |  0:00:07s\n",
      "epoch 10 | loss: 0.37701 | val_0_auc: 0.83805 |  0:00:08s\n",
      "epoch 11 | loss: 0.38955 | val_0_auc: 0.8358  |  0:00:08s\n",
      "epoch 12 | loss: 0.38185 | val_0_auc: 0.81097 |  0:00:09s\n",
      "epoch 13 | loss: 0.39418 | val_0_auc: 0.84009 |  0:00:10s\n",
      "epoch 14 | loss: 0.35883 | val_0_auc: 0.8398  |  0:00:11s\n",
      "epoch 15 | loss: 0.35098 | val_0_auc: 0.86754 |  0:00:11s\n",
      "epoch 16 | loss: 0.36454 | val_0_auc: 0.84604 |  0:00:12s\n",
      "epoch 17 | loss: 0.36673 | val_0_auc: 0.85766 |  0:00:13s\n",
      "epoch 18 | loss: 0.37998 | val_0_auc: 0.84328 |  0:00:14s\n",
      "epoch 19 | loss: 0.39253 | val_0_auc: 0.86035 |  0:00:14s\n",
      "epoch 20 | loss: 0.37978 | val_0_auc: 0.85236 |  0:00:15s\n",
      "epoch 21 | loss: 0.35963 | val_0_auc: 0.86688 |  0:00:16s\n",
      "epoch 22 | loss: 0.37531 | val_0_auc: 0.86362 |  0:00:17s\n",
      "epoch 23 | loss: 0.38073 | val_0_auc: 0.86725 |  0:00:18s\n",
      "epoch 24 | loss: 0.3712  | val_0_auc: 0.84241 |  0:00:18s\n",
      "epoch 25 | loss: 0.38641 | val_0_auc: 0.85664 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.86754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54778 | val_0_auc: 0.8183  |  0:00:00s\n",
      "epoch 1  | loss: 0.46452 | val_0_auc: 0.87625 |  0:00:01s\n",
      "epoch 2  | loss: 0.42014 | val_0_auc: 0.84125 |  0:00:02s\n",
      "epoch 3  | loss: 0.39737 | val_0_auc: 0.80908 |  0:00:03s\n",
      "epoch 4  | loss: 0.39471 | val_0_auc: 0.81685 |  0:00:04s\n",
      "epoch 5  | loss: 0.41832 | val_0_auc: 0.85338 |  0:00:04s\n",
      "epoch 6  | loss: 0.44397 | val_0_auc: 0.84982 |  0:00:05s\n",
      "epoch 7  | loss: 0.39663 | val_0_auc: 0.84488 |  0:00:06s\n",
      "epoch 8  | loss: 0.39183 | val_0_auc: 0.86129 |  0:00:07s\n",
      "epoch 9  | loss: 0.3923  | val_0_auc: 0.85882 |  0:00:08s\n",
      "epoch 10 | loss: 0.39846 | val_0_auc: 0.83617 |  0:00:08s\n",
      "epoch 11 | loss: 0.41447 | val_0_auc: 0.84713 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.87625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54522 | val_0_auc: 0.79506 |  0:00:00s\n",
      "epoch 1  | loss: 0.46049 | val_0_auc: 0.83718 |  0:00:01s\n",
      "epoch 2  | loss: 0.43588 | val_0_auc: 0.84938 |  0:00:02s\n",
      "epoch 3  | loss: 0.41084 | val_0_auc: 0.85868 |  0:00:03s\n",
      "epoch 4  | loss: 0.41651 | val_0_auc: 0.84299 |  0:00:03s\n",
      "epoch 5  | loss: 0.43026 | val_0_auc: 0.84677 |  0:00:04s\n",
      "epoch 6  | loss: 0.44513 | val_0_auc: 0.83893 |  0:00:05s\n",
      "epoch 7  | loss: 0.38352 | val_0_auc: 0.81583 |  0:00:06s\n",
      "epoch 8  | loss: 0.4004  | val_0_auc: 0.83021 |  0:00:07s\n",
      "epoch 9  | loss: 0.39589 | val_0_auc: 0.8366  |  0:00:07s\n",
      "epoch 10 | loss: 0.4095  | val_0_auc: 0.84263 |  0:00:08s\n",
      "epoch 11 | loss: 0.42582 | val_0_auc: 0.82847 |  0:00:09s\n",
      "epoch 12 | loss: 0.39862 | val_0_auc: 0.85113 |  0:00:10s\n",
      "epoch 13 | loss: 0.37941 | val_0_auc: 0.87407 |  0:00:11s\n",
      "epoch 14 | loss: 0.38591 | val_0_auc: 0.88475 |  0:00:11s\n",
      "epoch 15 | loss: 0.39877 | val_0_auc: 0.84357 |  0:00:12s\n",
      "epoch 16 | loss: 0.40203 | val_0_auc: 0.87988 |  0:00:13s\n",
      "epoch 17 | loss: 0.3933  | val_0_auc: 0.87386 |  0:00:14s\n",
      "epoch 18 | loss: 0.41054 | val_0_auc: 0.89717 |  0:00:15s\n",
      "epoch 19 | loss: 0.39266 | val_0_auc: 0.89281 |  0:00:15s\n",
      "epoch 20 | loss: 0.38228 | val_0_auc: 0.88126 |  0:00:16s\n",
      "epoch 21 | loss: 0.39082 | val_0_auc: 0.88243 |  0:00:17s\n",
      "epoch 22 | loss: 0.39021 | val_0_auc: 0.88112 |  0:00:18s\n",
      "epoch 23 | loss: 0.38377 | val_0_auc: 0.89898 |  0:00:18s\n",
      "epoch 24 | loss: 0.39491 | val_0_auc: 0.86863 |  0:00:19s\n",
      "epoch 25 | loss: 0.3836  | val_0_auc: 0.87277 |  0:00:20s\n",
      "epoch 26 | loss: 0.39661 | val_0_auc: 0.86035 |  0:00:21s\n",
      "epoch 27 | loss: 0.39272 | val_0_auc: 0.85802 |  0:00:22s\n",
      "epoch 28 | loss: 0.38283 | val_0_auc: 0.89158 |  0:00:22s\n",
      "epoch 29 | loss: 0.42077 | val_0_auc: 0.88373 |  0:00:23s\n",
      "epoch 30 | loss: 0.40209 | val_0_auc: 0.88184 |  0:00:24s\n",
      "epoch 31 | loss: 0.38716 | val_0_auc: 0.89622 |  0:00:25s\n",
      "epoch 32 | loss: 0.36774 | val_0_auc: 0.89695 |  0:00:25s\n",
      "epoch 33 | loss: 0.38442 | val_0_auc: 0.88482 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.89898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.50331 | val_0_auc: 0.73943 |  0:00:00s\n",
      "epoch 1  | loss: 0.47433 | val_0_auc: 0.77545 |  0:00:01s\n",
      "epoch 2  | loss: 0.39539 | val_0_auc: 0.77422 |  0:00:02s\n",
      "epoch 3  | loss: 0.40399 | val_0_auc: 0.80871 |  0:00:03s\n",
      "epoch 4  | loss: 0.39199 | val_0_auc: 0.85359 |  0:00:03s\n",
      "epoch 5  | loss: 0.39311 | val_0_auc: 0.85635 |  0:00:04s\n",
      "epoch 6  | loss: 0.40717 | val_0_auc: 0.87662 |  0:00:05s\n",
      "epoch 7  | loss: 0.37984 | val_0_auc: 0.85163 |  0:00:06s\n",
      "epoch 8  | loss: 0.38356 | val_0_auc: 0.87255 |  0:00:06s\n",
      "epoch 9  | loss: 0.39808 | val_0_auc: 0.85505 |  0:00:07s\n",
      "epoch 10 | loss: 0.37936 | val_0_auc: 0.8658  |  0:00:08s\n",
      "epoch 11 | loss: 0.39308 | val_0_auc: 0.86841 |  0:00:09s\n",
      "epoch 12 | loss: 0.38767 | val_0_auc: 0.87298 |  0:00:09s\n",
      "epoch 13 | loss: 0.35516 | val_0_auc: 0.85759 |  0:00:10s\n",
      "epoch 14 | loss: 0.38927 | val_0_auc: 0.84386 |  0:00:11s\n",
      "epoch 15 | loss: 0.38793 | val_0_auc: 0.80487 |  0:00:12s\n",
      "epoch 16 | loss: 0.36255 | val_0_auc: 0.86369 |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.87662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59916 | val_0_auc: 0.8154  |  0:00:00s\n",
      "epoch 1  | loss: 0.48036 | val_0_auc: 0.84401 |  0:00:01s\n",
      "epoch 2  | loss: 0.4551  | val_0_auc: 0.878   |  0:00:02s\n",
      "epoch 3  | loss: 0.44618 | val_0_auc: 0.84996 |  0:00:02s\n",
      "epoch 4  | loss: 0.42774 | val_0_auc: 0.85999 |  0:00:03s\n",
      "epoch 5  | loss: 0.44691 | val_0_auc: 0.80799 |  0:00:04s\n",
      "epoch 6  | loss: 0.42957 | val_0_auc: 0.82919 |  0:00:05s\n",
      "epoch 7  | loss: 0.41372 | val_0_auc: 0.83348 |  0:00:06s\n",
      "epoch 8  | loss: 0.42718 | val_0_auc: 0.82389 |  0:00:07s\n",
      "epoch 9  | loss: 0.41292 | val_0_auc: 0.81874 |  0:00:07s\n",
      "epoch 10 | loss: 0.42295 | val_0_auc: 0.83253 |  0:00:08s\n",
      "epoch 11 | loss: 0.40931 | val_0_auc: 0.82607 |  0:00:09s\n",
      "epoch 12 | loss: 0.40354 | val_0_auc: 0.86652 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70026 | val_0_auc: 0.83471 |  0:00:01s\n",
      "epoch 1  | loss: 0.54526 | val_0_auc: 0.73566 |  0:00:02s\n",
      "epoch 2  | loss: 0.43936 | val_0_auc: 0.80581 |  0:00:03s\n",
      "epoch 3  | loss: 0.44157 | val_0_auc: 0.83072 |  0:00:05s\n",
      "epoch 4  | loss: 0.4373  | val_0_auc: 0.83057 |  0:00:06s\n",
      "epoch 5  | loss: 0.42328 | val_0_auc: 0.7955  |  0:00:07s\n",
      "epoch 6  | loss: 0.42838 | val_0_auc: 0.76761 |  0:00:08s\n",
      "epoch 7  | loss: 0.44044 | val_0_auc: 0.83428 |  0:00:09s\n",
      "epoch 8  | loss: 0.40924 | val_0_auc: 0.85548 |  0:00:11s\n",
      "epoch 9  | loss: 0.40427 | val_0_auc: 0.83849 |  0:00:12s\n",
      "epoch 10 | loss: 0.39998 | val_0_auc: 0.85323 |  0:00:13s\n",
      "epoch 11 | loss: 0.37684 | val_0_auc: 0.84096 |  0:00:14s\n",
      "epoch 12 | loss: 0.39101 | val_0_auc: 0.85846 |  0:00:15s\n",
      "epoch 13 | loss: 0.38627 | val_0_auc: 0.87778 |  0:00:17s\n",
      "epoch 14 | loss: 0.3857  | val_0_auc: 0.86855 |  0:00:18s\n",
      "epoch 15 | loss: 0.41163 | val_0_auc: 0.86609 |  0:00:19s\n",
      "epoch 16 | loss: 0.38004 | val_0_auc: 0.86892 |  0:00:20s\n",
      "epoch 17 | loss: 0.36552 | val_0_auc: 0.87422 |  0:00:22s\n",
      "epoch 18 | loss: 0.39092 | val_0_auc: 0.83428 |  0:00:23s\n",
      "epoch 19 | loss: 0.38115 | val_0_auc: 0.85316 |  0:00:24s\n",
      "epoch 20 | loss: 0.35578 | val_0_auc: 0.87291 |  0:00:25s\n",
      "epoch 21 | loss: 0.37422 | val_0_auc: 0.86725 |  0:00:26s\n",
      "epoch 22 | loss: 0.36889 | val_0_auc: 0.87756 |  0:00:28s\n",
      "epoch 23 | loss: 0.36395 | val_0_auc: 0.87073 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.87778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.72153 | val_0_auc: 0.38664 |  0:00:01s\n",
      "epoch 1  | loss: 0.60284 | val_0_auc: 0.78351 |  0:00:02s\n",
      "epoch 2  | loss: 0.46422 | val_0_auc: 0.71387 |  0:00:03s\n",
      "epoch 3  | loss: 0.4253  | val_0_auc: 0.79884 |  0:00:04s\n",
      "epoch 4  | loss: 0.38196 | val_0_auc: 0.84386 |  0:00:06s\n",
      "epoch 5  | loss: 0.41862 | val_0_auc: 0.8411  |  0:00:07s\n",
      "epoch 6  | loss: 0.43216 | val_0_auc: 0.8366  |  0:00:08s\n",
      "epoch 7  | loss: 0.44044 | val_0_auc: 0.85432 |  0:00:09s\n",
      "epoch 8  | loss: 0.40682 | val_0_auc: 0.86158 |  0:00:11s\n",
      "epoch 9  | loss: 0.40194 | val_0_auc: 0.83922 |  0:00:12s\n",
      "epoch 10 | loss: 0.40363 | val_0_auc: 0.86006 |  0:00:13s\n",
      "epoch 11 | loss: 0.38422 | val_0_auc: 0.84597 |  0:00:14s\n",
      "epoch 12 | loss: 0.39092 | val_0_auc: 0.86325 |  0:00:15s\n",
      "epoch 13 | loss: 0.38488 | val_0_auc: 0.85258 |  0:00:17s\n",
      "epoch 14 | loss: 0.39904 | val_0_auc: 0.85664 |  0:00:18s\n",
      "epoch 15 | loss: 0.408   | val_0_auc: 0.8565  |  0:00:19s\n",
      "epoch 16 | loss: 0.39651 | val_0_auc: 0.85461 |  0:00:21s\n",
      "epoch 17 | loss: 0.36285 | val_0_auc: 0.84924 |  0:00:22s\n",
      "epoch 18 | loss: 0.41421 | val_0_auc: 0.85628 |  0:00:23s\n",
      "epoch 19 | loss: 0.38578 | val_0_auc: 0.8703  |  0:00:24s\n",
      "epoch 20 | loss: 0.38443 | val_0_auc: 0.85802 |  0:00:26s\n",
      "epoch 21 | loss: 0.38341 | val_0_auc: 0.85069 |  0:00:27s\n",
      "epoch 22 | loss: 0.38646 | val_0_auc: 0.86609 |  0:00:28s\n",
      "epoch 23 | loss: 0.37471 | val_0_auc: 0.87248 |  0:00:29s\n",
      "epoch 24 | loss: 0.39478 | val_0_auc: 0.87349 |  0:00:30s\n",
      "epoch 25 | loss: 0.3903  | val_0_auc: 0.81511 |  0:00:32s\n",
      "epoch 26 | loss: 0.41121 | val_0_auc: 0.88192 |  0:00:33s\n",
      "epoch 27 | loss: 0.40058 | val_0_auc: 0.87015 |  0:00:34s\n",
      "epoch 28 | loss: 0.39726 | val_0_auc: 0.85628 |  0:00:35s\n",
      "epoch 29 | loss: 0.41235 | val_0_auc: 0.88126 |  0:00:37s\n",
      "epoch 30 | loss: 0.41589 | val_0_auc: 0.87647 |  0:00:38s\n",
      "epoch 31 | loss: 0.40917 | val_0_auc: 0.86456 |  0:00:39s\n",
      "epoch 32 | loss: 0.38618 | val_0_auc: 0.86783 |  0:00:40s\n",
      "epoch 33 | loss: 0.36587 | val_0_auc: 0.84357 |  0:00:42s\n",
      "epoch 34 | loss: 0.39184 | val_0_auc: 0.87633 |  0:00:43s\n",
      "epoch 35 | loss: 0.38153 | val_0_auc: 0.87894 |  0:00:44s\n",
      "epoch 36 | loss: 0.39525 | val_0_auc: 0.86638 |  0:00:45s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.88192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76736 | val_0_auc: 0.6093  |  0:00:01s\n",
      "epoch 1  | loss: 0.5708  | val_0_auc: 0.74568 |  0:00:02s\n",
      "epoch 2  | loss: 0.53205 | val_0_auc: 0.7663  |  0:00:03s\n",
      "epoch 3  | loss: 0.44468 | val_0_auc: 0.67683 |  0:00:05s\n",
      "epoch 4  | loss: 0.42803 | val_0_auc: 0.75643 |  0:00:06s\n",
      "epoch 5  | loss: 0.44507 | val_0_auc: 0.76805 |  0:00:07s\n",
      "epoch 6  | loss: 0.4192  | val_0_auc: 0.82367 |  0:00:08s\n",
      "epoch 7  | loss: 0.40698 | val_0_auc: 0.82702 |  0:00:09s\n",
      "epoch 8  | loss: 0.39987 | val_0_auc: 0.82527 |  0:00:11s\n",
      "epoch 9  | loss: 0.40474 | val_0_auc: 0.79753 |  0:00:12s\n",
      "epoch 10 | loss: 0.44929 | val_0_auc: 0.81409 |  0:00:13s\n",
      "epoch 11 | loss: 0.38198 | val_0_auc: 0.83486 |  0:00:14s\n",
      "epoch 12 | loss: 0.4065  | val_0_auc: 0.81075 |  0:00:16s\n",
      "epoch 13 | loss: 0.41164 | val_0_auc: 0.82121 |  0:00:17s\n",
      "epoch 14 | loss: 0.44517 | val_0_auc: 0.81365 |  0:00:18s\n",
      "epoch 15 | loss: 0.39651 | val_0_auc: 0.8342  |  0:00:19s\n",
      "epoch 16 | loss: 0.41944 | val_0_auc: 0.86347 |  0:00:20s\n",
      "epoch 17 | loss: 0.38558 | val_0_auc: 0.87291 |  0:00:21s\n",
      "epoch 18 | loss: 0.40567 | val_0_auc: 0.83312 |  0:00:23s\n",
      "epoch 19 | loss: 0.39617 | val_0_auc: 0.85403 |  0:00:24s\n",
      "epoch 20 | loss: 0.39107 | val_0_auc: 0.85911 |  0:00:25s\n",
      "epoch 21 | loss: 0.40408 | val_0_auc: 0.85425 |  0:00:26s\n",
      "epoch 22 | loss: 0.39589 | val_0_auc: 0.86289 |  0:00:28s\n",
      "epoch 23 | loss: 0.38879 | val_0_auc: 0.86652 |  0:00:29s\n",
      "epoch 24 | loss: 0.39947 | val_0_auc: 0.86536 |  0:00:30s\n",
      "epoch 25 | loss: 0.36384 | val_0_auc: 0.86115 |  0:00:31s\n",
      "epoch 26 | loss: 0.38857 | val_0_auc: 0.86718 |  0:00:32s\n",
      "epoch 27 | loss: 0.3941  | val_0_auc: 0.82505 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.87291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.90486 | val_0_auc: 0.73297 |  0:00:01s\n",
      "epoch 1  | loss: 0.51312 | val_0_auc: 0.62273 |  0:00:02s\n",
      "epoch 2  | loss: 0.49867 | val_0_auc: 0.82266 |  0:00:03s\n",
      "epoch 3  | loss: 0.40479 | val_0_auc: 0.79143 |  0:00:05s\n",
      "epoch 4  | loss: 0.41371 | val_0_auc: 0.8167  |  0:00:06s\n",
      "epoch 5  | loss: 0.41387 | val_0_auc: 0.73261 |  0:00:07s\n",
      "epoch 6  | loss: 0.43652 | val_0_auc: 0.74677 |  0:00:08s\n",
      "epoch 7  | loss: 0.44287 | val_0_auc: 0.75178 |  0:00:09s\n",
      "epoch 8  | loss: 0.40538 | val_0_auc: 0.81641 |  0:00:11s\n",
      "epoch 9  | loss: 0.4182  | val_0_auc: 0.76383 |  0:00:12s\n",
      "epoch 10 | loss: 0.42328 | val_0_auc: 0.8032  |  0:00:13s\n",
      "epoch 11 | loss: 0.38819 | val_0_auc: 0.78126 |  0:00:14s\n",
      "epoch 12 | loss: 0.42539 | val_0_auc: 0.80763 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.82266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.86006 | val_0_auc: 0.76521 |  0:00:01s\n",
      "epoch 1  | loss: 0.6226  | val_0_auc: 0.82687 |  0:00:02s\n",
      "epoch 2  | loss: 0.55063 | val_0_auc: 0.6992  |  0:00:03s\n",
      "epoch 3  | loss: 0.43343 | val_0_auc: 0.82948 |  0:00:04s\n",
      "epoch 4  | loss: 0.44975 | val_0_auc: 0.80959 |  0:00:05s\n",
      "epoch 5  | loss: 0.45303 | val_0_auc: 0.54757 |  0:00:07s\n",
      "epoch 6  | loss: 0.42172 | val_0_auc: 0.86623 |  0:00:08s\n",
      "epoch 7  | loss: 0.43128 | val_0_auc: 0.86202 |  0:00:09s\n",
      "epoch 8  | loss: 0.43246 | val_0_auc: 0.84916 |  0:00:10s\n",
      "epoch 9  | loss: 0.40995 | val_0_auc: 0.86688 |  0:00:12s\n",
      "epoch 10 | loss: 0.44347 | val_0_auc: 0.87582 |  0:00:13s\n",
      "epoch 11 | loss: 0.43333 | val_0_auc: 0.89906 |  0:00:14s\n",
      "epoch 12 | loss: 0.43316 | val_0_auc: 0.88054 |  0:00:16s\n",
      "epoch 13 | loss: 0.41059 | val_0_auc: 0.87044 |  0:00:17s\n",
      "epoch 14 | loss: 0.41784 | val_0_auc: 0.86049 |  0:00:18s\n",
      "epoch 15 | loss: 0.39134 | val_0_auc: 0.86805 |  0:00:19s\n",
      "epoch 16 | loss: 0.37775 | val_0_auc: 0.88264 |  0:00:20s\n",
      "epoch 17 | loss: 0.40541 | val_0_auc: 0.85788 |  0:00:22s\n",
      "epoch 18 | loss: 0.4322  | val_0_auc: 0.88664 |  0:00:23s\n",
      "epoch 19 | loss: 0.43049 | val_0_auc: 0.8711  |  0:00:24s\n",
      "epoch 20 | loss: 0.40758 | val_0_auc: 0.86972 |  0:00:25s\n",
      "epoch 21 | loss: 0.4007  | val_0_auc: 0.86471 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.89906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.78883 | val_0_auc: 0.67393 |  0:00:01s\n",
      "epoch 1  | loss: 0.55884 | val_0_auc: 0.69557 |  0:00:02s\n",
      "epoch 2  | loss: 0.48878 | val_0_auc: 0.82106 |  0:00:03s\n",
      "epoch 3  | loss: 0.45706 | val_0_auc: 0.86275 |  0:00:04s\n",
      "epoch 4  | loss: 0.39518 | val_0_auc: 0.82302 |  0:00:06s\n",
      "epoch 5  | loss: 0.38491 | val_0_auc: 0.83457 |  0:00:07s\n",
      "epoch 6  | loss: 0.43113 | val_0_auc: 0.7955  |  0:00:08s\n",
      "epoch 7  | loss: 0.43497 | val_0_auc: 0.8276  |  0:00:09s\n",
      "epoch 8  | loss: 0.39192 | val_0_auc: 0.82832 |  0:00:11s\n",
      "epoch 9  | loss: 0.40425 | val_0_auc: 0.82484 |  0:00:12s\n",
      "epoch 10 | loss: 0.41692 | val_0_auc: 0.83733 |  0:00:13s\n",
      "epoch 11 | loss: 0.39688 | val_0_auc: 0.85359 |  0:00:14s\n",
      "epoch 12 | loss: 0.38851 | val_0_auc: 0.84328 |  0:00:16s\n",
      "epoch 13 | loss: 0.3996  | val_0_auc: 0.84851 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.86275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71416 | val_0_auc: 0.72876 |  0:00:01s\n",
      "epoch 1  | loss: 0.58165 | val_0_auc: 0.76957 |  0:00:02s\n",
      "epoch 2  | loss: 0.52615 | val_0_auc: 0.84081 |  0:00:03s\n",
      "epoch 3  | loss: 0.43829 | val_0_auc: 0.79448 |  0:00:05s\n",
      "epoch 4  | loss: 0.43875 | val_0_auc: 0.80828 |  0:00:06s\n",
      "epoch 5  | loss: 0.37427 | val_0_auc: 0.82179 |  0:00:07s\n",
      "epoch 6  | loss: 0.45495 | val_0_auc: 0.79434 |  0:00:09s\n",
      "epoch 7  | loss: 0.43408 | val_0_auc: 0.83188 |  0:00:10s\n",
      "epoch 8  | loss: 0.42755 | val_0_auc: 0.82716 |  0:00:11s\n",
      "epoch 9  | loss: 0.41651 | val_0_auc: 0.83718 |  0:00:12s\n",
      "epoch 10 | loss: 0.41    | val_0_auc: 0.85534 |  0:00:14s\n",
      "epoch 11 | loss: 0.40498 | val_0_auc: 0.84662 |  0:00:15s\n",
      "epoch 12 | loss: 0.44702 | val_0_auc: 0.83922 |  0:00:16s\n",
      "epoch 13 | loss: 0.42001 | val_0_auc: 0.83994 |  0:00:17s\n",
      "epoch 14 | loss: 0.40813 | val_0_auc: 0.83232 |  0:00:19s\n",
      "epoch 15 | loss: 0.40431 | val_0_auc: 0.84902 |  0:00:20s\n",
      "epoch 16 | loss: 0.39624 | val_0_auc: 0.85309 |  0:00:21s\n",
      "epoch 17 | loss: 0.39553 | val_0_auc: 0.82062 |  0:00:23s\n",
      "epoch 18 | loss: 0.3988  | val_0_auc: 0.82571 |  0:00:24s\n",
      "epoch 19 | loss: 0.41891 | val_0_auc: 0.7992  |  0:00:25s\n",
      "epoch 20 | loss: 0.41316 | val_0_auc: 0.83007 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.85534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.7383  | val_0_auc: 0.8533  |  0:00:01s\n",
      "epoch 1  | loss: 0.54678 | val_0_auc: 0.62672 |  0:00:02s\n",
      "epoch 2  | loss: 0.5211  | val_0_auc: 0.8427  |  0:00:03s\n",
      "epoch 3  | loss: 0.46501 | val_0_auc: 0.84909 |  0:00:05s\n",
      "epoch 4  | loss: 0.41762 | val_0_auc: 0.84488 |  0:00:06s\n",
      "epoch 5  | loss: 0.40853 | val_0_auc: 0.84895 |  0:00:07s\n",
      "epoch 6  | loss: 0.44166 | val_0_auc: 0.84459 |  0:00:08s\n",
      "epoch 7  | loss: 0.41009 | val_0_auc: 0.85113 |  0:00:10s\n",
      "epoch 8  | loss: 0.45343 | val_0_auc: 0.82527 |  0:00:11s\n",
      "epoch 9  | loss: 0.41604 | val_0_auc: 0.83479 |  0:00:12s\n",
      "epoch 10 | loss: 0.37055 | val_0_auc: 0.85345 |  0:00:13s\n",
      "epoch 11 | loss: 0.40178 | val_0_auc: 0.86086 |  0:00:15s\n",
      "epoch 12 | loss: 0.41145 | val_0_auc: 0.87095 |  0:00:16s\n",
      "epoch 13 | loss: 0.43939 | val_0_auc: 0.87328 |  0:00:17s\n",
      "epoch 14 | loss: 0.40848 | val_0_auc: 0.86412 |  0:00:18s\n",
      "epoch 15 | loss: 0.40889 | val_0_auc: 0.88794 |  0:00:20s\n",
      "epoch 16 | loss: 0.40805 | val_0_auc: 0.85621 |  0:00:21s\n",
      "epoch 17 | loss: 0.39573 | val_0_auc: 0.87611 |  0:00:22s\n",
      "epoch 18 | loss: 0.39755 | val_0_auc: 0.88155 |  0:00:24s\n",
      "epoch 19 | loss: 0.39982 | val_0_auc: 0.8854  |  0:00:25s\n",
      "epoch 20 | loss: 0.40766 | val_0_auc: 0.88199 |  0:00:26s\n",
      "epoch 21 | loss: 0.37656 | val_0_auc: 0.86914 |  0:00:28s\n",
      "epoch 22 | loss: 0.40703 | val_0_auc: 0.87407 |  0:00:29s\n",
      "epoch 23 | loss: 0.3943  | val_0_auc: 0.88656 |  0:00:30s\n",
      "epoch 24 | loss: 0.40294 | val_0_auc: 0.87858 |  0:00:31s\n",
      "epoch 25 | loss: 0.39763 | val_0_auc: 0.87335 |  0:00:33s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.88794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.74913 | val_0_auc: 0.79724 |  0:00:01s\n",
      "epoch 1  | loss: 0.46897 | val_0_auc: 0.81743 |  0:00:02s\n",
      "epoch 2  | loss: 0.43336 | val_0_auc: 0.84415 |  0:00:03s\n",
      "epoch 3  | loss: 0.44356 | val_0_auc: 0.88424 |  0:00:05s\n",
      "epoch 4  | loss: 0.43864 | val_0_auc: 0.85389 |  0:00:06s\n",
      "epoch 5  | loss: 0.38599 | val_0_auc: 0.84546 |  0:00:07s\n",
      "epoch 6  | loss: 0.42804 | val_0_auc: 0.85548 |  0:00:08s\n",
      "epoch 7  | loss: 0.3968  | val_0_auc: 0.86129 |  0:00:10s\n",
      "epoch 8  | loss: 0.45729 | val_0_auc: 0.85461 |  0:00:11s\n",
      "epoch 9  | loss: 0.41066 | val_0_auc: 0.8703  |  0:00:12s\n",
      "epoch 10 | loss: 0.38381 | val_0_auc: 0.85577 |  0:00:13s\n",
      "epoch 11 | loss: 0.44507 | val_0_auc: 0.86623 |  0:00:15s\n",
      "epoch 12 | loss: 0.41111 | val_0_auc: 0.88511 |  0:00:16s\n",
      "epoch 13 | loss: 0.39471 | val_0_auc: 0.88061 |  0:00:17s\n",
      "epoch 14 | loss: 0.39415 | val_0_auc: 0.87596 |  0:00:18s\n",
      "epoch 15 | loss: 0.38716 | val_0_auc: 0.88831 |  0:00:20s\n",
      "epoch 16 | loss: 0.39104 | val_0_auc: 0.8472  |  0:00:21s\n",
      "epoch 17 | loss: 0.40579 | val_0_auc: 0.8671  |  0:00:22s\n",
      "epoch 18 | loss: 0.38764 | val_0_auc: 0.88177 |  0:00:23s\n",
      "epoch 19 | loss: 0.38283 | val_0_auc: 0.88293 |  0:00:25s\n",
      "epoch 20 | loss: 0.37018 | val_0_auc: 0.88322 |  0:00:26s\n",
      "epoch 21 | loss: 0.36948 | val_0_auc: 0.86986 |  0:00:27s\n",
      "epoch 22 | loss: 0.38232 | val_0_auc: 0.86115 |  0:00:29s\n",
      "epoch 23 | loss: 0.38224 | val_0_auc: 0.86057 |  0:00:30s\n",
      "epoch 24 | loss: 0.36344 | val_0_auc: 0.84808 |  0:00:31s\n",
      "epoch 25 | loss: 0.37623 | val_0_auc: 0.86376 |  0:00:33s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.88831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.77834 | val_0_auc: 0.81678 |  0:00:01s\n",
      "epoch 1  | loss: 0.55529 | val_0_auc: 0.82803 |  0:00:02s\n",
      "epoch 2  | loss: 0.48846 | val_0_auc: 0.84256 |  0:00:03s\n",
      "epoch 3  | loss: 0.47072 | val_0_auc: 0.82977 |  0:00:05s\n",
      "epoch 4  | loss: 0.44713 | val_0_auc: 0.80654 |  0:00:06s\n",
      "epoch 5  | loss: 0.45408 | val_0_auc: 0.84067 |  0:00:07s\n",
      "epoch 6  | loss: 0.42592 | val_0_auc: 0.80276 |  0:00:08s\n",
      "epoch 7  | loss: 0.40915 | val_0_auc: 0.82426 |  0:00:10s\n",
      "epoch 8  | loss: 0.4321  | val_0_auc: 0.82092 |  0:00:11s\n",
      "epoch 9  | loss: 0.42362 | val_0_auc: 0.82731 |  0:00:12s\n",
      "epoch 10 | loss: 0.44497 | val_0_auc: 0.84575 |  0:00:13s\n",
      "epoch 11 | loss: 0.40952 | val_0_auc: 0.826   |  0:00:15s\n",
      "epoch 12 | loss: 0.45198 | val_0_auc: 0.80523 |  0:00:16s\n",
      "epoch 13 | loss: 0.40786 | val_0_auc: 0.7923  |  0:00:17s\n",
      "epoch 14 | loss: 0.40453 | val_0_auc: 0.8764  |  0:00:18s\n",
      "epoch 15 | loss: 0.38938 | val_0_auc: 0.84837 |  0:00:20s\n",
      "epoch 16 | loss: 0.41268 | val_0_auc: 0.8581  |  0:00:21s\n",
      "epoch 17 | loss: 0.43472 | val_0_auc: 0.86071 |  0:00:22s\n",
      "epoch 18 | loss: 0.4166  | val_0_auc: 0.86986 |  0:00:23s\n",
      "epoch 19 | loss: 0.39703 | val_0_auc: 0.85156 |  0:00:25s\n",
      "epoch 20 | loss: 0.40188 | val_0_auc: 0.80886 |  0:00:26s\n",
      "epoch 21 | loss: 0.38452 | val_0_auc: 0.86521 |  0:00:27s\n",
      "epoch 22 | loss: 0.40423 | val_0_auc: 0.88177 |  0:00:29s\n",
      "epoch 23 | loss: 0.42028 | val_0_auc: 0.86289 |  0:00:30s\n",
      "epoch 24 | loss: 0.41542 | val_0_auc: 0.86521 |  0:00:31s\n",
      "epoch 25 | loss: 0.3751  | val_0_auc: 0.86187 |  0:00:33s\n",
      "epoch 26 | loss: 0.39013 | val_0_auc: 0.86855 |  0:00:34s\n",
      "epoch 27 | loss: 0.39348 | val_0_auc: 0.88816 |  0:00:35s\n",
      "epoch 28 | loss: 0.4075  | val_0_auc: 0.89165 |  0:00:36s\n",
      "epoch 29 | loss: 0.396   | val_0_auc: 0.88773 |  0:00:38s\n",
      "epoch 30 | loss: 0.39757 | val_0_auc: 0.88424 |  0:00:39s\n",
      "epoch 31 | loss: 0.38999 | val_0_auc: 0.88046 |  0:00:40s\n",
      "epoch 32 | loss: 0.38567 | val_0_auc: 0.8854  |  0:00:41s\n",
      "epoch 33 | loss: 0.40681 | val_0_auc: 0.88889 |  0:00:43s\n",
      "epoch 34 | loss: 0.41884 | val_0_auc: 0.89281 |  0:00:44s\n",
      "epoch 35 | loss: 0.40721 | val_0_auc: 0.89993 |  0:00:45s\n",
      "epoch 36 | loss: 0.38696 | val_0_auc: 0.89368 |  0:00:47s\n",
      "epoch 37 | loss: 0.40119 | val_0_auc: 0.88032 |  0:00:48s\n",
      "epoch 38 | loss: 0.38873 | val_0_auc: 0.88584 |  0:00:49s\n",
      "epoch 39 | loss: 0.39423 | val_0_auc: 0.89237 |  0:00:50s\n",
      "epoch 40 | loss: 0.3766  | val_0_auc: 0.88889 |  0:00:52s\n",
      "epoch 41 | loss: 0.37074 | val_0_auc: 0.88337 |  0:00:53s\n",
      "epoch 42 | loss: 0.3801  | val_0_auc: 0.88439 |  0:00:54s\n",
      "epoch 43 | loss: 0.38666 | val_0_auc: 0.88903 |  0:00:56s\n",
      "epoch 44 | loss: 0.39347 | val_0_auc: 0.88831 |  0:00:57s\n",
      "epoch 45 | loss: 0.3808  | val_0_auc: 0.88308 |  0:00:58s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.89993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80345 | val_0_auc: 0.82164 |  0:00:01s\n",
      "epoch 1  | loss: 0.49202 | val_0_auc: 0.75824 |  0:00:02s\n",
      "epoch 2  | loss: 0.47431 | val_0_auc: 0.65802 |  0:00:03s\n",
      "epoch 3  | loss: 0.42427 | val_0_auc: 0.81743 |  0:00:04s\n",
      "epoch 4  | loss: 0.46314 | val_0_auc: 0.7573  |  0:00:06s\n",
      "epoch 5  | loss: 0.42437 | val_0_auc: 0.69506 |  0:00:07s\n",
      "epoch 6  | loss: 0.40431 | val_0_auc: 0.75178 |  0:00:08s\n",
      "epoch 7  | loss: 0.42852 | val_0_auc: 0.75439 |  0:00:09s\n",
      "epoch 8  | loss: 0.43726 | val_0_auc: 0.81176 |  0:00:10s\n",
      "epoch 9  | loss: 0.37192 | val_0_auc: 0.82004 |  0:00:12s\n",
      "epoch 10 | loss: 0.37616 | val_0_auc: 0.80392 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.82164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.9558  | val_0_auc: 0.79129 |  0:00:01s\n",
      "epoch 1  | loss: 0.53868 | val_0_auc: 0.83588 |  0:00:02s\n",
      "epoch 2  | loss: 0.40083 | val_0_auc: 0.70428 |  0:00:03s\n",
      "epoch 3  | loss: 0.42177 | val_0_auc: 0.83181 |  0:00:04s\n",
      "epoch 4  | loss: 0.40687 | val_0_auc: 0.85127 |  0:00:06s\n",
      "epoch 5  | loss: 0.43485 | val_0_auc: 0.80697 |  0:00:07s\n",
      "epoch 6  | loss: 0.43642 | val_0_auc: 0.81946 |  0:00:08s\n",
      "epoch 7  | loss: 0.39211 | val_0_auc: 0.85447 |  0:00:09s\n",
      "epoch 8  | loss: 0.40604 | val_0_auc: 0.80908 |  0:00:11s\n",
      "epoch 9  | loss: 0.3854  | val_0_auc: 0.80654 |  0:00:12s\n",
      "epoch 10 | loss: 0.38174 | val_0_auc: 0.80886 |  0:00:13s\n",
      "epoch 11 | loss: 0.42364 | val_0_auc: 0.82948 |  0:00:15s\n",
      "epoch 12 | loss: 0.41965 | val_0_auc: 0.84938 |  0:00:16s\n",
      "epoch 13 | loss: 0.38999 | val_0_auc: 0.84909 |  0:00:17s\n",
      "epoch 14 | loss: 0.40257 | val_0_auc: 0.86202 |  0:00:18s\n",
      "epoch 15 | loss: 0.38896 | val_0_auc: 0.85563 |  0:00:20s\n",
      "epoch 16 | loss: 0.37841 | val_0_auc: 0.87509 |  0:00:21s\n",
      "epoch 17 | loss: 0.38892 | val_0_auc: 0.87248 |  0:00:22s\n",
      "epoch 18 | loss: 0.39645 | val_0_auc: 0.87349 |  0:00:23s\n",
      "epoch 19 | loss: 0.39689 | val_0_auc: 0.89354 |  0:00:24s\n",
      "epoch 20 | loss: 0.40012 | val_0_auc: 0.89136 |  0:00:26s\n",
      "epoch 21 | loss: 0.38005 | val_0_auc: 0.9008  |  0:00:27s\n",
      "epoch 22 | loss: 0.3752  | val_0_auc: 0.89746 |  0:00:28s\n",
      "epoch 23 | loss: 0.40719 | val_0_auc: 0.86514 |  0:00:29s\n",
      "epoch 24 | loss: 0.37298 | val_0_auc: 0.90225 |  0:00:31s\n",
      "epoch 25 | loss: 0.39948 | val_0_auc: 0.88497 |  0:00:32s\n",
      "epoch 26 | loss: 0.39925 | val_0_auc: 0.88932 |  0:00:33s\n",
      "epoch 27 | loss: 0.38342 | val_0_auc: 0.89121 |  0:00:34s\n",
      "epoch 28 | loss: 0.37555 | val_0_auc: 0.89034 |  0:00:35s\n",
      "epoch 29 | loss: 0.39357 | val_0_auc: 0.88076 |  0:00:37s\n",
      "epoch 30 | loss: 0.39612 | val_0_auc: 0.87436 |  0:00:38s\n",
      "epoch 31 | loss: 0.39716 | val_0_auc: 0.87996 |  0:00:39s\n",
      "epoch 32 | loss: 0.38377 | val_0_auc: 0.88257 |  0:00:40s\n",
      "epoch 33 | loss: 0.36593 | val_0_auc: 0.88134 |  0:00:42s\n",
      "epoch 34 | loss: 0.38713 | val_0_auc: 0.88635 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.90225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.88366 | val_0_auc: 0.83747 |  0:00:01s\n",
      "epoch 1  | loss: 0.4967  | val_0_auc: 0.80378 |  0:00:02s\n",
      "epoch 2  | loss: 0.46125 | val_0_auc: 0.81743 |  0:00:03s\n",
      "epoch 3  | loss: 0.44134 | val_0_auc: 0.84168 |  0:00:05s\n",
      "epoch 4  | loss: 0.42048 | val_0_auc: 0.85214 |  0:00:06s\n",
      "epoch 5  | loss: 0.42286 | val_0_auc: 0.85505 |  0:00:07s\n",
      "epoch 6  | loss: 0.422   | val_0_auc: 0.84532 |  0:00:09s\n",
      "epoch 7  | loss: 0.43299 | val_0_auc: 0.86507 |  0:00:10s\n",
      "epoch 8  | loss: 0.41223 | val_0_auc: 0.83224 |  0:00:11s\n",
      "epoch 9  | loss: 0.41682 | val_0_auc: 0.83413 |  0:00:13s\n",
      "epoch 10 | loss: 0.4043  | val_0_auc: 0.86173 |  0:00:14s\n",
      "epoch 11 | loss: 0.41497 | val_0_auc: 0.86071 |  0:00:15s\n",
      "epoch 12 | loss: 0.42967 | val_0_auc: 0.8655  |  0:00:17s\n",
      "epoch 13 | loss: 0.42769 | val_0_auc: 0.86275 |  0:00:18s\n",
      "epoch 14 | loss: 0.4093  | val_0_auc: 0.86231 |  0:00:19s\n",
      "epoch 15 | loss: 0.40442 | val_0_auc: 0.86521 |  0:00:21s\n",
      "epoch 16 | loss: 0.38528 | val_0_auc: 0.85911 |  0:00:22s\n",
      "epoch 17 | loss: 0.39483 | val_0_auc: 0.87596 |  0:00:23s\n",
      "epoch 18 | loss: 0.41895 | val_0_auc: 0.89092 |  0:00:25s\n",
      "epoch 19 | loss: 0.37718 | val_0_auc: 0.88903 |  0:00:26s\n",
      "epoch 20 | loss: 0.37609 | val_0_auc: 0.86892 |  0:00:27s\n",
      "epoch 21 | loss: 0.38584 | val_0_auc: 0.87836 |  0:00:29s\n",
      "epoch 22 | loss: 0.41032 | val_0_auc: 0.88678 |  0:00:30s\n",
      "epoch 23 | loss: 0.38773 | val_0_auc: 0.89041 |  0:00:32s\n",
      "epoch 24 | loss: 0.39944 | val_0_auc: 0.89187 |  0:00:33s\n",
      "epoch 25 | loss: 0.40129 | val_0_auc: 0.87785 |  0:00:34s\n",
      "epoch 26 | loss: 0.40155 | val_0_auc: 0.89412 |  0:00:36s\n",
      "epoch 27 | loss: 0.39239 | val_0_auc: 0.8915  |  0:00:37s\n",
      "epoch 28 | loss: 0.3838  | val_0_auc: 0.88598 |  0:00:39s\n",
      "epoch 29 | loss: 0.39138 | val_0_auc: 0.89506 |  0:00:40s\n",
      "epoch 30 | loss: 0.38949 | val_0_auc: 0.88141 |  0:00:41s\n",
      "epoch 31 | loss: 0.39165 | val_0_auc: 0.89201 |  0:00:43s\n",
      "epoch 32 | loss: 0.37589 | val_0_auc: 0.89317 |  0:00:44s\n",
      "epoch 33 | loss: 0.38134 | val_0_auc: 0.89165 |  0:00:45s\n",
      "epoch 34 | loss: 0.38705 | val_0_auc: 0.88388 |  0:00:47s\n",
      "epoch 35 | loss: 0.38364 | val_0_auc: 0.89063 |  0:00:48s\n",
      "epoch 36 | loss: 0.37071 | val_0_auc: 0.88511 |  0:00:49s\n",
      "epoch 37 | loss: 0.39444 | val_0_auc: 0.87662 |  0:00:50s\n",
      "epoch 38 | loss: 0.38894 | val_0_auc: 0.87872 |  0:00:52s\n",
      "epoch 39 | loss: 0.38594 | val_0_auc: 0.88954 |  0:00:53s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.89506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.83771 | val_0_auc: 0.79223 |  0:00:01s\n",
      "epoch 1  | loss: 0.48889 | val_0_auc: 0.76688 |  0:00:02s\n",
      "epoch 2  | loss: 0.44989 | val_0_auc: 0.74887 |  0:00:04s\n",
      "epoch 3  | loss: 0.45388 | val_0_auc: 0.79826 |  0:00:05s\n",
      "epoch 4  | loss: 0.40253 | val_0_auc: 0.83805 |  0:00:06s\n",
      "epoch 5  | loss: 0.40449 | val_0_auc: 0.86405 |  0:00:08s\n",
      "epoch 6  | loss: 0.40272 | val_0_auc: 0.83994 |  0:00:09s\n",
      "epoch 7  | loss: 0.41951 | val_0_auc: 0.84415 |  0:00:10s\n",
      "epoch 8  | loss: 0.39336 | val_0_auc: 0.82789 |  0:00:11s\n",
      "epoch 9  | loss: 0.40976 | val_0_auc: 0.83849 |  0:00:13s\n",
      "epoch 10 | loss: 0.37442 | val_0_auc: 0.84386 |  0:00:14s\n",
      "epoch 11 | loss: 0.40301 | val_0_auc: 0.83675 |  0:00:15s\n",
      "epoch 12 | loss: 0.41678 | val_0_auc: 0.84183 |  0:00:16s\n",
      "epoch 13 | loss: 0.38788 | val_0_auc: 0.83893 |  0:00:18s\n",
      "epoch 14 | loss: 0.40731 | val_0_auc: 0.86434 |  0:00:19s\n",
      "epoch 15 | loss: 0.39975 | val_0_auc: 0.87785 |  0:00:20s\n",
      "epoch 16 | loss: 0.40711 | val_0_auc: 0.89034 |  0:00:21s\n",
      "epoch 17 | loss: 0.40723 | val_0_auc: 0.88293 |  0:00:23s\n",
      "epoch 18 | loss: 0.40298 | val_0_auc: 0.82367 |  0:00:24s\n",
      "epoch 19 | loss: 0.38916 | val_0_auc: 0.83413 |  0:00:25s\n",
      "epoch 20 | loss: 0.37706 | val_0_auc: 0.84241 |  0:00:26s\n",
      "epoch 21 | loss: 0.39047 | val_0_auc: 0.84924 |  0:00:27s\n",
      "epoch 22 | loss: 0.37698 | val_0_auc: 0.88046 |  0:00:29s\n",
      "epoch 23 | loss: 0.38766 | val_0_auc: 0.87633 |  0:00:30s\n",
      "epoch 24 | loss: 0.38984 | val_0_auc: 0.88141 |  0:00:31s\n",
      "epoch 25 | loss: 0.37726 | val_0_auc: 0.85403 |  0:00:32s\n",
      "epoch 26 | loss: 0.38388 | val_0_auc: 0.86369 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.89034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.90579 | val_0_auc: 0.84626 |  0:00:01s\n",
      "epoch 1  | loss: 0.53737 | val_0_auc: 0.76536 |  0:00:02s\n",
      "epoch 2  | loss: 0.48319 | val_0_auc: 0.75599 |  0:00:04s\n",
      "epoch 3  | loss: 0.48245 | val_0_auc: 0.79136 |  0:00:05s\n",
      "epoch 4  | loss: 0.43849 | val_0_auc: 0.80094 |  0:00:06s\n",
      "epoch 5  | loss: 0.41904 | val_0_auc: 0.80922 |  0:00:08s\n",
      "epoch 6  | loss: 0.43119 | val_0_auc: 0.83304 |  0:00:09s\n",
      "epoch 7  | loss: 0.39919 | val_0_auc: 0.82919 |  0:00:10s\n",
      "epoch 8  | loss: 0.39373 | val_0_auc: 0.85142 |  0:00:11s\n",
      "epoch 9  | loss: 0.41647 | val_0_auc: 0.86914 |  0:00:13s\n",
      "epoch 10 | loss: 0.41405 | val_0_auc: 0.84096 |  0:00:14s\n",
      "epoch 11 | loss: 0.42955 | val_0_auc: 0.8565  |  0:00:15s\n",
      "epoch 12 | loss: 0.39742 | val_0_auc: 0.86805 |  0:00:16s\n",
      "epoch 13 | loss: 0.40973 | val_0_auc: 0.85969 |  0:00:18s\n",
      "epoch 14 | loss: 0.40887 | val_0_auc: 0.86311 |  0:00:19s\n",
      "epoch 15 | loss: 0.42628 | val_0_auc: 0.8703  |  0:00:20s\n",
      "epoch 16 | loss: 0.42176 | val_0_auc: 0.82215 |  0:00:21s\n",
      "epoch 17 | loss: 0.43778 | val_0_auc: 0.82498 |  0:00:22s\n",
      "epoch 18 | loss: 0.43392 | val_0_auc: 0.84873 |  0:00:24s\n",
      "epoch 19 | loss: 0.41553 | val_0_auc: 0.85614 |  0:00:25s\n",
      "epoch 20 | loss: 0.3983  | val_0_auc: 0.86216 |  0:00:26s\n",
      "epoch 21 | loss: 0.40987 | val_0_auc: 0.85272 |  0:00:27s\n",
      "epoch 22 | loss: 0.39937 | val_0_auc: 0.86536 |  0:00:29s\n",
      "epoch 23 | loss: 0.39443 | val_0_auc: 0.85207 |  0:00:30s\n",
      "epoch 24 | loss: 0.40203 | val_0_auc: 0.85643 |  0:00:31s\n",
      "epoch 25 | loss: 0.4137  | val_0_auc: 0.85309 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55698 | val_0_auc: 0.67473 |  0:00:01s\n",
      "epoch 1  | loss: 0.47535 | val_0_auc: 0.80959 |  0:00:02s\n",
      "epoch 2  | loss: 0.47693 | val_0_auc: 0.76383 |  0:00:04s\n",
      "epoch 3  | loss: 0.40424 | val_0_auc: 0.82222 |  0:00:05s\n",
      "epoch 4  | loss: 0.40223 | val_0_auc: 0.78373 |  0:00:06s\n",
      "epoch 5  | loss: 0.3916  | val_0_auc: 0.82571 |  0:00:07s\n",
      "epoch 6  | loss: 0.43237 | val_0_auc: 0.86667 |  0:00:09s\n",
      "epoch 7  | loss: 0.39448 | val_0_auc: 0.84924 |  0:00:10s\n",
      "epoch 8  | loss: 0.40555 | val_0_auc: 0.82585 |  0:00:11s\n",
      "epoch 9  | loss: 0.41044 | val_0_auc: 0.85853 |  0:00:13s\n",
      "epoch 10 | loss: 0.41279 | val_0_auc: 0.85766 |  0:00:14s\n",
      "epoch 11 | loss: 0.3874  | val_0_auc: 0.81845 |  0:00:15s\n",
      "epoch 12 | loss: 0.40129 | val_0_auc: 0.79739 |  0:00:17s\n",
      "epoch 13 | loss: 0.40416 | val_0_auc: 0.83036 |  0:00:18s\n",
      "epoch 14 | loss: 0.38467 | val_0_auc: 0.85258 |  0:00:19s\n",
      "epoch 15 | loss: 0.40265 | val_0_auc: 0.86667 |  0:00:20s\n",
      "epoch 16 | loss: 0.38385 | val_0_auc: 0.87306 |  0:00:22s\n",
      "epoch 17 | loss: 0.38213 | val_0_auc: 0.8602  |  0:00:23s\n",
      "epoch 18 | loss: 0.39005 | val_0_auc: 0.86645 |  0:00:24s\n",
      "epoch 19 | loss: 0.38801 | val_0_auc: 0.85897 |  0:00:25s\n",
      "epoch 20 | loss: 0.37762 | val_0_auc: 0.88301 |  0:00:26s\n",
      "epoch 21 | loss: 0.39194 | val_0_auc: 0.86718 |  0:00:28s\n",
      "epoch 22 | loss: 0.38139 | val_0_auc: 0.87712 |  0:00:29s\n",
      "epoch 23 | loss: 0.37209 | val_0_auc: 0.87988 |  0:00:30s\n",
      "epoch 24 | loss: 0.36593 | val_0_auc: 0.86652 |  0:00:31s\n",
      "epoch 25 | loss: 0.38899 | val_0_auc: 0.87756 |  0:00:33s\n",
      "epoch 26 | loss: 0.40215 | val_0_auc: 0.8915  |  0:00:34s\n",
      "epoch 27 | loss: 0.38172 | val_0_auc: 0.89252 |  0:00:35s\n",
      "epoch 28 | loss: 0.38634 | val_0_auc: 0.89121 |  0:00:36s\n",
      "epoch 29 | loss: 0.36297 | val_0_auc: 0.88794 |  0:00:38s\n",
      "epoch 30 | loss: 0.38135 | val_0_auc: 0.8923  |  0:00:39s\n",
      "epoch 31 | loss: 0.37863 | val_0_auc: 0.8984  |  0:00:40s\n",
      "epoch 32 | loss: 0.36489 | val_0_auc: 0.90552 |  0:00:42s\n",
      "epoch 33 | loss: 0.35618 | val_0_auc: 0.88322 |  0:00:43s\n",
      "epoch 34 | loss: 0.36282 | val_0_auc: 0.89078 |  0:00:44s\n",
      "epoch 35 | loss: 0.35734 | val_0_auc: 0.88482 |  0:00:45s\n",
      "epoch 36 | loss: 0.38436 | val_0_auc: 0.88555 |  0:00:47s\n",
      "epoch 37 | loss: 0.37074 | val_0_auc: 0.89179 |  0:00:48s\n",
      "epoch 38 | loss: 0.35647 | val_0_auc: 0.87814 |  0:00:49s\n",
      "epoch 39 | loss: 0.37858 | val_0_auc: 0.89804 |  0:00:50s\n",
      "epoch 40 | loss: 0.36312 | val_0_auc: 0.89441 |  0:00:52s\n",
      "epoch 41 | loss: 0.34738 | val_0_auc: 0.89717 |  0:00:53s\n",
      "epoch 42 | loss: 0.35589 | val_0_auc: 0.89906 |  0:00:54s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.90552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65933 | val_0_auc: 0.81365 |  0:00:01s\n",
      "epoch 1  | loss: 0.41514 | val_0_auc: 0.80603 |  0:00:02s\n",
      "epoch 2  | loss: 0.46213 | val_0_auc: 0.80392 |  0:00:03s\n",
      "epoch 3  | loss: 0.40624 | val_0_auc: 0.79702 |  0:00:05s\n",
      "epoch 4  | loss: 0.40138 | val_0_auc: 0.79499 |  0:00:06s\n",
      "epoch 5  | loss: 0.40772 | val_0_auc: 0.78874 |  0:00:07s\n",
      "epoch 6  | loss: 0.44476 | val_0_auc: 0.77531 |  0:00:09s\n",
      "epoch 7  | loss: 0.41859 | val_0_auc: 0.80436 |  0:00:10s\n",
      "epoch 8  | loss: 0.42573 | val_0_auc: 0.81903 |  0:00:11s\n",
      "epoch 9  | loss: 0.40981 | val_0_auc: 0.80835 |  0:00:12s\n",
      "epoch 10 | loss: 0.40539 | val_0_auc: 0.80988 |  0:00:14s\n",
      "epoch 11 | loss: 0.39263 | val_0_auc: 0.77676 |  0:00:15s\n",
      "epoch 12 | loss: 0.38687 | val_0_auc: 0.83086 |  0:00:16s\n",
      "epoch 13 | loss: 0.39217 | val_0_auc: 0.82992 |  0:00:17s\n",
      "epoch 14 | loss: 0.39107 | val_0_auc: 0.85505 |  0:00:19s\n",
      "epoch 15 | loss: 0.3875  | val_0_auc: 0.86899 |  0:00:20s\n",
      "epoch 16 | loss: 0.37381 | val_0_auc: 0.84038 |  0:00:21s\n",
      "epoch 17 | loss: 0.37993 | val_0_auc: 0.852   |  0:00:23s\n",
      "epoch 18 | loss: 0.39199 | val_0_auc: 0.85664 |  0:00:24s\n",
      "epoch 19 | loss: 0.35972 | val_0_auc: 0.85512 |  0:00:25s\n",
      "epoch 20 | loss: 0.37842 | val_0_auc: 0.86275 |  0:00:26s\n",
      "epoch 21 | loss: 0.3886  | val_0_auc: 0.87371 |  0:00:28s\n",
      "epoch 22 | loss: 0.37867 | val_0_auc: 0.86463 |  0:00:29s\n",
      "epoch 23 | loss: 0.39919 | val_0_auc: 0.87044 |  0:00:30s\n",
      "epoch 24 | loss: 0.37483 | val_0_auc: 0.87052 |  0:00:32s\n",
      "epoch 25 | loss: 0.398   | val_0_auc: 0.8663  |  0:00:33s\n",
      "epoch 26 | loss: 0.39713 | val_0_auc: 0.87654 |  0:00:34s\n",
      "epoch 27 | loss: 0.37941 | val_0_auc: 0.87785 |  0:00:36s\n",
      "epoch 28 | loss: 0.38733 | val_0_auc: 0.88722 |  0:00:37s\n",
      "epoch 29 | loss: 0.37424 | val_0_auc: 0.88097 |  0:00:38s\n",
      "epoch 30 | loss: 0.38264 | val_0_auc: 0.86841 |  0:00:40s\n",
      "epoch 31 | loss: 0.37699 | val_0_auc: 0.88105 |  0:00:41s\n",
      "epoch 32 | loss: 0.37461 | val_0_auc: 0.88264 |  0:00:42s\n",
      "epoch 33 | loss: 0.36156 | val_0_auc: 0.88395 |  0:00:43s\n",
      "epoch 34 | loss: 0.3713  | val_0_auc: 0.88032 |  0:00:45s\n",
      "epoch 35 | loss: 0.37768 | val_0_auc: 0.87102 |  0:00:46s\n",
      "epoch 36 | loss: 0.37552 | val_0_auc: 0.88671 |  0:00:47s\n",
      "epoch 37 | loss: 0.38635 | val_0_auc: 0.88606 |  0:00:49s\n",
      "epoch 38 | loss: 0.38651 | val_0_auc: 0.87858 |  0:00:50s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.88722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58373 | val_0_auc: 0.72832 |  0:00:01s\n",
      "epoch 1  | loss: 0.45678 | val_0_auc: 0.82309 |  0:00:02s\n",
      "epoch 2  | loss: 0.46319 | val_0_auc: 0.8488  |  0:00:03s\n",
      "epoch 3  | loss: 0.42784 | val_0_auc: 0.83588 |  0:00:05s\n",
      "epoch 4  | loss: 0.41985 | val_0_auc: 0.85069 |  0:00:06s\n",
      "epoch 5  | loss: 0.428   | val_0_auc: 0.86115 |  0:00:07s\n",
      "epoch 6  | loss: 0.42005 | val_0_auc: 0.85897 |  0:00:09s\n",
      "epoch 7  | loss: 0.40423 | val_0_auc: 0.87255 |  0:00:10s\n",
      "epoch 8  | loss: 0.40844 | val_0_auc: 0.86289 |  0:00:11s\n",
      "epoch 9  | loss: 0.3964  | val_0_auc: 0.85977 |  0:00:13s\n",
      "epoch 10 | loss: 0.40411 | val_0_auc: 0.86318 |  0:00:14s\n",
      "epoch 11 | loss: 0.40123 | val_0_auc: 0.84699 |  0:00:15s\n",
      "epoch 12 | loss: 0.38301 | val_0_auc: 0.84808 |  0:00:16s\n",
      "epoch 13 | loss: 0.40208 | val_0_auc: 0.85454 |  0:00:18s\n",
      "epoch 14 | loss: 0.39942 | val_0_auc: 0.86412 |  0:00:19s\n",
      "epoch 15 | loss: 0.39725 | val_0_auc: 0.87691 |  0:00:20s\n",
      "epoch 16 | loss: 0.39478 | val_0_auc: 0.86412 |  0:00:22s\n",
      "epoch 17 | loss: 0.38521 | val_0_auc: 0.86928 |  0:00:23s\n",
      "epoch 18 | loss: 0.38442 | val_0_auc: 0.87705 |  0:00:24s\n",
      "epoch 19 | loss: 0.37787 | val_0_auc: 0.84459 |  0:00:25s\n",
      "epoch 20 | loss: 0.42421 | val_0_auc: 0.8252  |  0:00:27s\n",
      "epoch 21 | loss: 0.40563 | val_0_auc: 0.85621 |  0:00:28s\n",
      "epoch 22 | loss: 0.4053  | val_0_auc: 0.87938 |  0:00:30s\n",
      "epoch 23 | loss: 0.39289 | val_0_auc: 0.86797 |  0:00:31s\n",
      "epoch 24 | loss: 0.38532 | val_0_auc: 0.8305  |  0:00:32s\n",
      "epoch 25 | loss: 0.40908 | val_0_auc: 0.86064 |  0:00:34s\n",
      "epoch 26 | loss: 0.41206 | val_0_auc: 0.87553 |  0:00:35s\n",
      "epoch 27 | loss: 0.39688 | val_0_auc: 0.87509 |  0:00:36s\n",
      "epoch 28 | loss: 0.39554 | val_0_auc: 0.87451 |  0:00:37s\n",
      "epoch 29 | loss: 0.36171 | val_0_auc: 0.8732  |  0:00:39s\n",
      "epoch 30 | loss: 0.39704 | val_0_auc: 0.85556 |  0:00:40s\n",
      "epoch 31 | loss: 0.39409 | val_0_auc: 0.87328 |  0:00:41s\n",
      "epoch 32 | loss: 0.38822 | val_0_auc: 0.87001 |  0:00:43s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.87938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56293 | val_0_auc: 0.82171 |  0:00:01s\n",
      "epoch 1  | loss: 0.46153 | val_0_auc: 0.84081 |  0:00:02s\n",
      "epoch 2  | loss: 0.47671 | val_0_auc: 0.83646 |  0:00:04s\n",
      "epoch 3  | loss: 0.40539 | val_0_auc: 0.82869 |  0:00:05s\n",
      "epoch 4  | loss: 0.42945 | val_0_auc: 0.85701 |  0:00:06s\n",
      "epoch 5  | loss: 0.39837 | val_0_auc: 0.85294 |  0:00:08s\n",
      "epoch 6  | loss: 0.40089 | val_0_auc: 0.83007 |  0:00:09s\n",
      "epoch 7  | loss: 0.41002 | val_0_auc: 0.82571 |  0:00:10s\n",
      "epoch 8  | loss: 0.40657 | val_0_auc: 0.8472  |  0:00:11s\n",
      "epoch 9  | loss: 0.42618 | val_0_auc: 0.85418 |  0:00:13s\n",
      "epoch 10 | loss: 0.42363 | val_0_auc: 0.84808 |  0:00:14s\n",
      "epoch 11 | loss: 0.42173 | val_0_auc: 0.85795 |  0:00:15s\n",
      "epoch 12 | loss: 0.39717 | val_0_auc: 0.85679 |  0:00:17s\n",
      "epoch 13 | loss: 0.3925  | val_0_auc: 0.84546 |  0:00:18s\n",
      "epoch 14 | loss: 0.39153 | val_0_auc: 0.83638 |  0:00:19s\n",
      "epoch 15 | loss: 0.39352 | val_0_auc: 0.84096 |  0:00:20s\n",
      "epoch 16 | loss: 0.38009 | val_0_auc: 0.85156 |  0:00:22s\n",
      "epoch 17 | loss: 0.41997 | val_0_auc: 0.85817 |  0:00:23s\n",
      "epoch 18 | loss: 0.37859 | val_0_auc: 0.85657 |  0:00:24s\n",
      "epoch 19 | loss: 0.37607 | val_0_auc: 0.86587 |  0:00:25s\n",
      "epoch 20 | loss: 0.39519 | val_0_auc: 0.8573  |  0:00:27s\n",
      "epoch 21 | loss: 0.40623 | val_0_auc: 0.86703 |  0:00:28s\n",
      "epoch 22 | loss: 0.40551 | val_0_auc: 0.89049 |  0:00:29s\n",
      "epoch 23 | loss: 0.38744 | val_0_auc: 0.88054 |  0:00:30s\n",
      "epoch 24 | loss: 0.38059 | val_0_auc: 0.87073 |  0:00:32s\n",
      "epoch 25 | loss: 0.4032  | val_0_auc: 0.88555 |  0:00:33s\n",
      "epoch 26 | loss: 0.4032  | val_0_auc: 0.86565 |  0:00:34s\n",
      "epoch 27 | loss: 0.37256 | val_0_auc: 0.87611 |  0:00:36s\n",
      "epoch 28 | loss: 0.37386 | val_0_auc: 0.86405 |  0:00:37s\n",
      "epoch 29 | loss: 0.39114 | val_0_auc: 0.84982 |  0:00:38s\n",
      "epoch 30 | loss: 0.38891 | val_0_auc: 0.86485 |  0:00:40s\n",
      "epoch 31 | loss: 0.39512 | val_0_auc: 0.8679  |  0:00:41s\n",
      "epoch 32 | loss: 0.39802 | val_0_auc: 0.87821 |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.89049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60574 | val_0_auc: 0.86129 |  0:00:01s\n",
      "epoch 1  | loss: 0.48236 | val_0_auc: 0.83863 |  0:00:02s\n",
      "epoch 2  | loss: 0.46563 | val_0_auc: 0.83965 |  0:00:03s\n",
      "epoch 3  | loss: 0.44178 | val_0_auc: 0.83007 |  0:00:04s\n",
      "epoch 4  | loss: 0.45394 | val_0_auc: 0.83588 |  0:00:06s\n",
      "epoch 5  | loss: 0.41367 | val_0_auc: 0.84328 |  0:00:07s\n",
      "epoch 6  | loss: 0.39785 | val_0_auc: 0.80988 |  0:00:08s\n",
      "epoch 7  | loss: 0.43855 | val_0_auc: 0.85505 |  0:00:09s\n",
      "epoch 8  | loss: 0.42779 | val_0_auc: 0.82251 |  0:00:11s\n",
      "epoch 9  | loss: 0.43272 | val_0_auc: 0.83667 |  0:00:12s\n",
      "epoch 10 | loss: 0.40878 | val_0_auc: 0.83725 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.86129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64332 | val_0_auc: 0.59223 |  0:00:00s\n",
      "epoch 1  | loss: 0.45823 | val_0_auc: 0.79521 |  0:00:01s\n",
      "epoch 2  | loss: 0.47054 | val_0_auc: 0.84444 |  0:00:02s\n",
      "epoch 3  | loss: 0.42458 | val_0_auc: 0.84996 |  0:00:03s\n",
      "epoch 4  | loss: 0.39181 | val_0_auc: 0.84481 |  0:00:04s\n",
      "epoch 5  | loss: 0.38848 | val_0_auc: 0.83805 |  0:00:04s\n",
      "epoch 6  | loss: 0.39793 | val_0_auc: 0.82251 |  0:00:05s\n",
      "epoch 7  | loss: 0.39226 | val_0_auc: 0.83529 |  0:00:06s\n",
      "epoch 8  | loss: 0.36928 | val_0_auc: 0.83057 |  0:00:07s\n",
      "epoch 9  | loss: 0.39674 | val_0_auc: 0.84822 |  0:00:07s\n",
      "epoch 10 | loss: 0.38488 | val_0_auc: 0.85599 |  0:00:08s\n",
      "epoch 11 | loss: 0.37782 | val_0_auc: 0.83101 |  0:00:09s\n",
      "epoch 12 | loss: 0.40126 | val_0_auc: 0.84394 |  0:00:10s\n",
      "epoch 13 | loss: 0.38779 | val_0_auc: 0.83784 |  0:00:11s\n",
      "epoch 14 | loss: 0.38289 | val_0_auc: 0.86681 |  0:00:12s\n",
      "epoch 15 | loss: 0.36578 | val_0_auc: 0.86042 |  0:00:12s\n",
      "epoch 16 | loss: 0.37675 | val_0_auc: 0.84532 |  0:00:13s\n",
      "epoch 17 | loss: 0.36974 | val_0_auc: 0.85156 |  0:00:14s\n",
      "epoch 18 | loss: 0.38425 | val_0_auc: 0.87001 |  0:00:15s\n",
      "epoch 19 | loss: 0.38777 | val_0_auc: 0.83246 |  0:00:16s\n",
      "epoch 20 | loss: 0.37488 | val_0_auc: 0.85229 |  0:00:17s\n",
      "epoch 21 | loss: 0.40007 | val_0_auc: 0.85999 |  0:00:18s\n",
      "epoch 22 | loss: 0.36891 | val_0_auc: 0.88664 |  0:00:19s\n",
      "epoch 23 | loss: 0.38945 | val_0_auc: 0.88686 |  0:00:20s\n",
      "epoch 24 | loss: 0.37629 | val_0_auc: 0.88402 |  0:00:21s\n",
      "epoch 25 | loss: 0.3823  | val_0_auc: 0.88228 |  0:00:22s\n",
      "epoch 26 | loss: 0.37572 | val_0_auc: 0.87974 |  0:00:23s\n",
      "epoch 27 | loss: 0.3673  | val_0_auc: 0.88068 |  0:00:24s\n",
      "epoch 28 | loss: 0.36914 | val_0_auc: 0.88845 |  0:00:25s\n",
      "epoch 29 | loss: 0.37526 | val_0_auc: 0.88548 |  0:00:25s\n",
      "epoch 30 | loss: 0.37034 | val_0_auc: 0.88119 |  0:00:26s\n",
      "epoch 31 | loss: 0.35964 | val_0_auc: 0.88017 |  0:00:27s\n",
      "epoch 32 | loss: 0.38176 | val_0_auc: 0.87248 |  0:00:28s\n",
      "epoch 33 | loss: 0.3779  | val_0_auc: 0.87814 |  0:00:28s\n",
      "epoch 34 | loss: 0.35685 | val_0_auc: 0.8894  |  0:00:29s\n",
      "epoch 35 | loss: 0.343   | val_0_auc: 0.8817  |  0:00:30s\n",
      "epoch 36 | loss: 0.37327 | val_0_auc: 0.88351 |  0:00:31s\n",
      "epoch 37 | loss: 0.3433  | val_0_auc: 0.88482 |  0:00:32s\n",
      "epoch 38 | loss: 0.3658  | val_0_auc: 0.89107 |  0:00:32s\n",
      "epoch 39 | loss: 0.36022 | val_0_auc: 0.88751 |  0:00:33s\n",
      "epoch 40 | loss: 0.35006 | val_0_auc: 0.88119 |  0:00:34s\n",
      "epoch 41 | loss: 0.35775 | val_0_auc: 0.87603 |  0:00:35s\n",
      "epoch 42 | loss: 0.38323 | val_0_auc: 0.88163 |  0:00:36s\n",
      "epoch 43 | loss: 0.37937 | val_0_auc: 0.87611 |  0:00:37s\n",
      "epoch 44 | loss: 0.36889 | val_0_auc: 0.87248 |  0:00:37s\n",
      "epoch 45 | loss: 0.36044 | val_0_auc: 0.878   |  0:00:38s\n",
      "epoch 46 | loss: 0.35804 | val_0_auc: 0.87829 |  0:00:39s\n",
      "epoch 47 | loss: 0.35517 | val_0_auc: 0.87814 |  0:00:40s\n",
      "epoch 48 | loss: 0.3591  | val_0_auc: 0.88301 |  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.89107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55018 | val_0_auc: 0.84023 |  0:00:00s\n",
      "epoch 1  | loss: 0.4243  | val_0_auc: 0.84633 |  0:00:01s\n",
      "epoch 2  | loss: 0.42513 | val_0_auc: 0.84691 |  0:00:02s\n",
      "epoch 3  | loss: 0.44175 | val_0_auc: 0.82963 |  0:00:03s\n",
      "epoch 4  | loss: 0.4091  | val_0_auc: 0.84343 |  0:00:04s\n",
      "epoch 5  | loss: 0.41109 | val_0_auc: 0.85999 |  0:00:05s\n",
      "epoch 6  | loss: 0.43983 | val_0_auc: 0.86463 |  0:00:06s\n",
      "epoch 7  | loss: 0.3975  | val_0_auc: 0.8671  |  0:00:06s\n",
      "epoch 8  | loss: 0.39356 | val_0_auc: 0.86071 |  0:00:07s\n",
      "epoch 9  | loss: 0.39906 | val_0_auc: 0.83907 |  0:00:08s\n",
      "epoch 10 | loss: 0.40829 | val_0_auc: 0.86144 |  0:00:09s\n",
      "epoch 11 | loss: 0.39963 | val_0_auc: 0.8655  |  0:00:10s\n",
      "epoch 12 | loss: 0.3786  | val_0_auc: 0.87466 |  0:00:11s\n",
      "epoch 13 | loss: 0.38976 | val_0_auc: 0.88177 |  0:00:12s\n",
      "epoch 14 | loss: 0.40226 | val_0_auc: 0.88221 |  0:00:13s\n",
      "epoch 15 | loss: 0.36701 | val_0_auc: 0.88221 |  0:00:14s\n",
      "epoch 16 | loss: 0.39833 | val_0_auc: 0.86376 |  0:00:15s\n",
      "epoch 17 | loss: 0.42117 | val_0_auc: 0.87088 |  0:00:15s\n",
      "epoch 18 | loss: 0.38594 | val_0_auc: 0.88163 |  0:00:16s\n",
      "epoch 19 | loss: 0.38369 | val_0_auc: 0.87771 |  0:00:17s\n",
      "epoch 20 | loss: 0.39964 | val_0_auc: 0.86492 |  0:00:18s\n",
      "epoch 21 | loss: 0.39864 | val_0_auc: 0.86376 |  0:00:19s\n",
      "epoch 22 | loss: 0.37613 | val_0_auc: 0.86231 |  0:00:20s\n",
      "epoch 23 | loss: 0.37471 | val_0_auc: 0.86507 |  0:00:21s\n",
      "epoch 24 | loss: 0.38699 | val_0_auc: 0.86834 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.88221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58046 | val_0_auc: 0.71888 |  0:00:00s\n",
      "epoch 1  | loss: 0.50021 | val_0_auc: 0.83428 |  0:00:01s\n",
      "epoch 2  | loss: 0.45535 | val_0_auc: 0.83384 |  0:00:02s\n",
      "epoch 3  | loss: 0.45089 | val_0_auc: 0.82832 |  0:00:03s\n",
      "epoch 4  | loss: 0.42829 | val_0_auc: 0.85628 |  0:00:04s\n",
      "epoch 5  | loss: 0.4117  | val_0_auc: 0.77516 |  0:00:05s\n",
      "epoch 6  | loss: 0.44226 | val_0_auc: 0.87727 |  0:00:06s\n",
      "epoch 7  | loss: 0.42744 | val_0_auc: 0.86478 |  0:00:06s\n",
      "epoch 8  | loss: 0.40239 | val_0_auc: 0.85236 |  0:00:07s\n",
      "epoch 9  | loss: 0.41753 | val_0_auc: 0.86935 |  0:00:08s\n",
      "epoch 10 | loss: 0.38077 | val_0_auc: 0.84582 |  0:00:09s\n",
      "epoch 11 | loss: 0.39994 | val_0_auc: 0.84633 |  0:00:10s\n",
      "epoch 12 | loss: 0.40724 | val_0_auc: 0.83486 |  0:00:10s\n",
      "epoch 13 | loss: 0.41135 | val_0_auc: 0.84619 |  0:00:11s\n",
      "epoch 14 | loss: 0.41868 | val_0_auc: 0.8159  |  0:00:12s\n",
      "epoch 15 | loss: 0.41951 | val_0_auc: 0.8382  |  0:00:13s\n",
      "epoch 16 | loss: 0.41263 | val_0_auc: 0.84829 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.87727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59167 | val_0_auc: 0.67829 |  0:00:00s\n",
      "epoch 1  | loss: 0.49657 | val_0_auc: 0.78577 |  0:00:01s\n",
      "epoch 2  | loss: 0.44296 | val_0_auc: 0.8658  |  0:00:02s\n",
      "epoch 3  | loss: 0.42972 | val_0_auc: 0.85519 |  0:00:03s\n",
      "epoch 4  | loss: 0.42139 | val_0_auc: 0.84866 |  0:00:04s\n",
      "epoch 5  | loss: 0.39119 | val_0_auc: 0.83253 |  0:00:04s\n",
      "epoch 6  | loss: 0.42749 | val_0_auc: 0.8459  |  0:00:05s\n",
      "epoch 7  | loss: 0.39986 | val_0_auc: 0.83675 |  0:00:06s\n",
      "epoch 8  | loss: 0.40127 | val_0_auc: 0.83181 |  0:00:07s\n",
      "epoch 9  | loss: 0.38037 | val_0_auc: 0.82629 |  0:00:08s\n",
      "epoch 10 | loss: 0.39745 | val_0_auc: 0.80828 |  0:00:08s\n",
      "epoch 11 | loss: 0.38395 | val_0_auc: 0.81206 |  0:00:09s\n",
      "epoch 12 | loss: 0.38908 | val_0_auc: 0.85592 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62187 | val_0_auc: 0.84009 |  0:00:00s\n",
      "epoch 1  | loss: 0.46816 | val_0_auc: 0.85054 |  0:00:01s\n",
      "epoch 2  | loss: 0.4162  | val_0_auc: 0.85468 |  0:00:02s\n",
      "epoch 3  | loss: 0.44737 | val_0_auc: 0.85258 |  0:00:03s\n",
      "epoch 4  | loss: 0.40266 | val_0_auc: 0.83784 |  0:00:04s\n",
      "epoch 5  | loss: 0.39631 | val_0_auc: 0.84837 |  0:00:04s\n",
      "epoch 6  | loss: 0.41905 | val_0_auc: 0.80305 |  0:00:05s\n",
      "epoch 7  | loss: 0.41691 | val_0_auc: 0.81699 |  0:00:06s\n",
      "epoch 8  | loss: 0.41292 | val_0_auc: 0.81481 |  0:00:07s\n",
      "epoch 9  | loss: 0.41225 | val_0_auc: 0.83094 |  0:00:07s\n",
      "epoch 10 | loss: 0.39331 | val_0_auc: 0.84372 |  0:00:08s\n",
      "epoch 11 | loss: 0.4169  | val_0_auc: 0.8533  |  0:00:09s\n",
      "epoch 12 | loss: 0.39921 | val_0_auc: 0.82121 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.85468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57642 | val_0_auc: 0.8862  |  0:00:00s\n",
      "epoch 1  | loss: 0.49792 | val_0_auc: 0.86158 |  0:00:01s\n",
      "epoch 2  | loss: 0.48978 | val_0_auc: 0.82847 |  0:00:02s\n",
      "epoch 3  | loss: 0.4524  | val_0_auc: 0.78083 |  0:00:03s\n",
      "epoch 4  | loss: 0.43734 | val_0_auc: 0.75338 |  0:00:04s\n",
      "epoch 5  | loss: 0.40291 | val_0_auc: 0.81525 |  0:00:04s\n",
      "epoch 6  | loss: 0.41145 | val_0_auc: 0.83253 |  0:00:05s\n",
      "epoch 7  | loss: 0.39535 | val_0_auc: 0.80102 |  0:00:06s\n",
      "epoch 8  | loss: 0.38679 | val_0_auc: 0.79985 |  0:00:07s\n",
      "epoch 9  | loss: 0.39677 | val_0_auc: 0.81307 |  0:00:08s\n",
      "epoch 10 | loss: 0.40891 | val_0_auc: 0.8045  |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63006 | val_0_auc: 0.7016  |  0:00:00s\n",
      "epoch 1  | loss: 0.45084 | val_0_auc: 0.79724 |  0:00:01s\n",
      "epoch 2  | loss: 0.45515 | val_0_auc: 0.73493 |  0:00:02s\n",
      "epoch 3  | loss: 0.44873 | val_0_auc: 0.75192 |  0:00:03s\n",
      "epoch 4  | loss: 0.41582 | val_0_auc: 0.80537 |  0:00:04s\n",
      "epoch 5  | loss: 0.3987  | val_0_auc: 0.84808 |  0:00:05s\n",
      "epoch 6  | loss: 0.43347 | val_0_auc: 0.865   |  0:00:06s\n",
      "epoch 7  | loss: 0.40137 | val_0_auc: 0.86398 |  0:00:07s\n",
      "epoch 8  | loss: 0.4163  | val_0_auc: 0.86158 |  0:00:08s\n",
      "epoch 9  | loss: 0.43326 | val_0_auc: 0.86747 |  0:00:08s\n",
      "epoch 10 | loss: 0.42992 | val_0_auc: 0.8589  |  0:00:09s\n",
      "epoch 11 | loss: 0.41597 | val_0_auc: 0.86049 |  0:00:10s\n",
      "epoch 12 | loss: 0.38573 | val_0_auc: 0.8748  |  0:00:11s\n",
      "epoch 13 | loss: 0.40058 | val_0_auc: 0.86732 |  0:00:12s\n",
      "epoch 14 | loss: 0.40145 | val_0_auc: 0.85701 |  0:00:13s\n",
      "epoch 15 | loss: 0.39808 | val_0_auc: 0.85251 |  0:00:14s\n",
      "epoch 16 | loss: 0.42235 | val_0_auc: 0.87037 |  0:00:15s\n",
      "epoch 17 | loss: 0.41888 | val_0_auc: 0.87219 |  0:00:16s\n",
      "epoch 18 | loss: 0.39139 | val_0_auc: 0.88736 |  0:00:17s\n",
      "epoch 19 | loss: 0.38413 | val_0_auc: 0.89383 |  0:00:17s\n",
      "epoch 20 | loss: 0.41639 | val_0_auc: 0.89201 |  0:00:18s\n",
      "epoch 21 | loss: 0.40566 | val_0_auc: 0.8764  |  0:00:19s\n",
      "epoch 22 | loss: 0.39475 | val_0_auc: 0.8817  |  0:00:20s\n",
      "epoch 23 | loss: 0.37963 | val_0_auc: 0.88715 |  0:00:21s\n",
      "epoch 24 | loss: 0.40275 | val_0_auc: 0.89172 |  0:00:22s\n",
      "epoch 25 | loss: 0.39923 | val_0_auc: 0.89942 |  0:00:23s\n",
      "epoch 26 | loss: 0.4018  | val_0_auc: 0.89426 |  0:00:24s\n",
      "epoch 27 | loss: 0.39598 | val_0_auc: 0.89579 |  0:00:25s\n",
      "epoch 28 | loss: 0.36317 | val_0_auc: 0.8971  |  0:00:26s\n",
      "epoch 29 | loss: 0.40137 | val_0_auc: 0.88969 |  0:00:26s\n",
      "epoch 30 | loss: 0.39572 | val_0_auc: 0.87923 |  0:00:27s\n",
      "epoch 31 | loss: 0.39515 | val_0_auc: 0.87792 |  0:00:28s\n",
      "epoch 32 | loss: 0.40367 | val_0_auc: 0.87603 |  0:00:29s\n",
      "epoch 33 | loss: 0.38495 | val_0_auc: 0.88809 |  0:00:30s\n",
      "epoch 34 | loss: 0.37204 | val_0_auc: 0.88642 |  0:00:31s\n",
      "epoch 35 | loss: 0.38578 | val_0_auc: 0.88649 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.89942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58123 | val_0_auc: 0.7268  |  0:00:00s\n",
      "epoch 1  | loss: 0.50489 | val_0_auc: 0.82716 |  0:00:01s\n",
      "epoch 2  | loss: 0.45433 | val_0_auc: 0.79114 |  0:00:02s\n",
      "epoch 3  | loss: 0.46606 | val_0_auc: 0.79194 |  0:00:03s\n",
      "epoch 4  | loss: 0.43872 | val_0_auc: 0.77574 |  0:00:04s\n",
      "epoch 5  | loss: 0.44701 | val_0_auc: 0.82803 |  0:00:05s\n",
      "epoch 6  | loss: 0.44278 | val_0_auc: 0.83588 |  0:00:06s\n",
      "epoch 7  | loss: 0.42045 | val_0_auc: 0.85229 |  0:00:07s\n",
      "epoch 8  | loss: 0.41915 | val_0_auc: 0.84779 |  0:00:08s\n",
      "epoch 9  | loss: 0.40654 | val_0_auc: 0.85389 |  0:00:09s\n",
      "epoch 10 | loss: 0.38827 | val_0_auc: 0.84045 |  0:00:09s\n",
      "epoch 11 | loss: 0.39657 | val_0_auc: 0.85004 |  0:00:10s\n",
      "epoch 12 | loss: 0.3955  | val_0_auc: 0.83972 |  0:00:11s\n",
      "epoch 13 | loss: 0.39905 | val_0_auc: 0.8451  |  0:00:12s\n",
      "epoch 14 | loss: 0.4048  | val_0_auc: 0.85185 |  0:00:13s\n",
      "epoch 15 | loss: 0.40991 | val_0_auc: 0.87168 |  0:00:14s\n",
      "epoch 16 | loss: 0.4016  | val_0_auc: 0.85919 |  0:00:15s\n",
      "epoch 17 | loss: 0.41208 | val_0_auc: 0.85599 |  0:00:16s\n",
      "epoch 18 | loss: 0.38441 | val_0_auc: 0.88163 |  0:00:17s\n",
      "epoch 19 | loss: 0.39064 | val_0_auc: 0.87785 |  0:00:17s\n",
      "epoch 20 | loss: 0.40033 | val_0_auc: 0.86362 |  0:00:18s\n",
      "epoch 21 | loss: 0.40563 | val_0_auc: 0.8984  |  0:00:19s\n",
      "epoch 22 | loss: 0.39168 | val_0_auc: 0.88584 |  0:00:20s\n",
      "epoch 23 | loss: 0.39815 | val_0_auc: 0.88344 |  0:00:21s\n",
      "epoch 24 | loss: 0.39849 | val_0_auc: 0.88736 |  0:00:21s\n",
      "epoch 25 | loss: 0.39082 | val_0_auc: 0.88061 |  0:00:22s\n",
      "epoch 26 | loss: 0.41373 | val_0_auc: 0.89325 |  0:00:23s\n",
      "epoch 27 | loss: 0.40811 | val_0_auc: 0.89593 |  0:00:24s\n",
      "epoch 28 | loss: 0.38362 | val_0_auc: 0.88758 |  0:00:25s\n",
      "epoch 29 | loss: 0.38819 | val_0_auc: 0.88017 |  0:00:26s\n",
      "epoch 30 | loss: 0.38836 | val_0_auc: 0.89078 |  0:00:27s\n",
      "epoch 31 | loss: 0.39925 | val_0_auc: 0.89274 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6658  | val_0_auc: 0.40123 |  0:00:00s\n",
      "epoch 1  | loss: 0.50159 | val_0_auc: 0.79375 |  0:00:01s\n",
      "epoch 2  | loss: 0.44142 | val_0_auc: 0.82259 |  0:00:02s\n",
      "epoch 3  | loss: 0.43023 | val_0_auc: 0.81235 |  0:00:03s\n",
      "epoch 4  | loss: 0.41494 | val_0_auc: 0.81859 |  0:00:04s\n",
      "epoch 5  | loss: 0.47022 | val_0_auc: 0.83965 |  0:00:05s\n",
      "epoch 6  | loss: 0.46142 | val_0_auc: 0.84851 |  0:00:06s\n",
      "epoch 7  | loss: 0.44302 | val_0_auc: 0.85127 |  0:00:07s\n",
      "epoch 8  | loss: 0.42993 | val_0_auc: 0.86449 |  0:00:08s\n",
      "epoch 9  | loss: 0.36485 | val_0_auc: 0.83529 |  0:00:08s\n",
      "epoch 10 | loss: 0.41891 | val_0_auc: 0.85911 |  0:00:09s\n",
      "epoch 11 | loss: 0.38322 | val_0_auc: 0.8687  |  0:00:10s\n",
      "epoch 12 | loss: 0.39759 | val_0_auc: 0.86826 |  0:00:11s\n",
      "epoch 13 | loss: 0.40713 | val_0_auc: 0.88235 |  0:00:12s\n",
      "epoch 14 | loss: 0.38815 | val_0_auc: 0.86638 |  0:00:13s\n",
      "epoch 15 | loss: 0.38951 | val_0_auc: 0.88061 |  0:00:14s\n",
      "epoch 16 | loss: 0.38838 | val_0_auc: 0.86928 |  0:00:14s\n",
      "epoch 17 | loss: 0.38779 | val_0_auc: 0.85853 |  0:00:15s\n",
      "epoch 18 | loss: 0.40273 | val_0_auc: 0.88017 |  0:00:16s\n",
      "epoch 19 | loss: 0.39308 | val_0_auc: 0.8488  |  0:00:17s\n",
      "epoch 20 | loss: 0.39718 | val_0_auc: 0.86245 |  0:00:18s\n",
      "epoch 21 | loss: 0.38159 | val_0_auc: 0.87001 |  0:00:19s\n",
      "epoch 22 | loss: 0.36959 | val_0_auc: 0.86485 |  0:00:20s\n",
      "epoch 23 | loss: 0.39071 | val_0_auc: 0.865   |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65342 | val_0_auc: 0.85381 |  0:00:00s\n",
      "epoch 1  | loss: 0.49492 | val_0_auc: 0.84052 |  0:00:01s\n",
      "epoch 2  | loss: 0.44093 | val_0_auc: 0.85381 |  0:00:02s\n",
      "epoch 3  | loss: 0.47115 | val_0_auc: 0.85991 |  0:00:03s\n",
      "epoch 4  | loss: 0.4033  | val_0_auc: 0.77996 |  0:00:04s\n",
      "epoch 5  | loss: 0.41795 | val_0_auc: 0.82426 |  0:00:05s\n",
      "epoch 6  | loss: 0.4187  | val_0_auc: 0.81772 |  0:00:06s\n",
      "epoch 7  | loss: 0.43278 | val_0_auc: 0.8191  |  0:00:07s\n",
      "epoch 8  | loss: 0.42783 | val_0_auc: 0.81997 |  0:00:08s\n",
      "epoch 9  | loss: 0.42432 | val_0_auc: 0.81256 |  0:00:09s\n",
      "epoch 10 | loss: 0.40283 | val_0_auc: 0.8244  |  0:00:09s\n",
      "epoch 11 | loss: 0.43014 | val_0_auc: 0.81946 |  0:00:10s\n",
      "epoch 12 | loss: 0.4048  | val_0_auc: 0.81387 |  0:00:11s\n",
      "epoch 13 | loss: 0.40919 | val_0_auc: 0.8053  |  0:00:12s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.85991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54736 | val_0_auc: 0.81511 |  0:00:00s\n",
      "epoch 1  | loss: 0.42015 | val_0_auc: 0.76906 |  0:00:01s\n",
      "epoch 2  | loss: 0.42171 | val_0_auc: 0.85156 |  0:00:02s\n",
      "epoch 3  | loss: 0.4158  | val_0_auc: 0.85679 |  0:00:03s\n",
      "epoch 4  | loss: 0.41722 | val_0_auc: 0.79521 |  0:00:04s\n",
      "epoch 5  | loss: 0.38393 | val_0_auc: 0.85679 |  0:00:05s\n",
      "epoch 6  | loss: 0.38364 | val_0_auc: 0.85301 |  0:00:05s\n",
      "epoch 7  | loss: 0.3899  | val_0_auc: 0.8289  |  0:00:06s\n",
      "epoch 8  | loss: 0.37518 | val_0_auc: 0.86536 |  0:00:07s\n",
      "epoch 9  | loss: 0.36438 | val_0_auc: 0.852   |  0:00:08s\n",
      "epoch 10 | loss: 0.37895 | val_0_auc: 0.82585 |  0:00:09s\n",
      "epoch 11 | loss: 0.37478 | val_0_auc: 0.82861 |  0:00:10s\n",
      "epoch 12 | loss: 0.35551 | val_0_auc: 0.85258 |  0:00:11s\n",
      "epoch 13 | loss: 0.38257 | val_0_auc: 0.87814 |  0:00:11s\n",
      "epoch 14 | loss: 0.37795 | val_0_auc: 0.87407 |  0:00:12s\n",
      "epoch 15 | loss: 0.38646 | val_0_auc: 0.86797 |  0:00:13s\n",
      "epoch 16 | loss: 0.35694 | val_0_auc: 0.85374 |  0:00:14s\n",
      "epoch 17 | loss: 0.37864 | val_0_auc: 0.86725 |  0:00:15s\n",
      "epoch 18 | loss: 0.36436 | val_0_auc: 0.86892 |  0:00:15s\n",
      "epoch 19 | loss: 0.40241 | val_0_auc: 0.87153 |  0:00:16s\n",
      "epoch 20 | loss: 0.3741  | val_0_auc: 0.86616 |  0:00:17s\n",
      "epoch 21 | loss: 0.37822 | val_0_auc: 0.87843 |  0:00:18s\n",
      "epoch 22 | loss: 0.38616 | val_0_auc: 0.8533  |  0:00:18s\n",
      "epoch 23 | loss: 0.3689  | val_0_auc: 0.87233 |  0:00:19s\n",
      "epoch 24 | loss: 0.36354 | val_0_auc: 0.86492 |  0:00:20s\n",
      "epoch 25 | loss: 0.37032 | val_0_auc: 0.87749 |  0:00:21s\n",
      "epoch 26 | loss: 0.36779 | val_0_auc: 0.87131 |  0:00:22s\n",
      "epoch 27 | loss: 0.34945 | val_0_auc: 0.88351 |  0:00:22s\n",
      "epoch 28 | loss: 0.36259 | val_0_auc: 0.87698 |  0:00:23s\n",
      "epoch 29 | loss: 0.37677 | val_0_auc: 0.88911 |  0:00:24s\n",
      "epoch 30 | loss: 0.38708 | val_0_auc: 0.88744 |  0:00:25s\n",
      "epoch 31 | loss: 0.36303 | val_0_auc: 0.87589 |  0:00:26s\n",
      "epoch 32 | loss: 0.37144 | val_0_auc: 0.88853 |  0:00:26s\n",
      "epoch 33 | loss: 0.35472 | val_0_auc: 0.88526 |  0:00:27s\n",
      "epoch 34 | loss: 0.35642 | val_0_auc: 0.88148 |  0:00:28s\n",
      "epoch 35 | loss: 0.34896 | val_0_auc: 0.87974 |  0:00:29s\n",
      "epoch 36 | loss: 0.39374 | val_0_auc: 0.88279 |  0:00:29s\n",
      "epoch 37 | loss: 0.39731 | val_0_auc: 0.88831 |  0:00:30s\n",
      "epoch 38 | loss: 0.3717  | val_0_auc: 0.8846  |  0:00:31s\n",
      "epoch 39 | loss: 0.35499 | val_0_auc: 0.88533 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.88911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54781 | val_0_auc: 0.82781 |  0:00:00s\n",
      "epoch 1  | loss: 0.42577 | val_0_auc: 0.82397 |  0:00:01s\n",
      "epoch 2  | loss: 0.42528 | val_0_auc: 0.81176 |  0:00:02s\n",
      "epoch 3  | loss: 0.43366 | val_0_auc: 0.84299 |  0:00:03s\n",
      "epoch 4  | loss: 0.4032  | val_0_auc: 0.85171 |  0:00:04s\n",
      "epoch 5  | loss: 0.38013 | val_0_auc: 0.84299 |  0:00:05s\n",
      "epoch 6  | loss: 0.40211 | val_0_auc: 0.86173 |  0:00:05s\n",
      "epoch 7  | loss: 0.39701 | val_0_auc: 0.85991 |  0:00:06s\n",
      "epoch 8  | loss: 0.39058 | val_0_auc: 0.87102 |  0:00:07s\n",
      "epoch 9  | loss: 0.372   | val_0_auc: 0.87872 |  0:00:08s\n",
      "epoch 10 | loss: 0.39283 | val_0_auc: 0.83282 |  0:00:09s\n",
      "epoch 11 | loss: 0.39591 | val_0_auc: 0.83805 |  0:00:10s\n",
      "epoch 12 | loss: 0.38659 | val_0_auc: 0.84975 |  0:00:11s\n",
      "epoch 13 | loss: 0.38355 | val_0_auc: 0.85548 |  0:00:11s\n",
      "epoch 14 | loss: 0.39131 | val_0_auc: 0.87422 |  0:00:12s\n",
      "epoch 15 | loss: 0.3929  | val_0_auc: 0.86601 |  0:00:13s\n",
      "epoch 16 | loss: 0.38512 | val_0_auc: 0.84953 |  0:00:14s\n",
      "epoch 17 | loss: 0.37733 | val_0_auc: 0.86928 |  0:00:14s\n",
      "epoch 18 | loss: 0.38635 | val_0_auc: 0.88076 |  0:00:15s\n",
      "epoch 19 | loss: 0.40148 | val_0_auc: 0.8626  |  0:00:16s\n",
      "epoch 20 | loss: 0.37809 | val_0_auc: 0.87669 |  0:00:17s\n",
      "epoch 21 | loss: 0.38795 | val_0_auc: 0.87574 |  0:00:18s\n",
      "epoch 22 | loss: 0.38581 | val_0_auc: 0.87204 |  0:00:18s\n",
      "epoch 23 | loss: 0.37713 | val_0_auc: 0.86442 |  0:00:19s\n",
      "epoch 24 | loss: 0.36129 | val_0_auc: 0.87923 |  0:00:20s\n",
      "epoch 25 | loss: 0.37168 | val_0_auc: 0.85272 |  0:00:21s\n",
      "epoch 26 | loss: 0.39222 | val_0_auc: 0.88511 |  0:00:21s\n",
      "epoch 27 | loss: 0.37532 | val_0_auc: 0.88911 |  0:00:22s\n",
      "epoch 28 | loss: 0.37026 | val_0_auc: 0.88279 |  0:00:23s\n",
      "epoch 29 | loss: 0.37189 | val_0_auc: 0.88787 |  0:00:24s\n",
      "epoch 30 | loss: 0.38899 | val_0_auc: 0.86979 |  0:00:25s\n",
      "epoch 31 | loss: 0.36632 | val_0_auc: 0.85875 |  0:00:25s\n",
      "epoch 32 | loss: 0.36951 | val_0_auc: 0.87814 |  0:00:26s\n",
      "epoch 33 | loss: 0.37361 | val_0_auc: 0.8963  |  0:00:27s\n",
      "epoch 34 | loss: 0.37341 | val_0_auc: 0.89034 |  0:00:28s\n",
      "epoch 35 | loss: 0.35689 | val_0_auc: 0.89615 |  0:00:29s\n",
      "epoch 36 | loss: 0.37009 | val_0_auc: 0.87756 |  0:00:29s\n",
      "epoch 37 | loss: 0.395   | val_0_auc: 0.86718 |  0:00:30s\n",
      "epoch 38 | loss: 0.3745  | val_0_auc: 0.89847 |  0:00:31s\n",
      "epoch 39 | loss: 0.39408 | val_0_auc: 0.87596 |  0:00:32s\n",
      "epoch 40 | loss: 0.38374 | val_0_auc: 0.8854  |  0:00:32s\n",
      "epoch 41 | loss: 0.38314 | val_0_auc: 0.89099 |  0:00:33s\n",
      "epoch 42 | loss: 0.38463 | val_0_auc: 0.89114 |  0:00:34s\n",
      "epoch 43 | loss: 0.37118 | val_0_auc: 0.87734 |  0:00:35s\n",
      "epoch 44 | loss: 0.38218 | val_0_auc: 0.88025 |  0:00:36s\n",
      "epoch 45 | loss: 0.38468 | val_0_auc: 0.8931  |  0:00:37s\n",
      "epoch 46 | loss: 0.37923 | val_0_auc: 0.89361 |  0:00:38s\n",
      "epoch 47 | loss: 0.35702 | val_0_auc: 0.90022 |  0:00:38s\n",
      "epoch 48 | loss: 0.36238 | val_0_auc: 0.89833 |  0:00:39s\n",
      "epoch 49 | loss: 0.3757  | val_0_auc: 0.89688 |  0:00:40s\n",
      "epoch 50 | loss: 0.37853 | val_0_auc: 0.88773 |  0:00:41s\n",
      "epoch 51 | loss: 0.37525 | val_0_auc: 0.89303 |  0:00:42s\n",
      "epoch 52 | loss: 0.37059 | val_0_auc: 0.87073 |  0:00:43s\n",
      "epoch 53 | loss: 0.36758 | val_0_auc: 0.89426 |  0:00:43s\n",
      "epoch 54 | loss: 0.37333 | val_0_auc: 0.89368 |  0:00:44s\n",
      "epoch 55 | loss: 0.37761 | val_0_auc: 0.87008 |  0:00:45s\n",
      "epoch 56 | loss: 0.38033 | val_0_auc: 0.84336 |  0:00:46s\n",
      "epoch 57 | loss: 0.36002 | val_0_auc: 0.87415 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_0_auc = 0.90022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54981 | val_0_auc: 0.86754 |  0:00:00s\n",
      "epoch 1  | loss: 0.44025 | val_0_auc: 0.87015 |  0:00:01s\n",
      "epoch 2  | loss: 0.42614 | val_0_auc: 0.81206 |  0:00:02s\n",
      "epoch 3  | loss: 0.45764 | val_0_auc: 0.80857 |  0:00:03s\n",
      "epoch 4  | loss: 0.40549 | val_0_auc: 0.81656 |  0:00:03s\n",
      "epoch 5  | loss: 0.40848 | val_0_auc: 0.82455 |  0:00:04s\n",
      "epoch 6  | loss: 0.4082  | val_0_auc: 0.8215  |  0:00:05s\n",
      "epoch 7  | loss: 0.42275 | val_0_auc: 0.82338 |  0:00:06s\n",
      "epoch 8  | loss: 0.40381 | val_0_auc: 0.82992 |  0:00:06s\n",
      "epoch 9  | loss: 0.39487 | val_0_auc: 0.82789 |  0:00:07s\n",
      "epoch 10 | loss: 0.40447 | val_0_auc: 0.82193 |  0:00:08s\n",
      "epoch 11 | loss: 0.40797 | val_0_auc: 0.83079 |  0:00:09s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.87015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53927 | val_0_auc: 0.82367 |  0:00:00s\n",
      "epoch 1  | loss: 0.42843 | val_0_auc: 0.82527 |  0:00:01s\n",
      "epoch 2  | loss: 0.39818 | val_0_auc: 0.83994 |  0:00:02s\n",
      "epoch 3  | loss: 0.4548  | val_0_auc: 0.83863 |  0:00:03s\n",
      "epoch 4  | loss: 0.38629 | val_0_auc: 0.83965 |  0:00:03s\n",
      "epoch 5  | loss: 0.39928 | val_0_auc: 0.83936 |  0:00:04s\n",
      "epoch 6  | loss: 0.38996 | val_0_auc: 0.85359 |  0:00:05s\n",
      "epoch 7  | loss: 0.40953 | val_0_auc: 0.84967 |  0:00:06s\n",
      "epoch 8  | loss: 0.41722 | val_0_auc: 0.86289 |  0:00:07s\n",
      "epoch 9  | loss: 0.40785 | val_0_auc: 0.80276 |  0:00:07s\n",
      "epoch 10 | loss: 0.38597 | val_0_auc: 0.83987 |  0:00:08s\n",
      "epoch 11 | loss: 0.37891 | val_0_auc: 0.83936 |  0:00:09s\n",
      "epoch 12 | loss: 0.38802 | val_0_auc: 0.84503 |  0:00:10s\n",
      "epoch 13 | loss: 0.38041 | val_0_auc: 0.83239 |  0:00:10s\n",
      "epoch 14 | loss: 0.40776 | val_0_auc: 0.88439 |  0:00:11s\n",
      "epoch 15 | loss: 0.38981 | val_0_auc: 0.86253 |  0:00:12s\n",
      "epoch 16 | loss: 0.37912 | val_0_auc: 0.86609 |  0:00:13s\n",
      "epoch 17 | loss: 0.36793 | val_0_auc: 0.86289 |  0:00:14s\n",
      "epoch 18 | loss: 0.38075 | val_0_auc: 0.87734 |  0:00:15s\n",
      "epoch 19 | loss: 0.37486 | val_0_auc: 0.87124 |  0:00:15s\n",
      "epoch 20 | loss: 0.38016 | val_0_auc: 0.85846 |  0:00:16s\n",
      "epoch 21 | loss: 0.36686 | val_0_auc: 0.86456 |  0:00:17s\n",
      "epoch 22 | loss: 0.37491 | val_0_auc: 0.88257 |  0:00:18s\n",
      "epoch 23 | loss: 0.37858 | val_0_auc: 0.86093 |  0:00:18s\n",
      "epoch 24 | loss: 0.36756 | val_0_auc: 0.8581  |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.88439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53852 | val_0_auc: 0.80813 |  0:00:00s\n",
      "epoch 1  | loss: 0.4548  | val_0_auc: 0.86289 |  0:00:01s\n",
      "epoch 2  | loss: 0.44925 | val_0_auc: 0.80937 |  0:00:02s\n",
      "epoch 3  | loss: 0.43963 | val_0_auc: 0.79572 |  0:00:03s\n",
      "epoch 4  | loss: 0.45593 | val_0_auc: 0.8406  |  0:00:03s\n",
      "epoch 5  | loss: 0.43737 | val_0_auc: 0.84953 |  0:00:04s\n",
      "epoch 6  | loss: 0.41772 | val_0_auc: 0.85824 |  0:00:05s\n",
      "epoch 7  | loss: 0.41456 | val_0_auc: 0.87683 |  0:00:06s\n",
      "epoch 8  | loss: 0.43363 | val_0_auc: 0.88555 |  0:00:07s\n",
      "epoch 9  | loss: 0.41956 | val_0_auc: 0.84735 |  0:00:07s\n",
      "epoch 10 | loss: 0.41712 | val_0_auc: 0.89702 |  0:00:08s\n",
      "epoch 11 | loss: 0.41374 | val_0_auc: 0.88889 |  0:00:09s\n",
      "epoch 12 | loss: 0.41723 | val_0_auc: 0.88744 |  0:00:10s\n",
      "epoch 13 | loss: 0.38551 | val_0_auc: 0.8748  |  0:00:10s\n",
      "epoch 14 | loss: 0.39969 | val_0_auc: 0.88911 |  0:00:11s\n",
      "epoch 15 | loss: 0.41278 | val_0_auc: 0.88758 |  0:00:12s\n",
      "epoch 16 | loss: 0.41163 | val_0_auc: 0.88656 |  0:00:13s\n",
      "epoch 17 | loss: 0.38268 | val_0_auc: 0.8716  |  0:00:13s\n",
      "epoch 18 | loss: 0.41072 | val_0_auc: 0.88903 |  0:00:14s\n",
      "epoch 19 | loss: 0.40187 | val_0_auc: 0.8886  |  0:00:15s\n",
      "epoch 20 | loss: 0.41333 | val_0_auc: 0.88729 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.89702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5449  | val_0_auc: 0.85142 |  0:00:00s\n",
      "epoch 1  | loss: 0.42485 | val_0_auc: 0.80044 |  0:00:01s\n",
      "epoch 2  | loss: 0.45104 | val_0_auc: 0.83486 |  0:00:02s\n",
      "epoch 3  | loss: 0.43612 | val_0_auc: 0.84749 |  0:00:03s\n",
      "epoch 4  | loss: 0.4168  | val_0_auc: 0.78722 |  0:00:03s\n",
      "epoch 5  | loss: 0.37103 | val_0_auc: 0.77669 |  0:00:04s\n",
      "epoch 6  | loss: 0.38141 | val_0_auc: 0.72273 |  0:00:05s\n",
      "epoch 7  | loss: 0.39228 | val_0_auc: 0.78729 |  0:00:06s\n",
      "epoch 8  | loss: 0.38443 | val_0_auc: 0.84851 |  0:00:07s\n",
      "epoch 9  | loss: 0.36889 | val_0_auc: 0.80065 |  0:00:07s\n",
      "epoch 10 | loss: 0.39102 | val_0_auc: 0.82767 |  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.85142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5636  | val_0_auc: 0.63253 |  0:00:00s\n",
      "epoch 1  | loss: 0.45619 | val_0_auc: 0.83544 |  0:00:01s\n",
      "epoch 2  | loss: 0.46823 | val_0_auc: 0.61481 |  0:00:02s\n",
      "epoch 3  | loss: 0.46104 | val_0_auc: 0.79985 |  0:00:03s\n",
      "epoch 4  | loss: 0.44254 | val_0_auc: 0.7719  |  0:00:03s\n",
      "epoch 5  | loss: 0.41198 | val_0_auc: 0.8215  |  0:00:04s\n",
      "epoch 6  | loss: 0.43605 | val_0_auc: 0.80763 |  0:00:05s\n",
      "epoch 7  | loss: 0.42231 | val_0_auc: 0.79448 |  0:00:06s\n",
      "epoch 8  | loss: 0.4272  | val_0_auc: 0.84938 |  0:00:07s\n",
      "epoch 9  | loss: 0.40023 | val_0_auc: 0.86405 |  0:00:07s\n",
      "epoch 10 | loss: 0.40198 | val_0_auc: 0.86245 |  0:00:08s\n",
      "epoch 11 | loss: 0.41414 | val_0_auc: 0.85592 |  0:00:09s\n",
      "epoch 12 | loss: 0.40518 | val_0_auc: 0.8467  |  0:00:10s\n",
      "epoch 13 | loss: 0.3927  | val_0_auc: 0.85389 |  0:00:10s\n",
      "epoch 14 | loss: 0.3895  | val_0_auc: 0.84241 |  0:00:11s\n",
      "epoch 15 | loss: 0.41776 | val_0_auc: 0.85004 |  0:00:12s\n",
      "epoch 16 | loss: 0.39275 | val_0_auc: 0.85999 |  0:00:13s\n",
      "epoch 17 | loss: 0.40443 | val_0_auc: 0.84946 |  0:00:13s\n",
      "epoch 18 | loss: 0.41228 | val_0_auc: 0.83907 |  0:00:14s\n",
      "epoch 19 | loss: 0.44349 | val_0_auc: 0.85476 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.86405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.54252 | val_0_auc: 0.80073 |  0:00:00s\n",
      "epoch 1  | loss: 0.45302 | val_0_auc: 0.82789 |  0:00:01s\n",
      "epoch 2  | loss: 0.46685 | val_0_auc: 0.75715 |  0:00:02s\n",
      "epoch 3  | loss: 0.52435 | val_0_auc: 0.81191 |  0:00:03s\n",
      "epoch 4  | loss: 0.43331 | val_0_auc: 0.77052 |  0:00:03s\n",
      "epoch 5  | loss: 0.46615 | val_0_auc: 0.80363 |  0:00:04s\n",
      "epoch 6  | loss: 0.42838 | val_0_auc: 0.80566 |  0:00:05s\n",
      "epoch 7  | loss: 0.43498 | val_0_auc: 0.80407 |  0:00:06s\n",
      "epoch 8  | loss: 0.43008 | val_0_auc: 0.82113 |  0:00:06s\n",
      "epoch 9  | loss: 0.44027 | val_0_auc: 0.8281  |  0:00:07s\n",
      "epoch 10 | loss: 0.43094 | val_0_auc: 0.8276  |  0:00:08s\n",
      "epoch 11 | loss: 0.43216 | val_0_auc: 0.79579 |  0:00:09s\n",
      "epoch 12 | loss: 0.40886 | val_0_auc: 0.82803 |  0:00:09s\n",
      "epoch 13 | loss: 0.41572 | val_0_auc: 0.84495 |  0:00:10s\n",
      "epoch 14 | loss: 0.41322 | val_0_auc: 0.82426 |  0:00:11s\n",
      "epoch 15 | loss: 0.40621 | val_0_auc: 0.85214 |  0:00:12s\n",
      "epoch 16 | loss: 0.39215 | val_0_auc: 0.83871 |  0:00:13s\n",
      "epoch 17 | loss: 0.40335 | val_0_auc: 0.84219 |  0:00:14s\n",
      "epoch 18 | loss: 0.39627 | val_0_auc: 0.83972 |  0:00:14s\n",
      "epoch 19 | loss: 0.41365 | val_0_auc: 0.81743 |  0:00:15s\n",
      "epoch 20 | loss: 0.40288 | val_0_auc: 0.8435  |  0:00:16s\n",
      "epoch 21 | loss: 0.39352 | val_0_auc: 0.86732 |  0:00:17s\n",
      "epoch 22 | loss: 0.41772 | val_0_auc: 0.86921 |  0:00:17s\n",
      "epoch 23 | loss: 0.40887 | val_0_auc: 0.84706 |  0:00:18s\n",
      "epoch 24 | loss: 0.40915 | val_0_auc: 0.83675 |  0:00:19s\n",
      "epoch 25 | loss: 0.42429 | val_0_auc: 0.84154 |  0:00:20s\n",
      "epoch 26 | loss: 0.4265  | val_0_auc: 0.85984 |  0:00:21s\n",
      "epoch 27 | loss: 0.41617 | val_0_auc: 0.86718 |  0:00:21s\n",
      "epoch 28 | loss: 0.41629 | val_0_auc: 0.8276  |  0:00:22s\n",
      "epoch 29 | loss: 0.39176 | val_0_auc: 0.87662 |  0:00:23s\n",
      "epoch 30 | loss: 0.39575 | val_0_auc: 0.85483 |  0:00:24s\n",
      "epoch 31 | loss: 0.4045  | val_0_auc: 0.85352 |  0:00:24s\n",
      "epoch 32 | loss: 0.40057 | val_0_auc: 0.85527 |  0:00:25s\n",
      "epoch 33 | loss: 0.40746 | val_0_auc: 0.85752 |  0:00:26s\n",
      "epoch 34 | loss: 0.39532 | val_0_auc: 0.8594  |  0:00:27s\n",
      "epoch 35 | loss: 0.38789 | val_0_auc: 0.86354 |  0:00:27s\n",
      "epoch 36 | loss: 0.4026  | val_0_auc: 0.86289 |  0:00:28s\n",
      "epoch 37 | loss: 0.42418 | val_0_auc: 0.85265 |  0:00:29s\n",
      "epoch 38 | loss: 0.42241 | val_0_auc: 0.86086 |  0:00:30s\n",
      "epoch 39 | loss: 0.42013 | val_0_auc: 0.85846 |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.87662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.56005 | val_0_auc: 0.68729 |  0:00:00s\n",
      "epoch 1  | loss: 0.42188 | val_0_auc: 0.86855 |  0:00:01s\n",
      "epoch 2  | loss: 0.40916 | val_0_auc: 0.84176 |  0:00:02s\n",
      "epoch 3  | loss: 0.44835 | val_0_auc: 0.83471 |  0:00:03s\n",
      "epoch 4  | loss: 0.40037 | val_0_auc: 0.83936 |  0:00:03s\n",
      "epoch 5  | loss: 0.43521 | val_0_auc: 0.83384 |  0:00:04s\n",
      "epoch 6  | loss: 0.40452 | val_0_auc: 0.83972 |  0:00:05s\n",
      "epoch 7  | loss: 0.40879 | val_0_auc: 0.85345 |  0:00:06s\n",
      "epoch 8  | loss: 0.41459 | val_0_auc: 0.86289 |  0:00:06s\n",
      "epoch 9  | loss: 0.37909 | val_0_auc: 0.87204 |  0:00:07s\n",
      "epoch 10 | loss: 0.39786 | val_0_auc: 0.8809  |  0:00:08s\n",
      "epoch 11 | loss: 0.37852 | val_0_auc: 0.86609 |  0:00:09s\n",
      "epoch 12 | loss: 0.40004 | val_0_auc: 0.87364 |  0:00:10s\n",
      "epoch 13 | loss: 0.36386 | val_0_auc: 0.85919 |  0:00:10s\n",
      "epoch 14 | loss: 0.39759 | val_0_auc: 0.85999 |  0:00:11s\n",
      "epoch 15 | loss: 0.37087 | val_0_auc: 0.84735 |  0:00:12s\n",
      "epoch 16 | loss: 0.37982 | val_0_auc: 0.86681 |  0:00:13s\n",
      "epoch 17 | loss: 0.39729 | val_0_auc: 0.86514 |  0:00:13s\n",
      "epoch 18 | loss: 0.38665 | val_0_auc: 0.86006 |  0:00:14s\n",
      "epoch 19 | loss: 0.39271 | val_0_auc: 0.87792 |  0:00:15s\n",
      "epoch 20 | loss: 0.37223 | val_0_auc: 0.88184 |  0:00:16s\n",
      "epoch 21 | loss: 0.37997 | val_0_auc: 0.88272 |  0:00:17s\n",
      "epoch 22 | loss: 0.36844 | val_0_auc: 0.87596 |  0:00:17s\n",
      "epoch 23 | loss: 0.3689  | val_0_auc: 0.88678 |  0:00:18s\n",
      "epoch 24 | loss: 0.38027 | val_0_auc: 0.88606 |  0:00:19s\n",
      "epoch 25 | loss: 0.36276 | val_0_auc: 0.8902  |  0:00:20s\n",
      "epoch 26 | loss: 0.39128 | val_0_auc: 0.89673 |  0:00:21s\n",
      "epoch 27 | loss: 0.36735 | val_0_auc: 0.89208 |  0:00:21s\n",
      "epoch 28 | loss: 0.3607  | val_0_auc: 0.89267 |  0:00:22s\n",
      "epoch 29 | loss: 0.3751  | val_0_auc: 0.88243 |  0:00:23s\n",
      "epoch 30 | loss: 0.36441 | val_0_auc: 0.87211 |  0:00:24s\n",
      "epoch 31 | loss: 0.3723  | val_0_auc: 0.87422 |  0:00:24s\n",
      "epoch 32 | loss: 0.37272 | val_0_auc: 0.86834 |  0:00:25s\n",
      "epoch 33 | loss: 0.36531 | val_0_auc: 0.87669 |  0:00:26s\n",
      "epoch 34 | loss: 0.37024 | val_0_auc: 0.86151 |  0:00:27s\n",
      "epoch 35 | loss: 0.38705 | val_0_auc: 0.87473 |  0:00:27s\n",
      "epoch 36 | loss: 0.36545 | val_0_auc: 0.88969 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.89673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55004 | val_0_auc: 0.7146  |  0:00:00s\n",
      "epoch 1  | loss: 0.44737 | val_0_auc: 0.47524 |  0:00:01s\n",
      "epoch 2  | loss: 0.43949 | val_0_auc: 0.83384 |  0:00:02s\n",
      "epoch 3  | loss: 0.4436  | val_0_auc: 0.18359 |  0:00:02s\n",
      "epoch 4  | loss: 0.46424 | val_0_auc: 0.85359 |  0:00:03s\n",
      "epoch 5  | loss: 0.43778 | val_0_auc: 0.86783 |  0:00:04s\n",
      "epoch 6  | loss: 0.43188 | val_0_auc: 0.86885 |  0:00:05s\n",
      "epoch 7  | loss: 0.42826 | val_0_auc: 0.82702 |  0:00:06s\n",
      "epoch 8  | loss: 0.42852 | val_0_auc: 0.82977 |  0:00:06s\n",
      "epoch 9  | loss: 0.40286 | val_0_auc: 0.84386 |  0:00:07s\n",
      "epoch 10 | loss: 0.40069 | val_0_auc: 0.84023 |  0:00:08s\n",
      "epoch 11 | loss: 0.40999 | val_0_auc: 0.85272 |  0:00:09s\n",
      "epoch 12 | loss: 0.41716 | val_0_auc: 0.87291 |  0:00:09s\n",
      "epoch 13 | loss: 0.4007  | val_0_auc: 0.87306 |  0:00:10s\n",
      "epoch 14 | loss: 0.40544 | val_0_auc: 0.85752 |  0:00:11s\n",
      "epoch 15 | loss: 0.43602 | val_0_auc: 0.87771 |  0:00:12s\n",
      "epoch 16 | loss: 0.42951 | val_0_auc: 0.8992  |  0:00:12s\n",
      "epoch 17 | loss: 0.40849 | val_0_auc: 0.89499 |  0:00:13s\n",
      "epoch 18 | loss: 0.41271 | val_0_auc: 0.87654 |  0:00:14s\n",
      "epoch 19 | loss: 0.39881 | val_0_auc: 0.85316 |  0:00:15s\n",
      "epoch 20 | loss: 0.41804 | val_0_auc: 0.8504  |  0:00:16s\n",
      "epoch 21 | loss: 0.40166 | val_0_auc: 0.86158 |  0:00:17s\n",
      "epoch 22 | loss: 0.4004  | val_0_auc: 0.87262 |  0:00:17s\n",
      "epoch 23 | loss: 0.40133 | val_0_auc: 0.88105 |  0:00:18s\n",
      "epoch 24 | loss: 0.42942 | val_0_auc: 0.85882 |  0:00:19s\n",
      "epoch 25 | loss: 0.41648 | val_0_auc: 0.88598 |  0:00:20s\n",
      "epoch 26 | loss: 0.4019  | val_0_auc: 0.87175 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.8992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.786   | val_0_auc: 0.3244  |  0:00:01s\n",
      "epoch 1  | loss: 0.61205 | val_0_auc: 0.81394 |  0:00:03s\n",
      "epoch 2  | loss: 0.48017 | val_0_auc: 0.83617 |  0:00:05s\n",
      "epoch 3  | loss: 0.437   | val_0_auc: 0.6549  |  0:00:06s\n",
      "epoch 4  | loss: 0.43525 | val_0_auc: 0.8573  |  0:00:08s\n",
      "epoch 5  | loss: 0.42121 | val_0_auc: 0.82818 |  0:00:10s\n",
      "epoch 6  | loss: 0.38392 | val_0_auc: 0.82164 |  0:00:11s\n",
      "epoch 7  | loss: 0.38305 | val_0_auc: 0.77589 |  0:00:13s\n",
      "epoch 8  | loss: 0.37467 | val_0_auc: 0.82956 |  0:00:15s\n",
      "epoch 9  | loss: 0.38898 | val_0_auc: 0.85142 |  0:00:16s\n",
      "epoch 10 | loss: 0.3791  | val_0_auc: 0.8106  |  0:00:18s\n",
      "epoch 11 | loss: 0.37424 | val_0_auc: 0.86754 |  0:00:20s\n",
      "epoch 12 | loss: 0.38397 | val_0_auc: 0.84706 |  0:00:21s\n",
      "epoch 13 | loss: 0.40375 | val_0_auc: 0.86049 |  0:00:23s\n",
      "epoch 14 | loss: 0.38493 | val_0_auc: 0.8854  |  0:00:25s\n",
      "epoch 15 | loss: 0.39343 | val_0_auc: 0.85432 |  0:00:27s\n",
      "epoch 16 | loss: 0.36639 | val_0_auc: 0.85047 |  0:00:28s\n",
      "epoch 17 | loss: 0.39185 | val_0_auc: 0.85868 |  0:00:30s\n",
      "epoch 18 | loss: 0.36029 | val_0_auc: 0.86238 |  0:00:31s\n",
      "epoch 19 | loss: 0.36048 | val_0_auc: 0.85563 |  0:00:33s\n",
      "epoch 20 | loss: 0.36734 | val_0_auc: 0.85882 |  0:00:35s\n",
      "epoch 21 | loss: 0.37117 | val_0_auc: 0.88322 |  0:00:36s\n",
      "epoch 22 | loss: 0.39079 | val_0_auc: 0.86521 |  0:00:38s\n",
      "epoch 23 | loss: 0.38518 | val_0_auc: 0.8764  |  0:00:40s\n",
      "epoch 24 | loss: 0.35954 | val_0_auc: 0.87829 |  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.8854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.81087 | val_0_auc: 0.79913 |  0:00:01s\n",
      "epoch 1  | loss: 0.59949 | val_0_auc: 0.63297 |  0:00:03s\n",
      "epoch 2  | loss: 0.53465 | val_0_auc: 0.82927 |  0:00:05s\n",
      "epoch 3  | loss: 0.44442 | val_0_auc: 0.85105 |  0:00:06s\n",
      "epoch 4  | loss: 0.44307 | val_0_auc: 0.83319 |  0:00:08s\n",
      "epoch 5  | loss: 0.4681  | val_0_auc: 0.835   |  0:00:10s\n",
      "epoch 6  | loss: 0.4119  | val_0_auc: 0.74887 |  0:00:11s\n",
      "epoch 7  | loss: 0.43264 | val_0_auc: 0.84909 |  0:00:13s\n",
      "epoch 8  | loss: 0.4502  | val_0_auc: 0.82861 |  0:00:15s\n",
      "epoch 9  | loss: 0.45367 | val_0_auc: 0.81576 |  0:00:16s\n",
      "epoch 10 | loss: 0.41481 | val_0_auc: 0.83065 |  0:00:18s\n",
      "epoch 11 | loss: 0.39847 | val_0_auc: 0.80051 |  0:00:20s\n",
      "epoch 12 | loss: 0.41807 | val_0_auc: 0.84982 |  0:00:21s\n",
      "epoch 13 | loss: 0.41125 | val_0_auc: 0.85345 |  0:00:23s\n",
      "epoch 14 | loss: 0.39246 | val_0_auc: 0.82309 |  0:00:25s\n",
      "epoch 15 | loss: 0.41936 | val_0_auc: 0.85911 |  0:00:26s\n",
      "epoch 16 | loss: 0.39063 | val_0_auc: 0.86129 |  0:00:28s\n",
      "epoch 17 | loss: 0.39927 | val_0_auc: 0.87466 |  0:00:30s\n",
      "epoch 18 | loss: 0.42429 | val_0_auc: 0.84895 |  0:00:31s\n",
      "epoch 19 | loss: 0.39447 | val_0_auc: 0.87001 |  0:00:33s\n",
      "epoch 20 | loss: 0.41695 | val_0_auc: 0.84212 |  0:00:35s\n",
      "epoch 21 | loss: 0.39515 | val_0_auc: 0.8382  |  0:00:36s\n",
      "epoch 22 | loss: 0.41862 | val_0_auc: 0.85708 |  0:00:38s\n",
      "epoch 23 | loss: 0.4037  | val_0_auc: 0.86492 |  0:00:40s\n",
      "epoch 24 | loss: 0.39665 | val_0_auc: 0.87843 |  0:00:42s\n",
      "epoch 25 | loss: 0.39239 | val_0_auc: 0.88932 |  0:00:43s\n",
      "epoch 26 | loss: 0.40054 | val_0_auc: 0.88221 |  0:00:45s\n",
      "epoch 27 | loss: 0.37906 | val_0_auc: 0.86231 |  0:00:47s\n",
      "epoch 28 | loss: 0.38015 | val_0_auc: 0.87988 |  0:00:48s\n",
      "epoch 29 | loss: 0.38905 | val_0_auc: 0.86282 |  0:00:50s\n",
      "epoch 30 | loss: 0.40227 | val_0_auc: 0.87988 |  0:00:51s\n",
      "epoch 31 | loss: 0.41413 | val_0_auc: 0.85127 |  0:00:53s\n",
      "epoch 32 | loss: 0.39073 | val_0_auc: 0.87277 |  0:00:55s\n",
      "epoch 33 | loss: 0.39189 | val_0_auc: 0.8756  |  0:00:57s\n",
      "epoch 34 | loss: 0.4052  | val_0_auc: 0.8846  |  0:00:58s\n",
      "epoch 35 | loss: 0.39629 | val_0_auc: 0.88359 |  0:01:00s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.88932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.86851 | val_0_auc: 0.47785 |  0:00:01s\n",
      "epoch 1  | loss: 0.55526 | val_0_auc: 0.55396 |  0:00:03s\n",
      "epoch 2  | loss: 0.6156  | val_0_auc: 0.85664 |  0:00:05s\n",
      "epoch 3  | loss: 0.51628 | val_0_auc: 0.85766 |  0:00:07s\n",
      "epoch 4  | loss: 0.42872 | val_0_auc: 0.85185 |  0:00:09s\n",
      "epoch 5  | loss: 0.45823 | val_0_auc: 0.84321 |  0:00:10s\n",
      "epoch 6  | loss: 0.43655 | val_0_auc: 0.8549  |  0:00:12s\n",
      "epoch 7  | loss: 0.42038 | val_0_auc: 0.82556 |  0:00:14s\n",
      "epoch 8  | loss: 0.4275  | val_0_auc: 0.85054 |  0:00:15s\n",
      "epoch 9  | loss: 0.39814 | val_0_auc: 0.84779 |  0:00:17s\n",
      "epoch 10 | loss: 0.42389 | val_0_auc: 0.85171 |  0:00:19s\n",
      "epoch 11 | loss: 0.39977 | val_0_auc: 0.85694 |  0:00:20s\n",
      "epoch 12 | loss: 0.41705 | val_0_auc: 0.81423 |  0:00:22s\n",
      "epoch 13 | loss: 0.40309 | val_0_auc: 0.85621 |  0:00:24s\n",
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.85766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.79153 | val_0_auc: 0.84031 |  0:00:01s\n",
      "epoch 1  | loss: 0.63613 | val_0_auc: 0.83137 |  0:00:03s\n",
      "epoch 2  | loss: 0.47787 | val_0_auc: 0.6963  |  0:00:05s\n",
      "epoch 3  | loss: 0.46156 | val_0_auc: 0.79114 |  0:00:07s\n",
      "epoch 4  | loss: 0.43962 | val_0_auc: 0.84168 |  0:00:09s\n",
      "epoch 5  | loss: 0.37927 | val_0_auc: 0.87451 |  0:00:10s\n",
      "epoch 6  | loss: 0.38745 | val_0_auc: 0.87509 |  0:00:12s\n",
      "epoch 7  | loss: 0.37651 | val_0_auc: 0.82353 |  0:00:14s\n",
      "epoch 8  | loss: 0.39845 | val_0_auc: 0.80407 |  0:00:16s\n",
      "epoch 9  | loss: 0.39565 | val_0_auc: 0.81554 |  0:00:18s\n",
      "epoch 10 | loss: 0.42034 | val_0_auc: 0.84779 |  0:00:20s\n",
      "epoch 11 | loss: 0.39832 | val_0_auc: 0.82019 |  0:00:21s\n",
      "epoch 12 | loss: 0.39878 | val_0_auc: 0.85258 |  0:00:23s\n",
      "epoch 13 | loss: 0.3973  | val_0_auc: 0.82934 |  0:00:25s\n",
      "epoch 14 | loss: 0.37848 | val_0_auc: 0.85606 |  0:00:27s\n",
      "epoch 15 | loss: 0.40559 | val_0_auc: 0.83007 |  0:00:28s\n",
      "epoch 16 | loss: 0.37337 | val_0_auc: 0.80741 |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.87509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.85324 | val_0_auc: 0.7589  |  0:00:01s\n",
      "epoch 1  | loss: 0.59988 | val_0_auc: 0.77821 |  0:00:03s\n",
      "epoch 2  | loss: 0.59426 | val_0_auc: 0.77952 |  0:00:04s\n",
      "epoch 3  | loss: 0.44883 | val_0_auc: 0.82048 |  0:00:06s\n",
      "epoch 4  | loss: 0.45913 | val_0_auc: 0.81903 |  0:00:08s\n",
      "epoch 5  | loss: 0.42826 | val_0_auc: 0.7907  |  0:00:09s\n",
      "epoch 6  | loss: 0.44276 | val_0_auc: 0.75497 |  0:00:11s\n",
      "epoch 7  | loss: 0.44534 | val_0_auc: 0.84866 |  0:00:12s\n",
      "epoch 8  | loss: 0.43497 | val_0_auc: 0.86681 |  0:00:14s\n",
      "epoch 9  | loss: 0.38689 | val_0_auc: 0.87894 |  0:00:16s\n",
      "epoch 10 | loss: 0.43764 | val_0_auc: 0.86826 |  0:00:17s\n",
      "epoch 11 | loss: 0.41665 | val_0_auc: 0.86899 |  0:00:19s\n",
      "epoch 12 | loss: 0.39538 | val_0_auc: 0.87654 |  0:00:21s\n",
      "epoch 13 | loss: 0.43143 | val_0_auc: 0.87277 |  0:00:22s\n",
      "epoch 14 | loss: 0.43948 | val_0_auc: 0.88787 |  0:00:24s\n",
      "epoch 15 | loss: 0.41232 | val_0_auc: 0.8748  |  0:00:26s\n",
      "epoch 16 | loss: 0.434   | val_0_auc: 0.87916 |  0:00:28s\n",
      "epoch 17 | loss: 0.42093 | val_0_auc: 0.85185 |  0:00:29s\n",
      "epoch 18 | loss: 0.41859 | val_0_auc: 0.84895 |  0:00:31s\n",
      "epoch 19 | loss: 0.409   | val_0_auc: 0.86129 |  0:00:33s\n",
      "epoch 20 | loss: 0.4147  | val_0_auc: 0.86855 |  0:00:35s\n",
      "epoch 21 | loss: 0.39372 | val_0_auc: 0.87509 |  0:00:36s\n",
      "epoch 22 | loss: 0.40092 | val_0_auc: 0.88598 |  0:00:38s\n",
      "epoch 23 | loss: 0.38652 | val_0_auc: 0.88381 |  0:00:40s\n",
      "epoch 24 | loss: 0.38789 | val_0_auc: 0.85287 |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.88787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.57735 | val_0_auc: 0.23493 |  0:00:01s\n",
      "epoch 1  | loss: 0.42516 | val_0_auc: 0.71757 |  0:00:02s\n",
      "epoch 2  | loss: 0.4521  | val_0_auc: 0.79325 |  0:00:04s\n",
      "epoch 3  | loss: 0.41327 | val_0_auc: 0.85345 |  0:00:05s\n",
      "epoch 4  | loss: 0.4147  | val_0_auc: 0.84677 |  0:00:06s\n",
      "epoch 5  | loss: 0.3911  | val_0_auc: 0.84764 |  0:00:08s\n",
      "epoch 6  | loss: 0.42296 | val_0_auc: 0.83965 |  0:00:09s\n",
      "epoch 7  | loss: 0.40789 | val_0_auc: 0.85418 |  0:00:10s\n",
      "epoch 8  | loss: 0.40181 | val_0_auc: 0.8398  |  0:00:12s\n",
      "epoch 9  | loss: 0.3841  | val_0_auc: 0.84648 |  0:00:13s\n",
      "epoch 10 | loss: 0.40232 | val_0_auc: 0.85403 |  0:00:14s\n",
      "epoch 11 | loss: 0.37687 | val_0_auc: 0.8504  |  0:00:15s\n",
      "epoch 12 | loss: 0.38545 | val_0_auc: 0.85781 |  0:00:17s\n",
      "epoch 13 | loss: 0.37915 | val_0_auc: 0.86928 |  0:00:18s\n",
      "epoch 14 | loss: 0.37865 | val_0_auc: 0.85679 |  0:00:19s\n",
      "epoch 15 | loss: 0.36857 | val_0_auc: 0.85911 |  0:00:20s\n",
      "epoch 16 | loss: 0.38836 | val_0_auc: 0.85752 |  0:00:22s\n",
      "epoch 17 | loss: 0.37881 | val_0_auc: 0.88119 |  0:00:23s\n",
      "epoch 18 | loss: 0.3766  | val_0_auc: 0.87233 |  0:00:24s\n",
      "epoch 19 | loss: 0.36454 | val_0_auc: 0.8626  |  0:00:26s\n",
      "epoch 20 | loss: 0.35618 | val_0_auc: 0.87102 |  0:00:27s\n",
      "epoch 21 | loss: 0.40155 | val_0_auc: 0.88105 |  0:00:28s\n",
      "epoch 22 | loss: 0.35411 | val_0_auc: 0.88293 |  0:00:29s\n",
      "epoch 23 | loss: 0.37803 | val_0_auc: 0.88105 |  0:00:31s\n",
      "epoch 24 | loss: 0.35992 | val_0_auc: 0.87088 |  0:00:32s\n",
      "epoch 25 | loss: 0.37328 | val_0_auc: 0.88656 |  0:00:33s\n",
      "epoch 26 | loss: 0.38471 | val_0_auc: 0.86659 |  0:00:35s\n",
      "epoch 27 | loss: 0.38742 | val_0_auc: 0.8716  |  0:00:36s\n",
      "epoch 28 | loss: 0.38724 | val_0_auc: 0.88613 |  0:00:37s\n",
      "epoch 29 | loss: 0.37944 | val_0_auc: 0.89049 |  0:00:38s\n",
      "epoch 30 | loss: 0.37705 | val_0_auc: 0.89542 |  0:00:40s\n",
      "epoch 31 | loss: 0.3821  | val_0_auc: 0.88787 |  0:00:41s\n",
      "epoch 32 | loss: 0.3858  | val_0_auc: 0.89877 |  0:00:42s\n",
      "epoch 33 | loss: 0.36471 | val_0_auc: 0.8902  |  0:00:44s\n",
      "epoch 34 | loss: 0.3552  | val_0_auc: 0.88664 |  0:00:45s\n",
      "epoch 35 | loss: 0.37023 | val_0_auc: 0.89354 |  0:00:46s\n",
      "epoch 36 | loss: 0.38056 | val_0_auc: 0.8854  |  0:00:47s\n",
      "epoch 37 | loss: 0.38538 | val_0_auc: 0.88388 |  0:00:49s\n",
      "epoch 38 | loss: 0.37886 | val_0_auc: 0.89375 |  0:00:50s\n",
      "epoch 39 | loss: 0.38663 | val_0_auc: 0.90145 |  0:00:51s\n",
      "epoch 40 | loss: 0.37864 | val_0_auc: 0.8907  |  0:00:53s\n",
      "epoch 41 | loss: 0.36832 | val_0_auc: 0.89259 |  0:00:54s\n",
      "epoch 42 | loss: 0.35583 | val_0_auc: 0.89637 |  0:00:55s\n",
      "epoch 43 | loss: 0.35999 | val_0_auc: 0.88925 |  0:00:57s\n",
      "epoch 44 | loss: 0.3693  | val_0_auc: 0.88896 |  0:00:58s\n",
      "epoch 45 | loss: 0.35617 | val_0_auc: 0.89187 |  0:00:59s\n",
      "epoch 46 | loss: 0.37479 | val_0_auc: 0.88054 |  0:01:01s\n",
      "epoch 47 | loss: 0.36173 | val_0_auc: 0.87531 |  0:01:02s\n",
      "epoch 48 | loss: 0.35028 | val_0_auc: 0.88061 |  0:01:03s\n",
      "epoch 49 | loss: 0.36254 | val_0_auc: 0.88519 |  0:01:05s\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.90145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5799  | val_0_auc: 0.7963  |  0:00:01s\n",
      "epoch 1  | loss: 0.43648 | val_0_auc: 0.80915 |  0:00:02s\n",
      "epoch 2  | loss: 0.48352 | val_0_auc: 0.84916 |  0:00:03s\n",
      "epoch 3  | loss: 0.43744 | val_0_auc: 0.8008  |  0:00:05s\n",
      "epoch 4  | loss: 0.42129 | val_0_auc: 0.79216 |  0:00:06s\n",
      "epoch 5  | loss: 0.41698 | val_0_auc: 0.81772 |  0:00:07s\n",
      "epoch 6  | loss: 0.43273 | val_0_auc: 0.82455 |  0:00:08s\n",
      "epoch 7  | loss: 0.41188 | val_0_auc: 0.8321  |  0:00:10s\n",
      "epoch 8  | loss: 0.4394  | val_0_auc: 0.8305  |  0:00:11s\n",
      "epoch 9  | loss: 0.41816 | val_0_auc: 0.84081 |  0:00:12s\n",
      "epoch 10 | loss: 0.40824 | val_0_auc: 0.83747 |  0:00:14s\n",
      "epoch 11 | loss: 0.42367 | val_0_auc: 0.85679 |  0:00:15s\n",
      "epoch 12 | loss: 0.39919 | val_0_auc: 0.84633 |  0:00:16s\n",
      "epoch 13 | loss: 0.40171 | val_0_auc: 0.84154 |  0:00:17s\n",
      "epoch 14 | loss: 0.38398 | val_0_auc: 0.84662 |  0:00:19s\n",
      "epoch 15 | loss: 0.39375 | val_0_auc: 0.86151 |  0:00:20s\n",
      "epoch 16 | loss: 0.39386 | val_0_auc: 0.85577 |  0:00:21s\n",
      "epoch 17 | loss: 0.39327 | val_0_auc: 0.8711  |  0:00:22s\n",
      "epoch 18 | loss: 0.39592 | val_0_auc: 0.87357 |  0:00:24s\n",
      "epoch 19 | loss: 0.37494 | val_0_auc: 0.87538 |  0:00:25s\n",
      "epoch 20 | loss: 0.38358 | val_0_auc: 0.87117 |  0:00:26s\n",
      "epoch 21 | loss: 0.38344 | val_0_auc: 0.865   |  0:00:28s\n",
      "epoch 22 | loss: 0.37466 | val_0_auc: 0.87662 |  0:00:29s\n",
      "epoch 23 | loss: 0.40012 | val_0_auc: 0.87916 |  0:00:31s\n",
      "epoch 24 | loss: 0.39288 | val_0_auc: 0.85999 |  0:00:32s\n",
      "epoch 25 | loss: 0.4321  | val_0_auc: 0.86957 |  0:00:33s\n",
      "epoch 26 | loss: 0.40905 | val_0_auc: 0.85933 |  0:00:35s\n",
      "epoch 27 | loss: 0.40999 | val_0_auc: 0.87756 |  0:00:36s\n",
      "epoch 28 | loss: 0.38831 | val_0_auc: 0.86354 |  0:00:37s\n",
      "epoch 29 | loss: 0.38033 | val_0_auc: 0.87996 |  0:00:38s\n",
      "epoch 30 | loss: 0.39236 | val_0_auc: 0.86209 |  0:00:40s\n",
      "epoch 31 | loss: 0.38823 | val_0_auc: 0.87705 |  0:00:41s\n",
      "epoch 32 | loss: 0.39128 | val_0_auc: 0.8764  |  0:00:42s\n",
      "epoch 33 | loss: 0.39037 | val_0_auc: 0.86391 |  0:00:44s\n",
      "epoch 34 | loss: 0.38785 | val_0_auc: 0.86601 |  0:00:45s\n",
      "epoch 35 | loss: 0.39331 | val_0_auc: 0.86405 |  0:00:46s\n",
      "epoch 36 | loss: 0.40455 | val_0_auc: 0.88417 |  0:00:47s\n",
      "epoch 37 | loss: 0.3933  | val_0_auc: 0.88686 |  0:00:49s\n",
      "epoch 38 | loss: 0.40015 | val_0_auc: 0.85033 |  0:00:50s\n",
      "epoch 39 | loss: 0.39464 | val_0_auc: 0.861   |  0:00:51s\n",
      "epoch 40 | loss: 0.41353 | val_0_auc: 0.85389 |  0:00:52s\n",
      "epoch 41 | loss: 0.38437 | val_0_auc: 0.86543 |  0:00:54s\n",
      "epoch 42 | loss: 0.37728 | val_0_auc: 0.87139 |  0:00:55s\n",
      "epoch 43 | loss: 0.37496 | val_0_auc: 0.85846 |  0:00:56s\n",
      "epoch 44 | loss: 0.3802  | val_0_auc: 0.86391 |  0:00:58s\n",
      "epoch 45 | loss: 0.3801  | val_0_auc: 0.8642  |  0:00:59s\n",
      "epoch 46 | loss: 0.40081 | val_0_auc: 0.85389 |  0:01:00s\n",
      "epoch 47 | loss: 0.38424 | val_0_auc: 0.86819 |  0:01:02s\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.88686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63291 | val_0_auc: 0.85984 |  0:00:01s\n",
      "epoch 1  | loss: 0.47699 | val_0_auc: 0.76151 |  0:00:03s\n",
      "epoch 2  | loss: 0.47879 | val_0_auc: 0.83224 |  0:00:05s\n",
      "epoch 3  | loss: 0.44098 | val_0_auc: 0.85113 |  0:00:06s\n",
      "epoch 4  | loss: 0.42611 | val_0_auc: 0.86594 |  0:00:08s\n",
      "epoch 5  | loss: 0.41137 | val_0_auc: 0.87262 |  0:00:09s\n",
      "epoch 6  | loss: 0.40813 | val_0_auc: 0.86362 |  0:00:11s\n",
      "epoch 7  | loss: 0.39988 | val_0_auc: 0.87771 |  0:00:13s\n",
      "epoch 8  | loss: 0.41114 | val_0_auc: 0.87959 |  0:00:14s\n",
      "epoch 9  | loss: 0.42591 | val_0_auc: 0.87988 |  0:00:16s\n",
      "epoch 10 | loss: 0.40242 | val_0_auc: 0.86071 |  0:00:18s\n",
      "epoch 11 | loss: 0.4115  | val_0_auc: 0.86115 |  0:00:19s\n",
      "epoch 12 | loss: 0.3924  | val_0_auc: 0.85635 |  0:00:21s\n",
      "epoch 13 | loss: 0.42066 | val_0_auc: 0.85098 |  0:00:22s\n",
      "epoch 14 | loss: 0.39079 | val_0_auc: 0.85766 |  0:00:24s\n",
      "epoch 15 | loss: 0.40613 | val_0_auc: 0.85316 |  0:00:26s\n",
      "epoch 16 | loss: 0.40851 | val_0_auc: 0.83878 |  0:00:27s\n",
      "epoch 17 | loss: 0.39749 | val_0_auc: 0.79927 |  0:00:29s\n",
      "epoch 18 | loss: 0.38122 | val_0_auc: 0.82186 |  0:00:31s\n",
      "epoch 19 | loss: 0.37379 | val_0_auc: 0.85461 |  0:00:32s\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.87988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.61121 | val_0_auc: 0.4695  |  0:00:01s\n",
      "epoch 1  | loss: 0.53511 | val_0_auc: 0.70595 |  0:00:03s\n",
      "epoch 2  | loss: 0.48124 | val_0_auc: 0.79601 |  0:00:04s\n",
      "epoch 3  | loss: 0.41012 | val_0_auc: 0.83733 |  0:00:06s\n",
      "epoch 4  | loss: 0.40333 | val_0_auc: 0.82491 |  0:00:08s\n",
      "epoch 5  | loss: 0.40504 | val_0_auc: 0.85025 |  0:00:09s\n",
      "epoch 6  | loss: 0.39347 | val_0_auc: 0.78707 |  0:00:11s\n",
      "epoch 7  | loss: 0.40689 | val_0_auc: 0.81394 |  0:00:13s\n",
      "epoch 8  | loss: 0.37453 | val_0_auc: 0.8732  |  0:00:14s\n",
      "epoch 9  | loss: 0.40539 | val_0_auc: 0.83246 |  0:00:16s\n",
      "epoch 10 | loss: 0.39652 | val_0_auc: 0.81009 |  0:00:17s\n",
      "epoch 11 | loss: 0.41722 | val_0_auc: 0.85911 |  0:00:19s\n",
      "epoch 12 | loss: 0.39504 | val_0_auc: 0.85773 |  0:00:20s\n",
      "epoch 13 | loss: 0.38413 | val_0_auc: 0.81983 |  0:00:21s\n",
      "epoch 14 | loss: 0.40497 | val_0_auc: 0.83086 |  0:00:23s\n",
      "epoch 15 | loss: 0.38943 | val_0_auc: 0.84292 |  0:00:24s\n",
      "epoch 16 | loss: 0.36969 | val_0_auc: 0.8443  |  0:00:26s\n",
      "epoch 17 | loss: 0.40252 | val_0_auc: 0.86202 |  0:00:27s\n",
      "epoch 18 | loss: 0.37906 | val_0_auc: 0.87654 |  0:00:28s\n",
      "epoch 19 | loss: 0.37167 | val_0_auc: 0.87255 |  0:00:30s\n",
      "epoch 20 | loss: 0.38611 | val_0_auc: 0.84611 |  0:00:31s\n",
      "epoch 21 | loss: 0.42285 | val_0_auc: 0.85352 |  0:00:32s\n",
      "epoch 22 | loss: 0.38742 | val_0_auc: 0.87567 |  0:00:34s\n",
      "epoch 23 | loss: 0.39664 | val_0_auc: 0.88824 |  0:00:35s\n",
      "epoch 24 | loss: 0.35929 | val_0_auc: 0.87691 |  0:00:37s\n",
      "epoch 25 | loss: 0.39352 | val_0_auc: 0.8955  |  0:00:38s\n",
      "epoch 26 | loss: 0.38027 | val_0_auc: 0.87574 |  0:00:40s\n",
      "epoch 27 | loss: 0.3672  | val_0_auc: 0.88991 |  0:00:41s\n",
      "epoch 28 | loss: 0.3682  | val_0_auc: 0.89789 |  0:00:43s\n",
      "epoch 29 | loss: 0.36238 | val_0_auc: 0.88206 |  0:00:44s\n",
      "epoch 30 | loss: 0.38736 | val_0_auc: 0.89317 |  0:00:45s\n",
      "epoch 31 | loss: 0.36762 | val_0_auc: 0.88562 |  0:00:47s\n",
      "epoch 32 | loss: 0.37381 | val_0_auc: 0.88744 |  0:00:49s\n",
      "epoch 33 | loss: 0.366   | val_0_auc: 0.89542 |  0:00:50s\n",
      "epoch 34 | loss: 0.40748 | val_0_auc: 0.88199 |  0:00:52s\n",
      "epoch 35 | loss: 0.34557 | val_0_auc: 0.89637 |  0:00:53s\n",
      "epoch 36 | loss: 0.38032 | val_0_auc: 0.89521 |  0:00:55s\n",
      "epoch 37 | loss: 0.37502 | val_0_auc: 0.89049 |  0:00:56s\n",
      "epoch 38 | loss: 0.36696 | val_0_auc: 0.88918 |  0:00:58s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.89789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58265 | val_0_auc: 0.82338 |  0:00:01s\n",
      "epoch 1  | loss: 0.52093 | val_0_auc: 0.81561 |  0:00:02s\n",
      "epoch 2  | loss: 0.4749  | val_0_auc: 0.79158 |  0:00:04s\n",
      "epoch 3  | loss: 0.4805  | val_0_auc: 0.79027 |  0:00:05s\n",
      "epoch 4  | loss: 0.46892 | val_0_auc: 0.79114 |  0:00:07s\n",
      "epoch 5  | loss: 0.44007 | val_0_auc: 0.826   |  0:00:08s\n",
      "epoch 6  | loss: 0.40684 | val_0_auc: 0.82237 |  0:00:09s\n",
      "epoch 7  | loss: 0.4303  | val_0_auc: 0.78903 |  0:00:11s\n",
      "epoch 8  | loss: 0.44912 | val_0_auc: 0.80211 |  0:00:13s\n",
      "epoch 9  | loss: 0.4323  | val_0_auc: 0.83166 |  0:00:14s\n",
      "epoch 10 | loss: 0.41133 | val_0_auc: 0.82658 |  0:00:15s\n",
      "epoch 11 | loss: 0.41464 | val_0_auc: 0.80102 |  0:00:17s\n",
      "epoch 12 | loss: 0.41362 | val_0_auc: 0.83558 |  0:00:18s\n",
      "epoch 13 | loss: 0.39535 | val_0_auc: 0.85461 |  0:00:20s\n",
      "epoch 14 | loss: 0.39227 | val_0_auc: 0.83094 |  0:00:21s\n",
      "epoch 15 | loss: 0.40282 | val_0_auc: 0.81307 |  0:00:22s\n",
      "epoch 16 | loss: 0.41817 | val_0_auc: 0.82433 |  0:00:24s\n",
      "epoch 17 | loss: 0.42023 | val_0_auc: 0.8467  |  0:00:25s\n",
      "epoch 18 | loss: 0.40938 | val_0_auc: 0.85548 |  0:00:27s\n",
      "epoch 19 | loss: 0.39283 | val_0_auc: 0.86768 |  0:00:28s\n",
      "epoch 20 | loss: 0.41687 | val_0_auc: 0.87001 |  0:00:29s\n",
      "epoch 21 | loss: 0.4172  | val_0_auc: 0.85897 |  0:00:30s\n",
      "epoch 22 | loss: 0.40523 | val_0_auc: 0.87124 |  0:00:32s\n",
      "epoch 23 | loss: 0.3888  | val_0_auc: 0.86703 |  0:00:33s\n",
      "epoch 24 | loss: 0.39498 | val_0_auc: 0.86253 |  0:00:34s\n",
      "epoch 25 | loss: 0.41958 | val_0_auc: 0.88163 |  0:00:36s\n",
      "epoch 26 | loss: 0.40184 | val_0_auc: 0.87073 |  0:00:37s\n",
      "epoch 27 | loss: 0.40203 | val_0_auc: 0.85781 |  0:00:38s\n",
      "epoch 28 | loss: 0.39593 | val_0_auc: 0.84822 |  0:00:40s\n",
      "epoch 29 | loss: 0.41613 | val_0_auc: 0.88337 |  0:00:41s\n",
      "epoch 30 | loss: 0.40581 | val_0_auc: 0.88163 |  0:00:42s\n",
      "epoch 31 | loss: 0.40108 | val_0_auc: 0.87277 |  0:00:44s\n",
      "epoch 32 | loss: 0.40772 | val_0_auc: 0.89092 |  0:00:45s\n",
      "epoch 33 | loss: 0.40795 | val_0_auc: 0.87466 |  0:00:46s\n",
      "epoch 34 | loss: 0.41714 | val_0_auc: 0.8785  |  0:00:48s\n",
      "epoch 35 | loss: 0.39854 | val_0_auc: 0.87603 |  0:00:49s\n",
      "epoch 36 | loss: 0.41751 | val_0_auc: 0.87393 |  0:00:51s\n",
      "epoch 37 | loss: 0.42853 | val_0_auc: 0.87168 |  0:00:52s\n",
      "epoch 38 | loss: 0.4322  | val_0_auc: 0.86986 |  0:00:54s\n",
      "epoch 39 | loss: 0.41229 | val_0_auc: 0.83348 |  0:00:55s\n",
      "epoch 40 | loss: 0.41588 | val_0_auc: 0.87313 |  0:00:57s\n",
      "epoch 41 | loss: 0.40278 | val_0_auc: 0.90625 |  0:00:58s\n",
      "epoch 42 | loss: 0.41111 | val_0_auc: 0.89586 |  0:01:00s\n",
      "epoch 43 | loss: 0.42274 | val_0_auc: 0.88802 |  0:01:01s\n",
      "epoch 44 | loss: 0.39262 | val_0_auc: 0.87691 |  0:01:03s\n",
      "epoch 45 | loss: 0.40925 | val_0_auc: 0.87473 |  0:01:05s\n",
      "epoch 46 | loss: 0.41514 | val_0_auc: 0.88112 |  0:01:07s\n",
      "epoch 47 | loss: 0.41524 | val_0_auc: 0.86805 |  0:01:09s\n",
      "epoch 48 | loss: 0.40339 | val_0_auc: 0.88707 |  0:01:11s\n",
      "epoch 49 | loss: 0.39247 | val_0_auc: 0.88163 |  0:01:12s\n",
      "epoch 50 | loss: 0.39898 | val_0_auc: 0.91147 |  0:01:14s\n",
      "epoch 51 | loss: 0.41072 | val_0_auc: 0.91191 |  0:01:15s\n",
      "epoch 52 | loss: 0.41774 | val_0_auc: 0.87262 |  0:01:17s\n",
      "epoch 53 | loss: 0.41228 | val_0_auc: 0.87967 |  0:01:18s\n",
      "epoch 54 | loss: 0.38836 | val_0_auc: 0.88359 |  0:01:20s\n",
      "epoch 55 | loss: 0.41793 | val_0_auc: 0.86507 |  0:01:21s\n",
      "epoch 56 | loss: 0.38487 | val_0_auc: 0.86507 |  0:01:23s\n",
      "epoch 57 | loss: 0.41073 | val_0_auc: 0.84357 |  0:01:24s\n",
      "epoch 58 | loss: 0.39453 | val_0_auc: 0.87175 |  0:01:26s\n",
      "epoch 59 | loss: 0.40336 | val_0_auc: 0.87952 |  0:01:27s\n",
      "epoch 60 | loss: 0.39554 | val_0_auc: 0.88446 |  0:01:28s\n",
      "epoch 61 | loss: 0.39692 | val_0_auc: 0.88969 |  0:01:30s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.91191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.7259  | val_0_auc: 0.84379 |  0:00:01s\n",
      "epoch 1  | loss: 0.55119 | val_0_auc: 0.77357 |  0:00:02s\n",
      "epoch 2  | loss: 0.5265  | val_0_auc: 0.83558 |  0:00:04s\n",
      "epoch 3  | loss: 0.44083 | val_0_auc: 0.8443  |  0:00:05s\n",
      "epoch 4  | loss: 0.43896 | val_0_auc: 0.83733 |  0:00:07s\n",
      "epoch 5  | loss: 0.40313 | val_0_auc: 0.83486 |  0:00:08s\n",
      "epoch 6  | loss: 0.44937 | val_0_auc: 0.75018 |  0:00:10s\n",
      "epoch 7  | loss: 0.42953 | val_0_auc: 0.83224 |  0:00:11s\n",
      "epoch 8  | loss: 0.40929 | val_0_auc: 0.77117 |  0:00:13s\n",
      "epoch 9  | loss: 0.43313 | val_0_auc: 0.80537 |  0:00:14s\n",
      "epoch 10 | loss: 0.38648 | val_0_auc: 0.8451  |  0:00:16s\n",
      "epoch 11 | loss: 0.40992 | val_0_auc: 0.84139 |  0:00:18s\n",
      "epoch 12 | loss: 0.39602 | val_0_auc: 0.84459 |  0:00:19s\n",
      "epoch 13 | loss: 0.39126 | val_0_auc: 0.85563 |  0:00:21s\n",
      "epoch 14 | loss: 0.39575 | val_0_auc: 0.84938 |  0:00:23s\n",
      "epoch 15 | loss: 0.39193 | val_0_auc: 0.8671  |  0:00:25s\n",
      "epoch 16 | loss: 0.37935 | val_0_auc: 0.85962 |  0:00:27s\n",
      "epoch 17 | loss: 0.35421 | val_0_auc: 0.85127 |  0:00:29s\n",
      "epoch 18 | loss: 0.36628 | val_0_auc: 0.86173 |  0:00:31s\n",
      "epoch 19 | loss: 0.3898  | val_0_auc: 0.84227 |  0:00:33s\n",
      "epoch 20 | loss: 0.37323 | val_0_auc: 0.81503 |  0:00:35s\n",
      "epoch 21 | loss: 0.3674  | val_0_auc: 0.85832 |  0:00:37s\n",
      "epoch 22 | loss: 0.39138 | val_0_auc: 0.84633 |  0:00:39s\n",
      "epoch 23 | loss: 0.38135 | val_0_auc: 0.85556 |  0:00:41s\n",
      "epoch 24 | loss: 0.37504 | val_0_auc: 0.85948 |  0:00:42s\n",
      "epoch 25 | loss: 0.38799 | val_0_auc: 0.87502 |  0:00:44s\n",
      "epoch 26 | loss: 0.37146 | val_0_auc: 0.86449 |  0:00:46s\n",
      "epoch 27 | loss: 0.37133 | val_0_auc: 0.86667 |  0:00:48s\n",
      "epoch 28 | loss: 0.37001 | val_0_auc: 0.88497 |  0:00:49s\n",
      "epoch 29 | loss: 0.37961 | val_0_auc: 0.88344 |  0:00:51s\n",
      "epoch 30 | loss: 0.38558 | val_0_auc: 0.87495 |  0:00:53s\n",
      "epoch 31 | loss: 0.38298 | val_0_auc: 0.88097 |  0:00:55s\n",
      "epoch 32 | loss: 0.39444 | val_0_auc: 0.88199 |  0:00:57s\n",
      "epoch 33 | loss: 0.36822 | val_0_auc: 0.89099 |  0:00:59s\n",
      "epoch 34 | loss: 0.37705 | val_0_auc: 0.88439 |  0:01:01s\n",
      "epoch 35 | loss: 0.35972 | val_0_auc: 0.88511 |  0:01:03s\n",
      "epoch 36 | loss: 0.37106 | val_0_auc: 0.88569 |  0:01:05s\n",
      "epoch 37 | loss: 0.34674 | val_0_auc: 0.88831 |  0:01:06s\n",
      "epoch 38 | loss: 0.3788  | val_0_auc: 0.887   |  0:01:08s\n",
      "epoch 39 | loss: 0.36561 | val_0_auc: 0.87916 |  0:01:10s\n",
      "epoch 40 | loss: 0.36745 | val_0_auc: 0.88199 |  0:01:11s\n",
      "epoch 41 | loss: 0.3851  | val_0_auc: 0.87081 |  0:01:13s\n",
      "epoch 42 | loss: 0.36311 | val_0_auc: 0.87393 |  0:01:14s\n",
      "epoch 43 | loss: 0.3559  | val_0_auc: 0.87582 |  0:01:16s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.89099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.77972 | val_0_auc: 0.74699 |  0:00:01s\n",
      "epoch 1  | loss: 0.63215 | val_0_auc: 0.76855 |  0:00:03s\n",
      "epoch 2  | loss: 0.50311 | val_0_auc: 0.83893 |  0:00:04s\n",
      "epoch 3  | loss: 0.44141 | val_0_auc: 0.8626  |  0:00:06s\n",
      "epoch 4  | loss: 0.4157  | val_0_auc: 0.84749 |  0:00:08s\n",
      "epoch 5  | loss: 0.43911 | val_0_auc: 0.8     |  0:00:10s\n",
      "epoch 6  | loss: 0.39749 | val_0_auc: 0.82164 |  0:00:11s\n",
      "epoch 7  | loss: 0.44962 | val_0_auc: 0.83341 |  0:00:13s\n",
      "epoch 8  | loss: 0.4046  | val_0_auc: 0.84517 |  0:00:15s\n",
      "epoch 9  | loss: 0.40722 | val_0_auc: 0.83529 |  0:00:16s\n",
      "epoch 10 | loss: 0.42188 | val_0_auc: 0.84677 |  0:00:18s\n",
      "epoch 11 | loss: 0.41553 | val_0_auc: 0.8687  |  0:00:19s\n",
      "epoch 12 | loss: 0.42026 | val_0_auc: 0.85505 |  0:00:21s\n",
      "epoch 13 | loss: 0.39428 | val_0_auc: 0.83355 |  0:00:23s\n",
      "epoch 14 | loss: 0.40253 | val_0_auc: 0.84633 |  0:00:25s\n",
      "epoch 15 | loss: 0.41078 | val_0_auc: 0.85984 |  0:00:27s\n",
      "epoch 16 | loss: 0.39593 | val_0_auc: 0.86957 |  0:00:29s\n",
      "epoch 17 | loss: 0.38921 | val_0_auc: 0.87495 |  0:00:31s\n",
      "epoch 18 | loss: 0.38982 | val_0_auc: 0.87785 |  0:00:33s\n",
      "epoch 19 | loss: 0.41125 | val_0_auc: 0.89528 |  0:00:35s\n",
      "epoch 20 | loss: 0.40042 | val_0_auc: 0.87596 |  0:00:36s\n",
      "epoch 21 | loss: 0.38874 | val_0_auc: 0.8764  |  0:00:39s\n",
      "epoch 22 | loss: 0.39917 | val_0_auc: 0.85592 |  0:00:40s\n",
      "epoch 23 | loss: 0.3894  | val_0_auc: 0.85214 |  0:00:42s\n",
      "epoch 24 | loss: 0.39066 | val_0_auc: 0.87858 |  0:00:44s\n",
      "epoch 25 | loss: 0.38459 | val_0_auc: 0.88235 |  0:00:46s\n",
      "epoch 26 | loss: 0.3972  | val_0_auc: 0.87669 |  0:00:48s\n",
      "epoch 27 | loss: 0.38996 | val_0_auc: 0.88845 |  0:00:50s\n",
      "epoch 28 | loss: 0.39138 | val_0_auc: 0.88758 |  0:00:52s\n",
      "epoch 29 | loss: 0.38217 | val_0_auc: 0.87923 |  0:00:54s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.89528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82122 | val_0_auc: 0.71707 |  0:00:01s\n",
      "epoch 1  | loss: 0.57569 | val_0_auc: 0.79129 |  0:00:03s\n",
      "epoch 2  | loss: 0.53983 | val_0_auc: 0.67538 |  0:00:05s\n",
      "epoch 3  | loss: 0.47068 | val_0_auc: 0.76848 |  0:00:07s\n",
      "epoch 4  | loss: 0.46104 | val_0_auc: 0.71605 |  0:00:09s\n",
      "epoch 5  | loss: 0.4379  | val_0_auc: 0.79492 |  0:00:10s\n",
      "epoch 6  | loss: 0.4256  | val_0_auc: 0.8289  |  0:00:12s\n",
      "epoch 7  | loss: 0.43809 | val_0_auc: 0.85505 |  0:00:13s\n",
      "epoch 8  | loss: 0.46868 | val_0_auc: 0.8472  |  0:00:15s\n",
      "epoch 9  | loss: 0.41749 | val_0_auc: 0.83849 |  0:00:17s\n",
      "epoch 10 | loss: 0.42751 | val_0_auc: 0.84764 |  0:00:18s\n",
      "epoch 11 | loss: 0.40268 | val_0_auc: 0.86674 |  0:00:20s\n",
      "epoch 12 | loss: 0.41966 | val_0_auc: 0.8732  |  0:00:22s\n",
      "epoch 13 | loss: 0.44422 | val_0_auc: 0.87059 |  0:00:24s\n",
      "epoch 14 | loss: 0.38686 | val_0_auc: 0.8549  |  0:00:26s\n",
      "epoch 15 | loss: 0.41815 | val_0_auc: 0.84837 |  0:00:28s\n",
      "epoch 16 | loss: 0.41065 | val_0_auc: 0.85672 |  0:00:29s\n",
      "epoch 17 | loss: 0.39248 | val_0_auc: 0.85926 |  0:00:31s\n",
      "epoch 18 | loss: 0.39522 | val_0_auc: 0.88032 |  0:00:33s\n",
      "epoch 19 | loss: 0.40928 | val_0_auc: 0.85621 |  0:00:35s\n",
      "epoch 20 | loss: 0.39517 | val_0_auc: 0.83791 |  0:00:37s\n",
      "epoch 21 | loss: 0.39018 | val_0_auc: 0.85897 |  0:00:39s\n",
      "epoch 22 | loss: 0.39235 | val_0_auc: 0.84742 |  0:00:40s\n",
      "epoch 23 | loss: 0.39954 | val_0_auc: 0.8488  |  0:00:42s\n",
      "epoch 24 | loss: 0.38332 | val_0_auc: 0.86391 |  0:00:44s\n",
      "epoch 25 | loss: 0.38037 | val_0_auc: 0.8549  |  0:00:46s\n",
      "epoch 26 | loss: 0.41666 | val_0_auc: 0.84967 |  0:00:47s\n",
      "epoch 27 | loss: 0.4197  | val_0_auc: 0.83827 |  0:00:49s\n",
      "epoch 28 | loss: 0.40291 | val_0_auc: 0.85403 |  0:00:51s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.88032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80983 | val_0_auc: 0.8565  |  0:00:01s\n",
      "epoch 1  | loss: 0.58292 | val_0_auc: 0.79506 |  0:00:03s\n",
      "epoch 2  | loss: 0.51306 | val_0_auc: 0.80683 |  0:00:04s\n",
      "epoch 3  | loss: 0.45508 | val_0_auc: 0.83152 |  0:00:06s\n",
      "epoch 4  | loss: 0.45505 | val_0_auc: 0.8748  |  0:00:08s\n",
      "epoch 5  | loss: 0.43821 | val_0_auc: 0.80726 |  0:00:10s\n",
      "epoch 6  | loss: 0.41713 | val_0_auc: 0.82208 |  0:00:12s\n",
      "epoch 7  | loss: 0.45273 | val_0_auc: 0.80508 |  0:00:15s\n",
      "epoch 8  | loss: 0.43449 | val_0_auc: 0.82731 |  0:00:17s\n",
      "epoch 9  | loss: 0.38408 | val_0_auc: 0.82426 |  0:00:18s\n",
      "epoch 10 | loss: 0.38519 | val_0_auc: 0.83253 |  0:00:20s\n",
      "epoch 11 | loss: 0.38581 | val_0_auc: 0.84154 |  0:00:22s\n",
      "epoch 12 | loss: 0.40048 | val_0_auc: 0.85461 |  0:00:25s\n",
      "epoch 13 | loss: 0.41067 | val_0_auc: 0.86216 |  0:00:26s\n",
      "epoch 14 | loss: 0.37102 | val_0_auc: 0.85272 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.8748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.75979 | val_0_auc: 0.4716  |  0:00:02s\n",
      "epoch 1  | loss: 0.6007  | val_0_auc: 0.83442 |  0:00:04s\n",
      "epoch 2  | loss: 0.48838 | val_0_auc: 0.77269 |  0:00:05s\n",
      "epoch 3  | loss: 0.5091  | val_0_auc: 0.8382  |  0:00:07s\n",
      "epoch 4  | loss: 0.49662 | val_0_auc: 0.84909 |  0:00:09s\n",
      "epoch 5  | loss: 0.43035 | val_0_auc: 0.8276  |  0:00:11s\n",
      "epoch 6  | loss: 0.40945 | val_0_auc: 0.83137 |  0:00:13s\n",
      "epoch 7  | loss: 0.45925 | val_0_auc: 0.85243 |  0:00:15s\n",
      "epoch 8  | loss: 0.43091 | val_0_auc: 0.84967 |  0:00:17s\n",
      "epoch 9  | loss: 0.40958 | val_0_auc: 0.85621 |  0:00:19s\n",
      "epoch 10 | loss: 0.40539 | val_0_auc: 0.86369 |  0:00:20s\n",
      "epoch 11 | loss: 0.43922 | val_0_auc: 0.83588 |  0:00:22s\n",
      "epoch 12 | loss: 0.43132 | val_0_auc: 0.85781 |  0:00:24s\n",
      "epoch 13 | loss: 0.4466  | val_0_auc: 0.86216 |  0:00:26s\n",
      "epoch 14 | loss: 0.42355 | val_0_auc: 0.87574 |  0:00:28s\n",
      "epoch 15 | loss: 0.40833 | val_0_auc: 0.86885 |  0:00:30s\n",
      "epoch 16 | loss: 0.39047 | val_0_auc: 0.86202 |  0:00:32s\n",
      "epoch 17 | loss: 0.40229 | val_0_auc: 0.86391 |  0:00:33s\n",
      "epoch 18 | loss: 0.43311 | val_0_auc: 0.865   |  0:00:35s\n",
      "epoch 19 | loss: 0.41762 | val_0_auc: 0.8732  |  0:00:37s\n",
      "epoch 20 | loss: 0.40356 | val_0_auc: 0.86035 |  0:00:38s\n",
      "epoch 21 | loss: 0.40385 | val_0_auc: 0.88577 |  0:00:40s\n",
      "epoch 22 | loss: 0.40764 | val_0_auc: 0.86267 |  0:00:42s\n",
      "epoch 23 | loss: 0.41415 | val_0_auc: 0.87124 |  0:00:44s\n",
      "epoch 24 | loss: 0.41451 | val_0_auc: 0.88453 |  0:00:45s\n",
      "epoch 25 | loss: 0.40388 | val_0_auc: 0.85069 |  0:00:47s\n",
      "epoch 26 | loss: 0.3909  | val_0_auc: 0.88184 |  0:00:48s\n",
      "epoch 27 | loss: 0.38955 | val_0_auc: 0.86492 |  0:00:50s\n",
      "epoch 28 | loss: 0.40782 | val_0_auc: 0.87618 |  0:00:52s\n",
      "epoch 29 | loss: 0.39049 | val_0_auc: 0.80465 |  0:00:53s\n",
      "epoch 30 | loss: 0.40969 | val_0_auc: 0.83174 |  0:00:55s\n",
      "epoch 31 | loss: 0.41476 | val_0_auc: 0.89158 |  0:00:56s\n",
      "epoch 32 | loss: 0.4027  | val_0_auc: 0.88497 |  0:00:58s\n",
      "epoch 33 | loss: 0.41209 | val_0_auc: 0.87771 |  0:01:00s\n",
      "epoch 34 | loss: 0.40747 | val_0_auc: 0.87233 |  0:01:01s\n",
      "epoch 35 | loss: 0.39607 | val_0_auc: 0.874   |  0:01:03s\n",
      "epoch 36 | loss: 0.39248 | val_0_auc: 0.88315 |  0:01:04s\n",
      "epoch 37 | loss: 0.41995 | val_0_auc: 0.8663  |  0:01:06s\n",
      "epoch 38 | loss: 0.39146 | val_0_auc: 0.84379 |  0:01:08s\n",
      "epoch 39 | loss: 0.45299 | val_0_auc: 0.86906 |  0:01:09s\n",
      "epoch 40 | loss: 0.40183 | val_0_auc: 0.88134 |  0:01:11s\n",
      "epoch 41 | loss: 0.40929 | val_0_auc: 0.85018 |  0:01:12s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.89158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.5644  | val_0_auc: 0.79259 |  0:00:01s\n",
      "epoch 1  | loss: 0.40535 | val_0_auc: 0.72215 |  0:00:02s\n",
      "epoch 2  | loss: 0.39586 | val_0_auc: 0.82774 |  0:00:03s\n",
      "epoch 3  | loss: 0.41702 | val_0_auc: 0.79027 |  0:00:04s\n",
      "epoch 4  | loss: 0.38321 | val_0_auc: 0.84154 |  0:00:06s\n",
      "epoch 5  | loss: 0.40042 | val_0_auc: 0.83021 |  0:00:07s\n",
      "epoch 6  | loss: 0.38151 | val_0_auc: 0.85113 |  0:00:08s\n",
      "epoch 7  | loss: 0.40631 | val_0_auc: 0.86841 |  0:00:10s\n",
      "epoch 8  | loss: 0.36769 | val_0_auc: 0.78199 |  0:00:12s\n",
      "epoch 9  | loss: 0.38276 | val_0_auc: 0.84582 |  0:00:13s\n",
      "epoch 10 | loss: 0.36941 | val_0_auc: 0.73333 |  0:00:14s\n",
      "epoch 11 | loss: 0.39426 | val_0_auc: 0.82353 |  0:00:16s\n",
      "epoch 12 | loss: 0.38262 | val_0_auc: 0.81641 |  0:00:17s\n",
      "epoch 13 | loss: 0.40148 | val_0_auc: 0.80741 |  0:00:19s\n",
      "epoch 14 | loss: 0.3775  | val_0_auc: 0.86216 |  0:00:20s\n",
      "epoch 15 | loss: 0.37272 | val_0_auc: 0.87466 |  0:00:22s\n",
      "epoch 16 | loss: 0.37294 | val_0_auc: 0.85621 |  0:00:23s\n",
      "epoch 17 | loss: 0.36857 | val_0_auc: 0.87015 |  0:00:24s\n",
      "epoch 18 | loss: 0.39996 | val_0_auc: 0.84256 |  0:00:26s\n",
      "epoch 19 | loss: 0.37289 | val_0_auc: 0.85708 |  0:00:27s\n",
      "epoch 20 | loss: 0.36227 | val_0_auc: 0.86797 |  0:00:29s\n",
      "epoch 21 | loss: 0.37982 | val_0_auc: 0.8854  |  0:00:30s\n",
      "epoch 22 | loss: 0.37105 | val_0_auc: 0.85824 |  0:00:32s\n",
      "epoch 23 | loss: 0.36165 | val_0_auc: 0.86347 |  0:00:33s\n",
      "epoch 24 | loss: 0.37168 | val_0_auc: 0.88903 |  0:00:35s\n",
      "epoch 25 | loss: 0.37388 | val_0_auc: 0.86049 |  0:00:36s\n",
      "epoch 26 | loss: 0.3689  | val_0_auc: 0.87683 |  0:00:38s\n",
      "epoch 27 | loss: 0.38861 | val_0_auc: 0.87574 |  0:00:39s\n",
      "epoch 28 | loss: 0.35959 | val_0_auc: 0.86696 |  0:00:41s\n",
      "epoch 29 | loss: 0.35139 | val_0_auc: 0.87342 |  0:00:42s\n",
      "epoch 30 | loss: 0.35499 | val_0_auc: 0.87393 |  0:00:44s\n",
      "epoch 31 | loss: 0.35369 | val_0_auc: 0.8663  |  0:00:45s\n",
      "epoch 32 | loss: 0.36385 | val_0_auc: 0.8785  |  0:00:47s\n",
      "epoch 33 | loss: 0.34557 | val_0_auc: 0.87342 |  0:00:48s\n",
      "epoch 34 | loss: 0.35745 | val_0_auc: 0.88046 |  0:00:50s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.88903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.60152 | val_0_auc: 0.79782 |  0:00:01s\n",
      "epoch 1  | loss: 0.4112  | val_0_auc: 0.84749 |  0:00:02s\n",
      "epoch 2  | loss: 0.40317 | val_0_auc: 0.87872 |  0:00:04s\n",
      "epoch 3  | loss: 0.42449 | val_0_auc: 0.85156 |  0:00:05s\n",
      "epoch 4  | loss: 0.38053 | val_0_auc: 0.84662 |  0:00:07s\n",
      "epoch 5  | loss: 0.41384 | val_0_auc: 0.84895 |  0:00:08s\n",
      "epoch 6  | loss: 0.41036 | val_0_auc: 0.84473 |  0:00:10s\n",
      "epoch 7  | loss: 0.44212 | val_0_auc: 0.85185 |  0:00:11s\n",
      "epoch 8  | loss: 0.38032 | val_0_auc: 0.8642  |  0:00:12s\n",
      "epoch 9  | loss: 0.40833 | val_0_auc: 0.85781 |  0:00:14s\n",
      "epoch 10 | loss: 0.40028 | val_0_auc: 0.8488  |  0:00:15s\n",
      "epoch 11 | loss: 0.40632 | val_0_auc: 0.85033 |  0:00:17s\n",
      "epoch 12 | loss: 0.40381 | val_0_auc: 0.85221 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.87872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58688 | val_0_auc: 0.75004 |  0:00:01s\n",
      "epoch 1  | loss: 0.47612 | val_0_auc: 0.77981 |  0:00:02s\n",
      "epoch 2  | loss: 0.41692 | val_0_auc: 0.80951 |  0:00:04s\n",
      "epoch 3  | loss: 0.4512  | val_0_auc: 0.80908 |  0:00:05s\n",
      "epoch 4  | loss: 0.42295 | val_0_auc: 0.78221 |  0:00:07s\n",
      "epoch 5  | loss: 0.4298  | val_0_auc: 0.79739 |  0:00:08s\n",
      "epoch 6  | loss: 0.43385 | val_0_auc: 0.83224 |  0:00:09s\n",
      "epoch 7  | loss: 0.41618 | val_0_auc: 0.82905 |  0:00:11s\n",
      "epoch 8  | loss: 0.39157 | val_0_auc: 0.77487 |  0:00:12s\n",
      "epoch 9  | loss: 0.40956 | val_0_auc: 0.78068 |  0:00:14s\n",
      "epoch 10 | loss: 0.40952 | val_0_auc: 0.81191 |  0:00:15s\n",
      "epoch 11 | loss: 0.40069 | val_0_auc: 0.82077 |  0:00:17s\n",
      "epoch 12 | loss: 0.40468 | val_0_auc: 0.8199  |  0:00:18s\n",
      "epoch 13 | loss: 0.4092  | val_0_auc: 0.83885 |  0:00:19s\n",
      "epoch 14 | loss: 0.39446 | val_0_auc: 0.8467  |  0:00:21s\n",
      "epoch 15 | loss: 0.40835 | val_0_auc: 0.84953 |  0:00:22s\n",
      "epoch 16 | loss: 0.41738 | val_0_auc: 0.87582 |  0:00:24s\n",
      "epoch 17 | loss: 0.39178 | val_0_auc: 0.86267 |  0:00:25s\n",
      "epoch 18 | loss: 0.40393 | val_0_auc: 0.87771 |  0:00:26s\n",
      "epoch 19 | loss: 0.3795  | val_0_auc: 0.85759 |  0:00:28s\n",
      "epoch 20 | loss: 0.39421 | val_0_auc: 0.86783 |  0:00:29s\n",
      "epoch 21 | loss: 0.42033 | val_0_auc: 0.887   |  0:00:30s\n",
      "epoch 22 | loss: 0.42032 | val_0_auc: 0.87466 |  0:00:31s\n",
      "epoch 23 | loss: 0.36473 | val_0_auc: 0.88032 |  0:00:33s\n",
      "epoch 24 | loss: 0.43608 | val_0_auc: 0.87778 |  0:00:34s\n",
      "epoch 25 | loss: 0.40349 | val_0_auc: 0.88482 |  0:00:35s\n",
      "epoch 26 | loss: 0.38268 | val_0_auc: 0.86986 |  0:00:36s\n",
      "epoch 27 | loss: 0.37321 | val_0_auc: 0.8825  |  0:00:37s\n",
      "epoch 28 | loss: 0.3784  | val_0_auc: 0.86892 |  0:00:39s\n",
      "epoch 29 | loss: 0.37143 | val_0_auc: 0.87262 |  0:00:40s\n",
      "epoch 30 | loss: 0.38868 | val_0_auc: 0.8687  |  0:00:41s\n",
      "epoch 31 | loss: 0.37855 | val_0_auc: 0.87357 |  0:00:42s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.58555 | val_0_auc: 0.79492 |  0:00:01s\n",
      "epoch 1  | loss: 0.47687 | val_0_auc: 0.82629 |  0:00:02s\n",
      "epoch 2  | loss: 0.42681 | val_0_auc: 0.83689 |  0:00:03s\n",
      "epoch 3  | loss: 0.44701 | val_0_auc: 0.80276 |  0:00:04s\n",
      "epoch 4  | loss: 0.40757 | val_0_auc: 0.82861 |  0:00:05s\n",
      "epoch 5  | loss: 0.4049  | val_0_auc: 0.86347 |  0:00:06s\n",
      "epoch 6  | loss: 0.40776 | val_0_auc: 0.83834 |  0:00:08s\n",
      "epoch 7  | loss: 0.41589 | val_0_auc: 0.83689 |  0:00:09s\n",
      "epoch 8  | loss: 0.42156 | val_0_auc: 0.84895 |  0:00:10s\n",
      "epoch 9  | loss: 0.40364 | val_0_auc: 0.83195 |  0:00:11s\n",
      "epoch 10 | loss: 0.39194 | val_0_auc: 0.85025 |  0:00:13s\n",
      "epoch 11 | loss: 0.43186 | val_0_auc: 0.86841 |  0:00:14s\n",
      "epoch 12 | loss: 0.41246 | val_0_auc: 0.87916 |  0:00:15s\n",
      "epoch 13 | loss: 0.3973  | val_0_auc: 0.84706 |  0:00:16s\n",
      "epoch 14 | loss: 0.40086 | val_0_auc: 0.85084 |  0:00:17s\n",
      "epoch 15 | loss: 0.37735 | val_0_auc: 0.85374 |  0:00:19s\n",
      "epoch 16 | loss: 0.38443 | val_0_auc: 0.84953 |  0:00:20s\n",
      "epoch 17 | loss: 0.38848 | val_0_auc: 0.82731 |  0:00:21s\n",
      "epoch 18 | loss: 0.38241 | val_0_auc: 0.86877 |  0:00:22s\n",
      "epoch 19 | loss: 0.36301 | val_0_auc: 0.86885 |  0:00:23s\n",
      "epoch 20 | loss: 0.38621 | val_0_auc: 0.87633 |  0:00:25s\n",
      "epoch 21 | loss: 0.37788 | val_0_auc: 0.87858 |  0:00:26s\n",
      "epoch 22 | loss: 0.39487 | val_0_auc: 0.85679 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.87916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.59037 | val_0_auc: 0.81256 |  0:00:01s\n",
      "epoch 1  | loss: 0.45    | val_0_auc: 0.78359 |  0:00:02s\n",
      "epoch 2  | loss: 0.45902 | val_0_auc: 0.79884 |  0:00:03s\n",
      "epoch 3  | loss: 0.45984 | val_0_auc: 0.78155 |  0:00:04s\n",
      "epoch 4  | loss: 0.42604 | val_0_auc: 0.84227 |  0:00:06s\n",
      "epoch 5  | loss: 0.43134 | val_0_auc: 0.84212 |  0:00:07s\n",
      "epoch 6  | loss: 0.44415 | val_0_auc: 0.84691 |  0:00:08s\n",
      "epoch 7  | loss: 0.44433 | val_0_auc: 0.85359 |  0:00:10s\n",
      "epoch 8  | loss: 0.42687 | val_0_auc: 0.85069 |  0:00:11s\n",
      "epoch 9  | loss: 0.4278  | val_0_auc: 0.84517 |  0:00:13s\n",
      "epoch 10 | loss: 0.40831 | val_0_auc: 0.84415 |  0:00:15s\n",
      "epoch 11 | loss: 0.41415 | val_0_auc: 0.84503 |  0:00:16s\n",
      "epoch 12 | loss: 0.40798 | val_0_auc: 0.84125 |  0:00:17s\n",
      "epoch 13 | loss: 0.41351 | val_0_auc: 0.81983 |  0:00:19s\n",
      "epoch 14 | loss: 0.41568 | val_0_auc: 0.84793 |  0:00:20s\n",
      "epoch 15 | loss: 0.41266 | val_0_auc: 0.84357 |  0:00:22s\n",
      "epoch 16 | loss: 0.41986 | val_0_auc: 0.8581  |  0:00:24s\n",
      "epoch 17 | loss: 0.38573 | val_0_auc: 0.86202 |  0:00:25s\n",
      "epoch 18 | loss: 0.41794 | val_0_auc: 0.86914 |  0:00:27s\n",
      "epoch 19 | loss: 0.41501 | val_0_auc: 0.8626  |  0:00:28s\n",
      "epoch 20 | loss: 0.40152 | val_0_auc: 0.87466 |  0:00:30s\n",
      "epoch 21 | loss: 0.38522 | val_0_auc: 0.87335 |  0:00:31s\n",
      "epoch 22 | loss: 0.41323 | val_0_auc: 0.8801  |  0:00:33s\n",
      "epoch 23 | loss: 0.38675 | val_0_auc: 0.86841 |  0:00:34s\n",
      "epoch 24 | loss: 0.39831 | val_0_auc: 0.87654 |  0:00:36s\n",
      "epoch 25 | loss: 0.40697 | val_0_auc: 0.86144 |  0:00:37s\n",
      "epoch 26 | loss: 0.40128 | val_0_auc: 0.86899 |  0:00:39s\n",
      "epoch 27 | loss: 0.40002 | val_0_auc: 0.86594 |  0:00:41s\n",
      "epoch 28 | loss: 0.42076 | val_0_auc: 0.85955 |  0:00:42s\n",
      "epoch 29 | loss: 0.41066 | val_0_auc: 0.85396 |  0:00:43s\n",
      "epoch 30 | loss: 0.41944 | val_0_auc: 0.87073 |  0:00:45s\n",
      "epoch 31 | loss: 0.38705 | val_0_auc: 0.87633 |  0:00:46s\n",
      "epoch 32 | loss: 0.41986 | val_0_auc: 0.87843 |  0:00:48s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92718 | val_0_auc: 0.79375 |  0:00:03s\n",
      "epoch 1  | loss: 0.61453 | val_0_auc: 0.84386 |  0:00:06s\n",
      "epoch 2  | loss: 0.46525 | val_0_auc: 0.85505 |  0:00:08s\n",
      "epoch 3  | loss: 0.43818 | val_0_auc: 0.86362 |  0:00:11s\n",
      "epoch 4  | loss: 0.42953 | val_0_auc: 0.8841  |  0:00:14s\n",
      "epoch 5  | loss: 0.43017 | val_0_auc: 0.81264 |  0:00:16s\n",
      "epoch 6  | loss: 0.435   | val_0_auc: 0.84372 |  0:00:19s\n",
      "epoch 7  | loss: 0.41261 | val_0_auc: 0.85171 |  0:00:21s\n",
      "epoch 8  | loss: 0.39821 | val_0_auc: 0.8626  |  0:00:24s\n",
      "epoch 9  | loss: 0.42154 | val_0_auc: 0.84967 |  0:00:26s\n",
      "epoch 10 | loss: 0.39542 | val_0_auc: 0.87451 |  0:00:28s\n",
      "epoch 11 | loss: 0.42646 | val_0_auc: 0.85824 |  0:00:31s\n",
      "epoch 12 | loss: 0.39553 | val_0_auc: 0.85316 |  0:00:34s\n",
      "epoch 13 | loss: 0.41685 | val_0_auc: 0.85258 |  0:00:36s\n",
      "epoch 14 | loss: 0.42016 | val_0_auc: 0.8687  |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.8841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for TabNet: {'n_steps': 7, 'n_d': 32, 'n_a': 32, 'lambda_sparse': 0.001, 'gamma': 1.0}\n",
      "Best f1 score for TabNet during training:  0.8321501321224248\n"
     ]
    }
   ],
   "source": [
    "# 3. TabNet\n",
    "\n",
    "# hyperparameter Optimization\n",
    "\n",
    "tabnet_params = {\n",
    "    'n_d': [8, 16, 32],\n",
    "    'n_a': [8, 16, 32],\n",
    "    'n_steps': [3, 5, 7],\n",
    "    'gamma': [1.0, 1.3, 1.8],\n",
    "    'lambda_sparse': [0.001, 0.005, 0.01],\n",
    "}\n",
    "\n",
    "search_tabnet = RandomizedSearchCV(\n",
    "    TabNetClassifier(),\n",
    "    param_distributions=tabnet_params,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "# TabNet Training\n",
    "search_tabnet.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    eval_set=[(X_test_scaled, y_test)],\n",
    "    max_epochs=100,\n",
    "    patience=10,\n",
    "    batch_size=20\n",
    ")\n",
    "best_params_tabnet = search_tabnet.best_params_\n",
    "print(\"Best Parameters for TabNet:\", best_params_tabnet)\n",
    "print(\"Best f1 score for TabNet during training: \", search_tabnet.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37fb64a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for TabNet:\n",
      "Accuracy: 0.7469879518072289\n",
      "Precision: 0.672566371681416\n",
      "Recall: 0.9382716049382716\n",
      "F1 Score: 0.7835051546391752\n",
      "F2 Score: 0.8695652173913043\n",
      "AUC: 0.8840958605664487\n"
     ]
    }
   ],
   "source": [
    "# TabNet testing\n",
    "best_tabnet_model = search_tabnet.best_estimator_\n",
    "y_pred_tabnet = best_tabnet_model.predict(X_test_scaled)\n",
    "\n",
    "# TabNet performance Evaluation\n",
    "print(\"\\nEvaluation Metrics for TabNet:\")\n",
    "accuracy = accuracy_score(y_test, y_pred_tabnet)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred_tabnet)\n",
    "print(\"Precision:\", precision)\n",
    "recall = recall_score(y_test, y_pred_tabnet)\n",
    "print(\"Recall:\", recall)\n",
    "f1 = f1_score(y_test, y_pred_tabnet)\n",
    "print(\"F1 Score:\", f1)\n",
    "f_beta = fbeta_score(y_test, y_pred_tabnet, beta=2)\n",
    "print(\"F2 Score:\", f_beta)\n",
    "auc = roc_auc_score(y_test, best_tabnet_model.predict_proba(X_test_scaled)[:, 1])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c434a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "#Model prediction and Local attention weights - Interpretability\n",
    "prediction =  best_tabnet_model.predict(instance_to_explain)[0]\n",
    "print(f\"Model Prediction: {prediction}\")\n",
    "attention_masks_tuple = best_tabnet_model.explain(instance_to_explain)\n",
    "attention_masks_array, _ = attention_masks_tuple\n",
    "attention_weights = attention_masks_array[0]\n",
    "sorted_indices = np.argsort(attention_weights)[::-1]\n",
    "sorted_feature = np.array(feature_names)[sorted_indices]\n",
    "sorted_attention_weights = attention_weights[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70b0bdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising feature relevance by TabNet\n",
    "sorted_features = [feature_names[idx] for idx in sorted_indices]\n",
    "sorted_weights = [attention_weights[idx] for idx in sorted_indices]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_importances, color='lightgreen')\n",
    "plt.gca().tick_params( labelsize=18)\n",
    "plt.xlabel('Attention Weight', fontsize=18)\n",
    "plt.title('Ranked feature relevance for TabNet', fontsize=20)\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "983f7215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters for MLP: {'activation': 'relu', 'alpha': 6.469897343583279e-05, 'beta_1': 0.88, 'beta_2': 0.999, 'early_stopping': True, 'epsilon': 1e-09, 'hidden_layer_sizes': (128, 256, 512, 1024), 'learning_rate_init': 0.0007879746966350879, 'max_iter': 2494, 'n_iter_no_change': 148, 'validation_fraction': 0.3238996921063466}\n",
      "Best f1 score for rectifier network during training:  0.8211744617624511\n"
     ]
    }
   ],
   "source": [
    "# 4. Rectifier network\n",
    "\n",
    "# Hyperparameter optimization\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(8, 16), (16, 32), (8, 16, 32), (16, 32, 64), (32, 64, 128), (64, 128, 256),\n",
    "    (32, 64, 128, 256), (64, 128, 256, 512), (128, 256, 512, 1024), (8, 16, 32, 64, 128), (16, 32, 64, 128, 256)],\n",
    "    'max_iter': randint(1500, 3500),\n",
    "    'early_stopping': [True],\n",
    "    'n_iter_no_change': randint(100, 150),\n",
    "    'validation_fraction': uniform(0.15, 0.25),\n",
    "    'activation': ['relu'],\n",
    "    'learning_rate_init': uniform(1e-5, 1e-3), \n",
    "    'alpha': uniform(1e-6, 1e-4),\n",
    "    'beta_1': [0.9, 0.95, 0.85, 0.88],\n",
    "    'beta_2': [0.999, 0.9999, 0.9995, 0.9999],\n",
    "    'epsilon': [1e-8, 1e-9],\n",
    "}\n",
    "\n",
    "search_mlp = RandomizedSearchCV(\n",
    "    MLPClassifier(random_state=random_state),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "# Rectifier network training\n",
    "search_mlp.fit(X_train_scaled, y_train)\n",
    "best_params_mlp = search_mlp.best_params_\n",
    "print(\"Best Parameters for MLP:\", best_params_mlp)\n",
    "print(\"Best f1 score for rectifier network during training: \",  search_mlp.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5846d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for Rectifier Network:\n",
      "Accuracy: 0.8192771084337349\n",
      "Precision: 0.7931034482758621\n",
      "Recall: 0.8518518518518519\n",
      "F1 Score: 0.6558704453441295\n",
      "F2 Score: 0.8394160583941606\n",
      "AUC: 0.8640522875816994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de_de\\anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rectifier network Testing\n",
    "best_mlp_model =search_mlp.best_estimator_\n",
    "y_pred_mlp =best_mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Rectifier network Performance Evaluation\n",
    "print(\"\\nEvaluation Metrics for Rectifier Network:\")\n",
    "accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "precision = precision_score(y_test, y_pred_mlp)\n",
    "print(\"Precision:\", precision)\n",
    "recall= recall_score(y_test, y_pred_mlp)\n",
    "print(\"Recall:\", recall)\n",
    "f1= f1_score(y_test, best_mlp_model.predict(X_test))\n",
    "print(\"F1 Score:\", f1)\n",
    "f_beta = fbeta_score(y_test, y_pred_mlp, beta=2)\n",
    "print(\"F2 Score:\", f_beta)\n",
    "auc = roc_auc_score(y_test, best_mlp_model.predict_proba(X_test_scaled)[:, 1])\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4544eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed fwd weights:\n",
    "def mlp_relu_interpretation(model, x):\n",
    "    w_list, b_list = model.coefs_, model.intercepts_\n",
    "\n",
    "    layers = range(len(w_list))\n",
    "    layer_j = np.copy(x)\n",
    "    activation_pattern = []\n",
    "    for j in layers:\n",
    "        if j == len(w_list) - 1:\n",
    "            continue\n",
    "        layer_j = layer_j @ w_list[j] + b_list[j]\n",
    "        layer_j[layer_j <= 0] = 0\n",
    "        activation_pattern.extend(np.where(layer_j > 0))\n",
    "\n",
    "    for j in layers:\n",
    "        if j == 0:\n",
    "            feature_weights_layer = w_list[j][:, activation_pattern[j]]\n",
    "            intercepts_layer = b_list[j][activation_pattern[j]]\n",
    "        elif 0 < j < len(w_list) - 1:\n",
    "            layer_j_w_active_input = w_list[j][activation_pattern[j-1], :]\n",
    "            layer_j_w_active_output = layer_j_w_active_input[:, activation_pattern[j]]\n",
    "            feature_weights_layer = feature_weights_layer @ layer_j_w_active_output\n",
    "            intercepts_layer = intercepts_layer @ layer_j_w_active_output + b_list[j][activation_pattern[j]]\n",
    "        elif j == len(w_list) - 1:\n",
    "            layer_j_w_active_input = w_list[j][activation_pattern[j-1], :]\n",
    "            feature_weights_layer = feature_weights_layer @ layer_j_w_active_input\n",
    "            intercepts_layer = intercepts_layer @ layer_j_w_active_input + b_list[j]\n",
    "\n",
    "    return feature_weights_layer, intercepts_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dd736a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Model prediction and  feed fwd weights(Local linear models) extraction- Interpretability\n",
    "prediction = best_mlp_model.predict(instance_to_explain)[0]\n",
    "print(f\"Model Prediction: {prediction}\")\n",
    "feature_weights, intercepts = mlp_relu_interpretation(best_mlp_model, instance_to_explain)\n",
    "feature_weights_tuples = [(feature_index, weight) for feature_index, weight in enumerate(feature_weights.flatten())]\n",
    "sorted_feature_weights = sorted(feature_weights_tuples, key=lambda x: abs(x[1]), reverse=True)\n",
    "feature_index_to_name = {i: name for i, name in enumerate(feature_names)}\n",
    "sorted_feature_names = [feature_index_to_name.get(index, f'Unknown Feature {index}') for index, _ in sorted_feature_weights]\n",
    "absolute_weights = [abs(weight) for _, weight in sorted_feature_weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44596afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation feature relevance by rectifier network\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_feature_names, absolute_weights, color='lightpink')  \n",
    "plt.gca().tick_params(labelsize=18) \n",
    "plt.xlabel('Feature Weight (Absolute)', fontsize=18)  \n",
    "plt.title('Ranked Features Relevance by Rectifier Network (Absolute Weights)', fontsize=20)  \n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f487f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
